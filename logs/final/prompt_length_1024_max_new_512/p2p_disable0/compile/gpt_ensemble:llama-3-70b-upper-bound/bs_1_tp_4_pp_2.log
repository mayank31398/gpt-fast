W1201 10:44:38.125000 414228 site-packages/torch/distributed/run.py:793] 
W1201 10:44:38.125000 414228 site-packages/torch/distributed/run.py:793] *****************************************
W1201 10:44:38.125000 414228 site-packages/torch/distributed/run.py:793] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W1201 10:44:38.125000 414228 site-packages/torch/distributed/run.py:793] *****************************************
Traceback (most recent call last):
  File "/home/charlie/skip-residual/gpt-fast/benchmark.py", line 14, in <module>
    import torch._dynamo.config
  File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/__init__.py", line 3, in <module>
    from . import convert_frame, eval_frame, resume_execution
  File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 56, in <module>
    from . import config, exc, trace_rules
  File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/trace_rules.py", line 46, in <module>
    from .variables import (
  File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/variables/__init__.py", line 2, in <module>
    from .builtin import BuiltinVariable
  File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/variables/builtin.py", line 53, in <module>
    from .ctx_manager import EventVariable, StreamVariable
  File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/variables/ctx_manager.py", line 22, in <module>
    from .functions import (
  File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/variables/functions.py", line 43, in <module>
    from torch.distributed._composable.fsdp import _fsdp_param_group
  File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/distributed/_composable/__init__.py", line 3, in <module>
    from .fully_shard import fully_shard
  File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/distributed/_composable/fully_shard.py", line 10, in <module>
    from torch.distributed.fsdp._common_utils import _FSDPState
  File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/distributed/fsdp/__init__.py", line 1, in <module>
    from ._flat_param import FlatParameter as FlatParameter
  File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/distributed/fsdp/_flat_param.py", line 47, in <module>
    from ._fsdp_extensions import (
  File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/distributed/fsdp/_fsdp_extensions.py", line 6, in <module>
    from torch.distributed._shard.sharded_tensor.api import ShardedTensor
  File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/distributed/_shard/__init__.py", line 1, in <module>
    from .api import _shard_tensor, load_with_process_group, shard_module, shard_parameter
  File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/distributed/_shard/api.py", line 9, in <module>
    from torch.distributed._shard.sharded_tensor import ShardedTensor
  File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/distributed/_shard/sharded_tensor/__init__.py", line 8, in <module>
    from .api import (
  File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/distributed/_shard/sharded_tensor/api.py", line 31, in <module>
    from .reshard import reshard_local_shard, reshuffle_local_shard
  File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/distributed/_shard/sharded_tensor/reshard.py", line 14, in <module>
    from torch.distributed.nn.functional import all_to_all, all_to_all_single
  File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/distributed/nn/__init__.py", line 7, in <module>
    from .api.remote_module import RemoteModule
  File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/distributed/nn/api/remote_module.py", line 26, in <module>
    from torch.distributed.nn.jit import instantiator
  File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/distributed/nn/jit/instantiator.py", line 20, in <module>
    _TEMP_DIR = tempfile.TemporaryDirectory()
  File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/tempfile.py", line 835, in __init__
    self.name = mkdtemp(suffix, prefix, dir)
  File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/tempfile.py", line 384, in mkdtemp
    _os.mkdir(file, 0o700)
OSError: [Errno 28] No space left on device: '/tmp/tmpbgx0hqa3'
Traceback (most recent call last):
  File "/home/charlie/skip-residual/gpt-fast/benchmark.py", line 14, in <module>
    import torch._dynamo.config
  File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/__init__.py", line 3, in <module>
    from . import convert_frame, eval_frame, resume_execution
  File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 56, in <module>
    from . import config, exc, trace_rules
  File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/trace_rules.py", line 46, in <module>
    from .variables import (
  File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/variables/__init__.py", line 2, in <module>
    from .builtin import BuiltinVariable
  File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/variables/builtin.py", line 53, in <module>
    from .ctx_manager import EventVariable, StreamVariable
  File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/variables/ctx_manager.py", line 22, in <module>
    from .functions import (
  File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/variables/functions.py", line 43, in <module>
    from torch.distributed._composable.fsdp import _fsdp_param_group
  File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/distributed/_composable/__init__.py", line 3, in <module>
    from .fully_shard import fully_shard
  File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/distributed/_composable/fully_shard.py", line 10, in <module>
    from torch.distributed.fsdp._common_utils import _FSDPState
  File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/distributed/fsdp/__init__.py", line 1, in <module>
    from ._flat_param import FlatParameter as FlatParameter
  File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/distributed/fsdp/_flat_param.py", line 47, in <module>
    from ._fsdp_extensions import (
  File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/distributed/fsdp/_fsdp_extensions.py", line 6, in <module>
    from torch.distributed._shard.sharded_tensor.api import ShardedTensor
  File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/distributed/_shard/__init__.py", line 1, in <module>
    from .api import _shard_tensor, load_with_process_group, shard_module, shard_parameter
  File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/distributed/_shard/api.py", line 9, in <module>
    from torch.distributed._shard.sharded_tensor import ShardedTensor
  File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/distributed/_shard/sharded_tensor/__init__.py", line 8, in <module>
    from .api import (
  File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/distributed/_shard/sharded_tensor/api.py", line 31, in <module>
    from .reshard import reshard_local_shard, reshuffle_local_shard
  File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/distributed/_shard/sharded_tensor/reshard.py", line 14, in <module>
    from torch.distributed.nn.functional import all_to_all, all_to_all_single
  File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/distributed/nn/__init__.py", line 7, in <module>
    from .api.remote_module import RemoteModule
  File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/distributed/nn/api/remote_module.py", line 26, in <module>
    from torch.distributed.nn.jit import instantiator
  File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/distributed/nn/jit/instantiator.py", line 20, in <module>
    _TEMP_DIR = tempfile.TemporaryDirectory()
  File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/tempfile.py", line 835, in __init__
    self.name = mkdtemp(suffix, prefix, dir)
  File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/tempfile.py", line 384, in mkdtemp
    _os.mkdir(file, 0o700)
OSError: [Errno 28] No space left on device: '/tmp/tmp4cbasoyq'
W1201 10:44:40.689000 414228 site-packages/torch/distributed/elastic/multiprocessing/api.py:897] Sending process 414298 closing signal SIGTERM
W1201 10:44:40.690000 414228 site-packages/torch/distributed/elastic/multiprocessing/api.py:897] Sending process 414299 closing signal SIGTERM
W1201 10:44:40.690000 414228 site-packages/torch/distributed/elastic/multiprocessing/api.py:897] Sending process 414300 closing signal SIGTERM
W1201 10:44:40.690000 414228 site-packages/torch/distributed/elastic/multiprocessing/api.py:897] Sending process 414302 closing signal SIGTERM
W1201 10:44:40.690000 414228 site-packages/torch/distributed/elastic/multiprocessing/api.py:897] Sending process 414303 closing signal SIGTERM
W1201 10:44:40.690000 414228 site-packages/torch/distributed/elastic/multiprocessing/api.py:897] Sending process 414304 closing signal SIGTERM
E1201 10:44:40.835000 414228 site-packages/torch/distributed/elastic/multiprocessing/api.py:869] failed (exitcode: 1) local_rank: 0 (pid: 414297) of binary: /home/charlie/anaconda3/envs/gpt-fast/bin/python
Traceback (most recent call last):
  File "/home/charlie/anaconda3/envs/gpt-fast/bin/torchrun", line 8, in <module>
    sys.exit(main())
  File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 355, in wrapper
    return f(*args, **kwargs)
  File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/distributed/run.py", line 919, in main
    run(args)
  File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/distributed/run.py", line 910, in run
    elastic_launch(
  File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 138, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 269, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
benchmark.py FAILED
------------------------------------------------------------
Failures:
[1]:
  time      : 2024-12-01_10:44:40
  host      : mk-xii-22.cloud.together.ai
  rank      : 4 (local_rank: 4)
  exitcode  : 1 (pid: 414301)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2024-12-01_10:44:40
  host      : mk-xii-22.cloud.together.ai
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 414297)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
