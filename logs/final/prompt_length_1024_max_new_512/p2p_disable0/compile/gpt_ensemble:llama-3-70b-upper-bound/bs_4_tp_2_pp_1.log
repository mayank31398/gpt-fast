W1202 11:48:44.835000 1764371 site-packages/torch/distributed/run.py:793] 
W1202 11:48:44.835000 1764371 site-packages/torch/distributed/run.py:793] *****************************************
W1202 11:48:44.835000 1764371 site-packages/torch/distributed/run.py:793] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W1202 11:48:44.835000 1764371 site-packages/torch/distributed/run.py:793] *****************************************
DeviceMesh('cuda', [[0, 1]], mesh_dim_names=('pp', 'tp'))
Using device=cuda
Loading model ...
DeviceMesh('cuda', [[0, 1]], mesh_dim_names=('pp', 'tp'))
GPTEnsemble(
  (tok_embeddings): Embedding(128256, 8192)
  (layers): ModuleList(
    (0-79): 80 x EnsembleTransformerBlock(
      semi_compiled = False
      (attention): Attention(
        (wqkv): Linear(in_features=8192, out_features=5120, bias=False)
        (wo): Linear(in_features=4096, out_features=8192, bias=False)
      )
      (feed_forward): FeedForward(
        (w1): Linear(in_features=8192, out_features=28672, bias=False)
        (w2): Linear(in_features=14336, out_features=8192, bias=False)
      )
      (ffn_norm): RMSNorm()
      (attention_norm): RMSNorm()
    )
  )
  (norm): RMSNorm()
  (output): Linear(in_features=8192, out_features=128256, bias=False)
)
Time to load model: 1.40 seconds
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
Compiling prefill with dynamic=False
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py:222: UserWarning: TensorFloat32 tensor cores for float32 matrix multiplication available but not enabled. Consider setting `torch.set_float32_matmul_precision('high')` for better performance.
  warnings.warn(
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py:222: UserWarning: TensorFloat32 tensor cores for float32 matrix multiplication available but not enabled. Consider setting `torch.set_float32_matmul_precision('high')` for better performance.
  warnings.warn(
Prefill latency: 78.00254235090688 sec
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
Decode latency: 103.16398085514084 sec
Compilation time: 181.22 seconds
Compilation time: 181.17 seconds
Prefill latency: 0.7301908237859607 sec
Decode latency: 14.955302721820772 sec
Prefill latency: 0.7256070110015571 sec
Decode latency: 14.95745875313878 sec
Prefill latency: 0.724378414452076 sec
Decode latency: 14.956716946791857 sec
Prefill latency: 0.7253568903543055 sec
Decode latency: 14.958502657245845 sec
Prefill latency: 0.7272340459749103 sec
Decode latency: 14.958356224000454 sec
Time for inference 1: 15.69 sec total, 130.54 tokens/sec
Decode latency: 14.96 sec
Prefill latency: 0.73 sec
Bandwidth achieved: 9210.32 GB/s
FLOPS achieved: 27.63 TF/s

Prefill latency: 0.7261801459826529 sec
Decode latency: 14.957805211190134 sec
Time for inference 2: 15.69 sec total, 130.56 tokens/sec
Decode latency: 14.96 sec
Prefill latency: 0.73 sec
Bandwidth achieved: 9211.31 GB/s
FLOPS achieved: 27.63 TF/s

Prefill latency: 0.7271152148023248 sec
Decode latency: 14.958597070071846 sec
Time for inference 3: 15.69 sec total, 130.54 tokens/sec
Decode latency: 14.96 sec
Prefill latency: 0.73 sec
Bandwidth achieved: 9210.22 GB/s
FLOPS achieved: 27.63 TF/s

Prefill latency: 0.7261481573805213 sec
Decode latency: 14.958165329881012 sec
Time for inference 4: 15.69 sec total, 130.55 tokens/sec
Decode latency: 14.96 sec
Prefill latency: 0.73 sec
Bandwidth achieved: 9211.01 GB/s
FLOPS achieved: 27.63 TF/s

Prefill latency: 0.7273117820732296 sec
Decode latency: 14.95739128999412 sec
Time for inference 5: 15.69 sec total, 130.55 tokens/sec
Decode latency: 14.96 sec
Prefill latency: 0.73 sec
Bandwidth achieved: 9210.76 GB/s
FLOPS achieved: 27.63 TF/s

Prefill latency: 0.7284214259125292 sec
Decode latency: 14.95667839422822 sec
Time for inference 6: 15.69 sec total, 130.55 tokens/sec
Decode latency: 14.96 sec
Prefill latency: 0.73 sec
Bandwidth achieved: 9210.65 GB/s
FLOPS achieved: 27.63 TF/s

Prefill latency: 0.7273684120737016 sec
Decode latency: 14.957522112876177 sec
Time for inference 7: 15.69 sec total, 130.55 tokens/sec
Decode latency: 14.96 sec
Prefill latency: 0.73 sec
Bandwidth achieved: 9210.68 GB/s
FLOPS achieved: 27.63 TF/s

Prefill latency: 0.7274914076551795 sec
Decode latency: 14.957987929694355 sec
Time for inference 8: 15.69 sec total, 130.54 tokens/sec
Decode latency: 14.96 sec
Prefill latency: 0.73 sec
Bandwidth achieved: 9210.38 GB/s
FLOPS achieved: 27.63 TF/s

Prefill latency: 0.7265235320664942 sec
Decode latency: 14.958440074231476 sec
Time for inference 9: 15.69 sec total, 130.55 tokens/sec
Decode latency: 14.96 sec
Prefill latency: 0.73 sec
Bandwidth achieved: 9210.65 GB/s
FLOPS achieved: 27.63 TF/s

Prefill latency: 0.7301277108490467 sec
Decode latency: 14.958963179029524 sec
Time for inference 10: 15.69 sec total, 130.51 tokens/sec
Decode latency: 14.96 sec
Prefill latency: 0.73 sec
Bandwidth achieved: 9208.36 GB/s
FLOPS achieved: 27.63 TF/s

==========
Batch Size: 4
Prompt Length: 1024
Generated tokens: 512
Average decode latency: 14.9580 sec
Average prefill latency: 0.7274 sec
Average tokens/sec: 130.54
Memory used: 77.51 GB
Done. we are killing the process
[rank1]:[W1202 11:55:33.292513353 ProcessGroupNCCL.cpp:1374] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
[rank0]:[W1202 11:55:34.873733058 ProcessGroupNCCL.cpp:1374] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
