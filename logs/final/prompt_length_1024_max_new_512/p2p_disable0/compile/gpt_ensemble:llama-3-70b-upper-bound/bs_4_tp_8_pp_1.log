W1201 10:47:26.502000 417574 site-packages/torch/distributed/run.py:793] 
W1201 10:47:26.502000 417574 site-packages/torch/distributed/run.py:793] *****************************************
W1201 10:47:26.502000 417574 site-packages/torch/distributed/run.py:793] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W1201 10:47:26.502000 417574 site-packages/torch/distributed/run.py:793] *****************************************
DeviceMesh('cuda', [[0, 1, 2, 3, 4, 5, 6, 7]], mesh_dim_names=('pp', 'tp'))
Using device=cuda
Loading model ...
DeviceMesh('cuda', [[0, 1, 2, 3, 4, 5, 6, 7]], mesh_dim_names=('pp', 'tp'))
DeviceMesh('cuda', [[0, 1, 2, 3, 4, 5, 6, 7]], mesh_dim_names=('pp', 'tp'))
DeviceMesh('cuda', [[0, 1, 2, 3, 4, 5, 6, 7]], mesh_dim_names=('pp', 'tp'))
DeviceMesh('cuda', [[0, 1, 2, 3, 4, 5, 6, 7]], mesh_dim_names=('pp', 'tp'))
DeviceMesh('cuda', [[0, 1, 2, 3, 4, 5, 6, 7]], mesh_dim_names=('pp', 'tp'))
DeviceMesh('cuda', [[0, 1, 2, 3, 4, 5, 6, 7]], mesh_dim_names=('pp', 'tp'))
DeviceMesh('cuda', [[0, 1, 2, 3, 4, 5, 6, 7]], mesh_dim_names=('pp', 'tp'))
GPTEnsemble(
  (tok_embeddings): Embedding(128256, 8192)
  (layers): ModuleList(
    (0-79): 80 x EnsembleTransformerBlock(
      semi_compiled = False
      (attention): Attention(
        (wqkv): Linear(in_features=8192, out_features=1280, bias=False)
        (wo): Linear(in_features=1024, out_features=8192, bias=False)
      )
      (feed_forward): FeedForward(
        (w1): Linear(in_features=8192, out_features=7168, bias=False)
        (w2): Linear(in_features=3584, out_features=8192, bias=False)
      )
      (ffn_norm): RMSNorm()
      (attention_norm): RMSNorm()
    )
  )
  (norm): RMSNorm()
  (output): Linear(in_features=8192, out_features=128256, bias=False)
)
Time to load model: 1.27 seconds
Compiling prefill with dynamic=False
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py:222: UserWarning: TensorFloat32 tensor cores for float32 matrix multiplication available but not enabled. Consider setting `torch.set_float32_matmul_precision('high')` for better performance.
  warnings.warn(
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py:222: UserWarning: TensorFloat32 tensor cores for float32 matrix multiplication available but not enabled. Consider setting `torch.set_float32_matmul_precision('high')` for better performance.
  warnings.warn(
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py:222: UserWarning: TensorFloat32 tensor cores for float32 matrix multiplication available but not enabled. Consider setting `torch.set_float32_matmul_precision('high')` for better performance.
  warnings.warn(
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py:222: UserWarning: TensorFloat32 tensor cores for float32 matrix multiplication available but not enabled. Consider setting `torch.set_float32_matmul_precision('high')` for better performance.
  warnings.warn(
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py:222: UserWarning: TensorFloat32 tensor cores for float32 matrix multiplication available but not enabled. Consider setting `torch.set_float32_matmul_precision('high')` for better performance.
  warnings.warn(
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py:222: UserWarning: TensorFloat32 tensor cores for float32 matrix multiplication available but not enabled. Consider setting `torch.set_float32_matmul_precision('high')` for better performance.
  warnings.warn(
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py:222: UserWarning: TensorFloat32 tensor cores for float32 matrix multiplication available but not enabled. Consider setting `torch.set_float32_matmul_precision('high')` for better performance.
  warnings.warn(
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py:222: UserWarning: TensorFloat32 tensor cores for float32 matrix multiplication available but not enabled. Consider setting `torch.set_float32_matmul_precision('high')` for better performance.
  warnings.warn(
/home/charlie/skip-residual/gpt-fast/tmp8jit30i7/main.c:422:1: fatal error: error writing to /tmp/cc9AGgWc.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmplj1fnbbe/main.c:422:1: fatal error: error writing to /tmp/ccUYL6Sn.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpv5gfukj3/main.c:422:1: fatal error: error writing to /tmp/ccWyawaP.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpq67yn0tm/main.c:422:1: fatal error: error writing to /tmp/cchR45un.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpyw9n0l3k/main.c:422:1: fatal error: error writing to /tmp/ccid9Qqy.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmp4nemlnfz/main.c:422:1: fatal error: error writing to /tmp/ccLGQbKw.s: No space left on device
  422 | }
      | ^
compilation terminated.
[rank0]: Traceback (most recent call last):
[rank0]:   File "/home/charlie/skip-residual/gpt-fast/benchmark.py", line 708, in <module>
[rank0]:     main(
[rank0]:   File "/home/charlie/skip-residual/gpt-fast/benchmark.py", line 622, in main
[rank0]:     y, decode_latency, prefill_latency = generate(
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
[rank0]:     return func(*args, **kwargs)
[rank0]:   File "/home/charlie/skip-residual/gpt-fast/benchmark.py", line 336, in generate
[rank0]:     next_token = prefill(model, prompt.view(batch_size, -1), input_pos, **sampling_kwargs)
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py", line 556, in _fn
[rank0]:     return fn(*args, **kwargs)
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 1395, in __call__
[rank0]:     return self._torchdynamo_orig_callable(
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 545, in __call__
[rank0]:     return _compile(
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 977, in _compile
[rank0]:     guarded_code = compile_inner(code, one_graph, hooks, transform)
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 706, in compile_inner
[rank0]:     return _compile_inner(code, one_graph, hooks, transform)
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_utils_internal.py", line 95, in wrapper_function
[rank0]:     return function(*args, **kwargs)
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 741, in _compile_inner
[rank0]:     out_code = transform_code_object(code, transform)
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/bytecode_transformation.py", line 1348, in transform_code_object
[rank0]:     transformations(instructions, code_options)
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 229, in _fn
[rank0]:     return fn(*args, **kwargs)
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 658, in transform
[rank0]:     tracer.run()
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 2912, in run
[rank0]:     super().run()
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 1120, in run
[rank0]:     while self.step():
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 1032, in step
[rank0]:     self.dispatch_table[inst.opcode](self, inst)
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 3103, in RETURN_VALUE
[rank0]:     self._return(inst)
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 3088, in _return
[rank0]:     self.output.compile_subgraph(
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/output_graph.py", line 1077, in compile_subgraph
[rank0]:     self.compile_and_call_fx_graph(tx, list(reversed(stack_values)), root)
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/output_graph.py", line 1346, in compile_and_call_fx_graph
[rank0]:     compiled_fn = self.call_user_compiler(gm)
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/output_graph.py", line 1396, in call_user_compiler
[rank0]:     return self._call_user_compiler(gm)
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/output_graph.py", line 1445, in _call_user_compiler
[rank0]:     raise BackendCompilerFailed(self.compiler_fn, e).with_traceback(
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/output_graph.py", line 1426, in _call_user_compiler
[rank0]:     compiled_fn = compiler_fn(gm, self.example_inputs())
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/repro/after_dynamo.py", line 130, in __call__
[rank0]:     compiled_gm = compiler_fn(gm, example_inputs)
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/repro/after_dynamo.py", line 130, in __call__
[rank0]:     compiled_gm = compiler_fn(gm, example_inputs)
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/__init__.py", line 2301, in __call__
[rank0]:     return compile_fx(model_, inputs_, config_patches=self.config)
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 1708, in compile_fx
[rank0]:     return aot_autograd(
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/backends/common.py", line 72, in __call__
[rank0]:     cg = aot_module_simplified(gm, example_inputs, **self.kwargs)
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 1103, in aot_module_simplified
[rank0]:     compiled_fn = dispatch_and_compile()
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 1079, in dispatch_and_compile
[rank0]:     compiled_fn, _ = create_aot_dispatcher_function(
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 527, in create_aot_dispatcher_function
[rank0]:     return _create_aot_dispatcher_function(
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 778, in _create_aot_dispatcher_function
[rank0]:     compiled_fn, fw_metadata = compiler_fn(
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py", line 197, in aot_dispatch_base
[rank0]:     compiled_fw = compiler(fw_module, updated_flat_args)
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 1525, in fw_compiler_base
[rank0]:     return _fw_compiler_base(model, example_inputs, is_inference)
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 1594, in _fw_compiler_base
[rank0]:     return inner_compile(
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 587, in compile_fx_inner
[rank0]:     return wrap_compiler_debug(_compile_fx_inner, compiler_name="inductor")(
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/repro/after_aot.py", line 102, in debug_wrapper
[rank0]:     inner_compiled_fn = compiler_fn(gm, example_inputs)
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 744, in _compile_fx_inner
[rank0]:     compiled_graph = FxGraphCache.load(
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 1515, in load
[rank0]:     compiled_graph = compile_fx_fn(
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 651, in codegen_and_compile
[rank0]:     compiled_graph = fx_codegen_and_compile(gm, example_inputs, **fx_kwargs)
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 962, in fx_codegen_and_compile
[rank0]:     compiled_fn = graph.compile_to_fn()
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/graph.py", line 2034, in compile_to_fn
[rank0]:     return self.compile_to_module().call
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/graph.py", line 1954, in compile_to_module
[rank0]:     return self._compile_to_module()
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/graph.py", line 1988, in _compile_to_module
[rank0]:     mod = PyCodeCache.load_by_key_path(
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 3058, in load_by_key_path
[rank0]:     mod = _reload_python_module(key, path)
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/runtime/compile_tasks.py", line 45, in _reload_python_module
[rank0]:     exec(code, mod.__dict__, mod.__dict__)
[rank0]:   File "/home/charlie/skip-residual/gpt-fast/torchinductor_charlie/cu/ccurmo732zacep4m7fvzs6mvepehgltxps4hkjv7xh6stjxndfwv.py", line 1713, in <module>
[rank0]:     async_compile.wait(globals())
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/async_compile.py", line 319, in wait
[rank0]:     scope[key] = result.result()
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 3535, in result
[rank0]:     result = self.future.result()
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/concurrent/futures/_base.py", line 458, in result
[rank0]:     return self.__get_result()
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
[rank0]:     raise self._exception
[rank0]: torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:
[rank0]: SubprocException: An exception occurred in a subprocess:

[rank0]: Traceback (most recent call last):
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_worker/subproc_pool.py", line 280, in do_job
[rank0]:     result = job()
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/runtime/compile_tasks.py", line 68, in _worker_compile_triton
[rank0]:     load_kernel().precompile(warm_cache_only=True)
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/runtime/compile_tasks.py", line 13, in _reload_triton_kernel_in_subproc
[rank0]:     return _module_to_triton_kernel(reload_module(), kernel_name)
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/runtime/compile_tasks.py", line 29, in _reload_python_module_in_subproc
[rank0]:     return codecache.PyCodeCache.load_by_key_path(key, path)
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 3058, in load_by_key_path
[rank0]:     mod = _reload_python_module(key, path)
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/runtime/compile_tasks.py", line 45, in _reload_python_module
[rank0]:     exec(code, mod.__dict__, mod.__dict__)
[rank0]:   File "/home/charlie/skip-residual/gpt-fast/torchinductor_charlie/vn/cvntjy4edguqq5fm27r3pvhpkzbtaux3bvhi5jcvktgyphzkuhhz.py", line 9, in <module>
[rank0]:     triton_helpers.set_driver_to_gpu()
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/runtime/triton_helpers.py", line 57, in set_driver_to_gpu
[rank0]:     driver.set_active(backend.driver())
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/triton/backends/nvidia/driver.py", line 371, in __init__
[rank0]:     self.utils = CudaUtils()  # TODO: make static
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/triton/backends/nvidia/driver.py", line 80, in __init__
[rank0]:     mod = compile_module_from_src(Path(os.path.join(dirname, "driver.c")).read_text(), "cuda_utils")
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/triton/backends/nvidia/driver.py", line 57, in compile_module_from_src
[rank0]:     so = _build(name, src_path, tmpdir, library_dirs(), include_dir, libraries)
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/triton/runtime/build.py", line 48, in _build
[rank0]:     ret = subprocess.check_call(cc_cmd)
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/subprocess.py", line 369, in check_call
[rank0]:     raise CalledProcessError(retcode, cmd)
[rank0]: subprocess.CalledProcessError: Command '['/usr/bin/gcc', '/home/charlie/skip-residual/gpt-fast/tmpq67yn0tm/main.c', '-O3', '-shared', '-fPIC', '-o', '/home/charlie/skip-residual/gpt-fast/tmpq67yn0tm/cuda_utils.cpython-310-x86_64-linux-gnu.so', '-lcuda', '-L/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/triton/backends/nvidia/lib', '-L/lib/x86_64-linux-gnu', '-I/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/triton/backends/nvidia/include', '-I/home/charlie/skip-residual/gpt-fast/tmpq67yn0tm', '-I/home/charlie/anaconda3/envs/gpt-fast/include/python3.10']' returned non-zero exit status 1.


[rank0]: Set TORCH_LOGS="+dynamo" and TORCHDYNAMO_VERBOSE=1 for more information


[rank0]: You can suppress this exception and fall back to eager by setting:
[rank0]:     import torch._dynamo
[rank0]:     torch._dynamo.config.suppress_errors = True

/home/charlie/skip-residual/gpt-fast/tmpa9jq6nso/main.c:422:1: fatal error: error writing to /tmp/ccuoEug3.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpzt916fbf/main.c:422:1: fatal error: error writing to /tmp/cc6NCPZL.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpzs7yw9rb/main.c:422:1: fatal error: error writing to /tmp/cclpHsxq.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpercbrb0e/main.c:422:1: fatal error: error writing to /tmp/cctYasZh.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpcy8ivmsf/main.c:422:1: fatal error: error writing to /tmp/cc10KW7c.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpjw157apj/main.c:422:1: fatal error: error writing to /tmp/ccd1ihgQ.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpvbljph08/main.c:422:1: fatal error: error writing to /tmp/ccm6039e.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpreap07_q/main.c:422:1: fatal error: error writing to /tmp/ccVoeIrY.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmprxymtrvp/main.c:422:1: fatal error: error writing to /tmp/ccYl5erv.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpzwr920_7/main.c:422:1: fatal error: error writing to /tmp/cc6NfZtG.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmp3rupr763/main.c:422:1: fatal error: error writing to /tmp/cc4BEKhM.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpt3s_5mvf/main.c:422:1: fatal error: error writing to /tmp/ccV7njJJ.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmp_8tan06w/main.c:422:1: fatal error: error writing to /tmp/cc2yrIsd.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpt6pr976q/main.c:422:1: fatal error: error writing to /tmp/ccDOsYAG.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmp3gvp4s_t/main.c:422:1: fatal error: error writing to /tmp/ccljK2kp.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpy4x7o1xz/main.c:422:1: fatal error: error writing to /tmp/cc9GXaoe.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmp7ma00yua/main.c:422:1: fatal error: error writing to /tmp/ccLM2HDx.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpj_raqnjf/main.c:422:1: fatal error: error writing to /tmp/ccgPCGMV.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpe40h85r2/main.c:422:1: fatal error: error writing to /tmp/ccnhVmBE.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpj4gl1toi/main.c:422:1: fatal error: error writing to /tmp/ccr9E5Mx.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmphtk12sq6/main.c:422:1: fatal error: error writing to /tmp/ccYJjHHS.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpt71ksm52/main.c:422:1: fatal error: error writing to /tmp/ccU7P41E.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpd4yhs4os/main.c:422:1: fatal error: error writing to /tmp/ccBIatZM.s: No space left on device
  422 | }
      | ^
compilation terminated.
[rank5]: Traceback (most recent call last):
[rank5]:   File "/home/charlie/skip-residual/gpt-fast/benchmark.py", line 708, in <module>
[rank5]:     main(
[rank5]:   File "/home/charlie/skip-residual/gpt-fast/benchmark.py", line 622, in main
[rank5]:     y, decode_latency, prefill_latency = generate(
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
[rank5]:     return func(*args, **kwargs)
[rank5]:   File "/home/charlie/skip-residual/gpt-fast/benchmark.py", line 336, in generate
[rank5]:     next_token = prefill(model, prompt.view(batch_size, -1), input_pos, **sampling_kwargs)
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py", line 556, in _fn
[rank5]:     return fn(*args, **kwargs)
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 1395, in __call__
[rank5]:     return self._torchdynamo_orig_callable(
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 545, in __call__
[rank5]:     return _compile(
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 977, in _compile
[rank5]:     guarded_code = compile_inner(code, one_graph, hooks, transform)
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 706, in compile_inner
[rank5]:     return _compile_inner(code, one_graph, hooks, transform)
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_utils_internal.py", line 95, in wrapper_function
[rank5]:     return function(*args, **kwargs)
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 741, in _compile_inner
[rank5]:     out_code = transform_code_object(code, transform)
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/bytecode_transformation.py", line 1348, in transform_code_object
[rank5]:     transformations(instructions, code_options)
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 229, in _fn
[rank5]:     return fn(*args, **kwargs)
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 658, in transform
[rank5]:     tracer.run()
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 2912, in run
[rank5]:     super().run()
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 1120, in run
[rank5]:     while self.step():
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 1032, in step
[rank5]:     self.dispatch_table[inst.opcode](self, inst)
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 3103, in RETURN_VALUE
[rank5]:     self._return(inst)
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 3088, in _return
[rank5]:     self.output.compile_subgraph(
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/output_graph.py", line 1077, in compile_subgraph
[rank5]:     self.compile_and_call_fx_graph(tx, list(reversed(stack_values)), root)
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/output_graph.py", line 1346, in compile_and_call_fx_graph
[rank5]:     compiled_fn = self.call_user_compiler(gm)
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/output_graph.py", line 1396, in call_user_compiler
[rank5]:     return self._call_user_compiler(gm)
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/output_graph.py", line 1445, in _call_user_compiler
[rank5]:     raise BackendCompilerFailed(self.compiler_fn, e).with_traceback(
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/output_graph.py", line 1426, in _call_user_compiler
[rank5]:     compiled_fn = compiler_fn(gm, self.example_inputs())
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/repro/after_dynamo.py", line 130, in __call__
[rank5]:     compiled_gm = compiler_fn(gm, example_inputs)
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/repro/after_dynamo.py", line 130, in __call__
[rank5]:     compiled_gm = compiler_fn(gm, example_inputs)
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/__init__.py", line 2301, in __call__
[rank5]:     return compile_fx(model_, inputs_, config_patches=self.config)
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 1708, in compile_fx
[rank5]:     return aot_autograd(
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/backends/common.py", line 72, in __call__
[rank5]:     cg = aot_module_simplified(gm, example_inputs, **self.kwargs)
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 1103, in aot_module_simplified
[rank5]:     compiled_fn = dispatch_and_compile()
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 1079, in dispatch_and_compile
[rank5]:     compiled_fn, _ = create_aot_dispatcher_function(
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 527, in create_aot_dispatcher_function
[rank5]:     return _create_aot_dispatcher_function(
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 778, in _create_aot_dispatcher_function
[rank5]:     compiled_fn, fw_metadata = compiler_fn(
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py", line 197, in aot_dispatch_base
[rank5]:     compiled_fw = compiler(fw_module, updated_flat_args)
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 1525, in fw_compiler_base
[rank5]:     return _fw_compiler_base(model, example_inputs, is_inference)
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 1594, in _fw_compiler_base
[rank5]:     return inner_compile(
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 587, in compile_fx_inner
[rank5]:     return wrap_compiler_debug(_compile_fx_inner, compiler_name="inductor")(
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/repro/after_aot.py", line 102, in debug_wrapper
[rank5]:     inner_compiled_fn = compiler_fn(gm, example_inputs)
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 744, in _compile_fx_inner
[rank5]:     compiled_graph = FxGraphCache.load(
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 1515, in load
[rank5]:     compiled_graph = compile_fx_fn(
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 651, in codegen_and_compile
[rank5]:     compiled_graph = fx_codegen_and_compile(gm, example_inputs, **fx_kwargs)
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 962, in fx_codegen_and_compile
[rank5]:     compiled_fn = graph.compile_to_fn()
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/graph.py", line 2034, in compile_to_fn
[rank5]:     return self.compile_to_module().call
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/graph.py", line 1954, in compile_to_module
[rank5]:     return self._compile_to_module()
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/graph.py", line 1988, in _compile_to_module
[rank5]:     mod = PyCodeCache.load_by_key_path(
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 3058, in load_by_key_path
[rank5]:     mod = _reload_python_module(key, path)
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/runtime/compile_tasks.py", line 45, in _reload_python_module
[rank5]:     exec(code, mod.__dict__, mod.__dict__)
[rank5]:   File "/home/charlie/skip-residual/gpt-fast/torchinductor_charlie/zx/czx75leqszzr5cs6igsf6eziyspisxymc2fxbv3fzuullmt732y3.py", line 1713, in <module>
[rank5]:     async_compile.wait(globals())
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/async_compile.py", line 319, in wait
[rank5]:     scope[key] = result.result()
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 3535, in result
[rank5]:     result = self.future.result()
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/concurrent/futures/_base.py", line 451, in result
[rank5]:     return self.__get_result()
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
[rank5]:     raise self._exception
[rank5]: torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:
[rank5]: SubprocException: An exception occurred in a subprocess:

[rank5]: Traceback (most recent call last):
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_worker/subproc_pool.py", line 280, in do_job
[rank5]:     result = job()
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/runtime/compile_tasks.py", line 68, in _worker_compile_triton
[rank5]:     load_kernel().precompile(warm_cache_only=True)
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/runtime/compile_tasks.py", line 13, in _reload_triton_kernel_in_subproc
[rank5]:     return _module_to_triton_kernel(reload_module(), kernel_name)
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/runtime/compile_tasks.py", line 29, in _reload_python_module_in_subproc
[rank5]:     return codecache.PyCodeCache.load_by_key_path(key, path)
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 3058, in load_by_key_path
[rank5]:     mod = _reload_python_module(key, path)
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/runtime/compile_tasks.py", line 45, in _reload_python_module
[rank5]:     exec(code, mod.__dict__, mod.__dict__)
[rank5]:   File "/home/charlie/skip-residual/gpt-fast/torchinductor_charlie/dq/cdq3usxfxbsqlt4emqdn4lbrs32l3vfqcld7qq63o5yiutc4cxw2.py", line 9, in <module>
[rank5]:     triton_helpers.set_driver_to_gpu()
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/runtime/triton_helpers.py", line 57, in set_driver_to_gpu
[rank5]:     driver.set_active(backend.driver())
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/triton/backends/nvidia/driver.py", line 371, in __init__
[rank5]:     self.utils = CudaUtils()  # TODO: make static
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/triton/backends/nvidia/driver.py", line 80, in __init__
[rank5]:     mod = compile_module_from_src(Path(os.path.join(dirname, "driver.c")).read_text(), "cuda_utils")
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/triton/backends/nvidia/driver.py", line 57, in compile_module_from_src
[rank5]:     so = _build(name, src_path, tmpdir, library_dirs(), include_dir, libraries)
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/triton/runtime/build.py", line 48, in _build
[rank5]:     ret = subprocess.check_call(cc_cmd)
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/subprocess.py", line 369, in check_call
[rank5]:     raise CalledProcessError(retcode, cmd)
[rank5]: subprocess.CalledProcessError: Command '['/usr/bin/gcc', '/home/charlie/skip-residual/gpt-fast/tmp7ma00yua/main.c', '-O3', '-shared', '-fPIC', '-o', '/home/charlie/skip-residual/gpt-fast/tmp7ma00yua/cuda_utils.cpython-310-x86_64-linux-gnu.so', '-lcuda', '-L/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/triton/backends/nvidia/lib', '-L/lib/x86_64-linux-gnu', '-I/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/triton/backends/nvidia/include', '-I/home/charlie/skip-residual/gpt-fast/tmp7ma00yua', '-I/home/charlie/anaconda3/envs/gpt-fast/include/python3.10']' returned non-zero exit status 1.


[rank5]: Set TORCH_LOGS="+dynamo" and TORCHDYNAMO_VERBOSE=1 for more information


[rank5]: You can suppress this exception and fall back to eager by setting:
[rank5]:     import torch._dynamo
[rank5]:     torch._dynamo.config.suppress_errors = True

/home/charlie/skip-residual/gpt-fast/tmpw_bkovlr/main.c:422:1: fatal error: error writing to /tmp/cc79oSzw.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmp02i39wwp/main.c:422:1: fatal error: error writing to /tmp/ccgkBkuo.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpgygzrcaf/main.c:422:1: fatal error: error writing to /tmp/ccM26Rwp.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpg8_kom8h/main.c:422:1: fatal error: error writing to /tmp/ccV77dA9.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpr9nq0x93/main.c:422:1: fatal error: error writing to /tmp/ccqud1Eh.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmp_3qz_kll/main.c:422:1: fatal error: error writing to /tmp/ccD1rQMu.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpynokpd_s/main.c:422:1: fatal error: error writing to /tmp/ccdxn5lE.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpofm5ac_p/main.c:422:1: fatal error: error writing to /tmp/cceOjBpX.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmp8pf8_8sl/main.c:422:1: fatal error: error writing to /tmp/cc6dJ9kR.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpndi1rs1l/main.c:422:1: fatal error: error writing to /tmp/cc3Lq1zS.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpz9yid4yr/main.c:422:1: fatal error: error writing to /tmp/ccOyJlGm.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpsp2whbw1/main.c:422:1: fatal error: error writing to /tmp/ccSG3ZVb.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmp1ih_qtxy/main.c:422:1: fatal error: error writing to /tmp/ccsUYkas.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpkfv8ktkd/main.c:422:1: fatal error: error writing to /tmp/cc5tLFnl.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpyd6ah7bl/main.c:422:1: fatal error: error writing to /tmp/ccGqHc1K.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpyb65r_ke/main.c:422:1: fatal error: error writing to /tmp/ccDqkIMW.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpbpwi4lqj/main.c:422:1: fatal error: error writing to /tmp/ccOirura.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpwsd5o8mf/main.c:422:1: fatal error: error writing to /tmp/ccPbcuCQ.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmp1nsjjj16/main.c:422:1: fatal error: error writing to /tmp/ccbuNZY3.s: No space left on device
  422 | }
      | ^
compilation terminated.
[rank2]: Traceback (most recent call last):
[rank2]:   File "/home/charlie/skip-residual/gpt-fast/benchmark.py", line 708, in <module>
[rank2]:     main(
[rank2]:   File "/home/charlie/skip-residual/gpt-fast/benchmark.py", line 622, in main
[rank2]:     y, decode_latency, prefill_latency = generate(
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
[rank2]:     return func(*args, **kwargs)
[rank2]:   File "/home/charlie/skip-residual/gpt-fast/benchmark.py", line 336, in generate
[rank2]:     next_token = prefill(model, prompt.view(batch_size, -1), input_pos, **sampling_kwargs)
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py", line 556, in _fn
[rank2]:     return fn(*args, **kwargs)
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 1395, in __call__
[rank2]:     return self._torchdynamo_orig_callable(
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 545, in __call__
[rank2]:     return _compile(
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 977, in _compile
[rank2]:     guarded_code = compile_inner(code, one_graph, hooks, transform)
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 706, in compile_inner
[rank2]:     return _compile_inner(code, one_graph, hooks, transform)
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_utils_internal.py", line 95, in wrapper_function
[rank2]:     return function(*args, **kwargs)
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 741, in _compile_inner
[rank2]:     out_code = transform_code_object(code, transform)
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/bytecode_transformation.py", line 1348, in transform_code_object
[rank2]:     transformations(instructions, code_options)
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 229, in _fn
[rank2]:     return fn(*args, **kwargs)
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 658, in transform
[rank2]:     tracer.run()
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 2912, in run
[rank2]:     super().run()
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 1120, in run
[rank2]:     while self.step():
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 1032, in step
[rank2]:     self.dispatch_table[inst.opcode](self, inst)
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 3103, in RETURN_VALUE
[rank2]:     self._return(inst)
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 3088, in _return
[rank2]:     self.output.compile_subgraph(
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/output_graph.py", line 1077, in compile_subgraph
[rank2]:     self.compile_and_call_fx_graph(tx, list(reversed(stack_values)), root)
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/output_graph.py", line 1346, in compile_and_call_fx_graph
[rank2]:     compiled_fn = self.call_user_compiler(gm)
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/output_graph.py", line 1396, in call_user_compiler
[rank2]:     return self._call_user_compiler(gm)
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/output_graph.py", line 1445, in _call_user_compiler
[rank2]:     raise BackendCompilerFailed(self.compiler_fn, e).with_traceback(
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/output_graph.py", line 1426, in _call_user_compiler
[rank2]:     compiled_fn = compiler_fn(gm, self.example_inputs())
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/repro/after_dynamo.py", line 130, in __call__
[rank2]:     compiled_gm = compiler_fn(gm, example_inputs)
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/repro/after_dynamo.py", line 130, in __call__
[rank2]:     compiled_gm = compiler_fn(gm, example_inputs)
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/__init__.py", line 2301, in __call__
[rank2]:     return compile_fx(model_, inputs_, config_patches=self.config)
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 1708, in compile_fx
[rank2]:     return aot_autograd(
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/backends/common.py", line 72, in __call__
[rank2]:     cg = aot_module_simplified(gm, example_inputs, **self.kwargs)
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 1103, in aot_module_simplified
[rank2]:     compiled_fn = dispatch_and_compile()
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 1079, in dispatch_and_compile
[rank2]:     compiled_fn, _ = create_aot_dispatcher_function(
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 527, in create_aot_dispatcher_function
[rank2]:     return _create_aot_dispatcher_function(
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 778, in _create_aot_dispatcher_function
[rank2]:     compiled_fn, fw_metadata = compiler_fn(
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py", line 197, in aot_dispatch_base
[rank2]:     compiled_fw = compiler(fw_module, updated_flat_args)
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 1525, in fw_compiler_base
[rank2]:     return _fw_compiler_base(model, example_inputs, is_inference)
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 1594, in _fw_compiler_base
[rank2]:     return inner_compile(
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 587, in compile_fx_inner
[rank2]:     return wrap_compiler_debug(_compile_fx_inner, compiler_name="inductor")(
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/repro/after_aot.py", line 102, in debug_wrapper
[rank2]:     inner_compiled_fn = compiler_fn(gm, example_inputs)
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 744, in _compile_fx_inner
[rank2]:     compiled_graph = FxGraphCache.load(
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 1515, in load
[rank2]:     compiled_graph = compile_fx_fn(
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 651, in codegen_and_compile
[rank2]:     compiled_graph = fx_codegen_and_compile(gm, example_inputs, **fx_kwargs)
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 962, in fx_codegen_and_compile
[rank2]:     compiled_fn = graph.compile_to_fn()
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/graph.py", line 2034, in compile_to_fn
[rank2]:     return self.compile_to_module().call
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/graph.py", line 1954, in compile_to_module
[rank2]:     return self._compile_to_module()
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/graph.py", line 1988, in _compile_to_module
[rank2]:     mod = PyCodeCache.load_by_key_path(
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 3058, in load_by_key_path
[rank2]:     mod = _reload_python_module(key, path)
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/runtime/compile_tasks.py", line 45, in _reload_python_module
[rank2]:     exec(code, mod.__dict__, mod.__dict__)
[rank2]:   File "/home/charlie/skip-residual/gpt-fast/torchinductor_charlie/ct/cct65umpn477pb6hdjy5dn3rqmtgzpnnmncqkjpfgxxupdi54adj.py", line 1713, in <module>
[rank2]:     async_compile.wait(globals())
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/async_compile.py", line 319, in wait
[rank2]:     scope[key] = result.result()
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 3535, in result
[rank2]:     result = self.future.result()
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/concurrent/futures/_base.py", line 451, in result
[rank2]:     return self.__get_result()
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
[rank2]:     raise self._exception
[rank2]: torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:
[rank2]: SubprocException: An exception occurred in a subprocess:

[rank2]: Traceback (most recent call last):
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_worker/subproc_pool.py", line 280, in do_job
[rank2]:     result = job()
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/runtime/compile_tasks.py", line 68, in _worker_compile_triton
[rank2]:     load_kernel().precompile(warm_cache_only=True)
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/runtime/compile_tasks.py", line 13, in _reload_triton_kernel_in_subproc
[rank2]:     return _module_to_triton_kernel(reload_module(), kernel_name)
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/runtime/compile_tasks.py", line 29, in _reload_python_module_in_subproc
[rank2]:     return codecache.PyCodeCache.load_by_key_path(key, path)
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 3058, in load_by_key_path
[rank2]:     mod = _reload_python_module(key, path)
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/runtime/compile_tasks.py", line 45, in _reload_python_module
[rank2]:     exec(code, mod.__dict__, mod.__dict__)
[rank2]:   File "/home/charlie/skip-residual/gpt-fast/torchinductor_charlie/gj/cgjcjzxuwteh2wkxts2zm6ntozheqikup26doyreoprqjyrjnhsf.py", line 9, in <module>
[rank2]:     triton_helpers.set_driver_to_gpu()
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/runtime/triton_helpers.py", line 57, in set_driver_to_gpu
[rank2]:     driver.set_active(backend.driver())
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/triton/backends/nvidia/driver.py", line 371, in __init__
[rank2]:     self.utils = CudaUtils()  # TODO: make static
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/triton/backends/nvidia/driver.py", line 80, in __init__
[rank2]:     mod = compile_module_from_src(Path(os.path.join(dirname, "driver.c")).read_text(), "cuda_utils")
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/triton/backends/nvidia/driver.py", line 57, in compile_module_from_src
[rank2]:     so = _build(name, src_path, tmpdir, library_dirs(), include_dir, libraries)
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/triton/runtime/build.py", line 48, in _build
[rank2]:     ret = subprocess.check_call(cc_cmd)
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/subprocess.py", line 369, in check_call
[rank2]:     raise CalledProcessError(retcode, cmd)
[rank2]: subprocess.CalledProcessError: Command '['/usr/bin/gcc', '/home/charlie/skip-residual/gpt-fast/tmpyb65r_ke/main.c', '-O3', '-shared', '-fPIC', '-o', '/home/charlie/skip-residual/gpt-fast/tmpyb65r_ke/cuda_utils.cpython-310-x86_64-linux-gnu.so', '-lcuda', '-L/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/triton/backends/nvidia/lib', '-L/lib/x86_64-linux-gnu', '-I/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/triton/backends/nvidia/include', '-I/home/charlie/skip-residual/gpt-fast/tmpyb65r_ke', '-I/home/charlie/anaconda3/envs/gpt-fast/include/python3.10']' returned non-zero exit status 1.


[rank2]: Set TORCH_LOGS="+dynamo" and TORCHDYNAMO_VERBOSE=1 for more information


[rank2]: You can suppress this exception and fall back to eager by setting:
[rank2]:     import torch._dynamo
[rank2]:     torch._dynamo.config.suppress_errors = True

/home/charlie/skip-residual/gpt-fast/tmp3xw2csin/main.c:422:1: fatal error: error writing to /tmp/cc7JBWRq.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpcjjye5wc/main.c:422:1: fatal error: error writing to /tmp/cc9aP4F0.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpi1z34o06/main.c:422:1: fatal error: error writing to /tmp/ccMDiWtg.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmplh80xwir/main.c:422:1: fatal error: error writing to /tmp/ccE7ftTd.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpta1zbvrj/main.c:422:1: fatal error: error writing to /tmp/ccIzAR5o.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmp5bzdt3e0/main.c:422:1: fatal error: error writing to /tmp/cc57GDLn.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpka2vxbd7/main.c:422:1: fatal error: error writing to /tmp/cczQkCj0.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpt2edhegm/main.c:422:1: fatal error: error writing to /tmp/ccmExIX7.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpmb2kyx7u/main.c:422:1: fatal error: error writing to /tmp/ccYOS9sz.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmp5jav2c8c/main.c:422:1: fatal error: error writing to /tmp/ccl72bOS.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmp41hrww4q/main.c:422:1: fatal error: error writing to /tmp/ccbuGnjc.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpnxxd6aiz/main.c:422:1: fatal error: error writing to /tmp/ccYaJ8eK.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpci2rd0ek/main.c:422:1: fatal error: error writing to /tmp/ccy0xCTo.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmp_7hhfm1j/main.c:422:1: fatal error: error writing to /tmp/cc67REks.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmp2ftfg0io/main.c:422:1: fatal error: error writing to /tmp/cct1U1iE.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpa_tz3ixm/main.c:422:1: fatal error: error writing to /tmp/ccCpS96F.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmp86_uqnte/main.c:422:1: fatal error: error writing to /tmp/ccswzF2m.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmp0drc8eo2/main.c:422:1: fatal error: error writing to /tmp/cckykf4s.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmp19pik0_4/main.c:422:1: fatal error: error writing to /tmp/ccZY3e09.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpoinpd8w9/main.c:422:1: fatal error: error writing to /tmp/cc7yD9JK.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpb95f8v38/main.c:422:1: fatal error: error writing to /tmp/cc3NHlD8.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpeq59tnkt/main.c:422:1: fatal error: error writing to /tmp/ccehCYxI.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmp170pa3ta/main.c:422:1: fatal error: error writing to /tmp/cczpzd4J.s: No space left on device
  422 | }
      | ^
compilation terminated.
[rank1]: Traceback (most recent call last):
[rank1]:   File "/home/charlie/skip-residual/gpt-fast/benchmark.py", line 708, in <module>
[rank1]:     main(
[rank1]:   File "/home/charlie/skip-residual/gpt-fast/benchmark.py", line 622, in main
[rank1]:     y, decode_latency, prefill_latency = generate(
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
[rank1]:     return func(*args, **kwargs)
[rank1]:   File "/home/charlie/skip-residual/gpt-fast/benchmark.py", line 336, in generate
[rank1]:     next_token = prefill(model, prompt.view(batch_size, -1), input_pos, **sampling_kwargs)
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py", line 556, in _fn
[rank1]:     return fn(*args, **kwargs)
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 1395, in __call__
[rank1]:     return self._torchdynamo_orig_callable(
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 545, in __call__
[rank1]:     return _compile(
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 977, in _compile
[rank1]:     guarded_code = compile_inner(code, one_graph, hooks, transform)
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 706, in compile_inner
[rank1]:     return _compile_inner(code, one_graph, hooks, transform)
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_utils_internal.py", line 95, in wrapper_function
[rank1]:     return function(*args, **kwargs)
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 741, in _compile_inner
[rank1]:     out_code = transform_code_object(code, transform)
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/bytecode_transformation.py", line 1348, in transform_code_object
[rank1]:     transformations(instructions, code_options)
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 229, in _fn
[rank1]:     return fn(*args, **kwargs)
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 658, in transform
[rank1]:     tracer.run()
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 2912, in run
[rank1]:     super().run()
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 1120, in run
[rank1]:     while self.step():
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 1032, in step
[rank1]:     self.dispatch_table[inst.opcode](self, inst)
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 3103, in RETURN_VALUE
[rank1]:     self._return(inst)
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 3088, in _return
[rank1]:     self.output.compile_subgraph(
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/output_graph.py", line 1077, in compile_subgraph
[rank1]:     self.compile_and_call_fx_graph(tx, list(reversed(stack_values)), root)
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/output_graph.py", line 1346, in compile_and_call_fx_graph
[rank1]:     compiled_fn = self.call_user_compiler(gm)
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/output_graph.py", line 1396, in call_user_compiler
[rank1]:     return self._call_user_compiler(gm)
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/output_graph.py", line 1445, in _call_user_compiler
[rank1]:     raise BackendCompilerFailed(self.compiler_fn, e).with_traceback(
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/output_graph.py", line 1426, in _call_user_compiler
[rank1]:     compiled_fn = compiler_fn(gm, self.example_inputs())
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/repro/after_dynamo.py", line 130, in __call__
[rank1]:     compiled_gm = compiler_fn(gm, example_inputs)
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/repro/after_dynamo.py", line 130, in __call__
[rank1]:     compiled_gm = compiler_fn(gm, example_inputs)
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/__init__.py", line 2301, in __call__
[rank1]:     return compile_fx(model_, inputs_, config_patches=self.config)
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 1708, in compile_fx
[rank1]:     return aot_autograd(
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/backends/common.py", line 72, in __call__
[rank1]:     cg = aot_module_simplified(gm, example_inputs, **self.kwargs)
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 1103, in aot_module_simplified
[rank1]:     compiled_fn = dispatch_and_compile()
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 1079, in dispatch_and_compile
[rank1]:     compiled_fn, _ = create_aot_dispatcher_function(
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 527, in create_aot_dispatcher_function
[rank1]:     return _create_aot_dispatcher_function(
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 778, in _create_aot_dispatcher_function
[rank1]:     compiled_fn, fw_metadata = compiler_fn(
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py", line 197, in aot_dispatch_base
[rank1]:     compiled_fw = compiler(fw_module, updated_flat_args)
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 1525, in fw_compiler_base
[rank1]:     return _fw_compiler_base(model, example_inputs, is_inference)
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 1594, in _fw_compiler_base
[rank1]:     return inner_compile(
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 587, in compile_fx_inner
[rank1]:     return wrap_compiler_debug(_compile_fx_inner, compiler_name="inductor")(
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/repro/after_aot.py", line 102, in debug_wrapper
[rank1]:     inner_compiled_fn = compiler_fn(gm, example_inputs)
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 744, in _compile_fx_inner
[rank1]:     compiled_graph = FxGraphCache.load(
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 1515, in load
[rank1]:     compiled_graph = compile_fx_fn(
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 651, in codegen_and_compile
[rank1]:     compiled_graph = fx_codegen_and_compile(gm, example_inputs, **fx_kwargs)
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 962, in fx_codegen_and_compile
[rank1]:     compiled_fn = graph.compile_to_fn()
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/graph.py", line 2034, in compile_to_fn
[rank1]:     return self.compile_to_module().call
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/graph.py", line 1954, in compile_to_module
[rank1]:     return self._compile_to_module()
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/graph.py", line 1988, in _compile_to_module
[rank1]:     mod = PyCodeCache.load_by_key_path(
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 3058, in load_by_key_path
[rank1]:     mod = _reload_python_module(key, path)
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/runtime/compile_tasks.py", line 45, in _reload_python_module
[rank1]:     exec(code, mod.__dict__, mod.__dict__)
[rank1]:   File "/home/charlie/skip-residual/gpt-fast/torchinductor_charlie/6f/c6fnpsfkbur2fd52wgpbvexzajqupfk6gerpdeeupm6dqed2t3ig.py", line 1713, in <module>
[rank1]:     async_compile.wait(globals())
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/async_compile.py", line 319, in wait
[rank1]:     scope[key] = result.result()
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 3535, in result
[rank1]:     result = self.future.result()
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/concurrent/futures/_base.py", line 458, in result
[rank1]:     return self.__get_result()
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
[rank1]:     raise self._exception
[rank1]: torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:
[rank1]: SubprocException: An exception occurred in a subprocess:

[rank1]: Traceback (most recent call last):
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_worker/subproc_pool.py", line 280, in do_job
[rank1]:     result = job()
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/runtime/compile_tasks.py", line 68, in _worker_compile_triton
[rank1]:     load_kernel().precompile(warm_cache_only=True)
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/runtime/compile_tasks.py", line 13, in _reload_triton_kernel_in_subproc
[rank1]:     return _module_to_triton_kernel(reload_module(), kernel_name)
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/runtime/compile_tasks.py", line 29, in _reload_python_module_in_subproc
[rank1]:     return codecache.PyCodeCache.load_by_key_path(key, path)
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 3058, in load_by_key_path
[rank1]:     mod = _reload_python_module(key, path)
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/runtime/compile_tasks.py", line 45, in _reload_python_module
[rank1]:     exec(code, mod.__dict__, mod.__dict__)
[rank1]:   File "/home/charlie/skip-residual/gpt-fast/torchinductor_charlie/nb/cnbmgixuev4wxu6if63m6slu2v4j77cgwzqfiksvqws4jwgzfbpp.py", line 9, in <module>
[rank1]:     triton_helpers.set_driver_to_gpu()
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/runtime/triton_helpers.py", line 57, in set_driver_to_gpu
[rank1]:     driver.set_active(backend.driver())
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/triton/backends/nvidia/driver.py", line 371, in __init__
[rank1]:     self.utils = CudaUtils()  # TODO: make static
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/triton/backends/nvidia/driver.py", line 80, in __init__
[rank1]:     mod = compile_module_from_src(Path(os.path.join(dirname, "driver.c")).read_text(), "cuda_utils")
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/triton/backends/nvidia/driver.py", line 57, in compile_module_from_src
[rank1]:     so = _build(name, src_path, tmpdir, library_dirs(), include_dir, libraries)
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/triton/runtime/build.py", line 48, in _build
[rank1]:     ret = subprocess.check_call(cc_cmd)
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/subprocess.py", line 369, in check_call
[rank1]:     raise CalledProcessError(retcode, cmd)
[rank1]: subprocess.CalledProcessError: Command '['/usr/bin/gcc', '/home/charlie/skip-residual/gpt-fast/tmpoinpd8w9/main.c', '-O3', '-shared', '-fPIC', '-o', '/home/charlie/skip-residual/gpt-fast/tmpoinpd8w9/cuda_utils.cpython-310-x86_64-linux-gnu.so', '-lcuda', '-L/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/triton/backends/nvidia/lib', '-L/lib/x86_64-linux-gnu', '-I/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/triton/backends/nvidia/include', '-I/home/charlie/skip-residual/gpt-fast/tmpoinpd8w9', '-I/home/charlie/anaconda3/envs/gpt-fast/include/python3.10']' returned non-zero exit status 1.


[rank1]: Set TORCH_LOGS="+dynamo" and TORCHDYNAMO_VERBOSE=1 for more information


[rank1]: You can suppress this exception and fall back to eager by setting:
[rank1]:     import torch._dynamo
[rank1]:     torch._dynamo.config.suppress_errors = True

/home/charlie/skip-residual/gpt-fast/tmp_wf4imnn/main.c:422:1: fatal error: error writing to /tmp/cc401dmY.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpoiyz51ef/main.c:422:1: fatal error: error writing to /tmp/cc3D7bXR.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmp0v48ycga/main.c:422:1: fatal error: error writing to /tmp/cc1zLLXA.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmputo38jh_/main.c:422:1: fatal error: error writing to /tmp/cctQGuWQ.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpa70u6bbc/main.c:422:1: fatal error: error writing to /tmp/ccV2ysCt.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmp2w3mlqol/main.c:422:1: fatal error: error writing to /tmp/ccvazjst.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmp88p2x661/main.c:422:1: fatal error: error writing to /tmp/cc3Y74pj.s: No space left on device
  422 | }
      | ^
/home/charlie/skip-residual/gpt-fast/tmpsr_en6ms/main.c:422:1: fatal error: error writing to /tmp/cct93QaQ.s: No space left on device
  422 | }
      | ^
compilation terminated.
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpsp3rcki0/main.c:422:1: fatal error: error writing to /tmp/ccZYs5lw.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpioghrk1l/main.c:422:1: fatal error: error writing to /tmp/ccDW30fh.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpvh4skx99/main.c:422:1: fatal error: error writing to /tmp/ccXFQjD7.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpg_ah3iw9/main.c:422:1: fatal error: error writing to /tmp/ccRQJiAU.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmphmiwbdrc/main.c:422:1: fatal error: error writing to /tmp/ccQqWMdt.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmps4mw6j32/main.c:422:1: fatal error: error writing to /tmp/ccJB1czU.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpcw7w6z7p/main.c:422:1: fatal error: error writing to /tmp/ccCFGck5.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpcl9eyg6t/main.c:422:1: fatal error: error writing to /tmp/ccIaZ55I.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmp2qdzsqfu/main.c:422:1: fatal error: error writing to /tmp/ccXn0VfP.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpnokmsbxg/main.c:422:1: fatal error: error writing to /tmp/cccL71RT.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpxguc18a8/main.c:422:1: fatal error: error writing to /tmp/cceMFbRN.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpxxkqprr7/main.c:422:1: fatal error: error writing to /tmp/cctKt5UP.s: No space left on device
  422 | }
      | ^
/home/charlie/skip-residual/gpt-fast/tmpidfas4pv/main.c:422:1: fatal error: error writing to /tmp/ccXCun1E.s: No space left on device
  422 | }
      | ^
compilation terminated.
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpgn0xs2gn/main.c:422:1: fatal error: error writing to /tmp/ccx3Nwcc.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpgyyjhh1j/main.c:422:1: fatal error: error writing to /tmp/ccAVLwsq.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmp0zgdfbg6/main.c:422:1: fatal error: error writing to /tmp/ccH1cZGq.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmptd35lro7/main.c:422:1: fatal error: error writing to /tmp/cc3iYzEv.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpt7q6bgmr/main.c:422:1: fatal error: error writing to /tmp/ccBLEht1.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpb9_2yx4e/main.c:422:1: fatal error: error writing to /tmp/ccVcCRlE.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpf9vbmisw/main.c:422:1: fatal error: error writing to /tmp/ccxtUYyL.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpeac8xe04/main.c:422:1: fatal error: error writing to /tmp/ccBhUm2p.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpgv49345o/main.c:422:1: fatal error: error writing to /tmp/ccW7ok2f.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpv469oisr/main.c:422:1: fatal error: error writing to /tmp/ccRSwHTx.s: No space left on device
  422 | }
      | ^
compilation terminated.
[rank7]: Traceback (most recent call last):
[rank7]:   File "/home/charlie/skip-residual/gpt-fast/benchmark.py", line 708, in <module>
[rank7]:     main(
[rank7]:   File "/home/charlie/skip-residual/gpt-fast/benchmark.py", line 622, in main
[rank7]:     y, decode_latency, prefill_latency = generate(
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
[rank7]:     return func(*args, **kwargs)
[rank7]:   File "/home/charlie/skip-residual/gpt-fast/benchmark.py", line 336, in generate
[rank7]:     next_token = prefill(model, prompt.view(batch_size, -1), input_pos, **sampling_kwargs)
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py", line 556, in _fn
[rank7]:     return fn(*args, **kwargs)
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 1395, in __call__
[rank7]:     return self._torchdynamo_orig_callable(
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 545, in __call__
[rank7]:     return _compile(
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 977, in _compile
[rank7]:     guarded_code = compile_inner(code, one_graph, hooks, transform)
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 706, in compile_inner
[rank7]:     return _compile_inner(code, one_graph, hooks, transform)
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_utils_internal.py", line 95, in wrapper_function
[rank7]:     return function(*args, **kwargs)
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 741, in _compile_inner
[rank7]:     out_code = transform_code_object(code, transform)
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/bytecode_transformation.py", line 1348, in transform_code_object
[rank7]:     transformations(instructions, code_options)
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 229, in _fn
[rank7]:     return fn(*args, **kwargs)
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 658, in transform
[rank7]:     tracer.run()
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 2912, in run
[rank7]:     super().run()
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 1120, in run
[rank7]:     while self.step():
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 1032, in step
[rank7]:     self.dispatch_table[inst.opcode](self, inst)
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 3103, in RETURN_VALUE
[rank7]:     self._return(inst)
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 3088, in _return
[rank7]:     self.output.compile_subgraph(
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/output_graph.py", line 1077, in compile_subgraph
[rank7]:     self.compile_and_call_fx_graph(tx, list(reversed(stack_values)), root)
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/output_graph.py", line 1346, in compile_and_call_fx_graph
[rank7]:     compiled_fn = self.call_user_compiler(gm)
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/output_graph.py", line 1396, in call_user_compiler
[rank7]:     return self._call_user_compiler(gm)
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/output_graph.py", line 1445, in _call_user_compiler
[rank7]:     raise BackendCompilerFailed(self.compiler_fn, e).with_traceback(
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/output_graph.py", line 1426, in _call_user_compiler
[rank7]:     compiled_fn = compiler_fn(gm, self.example_inputs())
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/repro/after_dynamo.py", line 130, in __call__
[rank7]:     compiled_gm = compiler_fn(gm, example_inputs)
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/repro/after_dynamo.py", line 130, in __call__
[rank7]:     compiled_gm = compiler_fn(gm, example_inputs)
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/__init__.py", line 2301, in __call__
[rank7]:     return compile_fx(model_, inputs_, config_patches=self.config)
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 1708, in compile_fx
[rank7]:     return aot_autograd(
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/backends/common.py", line 72, in __call__
[rank7]:     cg = aot_module_simplified(gm, example_inputs, **self.kwargs)
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 1103, in aot_module_simplified
[rank7]:     compiled_fn = dispatch_and_compile()
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 1079, in dispatch_and_compile
[rank7]:     compiled_fn, _ = create_aot_dispatcher_function(
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 527, in create_aot_dispatcher_function
[rank7]:     return _create_aot_dispatcher_function(
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 778, in _create_aot_dispatcher_function
[rank7]:     compiled_fn, fw_metadata = compiler_fn(
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py", line 197, in aot_dispatch_base
[rank7]:     compiled_fw = compiler(fw_module, updated_flat_args)
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 1525, in fw_compiler_base
[rank7]:     return _fw_compiler_base(model, example_inputs, is_inference)
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 1594, in _fw_compiler_base
[rank7]:     return inner_compile(
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 587, in compile_fx_inner
[rank7]:     return wrap_compiler_debug(_compile_fx_inner, compiler_name="inductor")(
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/repro/after_aot.py", line 102, in debug_wrapper
[rank7]:     inner_compiled_fn = compiler_fn(gm, example_inputs)
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 744, in _compile_fx_inner
[rank7]:     compiled_graph = FxGraphCache.load(
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 1515, in load
[rank7]:     compiled_graph = compile_fx_fn(
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 651, in codegen_and_compile
[rank7]:     compiled_graph = fx_codegen_and_compile(gm, example_inputs, **fx_kwargs)
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 962, in fx_codegen_and_compile
[rank7]:     compiled_fn = graph.compile_to_fn()
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/graph.py", line 2034, in compile_to_fn
[rank7]:     return self.compile_to_module().call
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/graph.py", line 1954, in compile_to_module
[rank7]:     return self._compile_to_module()
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/graph.py", line 1988, in _compile_to_module
[rank7]:     mod = PyCodeCache.load_by_key_path(
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 3058, in load_by_key_path
[rank7]:     mod = _reload_python_module(key, path)
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/runtime/compile_tasks.py", line 45, in _reload_python_module
[rank7]:     exec(code, mod.__dict__, mod.__dict__)
[rank7]:   File "/home/charlie/skip-residual/gpt-fast/torchinductor_charlie/of/cofmfa2tiuxl5w63y7gmjdqy4ubnrgznv36spmhugx73d6kvpqlg.py", line 1713, in <module>
[rank7]:     async_compile.wait(globals())
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/async_compile.py", line 319, in wait
[rank7]:     scope[key] = result.result()
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 3535, in result
[rank7]:     result = self.future.result()
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/concurrent/futures/_base.py", line 451, in result
[rank7]:     return self.__get_result()
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
[rank7]:     raise self._exception
[rank7]: torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:
[rank7]: SubprocException: An exception occurred in a subprocess:

[rank7]: Traceback (most recent call last):
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_worker/subproc_pool.py", line 280, in do_job
[rank7]:     result = job()
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/runtime/compile_tasks.py", line 68, in _worker_compile_triton
[rank7]:     load_kernel().precompile(warm_cache_only=True)
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/runtime/compile_tasks.py", line 13, in _reload_triton_kernel_in_subproc
[rank7]:     return _module_to_triton_kernel(reload_module(), kernel_name)
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/runtime/compile_tasks.py", line 29, in _reload_python_module_in_subproc
[rank7]:     return codecache.PyCodeCache.load_by_key_path(key, path)
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 3058, in load_by_key_path
[rank7]:     mod = _reload_python_module(key, path)
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/runtime/compile_tasks.py", line 45, in _reload_python_module
[rank7]:     exec(code, mod.__dict__, mod.__dict__)
[rank7]:   File "/home/charlie/skip-residual/gpt-fast/torchinductor_charlie/o2/co2oampe2hdoaowbn4ttktymyrnq5xv5zs67oj5px2orgur67tvz.py", line 9, in <module>
[rank7]:     triton_helpers.set_driver_to_gpu()
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/runtime/triton_helpers.py", line 57, in set_driver_to_gpu
[rank7]:     driver.set_active(backend.driver())
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/triton/backends/nvidia/driver.py", line 371, in __init__
[rank7]:     self.utils = CudaUtils()  # TODO: make static
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/triton/backends/nvidia/driver.py", line 80, in __init__
[rank7]:     mod = compile_module_from_src(Path(os.path.join(dirname, "driver.c")).read_text(), "cuda_utils")
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/triton/backends/nvidia/driver.py", line 57, in compile_module_from_src
[rank7]:     so = _build(name, src_path, tmpdir, library_dirs(), include_dir, libraries)
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/triton/runtime/build.py", line 48, in _build
[rank7]:     ret = subprocess.check_call(cc_cmd)
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/subprocess.py", line 369, in check_call
[rank7]:     raise CalledProcessError(retcode, cmd)
[rank7]: subprocess.CalledProcessError: Command '['/usr/bin/gcc', '/home/charlie/skip-residual/gpt-fast/tmpxxkqprr7/main.c', '-O3', '-shared', '-fPIC', '-o', '/home/charlie/skip-residual/gpt-fast/tmpxxkqprr7/cuda_utils.cpython-310-x86_64-linux-gnu.so', '-lcuda', '-L/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/triton/backends/nvidia/lib', '-L/lib/x86_64-linux-gnu', '-I/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/triton/backends/nvidia/include', '-I/home/charlie/skip-residual/gpt-fast/tmpxxkqprr7', '-I/home/charlie/anaconda3/envs/gpt-fast/include/python3.10']' returned non-zero exit status 1.


[rank7]: Set TORCH_LOGS="+dynamo" and TORCHDYNAMO_VERBOSE=1 for more information


[rank7]: You can suppress this exception and fall back to eager by setting:
[rank7]:     import torch._dynamo
[rank7]:     torch._dynamo.config.suppress_errors = True

/home/charlie/skip-residual/gpt-fast/tmpwu6m_y6o/main.c:422:1: fatal error: error writing to /tmp/ccp5pNis.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpo4ot_bgm/main.c:422:1: fatal error: error writing to /tmp/ccxVUIkW.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmp_kb3hsk9/main.c:422:1: fatal error: error writing to /tmp/cc9u8ddE.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmp4e483kqw/main.c:422:1: fatal error: error writing to /tmp/ccXvFzgR.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpfiw8tm03/main.c:422:1: fatal error: error writing to /tmp/ccUH9u8c.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmptnqtxy83/main.c:422:1: fatal error: error writing to /tmp/cczTDvIg.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpayslssil/main.c:422:1: fatal error: error writing to /tmp/ccUNZ1HI.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpprt7ue25/main.c:422:1: fatal error: error writing to /tmp/ccjfGg6f.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpe7bh8_1c/main.c:422:1: fatal error: error writing to /tmp/ccm4sC9p.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpl69f9d6k/main.c:422:1: fatal error: error writing to /tmp/cc1bMXap.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmptm4b1th_/main.c:422:1: fatal error: error writing to /tmp/ccX1b8Rk.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpkgkev3ca/main.c:422:1: fatal error: error writing to /tmp/cc15g2oL.s: No space left on device
  422 | }
      | ^
compilation terminated.
[rank6]: Traceback (most recent call last):
[rank6]:   File "/home/charlie/skip-residual/gpt-fast/benchmark.py", line 708, in <module>
[rank6]:     main(
[rank6]:   File "/home/charlie/skip-residual/gpt-fast/benchmark.py", line 622, in main
[rank6]:     y, decode_latency, prefill_latency = generate(
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
[rank6]:     return func(*args, **kwargs)
[rank6]:   File "/home/charlie/skip-residual/gpt-fast/benchmark.py", line 336, in generate
[rank6]:     next_token = prefill(model, prompt.view(batch_size, -1), input_pos, **sampling_kwargs)
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py", line 556, in _fn
[rank6]:     return fn(*args, **kwargs)
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 1395, in __call__
[rank6]:     return self._torchdynamo_orig_callable(
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 545, in __call__
[rank6]:     return _compile(
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 977, in _compile
[rank6]:     guarded_code = compile_inner(code, one_graph, hooks, transform)
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 706, in compile_inner
[rank6]:     return _compile_inner(code, one_graph, hooks, transform)
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_utils_internal.py", line 95, in wrapper_function
[rank6]:     return function(*args, **kwargs)
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 741, in _compile_inner
[rank6]:     out_code = transform_code_object(code, transform)
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/bytecode_transformation.py", line 1348, in transform_code_object
[rank6]:     transformations(instructions, code_options)
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 229, in _fn
[rank6]:     return fn(*args, **kwargs)
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 658, in transform
[rank6]:     tracer.run()
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 2912, in run
[rank6]:     super().run()
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 1120, in run
[rank6]:     while self.step():
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 1032, in step
[rank6]:     self.dispatch_table[inst.opcode](self, inst)
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 3103, in RETURN_VALUE
[rank6]:     self._return(inst)
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 3088, in _return
[rank6]:     self.output.compile_subgraph(
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/output_graph.py", line 1077, in compile_subgraph
[rank6]:     self.compile_and_call_fx_graph(tx, list(reversed(stack_values)), root)
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/output_graph.py", line 1346, in compile_and_call_fx_graph
[rank6]:     compiled_fn = self.call_user_compiler(gm)
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/output_graph.py", line 1396, in call_user_compiler
[rank6]:     return self._call_user_compiler(gm)
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/output_graph.py", line 1445, in _call_user_compiler
[rank6]:     raise BackendCompilerFailed(self.compiler_fn, e).with_traceback(
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/output_graph.py", line 1426, in _call_user_compiler
[rank6]:     compiled_fn = compiler_fn(gm, self.example_inputs())
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/repro/after_dynamo.py", line 130, in __call__
[rank6]:     compiled_gm = compiler_fn(gm, example_inputs)
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/repro/after_dynamo.py", line 130, in __call__
[rank6]:     compiled_gm = compiler_fn(gm, example_inputs)
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/__init__.py", line 2301, in __call__
[rank6]:     return compile_fx(model_, inputs_, config_patches=self.config)
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 1708, in compile_fx
[rank6]:     return aot_autograd(
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/backends/common.py", line 72, in __call__
[rank6]:     cg = aot_module_simplified(gm, example_inputs, **self.kwargs)
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 1103, in aot_module_simplified
[rank6]:     compiled_fn = dispatch_and_compile()
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 1079, in dispatch_and_compile
[rank6]:     compiled_fn, _ = create_aot_dispatcher_function(
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 527, in create_aot_dispatcher_function
[rank6]:     return _create_aot_dispatcher_function(
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 778, in _create_aot_dispatcher_function
[rank6]:     compiled_fn, fw_metadata = compiler_fn(
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py", line 197, in aot_dispatch_base
[rank6]:     compiled_fw = compiler(fw_module, updated_flat_args)
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 1525, in fw_compiler_base
[rank6]:     return _fw_compiler_base(model, example_inputs, is_inference)
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 1594, in _fw_compiler_base
[rank6]:     return inner_compile(
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 587, in compile_fx_inner
[rank6]:     return wrap_compiler_debug(_compile_fx_inner, compiler_name="inductor")(
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/repro/after_aot.py", line 102, in debug_wrapper
[rank6]:     inner_compiled_fn = compiler_fn(gm, example_inputs)
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 744, in _compile_fx_inner
[rank6]:     compiled_graph = FxGraphCache.load(
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 1515, in load
[rank6]:     compiled_graph = compile_fx_fn(
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 651, in codegen_and_compile
[rank6]:     compiled_graph = fx_codegen_and_compile(gm, example_inputs, **fx_kwargs)
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 962, in fx_codegen_and_compile
[rank6]:     compiled_fn = graph.compile_to_fn()
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/graph.py", line 2034, in compile_to_fn
[rank6]:     return self.compile_to_module().call
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/graph.py", line 1954, in compile_to_module
[rank6]:     return self._compile_to_module()
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/graph.py", line 1988, in _compile_to_module
[rank6]:     mod = PyCodeCache.load_by_key_path(
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 3058, in load_by_key_path
[rank6]:     mod = _reload_python_module(key, path)
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/runtime/compile_tasks.py", line 45, in _reload_python_module
[rank6]:     exec(code, mod.__dict__, mod.__dict__)
[rank6]:   File "/home/charlie/skip-residual/gpt-fast/torchinductor_charlie/vf/cvfd5vexcahsaw4mjccdf6dyceb64tm775d64ssue65ldevlp35d.py", line 1713, in <module>
[rank6]:     async_compile.wait(globals())
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/async_compile.py", line 319, in wait
[rank6]:     scope[key] = result.result()
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 3535, in result
[rank6]:     result = self.future.result()
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/concurrent/futures/_base.py", line 451, in result
[rank6]:     return self.__get_result()
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
[rank6]:     raise self._exception
[rank6]: torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:
[rank6]: SubprocException: An exception occurred in a subprocess:

[rank6]: Traceback (most recent call last):
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_worker/subproc_pool.py", line 280, in do_job
[rank6]:     result = job()
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/runtime/compile_tasks.py", line 68, in _worker_compile_triton
[rank6]:     load_kernel().precompile(warm_cache_only=True)
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/runtime/compile_tasks.py", line 13, in _reload_triton_kernel_in_subproc
[rank6]:     return _module_to_triton_kernel(reload_module(), kernel_name)
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/runtime/compile_tasks.py", line 29, in _reload_python_module_in_subproc
[rank6]:     return codecache.PyCodeCache.load_by_key_path(key, path)
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 3058, in load_by_key_path
[rank6]:     mod = _reload_python_module(key, path)
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/runtime/compile_tasks.py", line 45, in _reload_python_module
[rank6]:     exec(code, mod.__dict__, mod.__dict__)
[rank6]:   File "/home/charlie/skip-residual/gpt-fast/torchinductor_charlie/jm/cjmoixurfevy6gyadfeec7armpr3uu7rhl76vpfmfx2qcblquj73.py", line 9, in <module>
[rank6]:     triton_helpers.set_driver_to_gpu()
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/runtime/triton_helpers.py", line 57, in set_driver_to_gpu
[rank6]:     driver.set_active(backend.driver())
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/triton/backends/nvidia/driver.py", line 371, in __init__
[rank6]:     self.utils = CudaUtils()  # TODO: make static
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/triton/backends/nvidia/driver.py", line 80, in __init__
[rank6]:     mod = compile_module_from_src(Path(os.path.join(dirname, "driver.c")).read_text(), "cuda_utils")
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/triton/backends/nvidia/driver.py", line 57, in compile_module_from_src
[rank6]:     so = _build(name, src_path, tmpdir, library_dirs(), include_dir, libraries)
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/triton/runtime/build.py", line 48, in _build
[rank6]:     ret = subprocess.check_call(cc_cmd)
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/subprocess.py", line 369, in check_call
[rank6]:     raise CalledProcessError(retcode, cmd)
[rank6]: subprocess.CalledProcessError: Command '['/usr/bin/gcc', '/home/charlie/skip-residual/gpt-fast/tmpt7q6bgmr/main.c', '-O3', '-shared', '-fPIC', '-o', '/home/charlie/skip-residual/gpt-fast/tmpt7q6bgmr/cuda_utils.cpython-310-x86_64-linux-gnu.so', '-lcuda', '-L/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/triton/backends/nvidia/lib', '-L/lib/x86_64-linux-gnu', '-I/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/triton/backends/nvidia/include', '-I/home/charlie/skip-residual/gpt-fast/tmpt7q6bgmr', '-I/home/charlie/anaconda3/envs/gpt-fast/include/python3.10']' returned non-zero exit status 1.


[rank6]: Set TORCH_LOGS="+dynamo" and TORCHDYNAMO_VERBOSE=1 for more information


[rank6]: You can suppress this exception and fall back to eager by setting:
[rank6]:     import torch._dynamo
[rank6]:     torch._dynamo.config.suppress_errors = True

/home/charlie/skip-residual/gpt-fast/tmp2p5th5_5/main.c:422:1: fatal error: error writing to /tmp/ccxvaT6p.s: No space left on device
  422 | }
      | ^
compilation terminated.
[rank3]: Traceback (most recent call last):
[rank3]:   File "/home/charlie/skip-residual/gpt-fast/benchmark.py", line 708, in <module>
[rank3]:     main(
[rank3]:   File "/home/charlie/skip-residual/gpt-fast/benchmark.py", line 622, in main
[rank3]:     y, decode_latency, prefill_latency = generate(
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
[rank3]:     return func(*args, **kwargs)
[rank3]:   File "/home/charlie/skip-residual/gpt-fast/benchmark.py", line 336, in generate
[rank3]:     next_token = prefill(model, prompt.view(batch_size, -1), input_pos, **sampling_kwargs)
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py", line 556, in _fn
[rank3]:     return fn(*args, **kwargs)
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 1395, in __call__
[rank3]:     return self._torchdynamo_orig_callable(
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 545, in __call__
[rank3]:     return _compile(
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 977, in _compile
[rank3]:     guarded_code = compile_inner(code, one_graph, hooks, transform)
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 706, in compile_inner
[rank3]:     return _compile_inner(code, one_graph, hooks, transform)
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_utils_internal.py", line 95, in wrapper_function
[rank3]:     return function(*args, **kwargs)
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 741, in _compile_inner
[rank3]:     out_code = transform_code_object(code, transform)
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/bytecode_transformation.py", line 1348, in transform_code_object
[rank3]:     transformations(instructions, code_options)
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 229, in _fn
[rank3]:     return fn(*args, **kwargs)
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 658, in transform
[rank3]:     tracer.run()
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 2912, in run
[rank3]:     super().run()
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 1120, in run
[rank3]:     while self.step():
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 1032, in step
[rank3]:     self.dispatch_table[inst.opcode](self, inst)
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 3103, in RETURN_VALUE
[rank3]:     self._return(inst)
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 3088, in _return
[rank3]:     self.output.compile_subgraph(
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/output_graph.py", line 1077, in compile_subgraph
[rank3]:     self.compile_and_call_fx_graph(tx, list(reversed(stack_values)), root)
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/output_graph.py", line 1346, in compile_and_call_fx_graph
[rank3]:     compiled_fn = self.call_user_compiler(gm)
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/output_graph.py", line 1396, in call_user_compiler
[rank3]:     return self._call_user_compiler(gm)
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/output_graph.py", line 1445, in _call_user_compiler
[rank3]:     raise BackendCompilerFailed(self.compiler_fn, e).with_traceback(
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/output_graph.py", line 1426, in _call_user_compiler
[rank3]:     compiled_fn = compiler_fn(gm, self.example_inputs())
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/repro/after_dynamo.py", line 130, in __call__
[rank3]:     compiled_gm = compiler_fn(gm, example_inputs)
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/repro/after_dynamo.py", line 130, in __call__
[rank3]:     compiled_gm = compiler_fn(gm, example_inputs)
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/__init__.py", line 2301, in __call__
[rank3]:     return compile_fx(model_, inputs_, config_patches=self.config)
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 1708, in compile_fx
[rank3]:     return aot_autograd(
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/backends/common.py", line 72, in __call__
[rank3]:     cg = aot_module_simplified(gm, example_inputs, **self.kwargs)
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 1103, in aot_module_simplified
[rank3]:     compiled_fn = dispatch_and_compile()
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 1079, in dispatch_and_compile
[rank3]:     compiled_fn, _ = create_aot_dispatcher_function(
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 527, in create_aot_dispatcher_function
[rank3]:     return _create_aot_dispatcher_function(
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 778, in _create_aot_dispatcher_function
[rank3]:     compiled_fn, fw_metadata = compiler_fn(
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py", line 197, in aot_dispatch_base
[rank3]:     compiled_fw = compiler(fw_module, updated_flat_args)
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 1525, in fw_compiler_base
[rank3]:     return _fw_compiler_base(model, example_inputs, is_inference)
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 1594, in _fw_compiler_base
[rank3]:     return inner_compile(
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 587, in compile_fx_inner
[rank3]:     return wrap_compiler_debug(_compile_fx_inner, compiler_name="inductor")(
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/repro/after_aot.py", line 102, in debug_wrapper
[rank3]:     inner_compiled_fn = compiler_fn(gm, example_inputs)
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 744, in _compile_fx_inner
[rank3]:     compiled_graph = FxGraphCache.load(
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 1515, in load
[rank3]:     compiled_graph = compile_fx_fn(
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 651, in codegen_and_compile
[rank3]:     compiled_graph = fx_codegen_and_compile(gm, example_inputs, **fx_kwargs)
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 962, in fx_codegen_and_compile
[rank3]:     compiled_fn = graph.compile_to_fn()
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/graph.py", line 2034, in compile_to_fn
[rank3]:     return self.compile_to_module().call
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/graph.py", line 1954, in compile_to_module
[rank3]:     return self._compile_to_module()
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/graph.py", line 1988, in _compile_to_module
[rank3]:     mod = PyCodeCache.load_by_key_path(
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 3058, in load_by_key_path
[rank3]:     mod = _reload_python_module(key, path)
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/runtime/compile_tasks.py", line 45, in _reload_python_module
[rank3]:     exec(code, mod.__dict__, mod.__dict__)
[rank3]:   File "/home/charlie/skip-residual/gpt-fast/torchinductor_charlie/5z/c5z3vz6uzcsripapxnkxih546nd5ildsfj7vbd3wnmkyt72awq2j.py", line 1713, in <module>
[rank3]:     async_compile.wait(globals())
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/async_compile.py", line 319, in wait
[rank3]:     scope[key] = result.result()
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 3535, in result
[rank3]:     result = self.future.result()
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/concurrent/futures/_base.py", line 451, in result
[rank3]:     return self.__get_result()
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
[rank3]:     raise self._exception
[rank3]: torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:
[rank3]: SubprocException: An exception occurred in a subprocess:

[rank3]: Traceback (most recent call last):
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_worker/subproc_pool.py", line 280, in do_job
[rank3]:     result = job()
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/runtime/compile_tasks.py", line 68, in _worker_compile_triton
[rank3]:     load_kernel().precompile(warm_cache_only=True)
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/runtime/compile_tasks.py", line 13, in _reload_triton_kernel_in_subproc
[rank3]:     return _module_to_triton_kernel(reload_module(), kernel_name)
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/runtime/compile_tasks.py", line 29, in _reload_python_module_in_subproc
[rank3]:     return codecache.PyCodeCache.load_by_key_path(key, path)
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 3058, in load_by_key_path
[rank3]:     mod = _reload_python_module(key, path)
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/runtime/compile_tasks.py", line 45, in _reload_python_module
[rank3]:     exec(code, mod.__dict__, mod.__dict__)
[rank3]:   File "/home/charlie/skip-residual/gpt-fast/torchinductor_charlie/5d/c5dik2skeg3nig3pcphffj4b5ga64dci4cflf4vgpex4zqgvyibp.py", line 9, in <module>
[rank3]:     triton_helpers.set_driver_to_gpu()
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/runtime/triton_helpers.py", line 57, in set_driver_to_gpu
[rank3]:     driver.set_active(backend.driver())
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/triton/backends/nvidia/driver.py", line 371, in __init__
[rank3]:     self.utils = CudaUtils()  # TODO: make static
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/triton/backends/nvidia/driver.py", line 80, in __init__
[rank3]:     mod = compile_module_from_src(Path(os.path.join(dirname, "driver.c")).read_text(), "cuda_utils")
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/triton/backends/nvidia/driver.py", line 57, in compile_module_from_src
[rank3]:     so = _build(name, src_path, tmpdir, library_dirs(), include_dir, libraries)
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/triton/runtime/build.py", line 48, in _build
[rank3]:     ret = subprocess.check_call(cc_cmd)
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/subprocess.py", line 369, in check_call
[rank3]:     raise CalledProcessError(retcode, cmd)
[rank3]: subprocess.CalledProcessError: Command '['/usr/bin/gcc', '/home/charlie/skip-residual/gpt-fast/tmptnqtxy83/main.c', '-O3', '-shared', '-fPIC', '-o', '/home/charlie/skip-residual/gpt-fast/tmptnqtxy83/cuda_utils.cpython-310-x86_64-linux-gnu.so', '-lcuda', '-L/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/triton/backends/nvidia/lib', '-L/lib/x86_64-linux-gnu', '-I/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/triton/backends/nvidia/include', '-I/home/charlie/skip-residual/gpt-fast/tmptnqtxy83', '-I/home/charlie/anaconda3/envs/gpt-fast/include/python3.10']' returned non-zero exit status 1.


[rank3]: Set TORCH_LOGS="+dynamo" and TORCHDYNAMO_VERBOSE=1 for more information


[rank3]: You can suppress this exception and fall back to eager by setting:
[rank3]:     import torch._dynamo
[rank3]:     torch._dynamo.config.suppress_errors = True

/home/charlie/skip-residual/gpt-fast/tmpx1v1ug0d/main.c:422:1: fatal error: error writing to /tmp/ccvX0DVS.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmp6mfosnld/main.c:422:1: fatal error: error writing to /tmp/ccENEIK2.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpcerffyh1/main.c:422:1: fatal error: error writing to /tmp/ccAU05qv.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmp03ag73ym/main.c:422:1: fatal error: error writing to /tmp/cckWXNwf.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpx3rvmh10/main.c:422:1: fatal error: error writing to /tmp/ccja2iHn.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmp2zgm2pql/main.c:422:1: fatal error: error writing to /tmp/ccLvqIdO.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmp495_etsm/main.c:422:1: fatal error: error writing to /tmp/ccPnr2pF.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpcjhy8vf9/main.c:422:1: fatal error: error writing to /tmp/ccBWAsnu.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmp2l27wcjf/main.c:422:1: fatal error: error writing to /tmp/ccAVqNfb.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmp3rencqqu/main.c:422:1: fatal error: error writing to /tmp/ccuhYcuK.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmp3jap74wj/main.c:422:1: fatal error: error writing to /tmp/ccHtbJdJ.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpiyg5a_yo/main.c:422:1: fatal error: error writing to /tmp/ccT0R1y4.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpa4x8ob0y/main.c:422:1: fatal error: error writing to /tmp/ccIkJIDc.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpgudm8keq/main.c:422:1: fatal error: error writing to /tmp/ccRKkaTw.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpfwpmy87p/main.c:422:1: fatal error: error writing to /tmp/ccE0tPkY.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpq2w0c43b/main.c:422:1: fatal error: error writing to /tmp/cc1uE45N.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmp1o6pvz8t/main.c:422:1: fatal error: error writing to /tmp/ccqLNnym.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmperq88jin/main.c:422:1: fatal error: error writing to /tmp/ccgELFVL.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmp4bedb5lq/main.c:422:1: fatal error: error writing to /tmp/cc7ZN8v2.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmp7xr97yzp/main.c:422:1: fatal error: error writing to /tmp/cclEZSqt.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpy8jt4wx0/main.c:422:1: fatal error: error writing to /tmp/ccaHctL2.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmphblp5ci4/main.c:422:1: fatal error: error writing to /tmp/ccJjcJNv.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmp8zjzstoq/main.c:422:1: fatal error: error writing to /tmp/cco1vBlS.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmp2oys70_u/main.c:422:1: fatal error: error writing to /tmp/ccR8pebp.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpo8c0fkjj/main.c:422:1: fatal error: error writing to /tmp/ccMP9pcx.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpjp58qodp/main.c:422:1: fatal error: error writing to /tmp/ccuFqqb9.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpw8_71_6g/main.c:422:1: fatal error: error writing to /tmp/ccdGJAwq.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmphnmp8zpm/main.c:422:1: fatal error: error writing to /tmp/ccEgI3Cq.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmp5f3ub0dv/main.c:422:1: fatal error: error writing to /tmp/cc7lEPMM.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpn_gj16_j/main.c:422:1: fatal error: error writing to /tmp/ccqCSOTY.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpxaptbt2d/main.c:422:1: fatal error: error writing to /tmp/cc2TfOUZ.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpzjil42lh/main.c:422:1: fatal error: error writing to /tmp/cc93N2f8.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmplp1zvqau/main.c:422:1: fatal error: error writing to /tmp/ccaspTvA.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmprmjwma25/main.c:422:1: fatal error: error writing to /tmp/cc34WYjH.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpw6c8yw3d/main.c:422:1: fatal error: error writing to /tmp/cc7J2jKa.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpxx3mqpcr/main.c:422:1: fatal error: error writing to /tmp/ccOcYcdB.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpf9rwemxk/main.c:422:1: fatal error: error writing to /tmp/ccTDFlz9.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpzux_cr3t/main.c:422:1: fatal error: error writing to /tmp/ccZ2J2ez.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmp28y91nmn/main.c:422:1: fatal error: error writing to /tmp/ccsy8pNH.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpt49d577d/main.c:422:1: fatal error: error writing to /tmp/cciwhMSR.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmp4xyk8ybp/main.c:422:1: fatal error: error writing to /tmp/ccwqlJeW.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpnrneh225/main.c:422:1: fatal error: error writing to /tmp/ccLfxnc8.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpcb4ozlg7/main.c:422:1: fatal error: error writing to /tmp/cc8kRsBU.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpqemqzr3n/main.c:422:1: fatal error: error writing to /tmp/ccONFDxD.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpmb6qwk6g/main.c:422:1: fatal error: error writing to /tmp/cc08fZyY.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpb3ysdsnz/main.c:422:1: fatal error: error writing to /tmp/ccPhYHk8.s: No space left on device
  422 | }
      | ^
compilation terminated.
[rank4]: Traceback (most recent call last):
[rank4]:   File "/home/charlie/skip-residual/gpt-fast/benchmark.py", line 708, in <module>
[rank4]:     main(
[rank4]:   File "/home/charlie/skip-residual/gpt-fast/benchmark.py", line 622, in main
[rank4]:     y, decode_latency, prefill_latency = generate(
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
[rank4]:     return func(*args, **kwargs)
[rank4]:   File "/home/charlie/skip-residual/gpt-fast/benchmark.py", line 336, in generate
[rank4]:     next_token = prefill(model, prompt.view(batch_size, -1), input_pos, **sampling_kwargs)
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py", line 556, in _fn
[rank4]:     return fn(*args, **kwargs)
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 1395, in __call__
[rank4]:     return self._torchdynamo_orig_callable(
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 545, in __call__
[rank4]:     return _compile(
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 977, in _compile
[rank4]:     guarded_code = compile_inner(code, one_graph, hooks, transform)
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 706, in compile_inner
[rank4]:     return _compile_inner(code, one_graph, hooks, transform)
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_utils_internal.py", line 95, in wrapper_function
[rank4]:     return function(*args, **kwargs)
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 741, in _compile_inner
[rank4]:     out_code = transform_code_object(code, transform)
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/bytecode_transformation.py", line 1348, in transform_code_object
[rank4]:     transformations(instructions, code_options)
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 229, in _fn
[rank4]:     return fn(*args, **kwargs)
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 658, in transform
[rank4]:     tracer.run()
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 2912, in run
[rank4]:     super().run()
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 1120, in run
[rank4]:     while self.step():
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 1032, in step
[rank4]:     self.dispatch_table[inst.opcode](self, inst)
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 3103, in RETURN_VALUE
[rank4]:     self._return(inst)
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 3088, in _return
[rank4]:     self.output.compile_subgraph(
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/output_graph.py", line 1077, in compile_subgraph
[rank4]:     self.compile_and_call_fx_graph(tx, list(reversed(stack_values)), root)
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/output_graph.py", line 1346, in compile_and_call_fx_graph
[rank4]:     compiled_fn = self.call_user_compiler(gm)
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/output_graph.py", line 1396, in call_user_compiler
[rank4]:     return self._call_user_compiler(gm)
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/output_graph.py", line 1445, in _call_user_compiler
[rank4]:     raise BackendCompilerFailed(self.compiler_fn, e).with_traceback(
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/output_graph.py", line 1426, in _call_user_compiler
[rank4]:     compiled_fn = compiler_fn(gm, self.example_inputs())
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/repro/after_dynamo.py", line 130, in __call__
[rank4]:     compiled_gm = compiler_fn(gm, example_inputs)
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/repro/after_dynamo.py", line 130, in __call__
[rank4]:     compiled_gm = compiler_fn(gm, example_inputs)
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/__init__.py", line 2301, in __call__
[rank4]:     return compile_fx(model_, inputs_, config_patches=self.config)
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 1708, in compile_fx
[rank4]:     return aot_autograd(
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/backends/common.py", line 72, in __call__
[rank4]:     cg = aot_module_simplified(gm, example_inputs, **self.kwargs)
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 1103, in aot_module_simplified
[rank4]:     compiled_fn = dispatch_and_compile()
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 1079, in dispatch_and_compile
[rank4]:     compiled_fn, _ = create_aot_dispatcher_function(
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 527, in create_aot_dispatcher_function
[rank4]:     return _create_aot_dispatcher_function(
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 778, in _create_aot_dispatcher_function
[rank4]:     compiled_fn, fw_metadata = compiler_fn(
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py", line 197, in aot_dispatch_base
[rank4]:     compiled_fw = compiler(fw_module, updated_flat_args)
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 1525, in fw_compiler_base
[rank4]:     return _fw_compiler_base(model, example_inputs, is_inference)
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 1594, in _fw_compiler_base
[rank4]:     return inner_compile(
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 587, in compile_fx_inner
[rank4]:     return wrap_compiler_debug(_compile_fx_inner, compiler_name="inductor")(
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/repro/after_aot.py", line 102, in debug_wrapper
[rank4]:     inner_compiled_fn = compiler_fn(gm, example_inputs)
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 744, in _compile_fx_inner
[rank4]:     compiled_graph = FxGraphCache.load(
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 1515, in load
[rank4]:     compiled_graph = compile_fx_fn(
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 651, in codegen_and_compile
[rank4]:     compiled_graph = fx_codegen_and_compile(gm, example_inputs, **fx_kwargs)
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 962, in fx_codegen_and_compile
[rank4]:     compiled_fn = graph.compile_to_fn()
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/graph.py", line 2034, in compile_to_fn
[rank4]:     return self.compile_to_module().call
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/graph.py", line 1954, in compile_to_module
[rank4]:     return self._compile_to_module()
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/graph.py", line 1988, in _compile_to_module
[rank4]:     mod = PyCodeCache.load_by_key_path(
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 3058, in load_by_key_path
[rank4]:     mod = _reload_python_module(key, path)
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/runtime/compile_tasks.py", line 45, in _reload_python_module
[rank4]:     exec(code, mod.__dict__, mod.__dict__)
[rank4]:   File "/home/charlie/skip-residual/gpt-fast/torchinductor_charlie/7p/c7prezew4lepupa6skg44zpq6azjnfmb2hnyn4pgx2qfuqqiwbxd.py", line 1713, in <module>
[rank4]:     async_compile.wait(globals())
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/async_compile.py", line 319, in wait
[rank4]:     scope[key] = result.result()
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 3535, in result
[rank4]:     result = self.future.result()
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/concurrent/futures/_base.py", line 451, in result
[rank4]:     return self.__get_result()
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
[rank4]:     raise self._exception
[rank4]: torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:
[rank4]: SubprocException: An exception occurred in a subprocess:

[rank4]: Traceback (most recent call last):
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_worker/subproc_pool.py", line 280, in do_job
[rank4]:     result = job()
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/runtime/compile_tasks.py", line 68, in _worker_compile_triton
[rank4]:     load_kernel().precompile(warm_cache_only=True)
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/runtime/compile_tasks.py", line 13, in _reload_triton_kernel_in_subproc
[rank4]:     return _module_to_triton_kernel(reload_module(), kernel_name)
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/runtime/compile_tasks.py", line 29, in _reload_python_module_in_subproc
[rank4]:     return codecache.PyCodeCache.load_by_key_path(key, path)
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 3058, in load_by_key_path
[rank4]:     mod = _reload_python_module(key, path)
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/runtime/compile_tasks.py", line 45, in _reload_python_module
[rank4]:     exec(code, mod.__dict__, mod.__dict__)
[rank4]:   File "/home/charlie/skip-residual/gpt-fast/torchinductor_charlie/5y/c5yibkmsag7hsr5pw7jihvrlv6sp2k75hm5hk26xrmojgegz5rgt.py", line 9, in <module>
[rank4]:     triton_helpers.set_driver_to_gpu()
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/runtime/triton_helpers.py", line 57, in set_driver_to_gpu
[rank4]:     driver.set_active(backend.driver())
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/triton/backends/nvidia/driver.py", line 371, in __init__
[rank4]:     self.utils = CudaUtils()  # TODO: make static
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/triton/backends/nvidia/driver.py", line 80, in __init__
[rank4]:     mod = compile_module_from_src(Path(os.path.join(dirname, "driver.c")).read_text(), "cuda_utils")
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/triton/backends/nvidia/driver.py", line 57, in compile_module_from_src
[rank4]:     so = _build(name, src_path, tmpdir, library_dirs(), include_dir, libraries)
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/triton/runtime/build.py", line 48, in _build
[rank4]:     ret = subprocess.check_call(cc_cmd)
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/subprocess.py", line 369, in check_call
[rank4]:     raise CalledProcessError(retcode, cmd)
[rank4]: subprocess.CalledProcessError: Command '['/usr/bin/gcc', '/home/charlie/skip-residual/gpt-fast/tmp4xyk8ybp/main.c', '-O3', '-shared', '-fPIC', '-o', '/home/charlie/skip-residual/gpt-fast/tmp4xyk8ybp/cuda_utils.cpython-310-x86_64-linux-gnu.so', '-lcuda', '-L/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/triton/backends/nvidia/lib', '-L/lib/x86_64-linux-gnu', '-I/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/triton/backends/nvidia/include', '-I/home/charlie/skip-residual/gpt-fast/tmp4xyk8ybp', '-I/home/charlie/anaconda3/envs/gpt-fast/include/python3.10']' returned non-zero exit status 1.


[rank4]: Set TORCH_LOGS="+dynamo" and TORCHDYNAMO_VERBOSE=1 for more information


[rank4]: You can suppress this exception and fall back to eager by setting:
[rank4]:     import torch._dynamo
[rank4]:     torch._dynamo.config.suppress_errors = True

/home/charlie/skip-residual/gpt-fast/tmpibe6h8o5/main.c:422:1: fatal error: error writing to /tmp/ccjSVR3p.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpd44o9dh5/main.c:422:1: fatal error: error writing to /tmp/ccjyRpgR.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpb5zu_g_v/main.c:422:1: fatal error: error writing to /tmp/ccLZB1v0.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpc3c1_78f/main.c:422:1: fatal error: error writing to /tmp/ccAIBKd0.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpy08i40t4/main.c:422:1: fatal error: error writing to /tmp/ccvL9jJl.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmp6nlaec7t/main.c:422:1: fatal error: error writing to /tmp/ccifdix0.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpido0mn4p/main.c:422:1: fatal error: error writing to /tmp/ccqWJXay.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpvlyggags/main.c:422:1: fatal error: error writing to /tmp/ccivH8PR.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmptqoanw8c/main.c:422:1: fatal error: error writing to /tmp/cc2XmI7F.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmp4myugk7j/main.c:422:1: fatal error: error writing to /tmp/cc7GlYRy.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmp2aq20co3/main.c:422:1: fatal error: error writing to /tmp/ccuo95tW.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmplapc0ueo/main.c:422:1: fatal error: error writing to /tmp/ccqUvWRH.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpqe0quddw/main.c:422:1: fatal error: error writing to /tmp/ccVvpiS2.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmp9uh8_1xe/main.c:422:1: fatal error: error writing to /tmp/ccua6IYJ.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpdejkt_0o/main.c:422:1: fatal error: error writing to /tmp/ccSq8B5H.s: No space left on device
  422 | }
      | ^
compilation terminated.
[rank0]:[W1201 10:48:45.978217277 ProcessGroupNCCL.cpp:1374] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
[rank5]:[W1201 10:48:46.615836294 ProcessGroupNCCL.cpp:1374] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
[rank2]:[W1201 10:48:46.918449530 ProcessGroupNCCL.cpp:1374] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
[rank1]:[W1201 10:48:46.147385594 ProcessGroupNCCL.cpp:1374] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
[rank7]:[W1201 10:48:47.359291827 ProcessGroupNCCL.cpp:1374] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
[rank3]:[W1201 10:48:47.674889551 ProcessGroupNCCL.cpp:1374] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
[rank4]:[W1201 10:48:47.825591666 ProcessGroupNCCL.cpp:1374] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
[rank6]:[W1201 10:48:47.882374761 ProcessGroupNCCL.cpp:1374] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
W1201 10:48:48.131000 417574 site-packages/torch/distributed/elastic/multiprocessing/api.py:897] Sending process 417645 closing signal SIGTERM
W1201 10:48:48.133000 417574 site-packages/torch/distributed/elastic/multiprocessing/api.py:897] Sending process 417646 closing signal SIGTERM
W1201 10:48:48.136000 417574 site-packages/torch/distributed/elastic/multiprocessing/api.py:897] Sending process 417647 closing signal SIGTERM
W1201 10:48:48.139000 417574 site-packages/torch/distributed/elastic/multiprocessing/api.py:897] Sending process 417648 closing signal SIGTERM
W1201 10:48:48.142000 417574 site-packages/torch/distributed/elastic/multiprocessing/api.py:897] Sending process 417649 closing signal SIGTERM
W1201 10:48:48.168000 417574 site-packages/torch/distributed/elastic/multiprocessing/api.py:897] Sending process 417650 closing signal SIGTERM
W1201 10:48:48.174000 417574 site-packages/torch/distributed/elastic/multiprocessing/api.py:897] Sending process 417651 closing signal SIGTERM
E1201 10:48:48.966000 417574 site-packages/torch/distributed/elastic/multiprocessing/api.py:869] failed (exitcode: 1) local_rank: 0 (pid: 417644) of binary: /home/charlie/anaconda3/envs/gpt-fast/bin/python
Traceback (most recent call last):
  File "/home/charlie/anaconda3/envs/gpt-fast/bin/torchrun", line 8, in <module>
    sys.exit(main())
  File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 355, in wrapper
    return f(*args, **kwargs)
  File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/distributed/run.py", line 919, in main
    run(args)
  File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/distributed/run.py", line 910, in run
    elastic_launch(
  File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 138, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 269, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
benchmark.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2024-12-01_10:48:48
  host      : mk-xii-22.cloud.together.ai
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 417644)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
