W1201 11:45:06.630000 484034 site-packages/torch/distributed/run.py:793] 
W1201 11:45:06.630000 484034 site-packages/torch/distributed/run.py:793] *****************************************
W1201 11:45:06.630000 484034 site-packages/torch/distributed/run.py:793] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W1201 11:45:06.630000 484034 site-packages/torch/distributed/run.py:793] *****************************************
DeviceMesh('cuda', [[0, 1, 2, 3, 4, 5, 6, 7]], mesh_dim_names=('pp', 'tp'))
Using device=cuda
Loading model ...
DeviceMesh('cuda', [[0, 1, 2, 3, 4, 5, 6, 7]], mesh_dim_names=('pp', 'tp'))
DeviceMesh('cuda', [[0, 1, 2, 3, 4, 5, 6, 7]], mesh_dim_names=('pp', 'tp'))
DeviceMesh('cuda', [[0, 1, 2, 3, 4, 5, 6, 7]], mesh_dim_names=('pp', 'tp'))
DeviceMesh('cuda', [[0, 1, 2, 3, 4, 5, 6, 7]], mesh_dim_names=('pp', 'tp'))
DeviceMesh('cuda', [[0, 1, 2, 3, 4, 5, 6, 7]], mesh_dim_names=('pp', 'tp'))
DeviceMesh('cuda', [[0, 1, 2, 3, 4, 5, 6, 7]], mesh_dim_names=('pp', 'tp'))
DeviceMesh('cuda', [[0, 1, 2, 3, 4, 5, 6, 7]], mesh_dim_names=('pp', 'tp'))
GPTParallel(
  (tok_embeddings): Embedding(128256, 8192)
  (layers): ModuleList(
    (0-79): 80 x ParallelTransformerBlock(
      semi_compiled = False
      (attention): FuseAttentionMLP(
        (wqkv1): Linear(in_features=8192, out_features=8448, bias=False)
        (wo): Linear(in_features=1024, out_features=8192, bias=False)
        (w2): Linear(in_features=3584, out_features=8192, bias=False)
      )
      (attention_norm): RMSNorm()
    )
  )
  (norm): RMSNorm()
  (output): Linear(in_features=8192, out_features=128256, bias=False)
)
Time to load model: 1.35 seconds
Compiling prefill with dynamic=False
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py:222: UserWarning: TensorFloat32 tensor cores for float32 matrix multiplication available but not enabled. Consider setting `torch.set_float32_matmul_precision('high')` for better performance.
  warnings.warn(
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py:222: UserWarning: TensorFloat32 tensor cores for float32 matrix multiplication available but not enabled. Consider setting `torch.set_float32_matmul_precision('high')` for better performance.
  warnings.warn(
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py:222: UserWarning: TensorFloat32 tensor cores for float32 matrix multiplication available but not enabled. Consider setting `torch.set_float32_matmul_precision('high')` for better performance.
  warnings.warn(
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py:222: UserWarning: TensorFloat32 tensor cores for float32 matrix multiplication available but not enabled. Consider setting `torch.set_float32_matmul_precision('high')` for better performance.
  warnings.warn(
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py:222: UserWarning: TensorFloat32 tensor cores for float32 matrix multiplication available but not enabled. Consider setting `torch.set_float32_matmul_precision('high')` for better performance.
  warnings.warn(
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py:222: UserWarning: TensorFloat32 tensor cores for float32 matrix multiplication available but not enabled. Consider setting `torch.set_float32_matmul_precision('high')` for better performance.
  warnings.warn(
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py:222: UserWarning: TensorFloat32 tensor cores for float32 matrix multiplication available but not enabled. Consider setting `torch.set_float32_matmul_precision('high')` for better performance.
  warnings.warn(
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py:222: UserWarning: TensorFloat32 tensor cores for float32 matrix multiplication available but not enabled. Consider setting `torch.set_float32_matmul_precision('high')` for better performance.
  warnings.warn(
/home/charlie/skip-residual/gpt-fast/tmp176rox96/main.c:422:1: fatal error: error writing to /tmp/ccGPZWhp.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpxyt6hgrw/main.c:422:1: fatal error: error writing to /tmp/cclvJNIk.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpl0z0sm5m/main.c:422:1: fatal error: error writing to /tmp/cczslAfy.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmp6yfiqyne/main.c:422:1: fatal error: error writing to /tmp/ccNxgnuJ.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpacg_c433/main.c:422:1: fatal error: error writing to /tmp/cckzBd7N.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpdov3gniw/main.c:422:1: fatal error: error writing to /tmp/ccDlWvkh.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmp7wu59f_9/main.c:422:1: fatal error: error writing to /tmp/ccWXmT0h.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpqpu4wvo0/main.c:422:1: fatal error: error writing to /tmp/cckdWPlr.s: No space left on device
  422 | }
      | ^
compilation terminated.
[rank2]: Traceback (most recent call last):
[rank2]:   File "/home/charlie/skip-residual/gpt-fast/benchmark.py", line 708, in <module>
[rank2]:     main(
[rank2]:   File "/home/charlie/skip-residual/gpt-fast/benchmark.py", line 622, in main
[rank2]:     y, decode_latency, prefill_latency = generate(
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
[rank2]:     return func(*args, **kwargs)
[rank2]:   File "/home/charlie/skip-residual/gpt-fast/benchmark.py", line 336, in generate
[rank2]:     next_token = prefill(model, prompt.view(batch_size, -1), input_pos, **sampling_kwargs)
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py", line 556, in _fn
[rank2]:     return fn(*args, **kwargs)
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 1395, in __call__
[rank2]:     return self._torchdynamo_orig_callable(
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 545, in __call__
[rank2]:     return _compile(
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 977, in _compile
[rank2]:     guarded_code = compile_inner(code, one_graph, hooks, transform)
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 706, in compile_inner
[rank2]:     return _compile_inner(code, one_graph, hooks, transform)
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_utils_internal.py", line 95, in wrapper_function
[rank2]:     return function(*args, **kwargs)
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 741, in _compile_inner
[rank2]:     out_code = transform_code_object(code, transform)
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/bytecode_transformation.py", line 1348, in transform_code_object
[rank2]:     transformations(instructions, code_options)
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 229, in _fn
[rank2]:     return fn(*args, **kwargs)
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 658, in transform
[rank2]:     tracer.run()
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 2912, in run
[rank2]:     super().run()
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 1120, in run
[rank2]:     while self.step():
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 1032, in step
[rank2]:     self.dispatch_table[inst.opcode](self, inst)
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 3103, in RETURN_VALUE
[rank2]:     self._return(inst)
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 3088, in _return
[rank2]:     self.output.compile_subgraph(
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/output_graph.py", line 1077, in compile_subgraph
[rank2]:     self.compile_and_call_fx_graph(tx, list(reversed(stack_values)), root)
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/output_graph.py", line 1346, in compile_and_call_fx_graph
[rank2]:     compiled_fn = self.call_user_compiler(gm)
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/output_graph.py", line 1396, in call_user_compiler
[rank2]:     return self._call_user_compiler(gm)
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/output_graph.py", line 1445, in _call_user_compiler
[rank2]:     raise BackendCompilerFailed(self.compiler_fn, e).with_traceback(
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/output_graph.py", line 1426, in _call_user_compiler
[rank2]:     compiled_fn = compiler_fn(gm, self.example_inputs())
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/repro/after_dynamo.py", line 130, in __call__
[rank2]:     compiled_gm = compiler_fn(gm, example_inputs)
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/repro/after_dynamo.py", line 130, in __call__
[rank2]:     compiled_gm = compiler_fn(gm, example_inputs)
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/__init__.py", line 2301, in __call__
[rank2]:     return compile_fx(model_, inputs_, config_patches=self.config)
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 1708, in compile_fx
[rank2]:     return aot_autograd(
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/backends/common.py", line 72, in __call__
[rank2]:     cg = aot_module_simplified(gm, example_inputs, **self.kwargs)
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 1103, in aot_module_simplified
[rank2]:     compiled_fn = dispatch_and_compile()
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 1079, in dispatch_and_compile
[rank2]:     compiled_fn, _ = create_aot_dispatcher_function(
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 527, in create_aot_dispatcher_function
[rank2]:     return _create_aot_dispatcher_function(
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 778, in _create_aot_dispatcher_function
[rank2]:     compiled_fn, fw_metadata = compiler_fn(
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py", line 197, in aot_dispatch_base
[rank2]:     compiled_fw = compiler(fw_module, updated_flat_args)
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 1525, in fw_compiler_base
[rank2]:     return _fw_compiler_base(model, example_inputs, is_inference)
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 1594, in _fw_compiler_base
[rank2]:     return inner_compile(
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 587, in compile_fx_inner
[rank2]:     return wrap_compiler_debug(_compile_fx_inner, compiler_name="inductor")(
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/repro/after_aot.py", line 102, in debug_wrapper
[rank2]:     inner_compiled_fn = compiler_fn(gm, example_inputs)
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 744, in _compile_fx_inner
[rank2]:     compiled_graph = FxGraphCache.load(
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 1515, in load
[rank2]:     compiled_graph = compile_fx_fn(
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 651, in codegen_and_compile
[rank2]:     compiled_graph = fx_codegen_and_compile(gm, example_inputs, **fx_kwargs)
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 962, in fx_codegen_and_compile
[rank2]:     compiled_fn = graph.compile_to_fn()
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/graph.py", line 2034, in compile_to_fn
[rank2]:     return self.compile_to_module().call
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/graph.py", line 1954, in compile_to_module
[rank2]:     return self._compile_to_module()
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/graph.py", line 1988, in _compile_to_module
[rank2]:     mod = PyCodeCache.load_by_key_path(
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 3058, in load_by_key_path
[rank2]:     mod = _reload_python_module(key, path)
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/runtime/compile_tasks.py", line 45, in _reload_python_module
[rank2]:     exec(code, mod.__dict__, mod.__dict__)
[rank2]:   File "/home/charlie/skip-residual/gpt-fast/torchinductor_charlie/m2/cm2lum2zzvjwkeaxsz5czkbhl7af6aqricm2d7pl2zocpnhb2iqb.py", line 1752, in <module>
[rank2]:     async_compile.wait(globals())
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/async_compile.py", line 319, in wait
[rank2]:     scope[key] = result.result()
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 3535, in result
[rank2]:     result = self.future.result()
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/concurrent/futures/_base.py", line 458, in result
[rank2]:     return self.__get_result()
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
[rank2]:     raise self._exception
[rank2]: torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:
[rank2]: SubprocException: An exception occurred in a subprocess:

[rank2]: Traceback (most recent call last):
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_worker/subproc_pool.py", line 280, in do_job
[rank2]:     result = job()
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/runtime/compile_tasks.py", line 68, in _worker_compile_triton
[rank2]:     load_kernel().precompile(warm_cache_only=True)
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/runtime/compile_tasks.py", line 13, in _reload_triton_kernel_in_subproc
[rank2]:     return _module_to_triton_kernel(reload_module(), kernel_name)
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/runtime/compile_tasks.py", line 29, in _reload_python_module_in_subproc
[rank2]:     return codecache.PyCodeCache.load_by_key_path(key, path)
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 3058, in load_by_key_path
[rank2]:     mod = _reload_python_module(key, path)
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/runtime/compile_tasks.py", line 45, in _reload_python_module
[rank2]:     exec(code, mod.__dict__, mod.__dict__)
[rank2]:   File "/home/charlie/skip-residual/gpt-fast/torchinductor_charlie/su/csuf6i5jrqjakzt6o3ji5lw6hvjcigx5ybgxhokftsitmqfe5phk.py", line 9, in <module>
[rank2]:     triton_helpers.set_driver_to_gpu()
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/runtime/triton_helpers.py", line 57, in set_driver_to_gpu
[rank2]:     driver.set_active(backend.driver())
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/triton/backends/nvidia/driver.py", line 371, in __init__
[rank2]:     self.utils = CudaUtils()  # TODO: make static
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/triton/backends/nvidia/driver.py", line 80, in __init__
[rank2]:     mod = compile_module_from_src(Path(os.path.join(dirname, "driver.c")).read_text(), "cuda_utils")
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/triton/backends/nvidia/driver.py", line 57, in compile_module_from_src
[rank2]:     so = _build(name, src_path, tmpdir, library_dirs(), include_dir, libraries)
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/triton/runtime/build.py", line 48, in _build
[rank2]:     ret = subprocess.check_call(cc_cmd)
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/subprocess.py", line 369, in check_call
[rank2]:     raise CalledProcessError(retcode, cmd)
[rank2]: subprocess.CalledProcessError: Command '['/usr/bin/gcc', '/home/charlie/skip-residual/gpt-fast/tmp6yfiqyne/main.c', '-O3', '-shared', '-fPIC', '-o', '/home/charlie/skip-residual/gpt-fast/tmp6yfiqyne/cuda_utils.cpython-310-x86_64-linux-gnu.so', '-lcuda', '-L/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/triton/backends/nvidia/lib', '-L/lib/x86_64-linux-gnu', '-I/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/triton/backends/nvidia/include', '-I/home/charlie/skip-residual/gpt-fast/tmp6yfiqyne', '-I/home/charlie/anaconda3/envs/gpt-fast/include/python3.10']' returned non-zero exit status 1.


[rank2]: Set TORCH_LOGS="+dynamo" and TORCHDYNAMO_VERBOSE=1 for more information


[rank2]: You can suppress this exception and fall back to eager by setting:
[rank2]:     import torch._dynamo
[rank2]:     torch._dynamo.config.suppress_errors = True

/home/charlie/skip-residual/gpt-fast/tmpzovkug2x/main.c:422:1: fatal error: error writing to /tmp/ccoRBwwp.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpxsm15w87/main.c:422:1: fatal error: error writing to /tmp/ccQhmgGI.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmp9005_vcs/main.c:422:1: fatal error: error writing to /tmp/ccme7RFO.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpfp6wn3c5/main.c:422:1: fatal error: error writing to /tmp/cc2H8hNf.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmp8eamngoy/main.c:422:1: fatal error: error writing to /tmp/ccK94mes.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpn5yka5dr/main.c:422:1: fatal error: error writing to /tmp/cc3qPAlZ.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpp99i6k7v/main.c:422:1: fatal error: error writing to /tmp/ccv1E8Jp.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpfcuupndi/main.c:422:1: fatal error: error writing to /tmp/ccXbM18Z.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmp6vvck2_5/main.c:422:1: fatal error: error writing to /tmp/ccXqUkBY.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpwmitcu72/main.c:422:1: fatal error: error writing to /tmp/ccXzPIf1.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmp5zcep7ng/main.c:422:1: fatal error: error writing to /tmp/ccpOMK9p.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpj43_28bf/main.c:422:1: fatal error: error writing to /tmp/ccKxniyt.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmppx1u9psb/main.c:422:1: fatal error: error writing to /tmp/cc8Mi6KY.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmp08it6gwd/main.c:422:1: fatal error: error writing to /tmp/ccMsHnig.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpi70j3l11/main.c:422:1: fatal error: error writing to /tmp/ccHfQ07D.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpneqkoccx/main.c:422:1: fatal error: error writing to /tmp/ccuzvdBw.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpxuk6bck9/main.c:422:1: fatal error: error writing to /tmp/ccdRgdQX.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmprpp63ekj/main.c:422:1: fatal error: error writing to /tmp/ccVpTIpb.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpawwu_jz9/main.c:422:1: fatal error: error writing to /tmp/ccmARHI9.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpft36jytv/main.c:422:1: fatal error: error writing to /tmp/ccYoY3Iw.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmp0u9mu_db/main.c:422:1: fatal error: error writing to /tmp/ccjvdq5I.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmp86zi626w/main.c:422:1: fatal error: error writing to /tmp/cc5BOJGy.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpwpr7f7le/main.c:422:1: fatal error: error writing to /tmp/ccqcBi2D.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpdv6y31g5/main.c:422:1: fatal error: error writing to /tmp/cciciIgp.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpo6x_hjl9/main.c:422:1: fatal error: error writing to /tmp/ccJ311tm.s: No space left on device
  422 | }
      | ^
compilation terminated.
[rank5]: Traceback (most recent call last):
[rank5]:   File "/home/charlie/skip-residual/gpt-fast/benchmark.py", line 708, in <module>
[rank5]:     main(
[rank5]:   File "/home/charlie/skip-residual/gpt-fast/benchmark.py", line 622, in main
[rank5]:     y, decode_latency, prefill_latency = generate(
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
[rank5]:     return func(*args, **kwargs)
[rank5]:   File "/home/charlie/skip-residual/gpt-fast/benchmark.py", line 336, in generate
[rank5]:     next_token = prefill(model, prompt.view(batch_size, -1), input_pos, **sampling_kwargs)
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py", line 556, in _fn
[rank5]:     return fn(*args, **kwargs)
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 1395, in __call__
[rank5]:     return self._torchdynamo_orig_callable(
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 545, in __call__
[rank5]:     return _compile(
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 977, in _compile
[rank5]:     guarded_code = compile_inner(code, one_graph, hooks, transform)
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 706, in compile_inner
[rank5]:     return _compile_inner(code, one_graph, hooks, transform)
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_utils_internal.py", line 95, in wrapper_function
[rank5]:     return function(*args, **kwargs)
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 741, in _compile_inner
[rank5]:     out_code = transform_code_object(code, transform)
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/bytecode_transformation.py", line 1348, in transform_code_object
[rank5]:     transformations(instructions, code_options)
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 229, in _fn
[rank5]:     return fn(*args, **kwargs)
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 658, in transform
[rank5]:     tracer.run()
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 2912, in run
[rank5]:     super().run()
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 1120, in run
[rank5]:     while self.step():
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 1032, in step
[rank5]:     self.dispatch_table[inst.opcode](self, inst)
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 3103, in RETURN_VALUE
[rank5]:     self._return(inst)
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 3088, in _return
[rank5]:     self.output.compile_subgraph(
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/output_graph.py", line 1077, in compile_subgraph
[rank5]:     self.compile_and_call_fx_graph(tx, list(reversed(stack_values)), root)
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/output_graph.py", line 1346, in compile_and_call_fx_graph
[rank5]:     compiled_fn = self.call_user_compiler(gm)
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/output_graph.py", line 1396, in call_user_compiler
[rank5]:     return self._call_user_compiler(gm)
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/output_graph.py", line 1445, in _call_user_compiler
[rank5]:     raise BackendCompilerFailed(self.compiler_fn, e).with_traceback(
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/output_graph.py", line 1426, in _call_user_compiler
[rank5]:     compiled_fn = compiler_fn(gm, self.example_inputs())
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/repro/after_dynamo.py", line 130, in __call__
[rank5]:     compiled_gm = compiler_fn(gm, example_inputs)
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/repro/after_dynamo.py", line 130, in __call__
[rank5]:     compiled_gm = compiler_fn(gm, example_inputs)
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/__init__.py", line 2301, in __call__
[rank5]:     return compile_fx(model_, inputs_, config_patches=self.config)
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 1708, in compile_fx
[rank5]:     return aot_autograd(
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/backends/common.py", line 72, in __call__
[rank5]:     cg = aot_module_simplified(gm, example_inputs, **self.kwargs)
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 1103, in aot_module_simplified
[rank5]:     compiled_fn = dispatch_and_compile()
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 1079, in dispatch_and_compile
[rank5]:     compiled_fn, _ = create_aot_dispatcher_function(
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 527, in create_aot_dispatcher_function
[rank5]:     return _create_aot_dispatcher_function(
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 778, in _create_aot_dispatcher_function
[rank5]:     compiled_fn, fw_metadata = compiler_fn(
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py", line 197, in aot_dispatch_base
[rank5]:     compiled_fw = compiler(fw_module, updated_flat_args)
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 1525, in fw_compiler_base
[rank5]:     return _fw_compiler_base(model, example_inputs, is_inference)
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 1594, in _fw_compiler_base
[rank5]:     return inner_compile(
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 587, in compile_fx_inner
[rank5]:     return wrap_compiler_debug(_compile_fx_inner, compiler_name="inductor")(
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/repro/after_aot.py", line 102, in debug_wrapper
[rank5]:     inner_compiled_fn = compiler_fn(gm, example_inputs)
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 744, in _compile_fx_inner
[rank5]:     compiled_graph = FxGraphCache.load(
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 1515, in load
[rank5]:     compiled_graph = compile_fx_fn(
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 651, in codegen_and_compile
[rank5]:     compiled_graph = fx_codegen_and_compile(gm, example_inputs, **fx_kwargs)
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 962, in fx_codegen_and_compile
[rank5]:     compiled_fn = graph.compile_to_fn()
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/graph.py", line 2034, in compile_to_fn
[rank5]:     return self.compile_to_module().call
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/graph.py", line 1954, in compile_to_module
[rank5]:     return self._compile_to_module()
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/graph.py", line 1988, in _compile_to_module
[rank5]:     mod = PyCodeCache.load_by_key_path(
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 3058, in load_by_key_path
[rank5]:     mod = _reload_python_module(key, path)
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/runtime/compile_tasks.py", line 45, in _reload_python_module
[rank5]:     exec(code, mod.__dict__, mod.__dict__)
[rank5]:   File "/home/charlie/skip-residual/gpt-fast/torchinductor_charlie/jp/cjpw2m6c5cag7wmf3z2cvju3lgsld2ue4xgvfd25fe4kzmtmiuo6.py", line 1752, in <module>
[rank5]:     async_compile.wait(globals())
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/async_compile.py", line 319, in wait
[rank5]:     scope[key] = result.result()
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 3535, in result
[rank5]:     result = self.future.result()
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/concurrent/futures/_base.py", line 458, in result
[rank5]:     return self.__get_result()
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
[rank5]:     raise self._exception
[rank5]: torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:
[rank5]: SubprocException: An exception occurred in a subprocess:

[rank5]: Traceback (most recent call last):
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_worker/subproc_pool.py", line 280, in do_job
[rank5]:     result = job()
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/runtime/compile_tasks.py", line 68, in _worker_compile_triton
[rank5]:     load_kernel().precompile(warm_cache_only=True)
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/runtime/compile_tasks.py", line 13, in _reload_triton_kernel_in_subproc
[rank5]:     return _module_to_triton_kernel(reload_module(), kernel_name)
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/runtime/compile_tasks.py", line 29, in _reload_python_module_in_subproc
[rank5]:     return codecache.PyCodeCache.load_by_key_path(key, path)
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 3058, in load_by_key_path
[rank5]:     mod = _reload_python_module(key, path)
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/runtime/compile_tasks.py", line 45, in _reload_python_module
[rank5]:     exec(code, mod.__dict__, mod.__dict__)
[rank5]:   File "/home/charlie/skip-residual/gpt-fast/torchinductor_charlie/j2/cj23k5l3j4wehptlrrja3ja7nf3cpuix4shdvhfwozftrqkv4tol.py", line 9, in <module>
[rank5]:     triton_helpers.set_driver_to_gpu()
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/runtime/triton_helpers.py", line 57, in set_driver_to_gpu
[rank5]:     driver.set_active(backend.driver())
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/triton/backends/nvidia/driver.py", line 371, in __init__
[rank5]:     self.utils = CudaUtils()  # TODO: make static
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/triton/backends/nvidia/driver.py", line 80, in __init__
[rank5]:     mod = compile_module_from_src(Path(os.path.join(dirname, "driver.c")).read_text(), "cuda_utils")
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/triton/backends/nvidia/driver.py", line 57, in compile_module_from_src
[rank5]:     so = _build(name, src_path, tmpdir, library_dirs(), include_dir, libraries)
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/triton/runtime/build.py", line 48, in _build
[rank5]:     ret = subprocess.check_call(cc_cmd)
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/subprocess.py", line 369, in check_call
[rank5]:     raise CalledProcessError(retcode, cmd)
[rank5]: subprocess.CalledProcessError: Command '['/usr/bin/gcc', '/home/charlie/skip-residual/gpt-fast/tmprpp63ekj/main.c', '-O3', '-shared', '-fPIC', '-o', '/home/charlie/skip-residual/gpt-fast/tmprpp63ekj/cuda_utils.cpython-310-x86_64-linux-gnu.so', '-lcuda', '-L/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/triton/backends/nvidia/lib', '-L/lib/x86_64-linux-gnu', '-I/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/triton/backends/nvidia/include', '-I/home/charlie/skip-residual/gpt-fast/tmprpp63ekj', '-I/home/charlie/anaconda3/envs/gpt-fast/include/python3.10']' returned non-zero exit status 1.


[rank5]: Set TORCH_LOGS="+dynamo" and TORCHDYNAMO_VERBOSE=1 for more information


[rank5]: You can suppress this exception and fall back to eager by setting:
[rank5]:     import torch._dynamo
[rank5]:     torch._dynamo.config.suppress_errors = True

/home/charlie/skip-residual/gpt-fast/tmpvq839_k1/main.c:422:1: fatal error: error writing to /tmp/ccZGPpmU.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpnlzsem31/main.c:422:1: fatal error: error writing to /tmp/ccWHv7l8.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpinsuzt5c/main.c:422:1: fatal error: error writing to /tmp/ccLIuLe3.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpurirzf7c/main.c:422:1: fatal error: error writing to /tmp/cciK3TVw.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpntsr6f6g/main.c:422:1: fatal error: error writing to /tmp/ccY2MG4c.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpd_m0gww_/main.c:422:1: fatal error: error writing to /tmp/ccHivLmt.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmp6cty4ynf/main.c:422:1: fatal error: error writing to /tmp/ccB8r4HA.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmp_146qy1o/main.c:422:1: fatal error: error writing to /tmp/ccPkd9ki.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmph4o92o7s/main.c:422:1: fatal error: error writing to /tmp/ccOK8u11.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpew5r81v5/main.c:422:1: fatal error: error writing to /tmp/ccVP8xK8.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpfd33s7q3/main.c:422:1: fatal error: error writing to /tmp/ccXkUEqr.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpac1syru_/main.c:422:1: fatal error: error writing to /tmp/ccueWIPg.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmp3zold86j/main.c:422:1: fatal error: error writing to /tmp/cc1AL1Cd.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpbjvkv8w1/main.c:422:1: fatal error: error writing to /tmp/ccFAQb3q.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmp8wmkb5v2/main.c:422:1: fatal error: error writing to /tmp/ccqVYkvM.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpfn78c20j/main.c:422:1: fatal error: error writing to /tmp/ccPuR99W.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpsskc8lfd/main.c:422:1: fatal error: error writing to /tmp/ccKQ0GWU.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpgjiuk2hf/main.c:422:1: fatal error: error writing to /tmp/cc11ed0K.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpd2p3no0y/main.c:422:1: fatal error: error writing to /tmp/ccxMZSQq.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmp20r_dd6b/main.c:422:1: fatal error: error writing to /tmp/ccAVKIBf.s: No space left on device
  422 | }
      | ^
compilation terminated.
[rank0]: Traceback (most recent call last):
[rank0]:   File "/home/charlie/skip-residual/gpt-fast/benchmark.py", line 708, in <module>
[rank0]:     main(
[rank0]:   File "/home/charlie/skip-residual/gpt-fast/benchmark.py", line 622, in main
[rank0]:     y, decode_latency, prefill_latency = generate(
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
[rank0]:     return func(*args, **kwargs)
[rank0]:   File "/home/charlie/skip-residual/gpt-fast/benchmark.py", line 336, in generate
[rank0]:     next_token = prefill(model, prompt.view(batch_size, -1), input_pos, **sampling_kwargs)
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py", line 556, in _fn
[rank0]:     return fn(*args, **kwargs)
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 1395, in __call__
[rank0]:     return self._torchdynamo_orig_callable(
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 545, in __call__
[rank0]:     return _compile(
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 977, in _compile
[rank0]:     guarded_code = compile_inner(code, one_graph, hooks, transform)
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 706, in compile_inner
[rank0]:     return _compile_inner(code, one_graph, hooks, transform)
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_utils_internal.py", line 95, in wrapper_function
[rank0]:     return function(*args, **kwargs)
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 741, in _compile_inner
[rank0]:     out_code = transform_code_object(code, transform)
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/bytecode_transformation.py", line 1348, in transform_code_object
[rank0]:     transformations(instructions, code_options)
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 229, in _fn
[rank0]:     return fn(*args, **kwargs)
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 658, in transform
[rank0]:     tracer.run()
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 2912, in run
[rank0]:     super().run()
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 1120, in run
[rank0]:     while self.step():
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 1032, in step
[rank0]:     self.dispatch_table[inst.opcode](self, inst)
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 3103, in RETURN_VALUE
[rank0]:     self._return(inst)
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 3088, in _return
[rank0]:     self.output.compile_subgraph(
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/output_graph.py", line 1077, in compile_subgraph
[rank0]:     self.compile_and_call_fx_graph(tx, list(reversed(stack_values)), root)
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/output_graph.py", line 1346, in compile_and_call_fx_graph
[rank0]:     compiled_fn = self.call_user_compiler(gm)
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/output_graph.py", line 1396, in call_user_compiler
[rank0]:     return self._call_user_compiler(gm)
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/output_graph.py", line 1445, in _call_user_compiler
[rank0]:     raise BackendCompilerFailed(self.compiler_fn, e).with_traceback(
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/output_graph.py", line 1426, in _call_user_compiler
[rank0]:     compiled_fn = compiler_fn(gm, self.example_inputs())
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/repro/after_dynamo.py", line 130, in __call__
[rank0]:     compiled_gm = compiler_fn(gm, example_inputs)
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/repro/after_dynamo.py", line 130, in __call__
[rank0]:     compiled_gm = compiler_fn(gm, example_inputs)
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/__init__.py", line 2301, in __call__
[rank0]:     return compile_fx(model_, inputs_, config_patches=self.config)
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 1708, in compile_fx
[rank0]:     return aot_autograd(
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/backends/common.py", line 72, in __call__
[rank0]:     cg = aot_module_simplified(gm, example_inputs, **self.kwargs)
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 1103, in aot_module_simplified
[rank0]:     compiled_fn = dispatch_and_compile()
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 1079, in dispatch_and_compile
[rank0]:     compiled_fn, _ = create_aot_dispatcher_function(
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 527, in create_aot_dispatcher_function
[rank0]:     return _create_aot_dispatcher_function(
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 778, in _create_aot_dispatcher_function
[rank0]:     compiled_fn, fw_metadata = compiler_fn(
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py", line 197, in aot_dispatch_base
[rank0]:     compiled_fw = compiler(fw_module, updated_flat_args)
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 1525, in fw_compiler_base
[rank0]:     return _fw_compiler_base(model, example_inputs, is_inference)
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 1594, in _fw_compiler_base
[rank0]:     return inner_compile(
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 587, in compile_fx_inner
[rank0]:     return wrap_compiler_debug(_compile_fx_inner, compiler_name="inductor")(
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/repro/after_aot.py", line 102, in debug_wrapper
[rank0]:     inner_compiled_fn = compiler_fn(gm, example_inputs)
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 744, in _compile_fx_inner
[rank0]:     compiled_graph = FxGraphCache.load(
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 1515, in load
[rank0]:     compiled_graph = compile_fx_fn(
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 651, in codegen_and_compile
[rank0]:     compiled_graph = fx_codegen_and_compile(gm, example_inputs, **fx_kwargs)
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 962, in fx_codegen_and_compile
[rank0]:     compiled_fn = graph.compile_to_fn()
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/graph.py", line 2034, in compile_to_fn
[rank0]:     return self.compile_to_module().call
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/graph.py", line 1954, in compile_to_module
[rank0]:     return self._compile_to_module()
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/graph.py", line 1988, in _compile_to_module
[rank0]:     mod = PyCodeCache.load_by_key_path(
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 3058, in load_by_key_path
[rank0]:     mod = _reload_python_module(key, path)
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/runtime/compile_tasks.py", line 45, in _reload_python_module
[rank0]:     exec(code, mod.__dict__, mod.__dict__)
[rank0]:   File "/home/charlie/skip-residual/gpt-fast/torchinductor_charlie/qw/cqwzeobf3wkrkcbmxrwzdb4ms7ifmajqe32n4merxtqrjifswau2.py", line 1752, in <module>
[rank0]:     async_compile.wait(globals())
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/async_compile.py", line 319, in wait
[rank0]:     scope[key] = result.result()
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 3535, in result
[rank0]:     result = self.future.result()
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/concurrent/futures/_base.py", line 458, in result
[rank0]:     return self.__get_result()
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
[rank0]:     raise self._exception
[rank0]: torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:
[rank0]: SubprocException: An exception occurred in a subprocess:

[rank0]: Traceback (most recent call last):
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_worker/subproc_pool.py", line 280, in do_job
[rank0]:     result = job()
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/runtime/compile_tasks.py", line 68, in _worker_compile_triton
[rank0]:     load_kernel().precompile(warm_cache_only=True)
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/runtime/compile_tasks.py", line 13, in _reload_triton_kernel_in_subproc
[rank0]:     return _module_to_triton_kernel(reload_module(), kernel_name)
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/runtime/compile_tasks.py", line 29, in _reload_python_module_in_subproc
[rank0]:     return codecache.PyCodeCache.load_by_key_path(key, path)
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 3058, in load_by_key_path
[rank0]:     mod = _reload_python_module(key, path)
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/runtime/compile_tasks.py", line 45, in _reload_python_module
[rank0]:     exec(code, mod.__dict__, mod.__dict__)
[rank0]:   File "/home/charlie/skip-residual/gpt-fast/torchinductor_charlie/xr/cxrh7bt777b7n5sr67ujqbmtj5wcdbbbrktxayg272ayrwragozs.py", line 9, in <module>
[rank0]:     triton_helpers.set_driver_to_gpu()
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/runtime/triton_helpers.py", line 57, in set_driver_to_gpu
[rank0]:     driver.set_active(backend.driver())
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/triton/backends/nvidia/driver.py", line 371, in __init__
[rank0]:     self.utils = CudaUtils()  # TODO: make static
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/triton/backends/nvidia/driver.py", line 80, in __init__
[rank0]:     mod = compile_module_from_src(Path(os.path.join(dirname, "driver.c")).read_text(), "cuda_utils")
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/triton/backends/nvidia/driver.py", line 57, in compile_module_from_src
[rank0]:     so = _build(name, src_path, tmpdir, library_dirs(), include_dir, libraries)
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/triton/runtime/build.py", line 48, in _build
[rank0]:     ret = subprocess.check_call(cc_cmd)
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/subprocess.py", line 369, in check_call
[rank0]:     raise CalledProcessError(retcode, cmd)
[rank0]: subprocess.CalledProcessError: Command '['/usr/bin/gcc', '/home/charlie/skip-residual/gpt-fast/tmph4o92o7s/main.c', '-O3', '-shared', '-fPIC', '-o', '/home/charlie/skip-residual/gpt-fast/tmph4o92o7s/cuda_utils.cpython-310-x86_64-linux-gnu.so', '-lcuda', '-L/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/triton/backends/nvidia/lib', '-L/lib/x86_64-linux-gnu', '-I/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/triton/backends/nvidia/include', '-I/home/charlie/skip-residual/gpt-fast/tmph4o92o7s', '-I/home/charlie/anaconda3/envs/gpt-fast/include/python3.10']' returned non-zero exit status 1.


[rank0]: Set TORCH_LOGS="+dynamo" and TORCHDYNAMO_VERBOSE=1 for more information


[rank0]: You can suppress this exception and fall back to eager by setting:
[rank0]:     import torch._dynamo
[rank0]:     torch._dynamo.config.suppress_errors = True

/home/charlie/skip-residual/gpt-fast/tmpp7fjk4zo/main.c:422:1: fatal error: error writing to /tmp/ccFUcbkh.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmp7cblzijn/main.c:422:1: fatal error: error writing to /tmp/cc0tSIcL.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpfxgga__l/main.c:422:1: fatal error: error writing to /tmp/ccvzNsld.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmp4q1n_8j_/main.c:422:1: fatal error: error writing to /tmp/ccCXaTRt.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmphv15j0pu/main.c:422:1: fatal error: error writing to /tmp/cc90O2lp.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpk8r0gzsp/main.c:422:1: fatal error: error writing to /tmp/cc1dpZkg.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmp3l1x03_k/main.c:422:1: fatal error: error writing to /tmp/ccF3A6M4.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpwzxipwzv/main.c:422:1: fatal error: error writing to /tmp/ccWdEAAS.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmp_ve92uh7/main.c:422:1: fatal error: error writing to /tmp/ccs9w9rF.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpd8x03yb4/main.c:422:1: fatal error: error writing to /tmp/ccbEVnBS.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpgmta82ai/main.c:422:1: fatal error: error writing to /tmp/cc4EwTcF.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmp06n8pu1e/main.c:422:1: fatal error: error writing to /tmp/cccXkcxK.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmp1oxwe0l8/main.c:422:1: fatal error: error writing to /tmp/ccP0Yuaj.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpo6knmx_y/main.c:422:1: fatal error: error writing to /tmp/cc2Xjebe.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmp946tyvqg/main.c:422:1: fatal error: error writing to /tmp/ccCdZsor.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmp_q2ifvhq/main.c:422:1: fatal error: error writing to /tmp/ccJ0eaoU.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmp4x8sccy2/main.c:422:1: fatal error: error writing to /tmp/ccFRMqNW.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmp0ggr6odg/main.c:422:1: fatal error: error writing to /tmp/ccmGZGEa.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmptln32e63/main.c:422:1: fatal error: error writing to /tmp/ccSk1tHo.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpuuatussl/main.c:422:1: fatal error: error writing to /tmp/ccACOPof.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpgu_melv8/main.c:422:1: fatal error: error writing to /tmp/ccEeXsiI.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmp2aihljvb/main.c:422:1: fatal error: error writing to /tmp/cc93awxr.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmp___mcog5/main.c:422:1: fatal error: error writing to /tmp/ccXSFaks.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpd8wvsc6b/main.c:422:1: fatal error: error writing to /tmp/ccPduebu.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpcsuw7gri/main.c:422:1: fatal error: error writing to /tmp/ccIiafjl.s: No space left on device
  422 | }
      | ^
compilation terminated.
[rank4]: Traceback (most recent call last):
[rank4]:   File "/home/charlie/skip-residual/gpt-fast/benchmark.py", line 708, in <module>
[rank4]:     main(
[rank4]:   File "/home/charlie/skip-residual/gpt-fast/benchmark.py", line 622, in main
[rank4]:     y, decode_latency, prefill_latency = generate(
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
[rank4]:     return func(*args, **kwargs)
[rank4]:   File "/home/charlie/skip-residual/gpt-fast/benchmark.py", line 336, in generate
[rank4]:     next_token = prefill(model, prompt.view(batch_size, -1), input_pos, **sampling_kwargs)
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py", line 556, in _fn
[rank4]:     return fn(*args, **kwargs)
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 1395, in __call__
[rank4]:     return self._torchdynamo_orig_callable(
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 545, in __call__
[rank4]:     return _compile(
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 977, in _compile
[rank4]:     guarded_code = compile_inner(code, one_graph, hooks, transform)
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 706, in compile_inner
[rank4]:     return _compile_inner(code, one_graph, hooks, transform)
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_utils_internal.py", line 95, in wrapper_function
[rank4]:     return function(*args, **kwargs)
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 741, in _compile_inner
[rank4]:     out_code = transform_code_object(code, transform)
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/bytecode_transformation.py", line 1348, in transform_code_object
[rank4]:     transformations(instructions, code_options)
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 229, in _fn
[rank4]:     return fn(*args, **kwargs)
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 658, in transform
[rank4]:     tracer.run()
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 2912, in run
[rank4]:     super().run()
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 1120, in run
[rank4]:     while self.step():
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 1032, in step
[rank4]:     self.dispatch_table[inst.opcode](self, inst)
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 3103, in RETURN_VALUE
[rank4]:     self._return(inst)
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 3088, in _return
[rank4]:     self.output.compile_subgraph(
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/output_graph.py", line 1077, in compile_subgraph
[rank4]:     self.compile_and_call_fx_graph(tx, list(reversed(stack_values)), root)
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/output_graph.py", line 1346, in compile_and_call_fx_graph
[rank4]:     compiled_fn = self.call_user_compiler(gm)
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/output_graph.py", line 1396, in call_user_compiler
[rank4]:     return self._call_user_compiler(gm)
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/output_graph.py", line 1445, in _call_user_compiler
[rank4]:     raise BackendCompilerFailed(self.compiler_fn, e).with_traceback(
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/output_graph.py", line 1426, in _call_user_compiler
[rank4]:     compiled_fn = compiler_fn(gm, self.example_inputs())
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/repro/after_dynamo.py", line 130, in __call__
[rank4]:     compiled_gm = compiler_fn(gm, example_inputs)
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/repro/after_dynamo.py", line 130, in __call__
[rank4]:     compiled_gm = compiler_fn(gm, example_inputs)
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/__init__.py", line 2301, in __call__
[rank4]:     return compile_fx(model_, inputs_, config_patches=self.config)
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 1708, in compile_fx
[rank4]:     return aot_autograd(
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/backends/common.py", line 72, in __call__
[rank4]:     cg = aot_module_simplified(gm, example_inputs, **self.kwargs)
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 1103, in aot_module_simplified
[rank4]:     compiled_fn = dispatch_and_compile()
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 1079, in dispatch_and_compile
[rank4]:     compiled_fn, _ = create_aot_dispatcher_function(
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 527, in create_aot_dispatcher_function
[rank4]:     return _create_aot_dispatcher_function(
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 778, in _create_aot_dispatcher_function
[rank4]:     compiled_fn, fw_metadata = compiler_fn(
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py", line 197, in aot_dispatch_base
[rank4]:     compiled_fw = compiler(fw_module, updated_flat_args)
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 1525, in fw_compiler_base
[rank4]:     return _fw_compiler_base(model, example_inputs, is_inference)
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 1594, in _fw_compiler_base
[rank4]:     return inner_compile(
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 587, in compile_fx_inner
[rank4]:     return wrap_compiler_debug(_compile_fx_inner, compiler_name="inductor")(
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/repro/after_aot.py", line 102, in debug_wrapper
[rank4]:     inner_compiled_fn = compiler_fn(gm, example_inputs)
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 744, in _compile_fx_inner
[rank4]:     compiled_graph = FxGraphCache.load(
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 1515, in load
[rank4]:     compiled_graph = compile_fx_fn(
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 651, in codegen_and_compile
[rank4]:     compiled_graph = fx_codegen_and_compile(gm, example_inputs, **fx_kwargs)
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 962, in fx_codegen_and_compile
[rank4]:     compiled_fn = graph.compile_to_fn()
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/graph.py", line 2034, in compile_to_fn
[rank4]:     return self.compile_to_module().call
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/graph.py", line 1954, in compile_to_module
[rank4]:     return self._compile_to_module()
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/graph.py", line 1988, in _compile_to_module
[rank4]:     mod = PyCodeCache.load_by_key_path(
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 3058, in load_by_key_path
[rank4]:     mod = _reload_python_module(key, path)
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/runtime/compile_tasks.py", line 45, in _reload_python_module
[rank4]:     exec(code, mod.__dict__, mod.__dict__)
[rank4]:   File "/home/charlie/skip-residual/gpt-fast/torchinductor_charlie/os/cos5xm3lrzo5rlisfks2sb3wwg5mffe54w2ky6zbtmkuikz3ddze.py", line 1752, in <module>
[rank4]:     async_compile.wait(globals())
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/async_compile.py", line 319, in wait
[rank4]:     scope[key] = result.result()
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 3535, in result
[rank4]:     result = self.future.result()
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/concurrent/futures/_base.py", line 458, in result
[rank4]:     return self.__get_result()
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
[rank4]:     raise self._exception
[rank4]: torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:
[rank4]: SubprocException: An exception occurred in a subprocess:

[rank4]: Traceback (most recent call last):
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_worker/subproc_pool.py", line 280, in do_job
[rank4]:     result = job()
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/runtime/compile_tasks.py", line 68, in _worker_compile_triton
[rank4]:     load_kernel().precompile(warm_cache_only=True)
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/runtime/compile_tasks.py", line 13, in _reload_triton_kernel_in_subproc
[rank4]:     return _module_to_triton_kernel(reload_module(), kernel_name)
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/runtime/compile_tasks.py", line 29, in _reload_python_module_in_subproc
[rank4]:     return codecache.PyCodeCache.load_by_key_path(key, path)
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 3058, in load_by_key_path
[rank4]:     mod = _reload_python_module(key, path)
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/runtime/compile_tasks.py", line 45, in _reload_python_module
[rank4]:     exec(code, mod.__dict__, mod.__dict__)
[rank4]:   File "/home/charlie/skip-residual/gpt-fast/torchinductor_charlie/tj/ctjwpd5qynijs5c6nudkasnrjwgkbszumne3gkpflr4wbxhvdw6c.py", line 9, in <module>
[rank4]:     triton_helpers.set_driver_to_gpu()
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/runtime/triton_helpers.py", line 57, in set_driver_to_gpu
[rank4]:     driver.set_active(backend.driver())
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/triton/backends/nvidia/driver.py", line 371, in __init__
[rank4]:     self.utils = CudaUtils()  # TODO: make static
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/triton/backends/nvidia/driver.py", line 80, in __init__
[rank4]:     mod = compile_module_from_src(Path(os.path.join(dirname, "driver.c")).read_text(), "cuda_utils")
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/triton/backends/nvidia/driver.py", line 57, in compile_module_from_src
[rank4]:     so = _build(name, src_path, tmpdir, library_dirs(), include_dir, libraries)
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/triton/runtime/build.py", line 48, in _build
[rank4]:     ret = subprocess.check_call(cc_cmd)
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/subprocess.py", line 369, in check_call
[rank4]:     raise CalledProcessError(retcode, cmd)
[rank4]: subprocess.CalledProcessError: Command '['/usr/bin/gcc', '/home/charlie/skip-residual/gpt-fast/tmp4x8sccy2/main.c', '-O3', '-shared', '-fPIC', '-o', '/home/charlie/skip-residual/gpt-fast/tmp4x8sccy2/cuda_utils.cpython-310-x86_64-linux-gnu.so', '-lcuda', '-L/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/triton/backends/nvidia/lib', '-L/lib/x86_64-linux-gnu', '-I/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/triton/backends/nvidia/include', '-I/home/charlie/skip-residual/gpt-fast/tmp4x8sccy2', '-I/home/charlie/anaconda3/envs/gpt-fast/include/python3.10']' returned non-zero exit status 1.


[rank4]: Set TORCH_LOGS="+dynamo" and TORCHDYNAMO_VERBOSE=1 for more information


[rank4]: You can suppress this exception and fall back to eager by setting:
[rank4]:     import torch._dynamo
[rank4]:     torch._dynamo.config.suppress_errors = True

/home/charlie/skip-residual/gpt-fast/tmp8x_aca_u/main.c:422:1: fatal error: error writing to /tmp/ccO2IFBl.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpuhn1tdxd/main.c:422:1: fatal error: error writing to /tmp/ccJziZnk.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpso42kwfu/main.c:422:1: fatal error: error writing to /tmp/ccEWzrMe.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmp84229ruy/main.c:422:1: fatal error: error writing to /tmp/ccqF5HVC.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpddf9sti7/main.c:422:1: fatal error: error writing to /tmp/cckHgULl.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpqm_q76bd/main.c:422:1: fatal error: error writing to /tmp/ccphqIgB.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpiyiyf_dm/main.c:422:1: fatal error: error writing to /tmp/ccGFmpE9.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpjl7ut6vv/main.c:422:1: fatal error: error writing to /tmp/cctFoTZ9.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmp44wnpi11/main.c:422:1: fatal error: error writing to /tmp/cc1Z6glG.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmphxcid1ri/main.c:422:1: fatal error: error writing to /tmp/cc1zw8iy.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpqblqw6gj/main.c:422:1: fatal error: error writing to /tmp/ccAokrTx.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpa1p1gg0j/main.c:422:1: fatal error: error writing to /tmp/ccwzMhXV.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmp4e6q8vhk/main.c:422:1: fatal error: error writing to /tmp/ccrElVmC.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmp5bieetuf/main.c:422:1: fatal error: error writing to /tmp/ccABOW4f.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpwj4gu_ys/main.c:422:1: fatal error: error writing to /tmp/cceP3CCP.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmp0sxqctf2/main.c:422:1: fatal error: error writing to /tmp/cctTsDkr.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmprgsouhw2/main.c:422:1: fatal error: error writing to /tmp/cctY3dAt.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpaexqlfdf/main.c:422:1: fatal error: error writing to /tmp/ccWiv3Yq.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpox5k9s1h/main.c:422:1: fatal error: error writing to /tmp/cc839vaJ.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmp31_6og6c/main.c:422:1: fatal error: error writing to /tmp/ccoBBZrN.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpkbgmbgp7/main.c:422:1: fatal error: error writing to /tmp/ccXWmW5Q.s: No space left on device
  422 | }
      | ^
compilation terminated.
[rank3]: Traceback (most recent call last):
[rank3]:   File "/home/charlie/skip-residual/gpt-fast/benchmark.py", line 708, in <module>
[rank3]:     main(
[rank3]:   File "/home/charlie/skip-residual/gpt-fast/benchmark.py", line 622, in main
[rank3]:     y, decode_latency, prefill_latency = generate(
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
[rank3]:     return func(*args, **kwargs)
[rank3]:   File "/home/charlie/skip-residual/gpt-fast/benchmark.py", line 336, in generate
[rank3]:     next_token = prefill(model, prompt.view(batch_size, -1), input_pos, **sampling_kwargs)
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py", line 556, in _fn
[rank3]:     return fn(*args, **kwargs)
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 1395, in __call__
[rank3]:     return self._torchdynamo_orig_callable(
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 545, in __call__
[rank3]:     return _compile(
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 977, in _compile
[rank3]:     guarded_code = compile_inner(code, one_graph, hooks, transform)
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 706, in compile_inner
[rank3]:     return _compile_inner(code, one_graph, hooks, transform)
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_utils_internal.py", line 95, in wrapper_function
[rank3]:     return function(*args, **kwargs)
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 741, in _compile_inner
[rank3]:     out_code = transform_code_object(code, transform)
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/bytecode_transformation.py", line 1348, in transform_code_object
[rank3]:     transformations(instructions, code_options)
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 229, in _fn
[rank3]:     return fn(*args, **kwargs)
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 658, in transform
[rank3]:     tracer.run()
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 2912, in run
[rank3]:     super().run()
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 1120, in run
[rank3]:     while self.step():
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 1032, in step
[rank3]:     self.dispatch_table[inst.opcode](self, inst)
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 3103, in RETURN_VALUE
[rank3]:     self._return(inst)
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 3088, in _return
[rank3]:     self.output.compile_subgraph(
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/output_graph.py", line 1077, in compile_subgraph
[rank3]:     self.compile_and_call_fx_graph(tx, list(reversed(stack_values)), root)
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/output_graph.py", line 1346, in compile_and_call_fx_graph
[rank3]:     compiled_fn = self.call_user_compiler(gm)
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/output_graph.py", line 1396, in call_user_compiler
[rank3]:     return self._call_user_compiler(gm)
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/output_graph.py", line 1445, in _call_user_compiler
[rank3]:     raise BackendCompilerFailed(self.compiler_fn, e).with_traceback(
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/output_graph.py", line 1426, in _call_user_compiler
[rank3]:     compiled_fn = compiler_fn(gm, self.example_inputs())
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/repro/after_dynamo.py", line 130, in __call__
[rank3]:     compiled_gm = compiler_fn(gm, example_inputs)
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/repro/after_dynamo.py", line 130, in __call__
[rank3]:     compiled_gm = compiler_fn(gm, example_inputs)
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/__init__.py", line 2301, in __call__
[rank3]:     return compile_fx(model_, inputs_, config_patches=self.config)
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 1708, in compile_fx
[rank3]:     return aot_autograd(
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/backends/common.py", line 72, in __call__
[rank3]:     cg = aot_module_simplified(gm, example_inputs, **self.kwargs)
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 1103, in aot_module_simplified
[rank3]:     compiled_fn = dispatch_and_compile()
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 1079, in dispatch_and_compile
[rank3]:     compiled_fn, _ = create_aot_dispatcher_function(
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 527, in create_aot_dispatcher_function
[rank3]:     return _create_aot_dispatcher_function(
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 778, in _create_aot_dispatcher_function
[rank3]:     compiled_fn, fw_metadata = compiler_fn(
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py", line 197, in aot_dispatch_base
[rank3]:     compiled_fw = compiler(fw_module, updated_flat_args)
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 1525, in fw_compiler_base
[rank3]:     return _fw_compiler_base(model, example_inputs, is_inference)
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 1594, in _fw_compiler_base
[rank3]:     return inner_compile(
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 587, in compile_fx_inner
[rank3]:     return wrap_compiler_debug(_compile_fx_inner, compiler_name="inductor")(
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/repro/after_aot.py", line 102, in debug_wrapper
[rank3]:     inner_compiled_fn = compiler_fn(gm, example_inputs)
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 744, in _compile_fx_inner
[rank3]:     compiled_graph = FxGraphCache.load(
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 1515, in load
[rank3]:     compiled_graph = compile_fx_fn(
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 651, in codegen_and_compile
[rank3]:     compiled_graph = fx_codegen_and_compile(gm, example_inputs, **fx_kwargs)
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 962, in fx_codegen_and_compile
[rank3]:     compiled_fn = graph.compile_to_fn()
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/graph.py", line 2034, in compile_to_fn
[rank3]:     return self.compile_to_module().call
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/graph.py", line 1954, in compile_to_module
[rank3]:     return self._compile_to_module()
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/graph.py", line 1988, in _compile_to_module
[rank3]:     mod = PyCodeCache.load_by_key_path(
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 3058, in load_by_key_path
[rank3]:     mod = _reload_python_module(key, path)
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/runtime/compile_tasks.py", line 45, in _reload_python_module
[rank3]:     exec(code, mod.__dict__, mod.__dict__)
[rank3]:   File "/home/charlie/skip-residual/gpt-fast/torchinductor_charlie/zf/czfrzjq7eckahj5tb3ifmythsk3ip753jkyjthsyojote3sknbck.py", line 1752, in <module>
[rank3]:     async_compile.wait(globals())
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/async_compile.py", line 319, in wait
[rank3]:     scope[key] = result.result()
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 3535, in result
[rank3]:     result = self.future.result()
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/concurrent/futures/_base.py", line 458, in result
[rank3]:     return self.__get_result()
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
[rank3]:     raise self._exception
[rank3]: torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:
[rank3]: SubprocException: An exception occurred in a subprocess:

[rank3]: Traceback (most recent call last):
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_worker/subproc_pool.py", line 280, in do_job
[rank3]:     result = job()
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/runtime/compile_tasks.py", line 68, in _worker_compile_triton
[rank3]:     load_kernel().precompile(warm_cache_only=True)
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/runtime/compile_tasks.py", line 13, in _reload_triton_kernel_in_subproc
[rank3]:     return _module_to_triton_kernel(reload_module(), kernel_name)
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/runtime/compile_tasks.py", line 29, in _reload_python_module_in_subproc
[rank3]:     return codecache.PyCodeCache.load_by_key_path(key, path)
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 3058, in load_by_key_path
[rank3]:     mod = _reload_python_module(key, path)
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/runtime/compile_tasks.py", line 45, in _reload_python_module
[rank3]:     exec(code, mod.__dict__, mod.__dict__)
[rank3]:   File "/home/charlie/skip-residual/gpt-fast/torchinductor_charlie/ip/cipjntsblq2qofl2zhjr6attkv7qldhtry2cngaaph2z22wq7kpn.py", line 9, in <module>
[rank3]:     triton_helpers.set_driver_to_gpu()
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/runtime/triton_helpers.py", line 57, in set_driver_to_gpu
[rank3]:     driver.set_active(backend.driver())
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/triton/backends/nvidia/driver.py", line 371, in __init__
[rank3]:     self.utils = CudaUtils()  # TODO: make static
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/triton/backends/nvidia/driver.py", line 80, in __init__
[rank3]:     mod = compile_module_from_src(Path(os.path.join(dirname, "driver.c")).read_text(), "cuda_utils")
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/triton/backends/nvidia/driver.py", line 57, in compile_module_from_src
[rank3]:     so = _build(name, src_path, tmpdir, library_dirs(), include_dir, libraries)
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/triton/runtime/build.py", line 48, in _build
[rank3]:     ret = subprocess.check_call(cc_cmd)
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/subprocess.py", line 369, in check_call
[rank3]:     raise CalledProcessError(retcode, cmd)
[rank3]: subprocess.CalledProcessError: Command '['/usr/bin/gcc', '/home/charlie/skip-residual/gpt-fast/tmp0sxqctf2/main.c', '-O3', '-shared', '-fPIC', '-o', '/home/charlie/skip-residual/gpt-fast/tmp0sxqctf2/cuda_utils.cpython-310-x86_64-linux-gnu.so', '-lcuda', '-L/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/triton/backends/nvidia/lib', '-L/lib/x86_64-linux-gnu', '-I/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/triton/backends/nvidia/include', '-I/home/charlie/skip-residual/gpt-fast/tmp0sxqctf2', '-I/home/charlie/anaconda3/envs/gpt-fast/include/python3.10']' returned non-zero exit status 1.


[rank3]: Set TORCH_LOGS="+dynamo" and TORCHDYNAMO_VERBOSE=1 for more information


[rank3]: You can suppress this exception and fall back to eager by setting:
[rank3]:     import torch._dynamo
[rank3]:     torch._dynamo.config.suppress_errors = True

/home/charlie/skip-residual/gpt-fast/tmpsbs7wmpw/main.c:422:1: fatal error: error writing to /tmp/ccTeKFdV.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpk58muudz/main.c:422:1: fatal error: error writing to /tmp/ccXuOVax.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpsnb2yemo/main.c:422:1: fatal error: error writing to /tmp/ccErFuNK.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmp3cbex7g2/main.c:422:1: fatal error: error writing to /tmp/ccnRf7S2.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmp3s0kgu2q/main.c:422:1: fatal error: error writing to /tmp/ccKZFtZO.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpg5uhx4p5/main.c:422:1: fatal error: error writing to /tmp/ccAqdWKs.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpnf97ling/main.c:422:1: fatal error: error writing to /tmp/ccCW0Kw6.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmp1owyyd_t/main.c:422:1: fatal error: error writing to /tmp/ccqFVtiY.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpqrcwgoey/main.c:422:1: fatal error: error writing to /tmp/ccs8LryN.s: No space left on device
  422 | }
      | ^
/home/charlie/skip-residual/gpt-fast/tmpdjmqtbw8/main.c:422:1: fatal error: error writing to /tmp/ccubt8EI.s: No space left on device
  422 | }
      | ^
compilation terminated.
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpmxkvmxyb/main.c:422:1: fatal error: error writing to /tmp/ccENYO6L.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpt08gy0ox/main.c:422:1: fatal error: error writing to /tmp/ccMgDSWL.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpa5n7la93/main.c:422:1: fatal error: error writing to /tmp/ccfrbaiK.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmp4z7402p8/main.c:422:1: fatal error: error writing to /tmp/ccHEez3t.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpbe7qn08c/main.c:422:1: fatal error: error writing to /tmp/ccuYnEjq.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpl6r1n98t/main.c:422:1: fatal error: error writing to /tmp/ccXRCdJl.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpdyy_h0q7/main.c:422:1: fatal error: error writing to /tmp/ccFABscv.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpsg7nun16/main.c:422:1: fatal error: error writing to /tmp/ccd2cZyY.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpki8f3xs3/main.c:422:1: fatal error: error writing to /tmp/cc0h3fMe.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpmdn8lt4l/main.c:422:1: fatal error: error writing to /tmp/cc6snmYN.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmp0abqbn4a/main.c:422:1: fatal error: error writing to /tmp/ccd4075N.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmptu7jansi/main.c:422:1: fatal error: error writing to /tmp/ccH9BvhT.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpgyqmhnha/main.c:422:1: fatal error: error writing to /tmp/ccPsdyMM.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmp0h1lybky/main.c:422:1: fatal error: error writing to /tmp/ccYaH3HG.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpv_mpey7v/main.c:422:1: fatal error: error writing to /tmp/cci9uLRy.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpyypuh6mm/main.c:422:1: fatal error: error writing to /tmp/ccdYHlXF.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpzi01iobi/main.c:422:1: fatal error: error writing to /tmp/ccZIyGoY.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpdedgjemz/main.c:422:1: fatal error: error writing to /tmp/ccvHei4H.s: No space left on device
  422 | }
      | ^
compilation terminated.
[rank6]: Traceback (most recent call last):
[rank6]:   File "/home/charlie/skip-residual/gpt-fast/benchmark.py", line 708, in <module>
[rank6]:     main(
[rank6]:   File "/home/charlie/skip-residual/gpt-fast/benchmark.py", line 622, in main
[rank6]:     y, decode_latency, prefill_latency = generate(
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
[rank6]:     return func(*args, **kwargs)
[rank6]:   File "/home/charlie/skip-residual/gpt-fast/benchmark.py", line 336, in generate
[rank6]:     next_token = prefill(model, prompt.view(batch_size, -1), input_pos, **sampling_kwargs)
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py", line 556, in _fn
[rank6]:     return fn(*args, **kwargs)
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 1395, in __call__
[rank6]:     return self._torchdynamo_orig_callable(
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 545, in __call__
[rank6]:     return _compile(
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 977, in _compile
[rank6]:     guarded_code = compile_inner(code, one_graph, hooks, transform)
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 706, in compile_inner
[rank6]:     return _compile_inner(code, one_graph, hooks, transform)
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_utils_internal.py", line 95, in wrapper_function
[rank6]:     return function(*args, **kwargs)
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 741, in _compile_inner
[rank6]:     out_code = transform_code_object(code, transform)
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/bytecode_transformation.py", line 1348, in transform_code_object
[rank6]:     transformations(instructions, code_options)
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 229, in _fn
[rank6]:     return fn(*args, **kwargs)
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 658, in transform
[rank6]:     tracer.run()
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 2912, in run
[rank6]:     super().run()
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 1120, in run
[rank6]:     while self.step():
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 1032, in step
[rank6]:     self.dispatch_table[inst.opcode](self, inst)
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 3103, in RETURN_VALUE
[rank6]:     self._return(inst)
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 3088, in _return
[rank6]:     self.output.compile_subgraph(
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/output_graph.py", line 1077, in compile_subgraph
[rank6]:     self.compile_and_call_fx_graph(tx, list(reversed(stack_values)), root)
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/output_graph.py", line 1346, in compile_and_call_fx_graph
[rank6]:     compiled_fn = self.call_user_compiler(gm)
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/output_graph.py", line 1396, in call_user_compiler
[rank6]:     return self._call_user_compiler(gm)
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/output_graph.py", line 1445, in _call_user_compiler
[rank6]:     raise BackendCompilerFailed(self.compiler_fn, e).with_traceback(
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/output_graph.py", line 1426, in _call_user_compiler
[rank6]:     compiled_fn = compiler_fn(gm, self.example_inputs())
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/repro/after_dynamo.py", line 130, in __call__
[rank6]:     compiled_gm = compiler_fn(gm, example_inputs)
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/repro/after_dynamo.py", line 130, in __call__
[rank6]:     compiled_gm = compiler_fn(gm, example_inputs)
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/__init__.py", line 2301, in __call__
[rank6]:     return compile_fx(model_, inputs_, config_patches=self.config)
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 1708, in compile_fx
[rank6]:     return aot_autograd(
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/backends/common.py", line 72, in __call__
[rank6]:     cg = aot_module_simplified(gm, example_inputs, **self.kwargs)
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 1103, in aot_module_simplified
[rank6]:     compiled_fn = dispatch_and_compile()
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 1079, in dispatch_and_compile
[rank6]:     compiled_fn, _ = create_aot_dispatcher_function(
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 527, in create_aot_dispatcher_function
[rank6]:     return _create_aot_dispatcher_function(
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 778, in _create_aot_dispatcher_function
[rank6]:     compiled_fn, fw_metadata = compiler_fn(
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py", line 197, in aot_dispatch_base
[rank6]:     compiled_fw = compiler(fw_module, updated_flat_args)
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 1525, in fw_compiler_base
[rank6]:     return _fw_compiler_base(model, example_inputs, is_inference)
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 1594, in _fw_compiler_base
[rank6]:     return inner_compile(
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 587, in compile_fx_inner
[rank6]:     return wrap_compiler_debug(_compile_fx_inner, compiler_name="inductor")(
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/repro/after_aot.py", line 102, in debug_wrapper
[rank6]:     inner_compiled_fn = compiler_fn(gm, example_inputs)
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 744, in _compile_fx_inner
[rank6]:     compiled_graph = FxGraphCache.load(
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 1515, in load
[rank6]:     compiled_graph = compile_fx_fn(
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 651, in codegen_and_compile
[rank6]:     compiled_graph = fx_codegen_and_compile(gm, example_inputs, **fx_kwargs)
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 962, in fx_codegen_and_compile
[rank6]:     compiled_fn = graph.compile_to_fn()
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/graph.py", line 2034, in compile_to_fn
[rank6]:     return self.compile_to_module().call
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/graph.py", line 1954, in compile_to_module
[rank6]:     return self._compile_to_module()
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/graph.py", line 1988, in _compile_to_module
[rank6]:     mod = PyCodeCache.load_by_key_path(
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 3058, in load_by_key_path
[rank6]:     mod = _reload_python_module(key, path)
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/runtime/compile_tasks.py", line 45, in _reload_python_module
[rank6]:     exec(code, mod.__dict__, mod.__dict__)
[rank6]:   File "/home/charlie/skip-residual/gpt-fast/torchinductor_charlie/fr/cfrsv7qg5thbkszyxhqga4h3pzzesck2v2spthcgkhtul7vl2wmq.py", line 1752, in <module>
[rank6]:     async_compile.wait(globals())
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/async_compile.py", line 319, in wait
[rank6]:     scope[key] = result.result()
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 3535, in result
[rank6]:     result = self.future.result()
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/concurrent/futures/_base.py", line 458, in result
[rank6]:     return self.__get_result()
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
[rank6]:     raise self._exception
[rank6]: torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:
[rank6]: SubprocException: An exception occurred in a subprocess:

[rank6]: Traceback (most recent call last):
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_worker/subproc_pool.py", line 280, in do_job
[rank6]:     result = job()
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/runtime/compile_tasks.py", line 68, in _worker_compile_triton
[rank6]:     load_kernel().precompile(warm_cache_only=True)
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/runtime/compile_tasks.py", line 13, in _reload_triton_kernel_in_subproc
[rank6]:     return _module_to_triton_kernel(reload_module(), kernel_name)
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/runtime/compile_tasks.py", line 29, in _reload_python_module_in_subproc
[rank6]:     return codecache.PyCodeCache.load_by_key_path(key, path)
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 3058, in load_by_key_path
[rank6]:     mod = _reload_python_module(key, path)
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/runtime/compile_tasks.py", line 45, in _reload_python_module
[rank6]:     exec(code, mod.__dict__, mod.__dict__)
[rank6]:   File "/home/charlie/skip-residual/gpt-fast/torchinductor_charlie/h3/ch3dbjqlxmjjbp6ri3btonzogbcsbcdgq5fyhar5o3mtansrqdrb.py", line 9, in <module>
[rank6]:     triton_helpers.set_driver_to_gpu()
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/runtime/triton_helpers.py", line 57, in set_driver_to_gpu
[rank6]:     driver.set_active(backend.driver())
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/triton/backends/nvidia/driver.py", line 371, in __init__
[rank6]:     self.utils = CudaUtils()  # TODO: make static
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/triton/backends/nvidia/driver.py", line 80, in __init__
[rank6]:     mod = compile_module_from_src(Path(os.path.join(dirname, "driver.c")).read_text(), "cuda_utils")
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/triton/backends/nvidia/driver.py", line 57, in compile_module_from_src
[rank6]:     so = _build(name, src_path, tmpdir, library_dirs(), include_dir, libraries)
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/triton/runtime/build.py", line 48, in _build
[rank6]:     ret = subprocess.check_call(cc_cmd)
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/subprocess.py", line 369, in check_call
[rank6]:     raise CalledProcessError(retcode, cmd)
[rank6]: subprocess.CalledProcessError: Command '['/usr/bin/gcc', '/home/charlie/skip-residual/gpt-fast/tmpki8f3xs3/main.c', '-O3', '-shared', '-fPIC', '-o', '/home/charlie/skip-residual/gpt-fast/tmpki8f3xs3/cuda_utils.cpython-310-x86_64-linux-gnu.so', '-lcuda', '-L/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/triton/backends/nvidia/lib', '-L/lib/x86_64-linux-gnu', '-I/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/triton/backends/nvidia/include', '-I/home/charlie/skip-residual/gpt-fast/tmpki8f3xs3', '-I/home/charlie/anaconda3/envs/gpt-fast/include/python3.10']' returned non-zero exit status 1.


[rank6]: Set TORCH_LOGS="+dynamo" and TORCHDYNAMO_VERBOSE=1 for more information


[rank6]: You can suppress this exception and fall back to eager by setting:
[rank6]:     import torch._dynamo
[rank6]:     torch._dynamo.config.suppress_errors = True

/home/charlie/skip-residual/gpt-fast/tmph9__6o60/main.c:422:1: fatal error: error writing to /tmp/ccn486op.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmp18aopos_/main.c:422:1: fatal error: error writing to /tmp/cclpa233.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmp3hme_o8k/main.c:422:1: fatal error: error writing to /tmp/ccKi9O20.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpt3pw8cu6/main.c:422:1: fatal error: error writing to /tmp/cc2PHfV3.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmp0c_x8mob/main.c:422:1: fatal error: error writing to /tmp/ccltiLZI.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpvek6ldvd/main.c:422:1: fatal error: error writing to /tmp/ccY8Zn37.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpxi8dsxhx/main.c:422:1: fatal error: error writing to /tmp/ccm8Vge7.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpzo9lxh2_/main.c:422:1: fatal error: error writing to /tmp/ccoE2uB4.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmp7qiv_9lv/main.c:422:1: fatal error: error writing to /tmp/ccoJh6uC.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpuo0fvjz8/main.c:422:1: fatal error: error writing to /tmp/ccPwsxJJ.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpguk1vs75/main.c:422:1: fatal error: error writing to /tmp/ccN06Mql.s: No space left on device
  422 | }
      | ^
compilation terminated.
[rank2]:[W1201 11:46:18.960269553 ProcessGroupNCCL.cpp:1374] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
/home/charlie/skip-residual/gpt-fast/tmp51sivdd3/main.c:422:1: fatal error: error writing to /tmp/ccSrkvdf.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpidc3l07r/main.c:422:1: fatal error: error writing to /tmp/ccxPCMBV.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpesjeu6u_/main.c:422:1: fatal error: error writing to /tmp/cc9ZjpIm.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpo55d5s5u/main.c:422:1: fatal error: error writing to /tmp/ccPAwi5m.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpmh2mm_ia/main.c:422:1: fatal error: error writing to /tmp/cck46iw6.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmp3j9y63z7/main.c:422:1: fatal error: error writing to /tmp/ccgpjt8V.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpqw8gn6cn/main.c:422:1: fatal error: error writing to /tmp/ccqXTMCu.s: No space left on device
  422 | }
      | ^
compilation terminated.
[rank7]: Traceback (most recent call last):
[rank7]:   File "/home/charlie/skip-residual/gpt-fast/benchmark.py", line 708, in <module>
[rank7]:     main(
[rank7]:   File "/home/charlie/skip-residual/gpt-fast/benchmark.py", line 622, in main
[rank7]:     y, decode_latency, prefill_latency = generate(
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
[rank7]:     return func(*args, **kwargs)
[rank7]:   File "/home/charlie/skip-residual/gpt-fast/benchmark.py", line 336, in generate
[rank7]:     next_token = prefill(model, prompt.view(batch_size, -1), input_pos, **sampling_kwargs)
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py", line 556, in _fn
[rank7]:     return fn(*args, **kwargs)
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 1395, in __call__
[rank7]:     return self._torchdynamo_orig_callable(
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 545, in __call__
[rank7]:     return _compile(
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 977, in _compile
[rank7]:     guarded_code = compile_inner(code, one_graph, hooks, transform)
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 706, in compile_inner
[rank7]:     return _compile_inner(code, one_graph, hooks, transform)
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_utils_internal.py", line 95, in wrapper_function
[rank7]:     return function(*args, **kwargs)
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 741, in _compile_inner
[rank7]:     out_code = transform_code_object(code, transform)
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/bytecode_transformation.py", line 1348, in transform_code_object
[rank7]:     transformations(instructions, code_options)
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 229, in _fn
[rank7]:     return fn(*args, **kwargs)
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 658, in transform
[rank7]:     tracer.run()
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 2912, in run
[rank7]:     super().run()
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 1120, in run
[rank7]:     while self.step():
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 1032, in step
[rank7]:     self.dispatch_table[inst.opcode](self, inst)
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 3103, in RETURN_VALUE
[rank7]:     self._return(inst)
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 3088, in _return
[rank7]:     self.output.compile_subgraph(
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/output_graph.py", line 1077, in compile_subgraph
[rank7]:     self.compile_and_call_fx_graph(tx, list(reversed(stack_values)), root)
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/output_graph.py", line 1346, in compile_and_call_fx_graph
[rank7]:     compiled_fn = self.call_user_compiler(gm)
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/output_graph.py", line 1396, in call_user_compiler
[rank7]:     return self._call_user_compiler(gm)
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/output_graph.py", line 1445, in _call_user_compiler
[rank7]:     raise BackendCompilerFailed(self.compiler_fn, e).with_traceback(
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/output_graph.py", line 1426, in _call_user_compiler
[rank7]:     compiled_fn = compiler_fn(gm, self.example_inputs())
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/repro/after_dynamo.py", line 130, in __call__
[rank7]:     compiled_gm = compiler_fn(gm, example_inputs)
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/repro/after_dynamo.py", line 130, in __call__
[rank7]:     compiled_gm = compiler_fn(gm, example_inputs)
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/__init__.py", line 2301, in __call__
[rank7]:     return compile_fx(model_, inputs_, config_patches=self.config)
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 1708, in compile_fx
[rank7]:     return aot_autograd(
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/backends/common.py", line 72, in __call__
[rank7]:     cg = aot_module_simplified(gm, example_inputs, **self.kwargs)
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 1103, in aot_module_simplified
[rank7]:     compiled_fn = dispatch_and_compile()
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 1079, in dispatch_and_compile
[rank7]:     compiled_fn, _ = create_aot_dispatcher_function(
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 527, in create_aot_dispatcher_function
[rank7]:     return _create_aot_dispatcher_function(
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 778, in _create_aot_dispatcher_function
[rank7]:     compiled_fn, fw_metadata = compiler_fn(
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py", line 197, in aot_dispatch_base
[rank7]:     compiled_fw = compiler(fw_module, updated_flat_args)
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 1525, in fw_compiler_base
[rank7]:     return _fw_compiler_base(model, example_inputs, is_inference)
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 1594, in _fw_compiler_base
[rank7]:     return inner_compile(
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 587, in compile_fx_inner
[rank7]:     return wrap_compiler_debug(_compile_fx_inner, compiler_name="inductor")(
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/repro/after_aot.py", line 102, in debug_wrapper
[rank7]:     inner_compiled_fn = compiler_fn(gm, example_inputs)
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 744, in _compile_fx_inner
[rank7]:     compiled_graph = FxGraphCache.load(
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 1515, in load
[rank7]:     compiled_graph = compile_fx_fn(
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 651, in codegen_and_compile
[rank7]:     compiled_graph = fx_codegen_and_compile(gm, example_inputs, **fx_kwargs)
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 962, in fx_codegen_and_compile
[rank7]:     compiled_fn = graph.compile_to_fn()
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/graph.py", line 2034, in compile_to_fn
[rank7]:     return self.compile_to_module().call
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/graph.py", line 1954, in compile_to_module
[rank7]:     return self._compile_to_module()
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/graph.py", line 1988, in _compile_to_module
[rank7]:     mod = PyCodeCache.load_by_key_path(
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 3058, in load_by_key_path
[rank7]:     mod = _reload_python_module(key, path)
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/runtime/compile_tasks.py", line 45, in _reload_python_module
[rank7]:     exec(code, mod.__dict__, mod.__dict__)
[rank7]:   File "/home/charlie/skip-residual/gpt-fast/torchinductor_charlie/fn/cfn6wpmcb5s4ltku3gaap5kpdahtyapvrkuicktvl4j6ocxe7d5f.py", line 1752, in <module>
[rank7]:     async_compile.wait(globals())
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/async_compile.py", line 319, in wait
[rank7]:     scope[key] = result.result()
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 3535, in result
[rank7]:     result = self.future.result()
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/concurrent/futures/_base.py", line 458, in result
[rank7]:     return self.__get_result()
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
[rank7]:     raise self._exception
[rank7]: torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:
[rank7]: SubprocException: An exception occurred in a subprocess:

[rank7]: Traceback (most recent call last):
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_worker/subproc_pool.py", line 280, in do_job
[rank7]:     result = job()
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/runtime/compile_tasks.py", line 68, in _worker_compile_triton
[rank7]:     load_kernel().precompile(warm_cache_only=True)
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/runtime/compile_tasks.py", line 13, in _reload_triton_kernel_in_subproc
[rank7]:     return _module_to_triton_kernel(reload_module(), kernel_name)
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/runtime/compile_tasks.py", line 29, in _reload_python_module_in_subproc
[rank7]:     return codecache.PyCodeCache.load_by_key_path(key, path)
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 3058, in load_by_key_path
[rank7]:     mod = _reload_python_module(key, path)
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/runtime/compile_tasks.py", line 45, in _reload_python_module
[rank7]:     exec(code, mod.__dict__, mod.__dict__)
[rank7]:   File "/home/charlie/skip-residual/gpt-fast/torchinductor_charlie/zi/czizyc2ldu6qevuvlk4jak2mal6sxzjspr6bn3glkjyu34oxqb25.py", line 9, in <module>
[rank7]:     triton_helpers.set_driver_to_gpu()
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/runtime/triton_helpers.py", line 57, in set_driver_to_gpu
[rank7]:     driver.set_active(backend.driver())
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/triton/backends/nvidia/driver.py", line 371, in __init__
[rank7]:     self.utils = CudaUtils()  # TODO: make static
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/triton/backends/nvidia/driver.py", line 80, in __init__
[rank7]:     mod = compile_module_from_src(Path(os.path.join(dirname, "driver.c")).read_text(), "cuda_utils")
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/triton/backends/nvidia/driver.py", line 57, in compile_module_from_src
[rank7]:     so = _build(name, src_path, tmpdir, library_dirs(), include_dir, libraries)
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/triton/runtime/build.py", line 48, in _build
[rank7]:     ret = subprocess.check_call(cc_cmd)
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/subprocess.py", line 369, in check_call
[rank7]:     raise CalledProcessError(retcode, cmd)
[rank7]: subprocess.CalledProcessError: Command '['/usr/bin/gcc', '/home/charlie/skip-residual/gpt-fast/tmpmh2mm_ia/main.c', '-O3', '-shared', '-fPIC', '-o', '/home/charlie/skip-residual/gpt-fast/tmpmh2mm_ia/cuda_utils.cpython-310-x86_64-linux-gnu.so', '-lcuda', '-L/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/triton/backends/nvidia/lib', '-L/lib/x86_64-linux-gnu', '-I/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/triton/backends/nvidia/include', '-I/home/charlie/skip-residual/gpt-fast/tmpmh2mm_ia', '-I/home/charlie/anaconda3/envs/gpt-fast/include/python3.10']' returned non-zero exit status 1.


[rank7]: Set TORCH_LOGS="+dynamo" and TORCHDYNAMO_VERBOSE=1 for more information


[rank7]: You can suppress this exception and fall back to eager by setting:
[rank7]:     import torch._dynamo
[rank7]:     torch._dynamo.config.suppress_errors = True

/home/charlie/skip-residual/gpt-fast/tmp6j90v_br/main.c:422:1: fatal error: error writing to /tmp/ccqklU4d.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpor8t6pkj/main.c:422:1: fatal error: error writing to /tmp/ccKvBIGE.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmp0myafxhb/main.c:422:1: fatal error: error writing to /tmp/ccgSjMd9.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpsupqqdyx/main.c:422:1: fatal error: error writing to /tmp/cc28PQEZ.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpm9h0_cjm/main.c:422:1: fatal error: error writing to /tmp/cc63WBIK.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpxts36nxy/main.c:422:1: fatal error: error writing to /tmp/cchppJHP.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmp_gur21v1/main.c:422:1: fatal error: error writing to /tmp/cc0gfngU.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpsybxq5vr/main.c:422:1: fatal error: error writing to /tmp/ccXmhyCA.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmp_adajgb4/main.c:422:1: fatal error: error writing to /tmp/ccJr1Nmq.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmptdhkvbf2/main.c:422:1: fatal error: error writing to /tmp/ccL0lQ3E.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpnxkhi4hv/main.c:422:1: fatal error: error writing to /tmp/ccB0pJ2q.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpvgqznrj4/main.c:422:1: fatal error: error writing to /tmp/ccB7uVSw.s: No space left on device
  422 | }
      | ^
compilation terminated.
[rank1]: Traceback (most recent call last):
[rank1]:   File "/home/charlie/skip-residual/gpt-fast/benchmark.py", line 708, in <module>
[rank1]:     main(
[rank1]:   File "/home/charlie/skip-residual/gpt-fast/benchmark.py", line 622, in main
[rank1]:     y, decode_latency, prefill_latency = generate(
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
[rank1]:     return func(*args, **kwargs)
[rank1]:   File "/home/charlie/skip-residual/gpt-fast/benchmark.py", line 336, in generate
[rank1]:     next_token = prefill(model, prompt.view(batch_size, -1), input_pos, **sampling_kwargs)
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py", line 556, in _fn
[rank1]:     return fn(*args, **kwargs)
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 1395, in __call__
[rank1]:     return self._torchdynamo_orig_callable(
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 545, in __call__
[rank1]:     return _compile(
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 977, in _compile
[rank1]:     guarded_code = compile_inner(code, one_graph, hooks, transform)
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 706, in compile_inner
[rank1]:     return _compile_inner(code, one_graph, hooks, transform)
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_utils_internal.py", line 95, in wrapper_function
[rank1]:     return function(*args, **kwargs)
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 741, in _compile_inner
[rank1]:     out_code = transform_code_object(code, transform)
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/bytecode_transformation.py", line 1348, in transform_code_object
[rank1]:     transformations(instructions, code_options)
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 229, in _fn
[rank1]:     return fn(*args, **kwargs)
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 658, in transform
[rank1]:     tracer.run()
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 2912, in run
[rank1]:     super().run()
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 1120, in run
[rank1]:     while self.step():
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 1032, in step
[rank1]:     self.dispatch_table[inst.opcode](self, inst)
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 3103, in RETURN_VALUE
[rank1]:     self._return(inst)
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 3088, in _return
[rank1]:     self.output.compile_subgraph(
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/output_graph.py", line 1077, in compile_subgraph
[rank1]:     self.compile_and_call_fx_graph(tx, list(reversed(stack_values)), root)
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/output_graph.py", line 1346, in compile_and_call_fx_graph
[rank1]:     compiled_fn = self.call_user_compiler(gm)
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/output_graph.py", line 1396, in call_user_compiler
[rank1]:     return self._call_user_compiler(gm)
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/output_graph.py", line 1445, in _call_user_compiler
[rank1]:     raise BackendCompilerFailed(self.compiler_fn, e).with_traceback(
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/output_graph.py", line 1426, in _call_user_compiler
[rank1]:     compiled_fn = compiler_fn(gm, self.example_inputs())
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/repro/after_dynamo.py", line 130, in __call__
[rank1]:     compiled_gm = compiler_fn(gm, example_inputs)
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/repro/after_dynamo.py", line 130, in __call__
[rank1]:     compiled_gm = compiler_fn(gm, example_inputs)
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/__init__.py", line 2301, in __call__
[rank1]:     return compile_fx(model_, inputs_, config_patches=self.config)
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 1708, in compile_fx
[rank1]:     return aot_autograd(
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/backends/common.py", line 72, in __call__
[rank1]:     cg = aot_module_simplified(gm, example_inputs, **self.kwargs)
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 1103, in aot_module_simplified
[rank1]:     compiled_fn = dispatch_and_compile()
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 1079, in dispatch_and_compile
[rank1]:     compiled_fn, _ = create_aot_dispatcher_function(
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 527, in create_aot_dispatcher_function
[rank1]:     return _create_aot_dispatcher_function(
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 778, in _create_aot_dispatcher_function
[rank1]:     compiled_fn, fw_metadata = compiler_fn(
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py", line 197, in aot_dispatch_base
[rank1]:     compiled_fw = compiler(fw_module, updated_flat_args)
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 1525, in fw_compiler_base
[rank1]:     return _fw_compiler_base(model, example_inputs, is_inference)
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 1594, in _fw_compiler_base
[rank1]:     return inner_compile(
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 587, in compile_fx_inner
[rank1]:     return wrap_compiler_debug(_compile_fx_inner, compiler_name="inductor")(
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/repro/after_aot.py", line 102, in debug_wrapper
[rank1]:     inner_compiled_fn = compiler_fn(gm, example_inputs)
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 744, in _compile_fx_inner
[rank1]:     compiled_graph = FxGraphCache.load(
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 1515, in load
[rank1]:     compiled_graph = compile_fx_fn(
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 651, in codegen_and_compile
[rank1]:     compiled_graph = fx_codegen_and_compile(gm, example_inputs, **fx_kwargs)
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 962, in fx_codegen_and_compile
[rank1]:     compiled_fn = graph.compile_to_fn()
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/graph.py", line 2034, in compile_to_fn
[rank1]:     return self.compile_to_module().call
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/graph.py", line 1954, in compile_to_module
[rank1]:     return self._compile_to_module()
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/graph.py", line 1988, in _compile_to_module
[rank1]:     mod = PyCodeCache.load_by_key_path(
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 3058, in load_by_key_path
[rank1]:     mod = _reload_python_module(key, path)
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/runtime/compile_tasks.py", line 45, in _reload_python_module
[rank1]:     exec(code, mod.__dict__, mod.__dict__)
[rank1]:   File "/home/charlie/skip-residual/gpt-fast/torchinductor_charlie/gs/cgsw2b4hhwndbilnzmhlijei22j73kgr2rkfhjibmgotvhon2j7x.py", line 1752, in <module>
[rank1]:     async_compile.wait(globals())
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/async_compile.py", line 319, in wait
[rank1]:     scope[key] = result.result()
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 3535, in result
[rank1]:     result = self.future.result()
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/concurrent/futures/_base.py", line 458, in result
[rank1]:     return self.__get_result()
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
[rank1]:     raise self._exception
[rank1]: torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:
[rank1]: SubprocException: An exception occurred in a subprocess:

[rank1]: Traceback (most recent call last):
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_worker/subproc_pool.py", line 280, in do_job
[rank1]:     result = job()
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/runtime/compile_tasks.py", line 68, in _worker_compile_triton
[rank1]:     load_kernel().precompile(warm_cache_only=True)
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/runtime/compile_tasks.py", line 13, in _reload_triton_kernel_in_subproc
[rank1]:     return _module_to_triton_kernel(reload_module(), kernel_name)
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/runtime/compile_tasks.py", line 29, in _reload_python_module_in_subproc
[rank1]:     return codecache.PyCodeCache.load_by_key_path(key, path)
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 3058, in load_by_key_path
[rank1]:     mod = _reload_python_module(key, path)
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/runtime/compile_tasks.py", line 45, in _reload_python_module
[rank1]:     exec(code, mod.__dict__, mod.__dict__)
[rank1]:   File "/home/charlie/skip-residual/gpt-fast/torchinductor_charlie/no/cnovb5vbzhhntozfwiz247c27hrjpautr7zh5inizbhhd2w4s74k.py", line 9, in <module>
[rank1]:     triton_helpers.set_driver_to_gpu()
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/runtime/triton_helpers.py", line 57, in set_driver_to_gpu
[rank1]:     driver.set_active(backend.driver())
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/triton/backends/nvidia/driver.py", line 371, in __init__
[rank1]:     self.utils = CudaUtils()  # TODO: make static
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/triton/backends/nvidia/driver.py", line 80, in __init__
[rank1]:     mod = compile_module_from_src(Path(os.path.join(dirname, "driver.c")).read_text(), "cuda_utils")
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/triton/backends/nvidia/driver.py", line 57, in compile_module_from_src
[rank1]:     so = _build(name, src_path, tmpdir, library_dirs(), include_dir, libraries)
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/triton/runtime/build.py", line 48, in _build
[rank1]:     ret = subprocess.check_call(cc_cmd)
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/subprocess.py", line 369, in check_call
[rank1]:     raise CalledProcessError(retcode, cmd)
[rank1]: subprocess.CalledProcessError: Command '['/usr/bin/gcc', '/home/charlie/skip-residual/gpt-fast/tmpxts36nxy/main.c', '-O3', '-shared', '-fPIC', '-o', '/home/charlie/skip-residual/gpt-fast/tmpxts36nxy/cuda_utils.cpython-310-x86_64-linux-gnu.so', '-lcuda', '-L/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/triton/backends/nvidia/lib', '-L/lib/x86_64-linux-gnu', '-I/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/triton/backends/nvidia/include', '-I/home/charlie/skip-residual/gpt-fast/tmpxts36nxy', '-I/home/charlie/anaconda3/envs/gpt-fast/include/python3.10']' returned non-zero exit status 1.


[rank1]: Set TORCH_LOGS="+dynamo" and TORCHDYNAMO_VERBOSE=1 for more information


[rank1]: You can suppress this exception and fall back to eager by setting:
[rank1]:     import torch._dynamo
[rank1]:     torch._dynamo.config.suppress_errors = True

/home/charlie/skip-residual/gpt-fast/tmp5jbwtcf1/main.c:422:1: fatal error: error writing to /tmp/ccUtE3g7.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpzo52q9cq/main.c:422:1: fatal error: error writing to /tmp/ccg15q9o.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpj8g79ki_/main.c:422:1: fatal error: error writing to /tmp/cchUdnnW.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmploewvtd0/main.c:422:1: fatal error: error writing to /tmp/ccA6HE3r.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmp4wb2w6yp/main.c:422:1: fatal error: error writing to /tmp/cc7y3yDi.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpkd75w7ls/main.c:422:1: fatal error: error writing to /tmp/ccGTaFLK.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmp29e606zh/main.c:422:1: fatal error: error writing to /tmp/ccXaYfLy.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpvnx4np62/main.c:422:1: fatal error: error writing to /tmp/ccNGd9wK.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpd9jmw184/main.c:422:1: fatal error: error writing to /tmp/ccQ6eFLB.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmp7syokiza/main.c:422:1: fatal error: error writing to /tmp/ccMwQ9C0.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpmd1nfuon/main.c:422:1: fatal error: error writing to /tmp/ccUMn6NM.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmp68g1a81z/main.c:422:1: fatal error: error writing to /tmp/cc9mor8c.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpygcresyc/main.c:422:1: fatal error: error writing to /tmp/cckUS5Yy.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpz4kmkff6/main.c:422:1: fatal error: error writing to /tmp/cc1LNeWL.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpwqw8trk9/main.c:422:1: fatal error: error writing to /tmp/cclJKpMu.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpaxsbcmrs/main.c:422:1: fatal error: error writing to /tmp/ccCfHrzw.s: No space left on device
  422 | }
      | ^
/home/charlie/skip-residual/gpt-fast/tmp3ze6de9l/main.c:422:1: fatal error: error writing to /tmp/ccnnjkaD.s: No space left on device
  422 | }
      | ^
compilation terminated.
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpq7ogcs_e/main.c:422:1: fatal error: error writing to /tmp/cc6E7t8E.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpdbcqkg0u/main.c:422:1: fatal error: error writing to /tmp/ccWxdN1Q.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmprvj4qg_8/main.c:422:1: fatal error: error writing to /tmp/cchryhSe.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmplqpbgqs5/main.c:422:1: fatal error: error writing to /tmp/ccjBsbgY.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpnvl3igp6/main.c:422:1: fatal error: error writing to /tmp/cc6Ty10a.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpbwwvfv0g/main.c:422:1: fatal error: error writing to /tmp/ccQ8NQlN.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpt_v2a3uh/main.c:422:1: fatal error: error writing to /tmp/cc6Mv5ZZ.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmp65fdrbe9/main.c:422:1: fatal error: error writing to /tmp/cc2TM5Oy.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmptmafanj4/main.c:422:1: fatal error: error writing to /tmp/ccbP3DLq.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmp633ynkp7/main.c:422:1: fatal error: error writing to /tmp/cc7Fo7hc.s: No space left on device
  422 | }
      | ^
compilation terminated.
[rank4]:[W1201 11:46:20.389978091 ProcessGroupNCCL.cpp:1374] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
[rank3]:[W1201 11:46:20.750304261 ProcessGroupNCCL.cpp:1374] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
[rank5]:[W1201 11:46:21.364917876 ProcessGroupNCCL.cpp:1374] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
[rank0]:[W1201 11:46:21.404500585 ProcessGroupNCCL.cpp:1374] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
[rank6]:[W1201 11:46:21.878180205 ProcessGroupNCCL.cpp:1374] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
[rank1]:[W1201 11:46:21.960266155 ProcessGroupNCCL.cpp:1374] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
[rank7]:[W1201 11:46:21.019565410 ProcessGroupNCCL.cpp:1374] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
W1201 11:46:21.930000 484034 site-packages/torch/distributed/elastic/multiprocessing/api.py:897] Sending process 484103 closing signal SIGTERM
W1201 11:46:21.933000 484034 site-packages/torch/distributed/elastic/multiprocessing/api.py:897] Sending process 484104 closing signal SIGTERM
W1201 11:46:21.936000 484034 site-packages/torch/distributed/elastic/multiprocessing/api.py:897] Sending process 484106 closing signal SIGTERM
W1201 11:46:21.941000 484034 site-packages/torch/distributed/elastic/multiprocessing/api.py:897] Sending process 484107 closing signal SIGTERM
W1201 11:46:21.944000 484034 site-packages/torch/distributed/elastic/multiprocessing/api.py:897] Sending process 484108 closing signal SIGTERM
W1201 11:46:21.946000 484034 site-packages/torch/distributed/elastic/multiprocessing/api.py:897] Sending process 484109 closing signal SIGTERM
W1201 11:46:21.948000 484034 site-packages/torch/distributed/elastic/multiprocessing/api.py:897] Sending process 484110 closing signal SIGTERM
E1201 11:46:22.698000 484034 site-packages/torch/distributed/elastic/multiprocessing/api.py:869] failed (exitcode: 1) local_rank: 2 (pid: 484105) of binary: /home/charlie/anaconda3/envs/gpt-fast/bin/python
Traceback (most recent call last):
  File "/home/charlie/anaconda3/envs/gpt-fast/bin/torchrun", line 8, in <module>
    sys.exit(main())
  File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 355, in wrapper
    return f(*args, **kwargs)
  File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/distributed/run.py", line 919, in main
    run(args)
  File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/distributed/run.py", line 910, in run
    elastic_launch(
  File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 138, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 269, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
benchmark.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2024-12-01_11:46:21
  host      : mk-xii-22.cloud.together.ai
  rank      : 2 (local_rank: 2)
  exitcode  : 1 (pid: 484105)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
