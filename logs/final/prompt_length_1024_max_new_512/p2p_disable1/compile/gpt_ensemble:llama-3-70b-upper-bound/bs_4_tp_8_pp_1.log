W1201 11:31:36.341000 467454 site-packages/torch/distributed/run.py:793] 
W1201 11:31:36.341000 467454 site-packages/torch/distributed/run.py:793] *****************************************
W1201 11:31:36.341000 467454 site-packages/torch/distributed/run.py:793] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W1201 11:31:36.341000 467454 site-packages/torch/distributed/run.py:793] *****************************************
DeviceMesh('cuda', [[0, 1, 2, 3, 4, 5, 6, 7]], mesh_dim_names=('pp', 'tp'))
Using device=cuda
Loading model ...
DeviceMesh('cuda', [[0, 1, 2, 3, 4, 5, 6, 7]], mesh_dim_names=('pp', 'tp'))
DeviceMesh('cuda', [[0, 1, 2, 3, 4, 5, 6, 7]], mesh_dim_names=('pp', 'tp'))
DeviceMesh('cuda', [[0, 1, 2, 3, 4, 5, 6, 7]], mesh_dim_names=('pp', 'tp'))
DeviceMesh('cuda', [[0, 1, 2, 3, 4, 5, 6, 7]], mesh_dim_names=('pp', 'tp'))
DeviceMesh('cuda', [[0, 1, 2, 3, 4, 5, 6, 7]], mesh_dim_names=('pp', 'tp'))
DeviceMesh('cuda', [[0, 1, 2, 3, 4, 5, 6, 7]], mesh_dim_names=('pp', 'tp'))
DeviceMesh('cuda', [[0, 1, 2, 3, 4, 5, 6, 7]], mesh_dim_names=('pp', 'tp'))
GPTEnsemble(
  (tok_embeddings): Embedding(128256, 8192)
  (layers): ModuleList(
    (0-79): 80 x EnsembleTransformerBlock(
      semi_compiled = False
      (attention): Attention(
        (wqkv): Linear(in_features=8192, out_features=1280, bias=False)
        (wo): Linear(in_features=1024, out_features=8192, bias=False)
      )
      (feed_forward): FeedForward(
        (w1): Linear(in_features=8192, out_features=7168, bias=False)
        (w2): Linear(in_features=3584, out_features=8192, bias=False)
      )
      (ffn_norm): RMSNorm()
      (attention_norm): RMSNorm()
    )
  )
  (norm): RMSNorm()
  (output): Linear(in_features=8192, out_features=128256, bias=False)
)
Time to load model: 1.52 seconds
Compiling prefill with dynamic=False
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py:222: UserWarning: TensorFloat32 tensor cores for float32 matrix multiplication available but not enabled. Consider setting `torch.set_float32_matmul_precision('high')` for better performance.
  warnings.warn(
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py:222: UserWarning: TensorFloat32 tensor cores for float32 matrix multiplication available but not enabled. Consider setting `torch.set_float32_matmul_precision('high')` for better performance.
  warnings.warn(
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py:222: UserWarning: TensorFloat32 tensor cores for float32 matrix multiplication available but not enabled. Consider setting `torch.set_float32_matmul_precision('high')` for better performance.
  warnings.warn(
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py:222: UserWarning: TensorFloat32 tensor cores for float32 matrix multiplication available but not enabled. Consider setting `torch.set_float32_matmul_precision('high')` for better performance.
  warnings.warn(
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py:222: UserWarning: TensorFloat32 tensor cores for float32 matrix multiplication available but not enabled. Consider setting `torch.set_float32_matmul_precision('high')` for better performance.
  warnings.warn(
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py:222: UserWarning: TensorFloat32 tensor cores for float32 matrix multiplication available but not enabled. Consider setting `torch.set_float32_matmul_precision('high')` for better performance.
  warnings.warn(
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py:222: UserWarning: TensorFloat32 tensor cores for float32 matrix multiplication available but not enabled. Consider setting `torch.set_float32_matmul_precision('high')` for better performance.
  warnings.warn(
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py:222: UserWarning: TensorFloat32 tensor cores for float32 matrix multiplication available but not enabled. Consider setting `torch.set_float32_matmul_precision('high')` for better performance.
  warnings.warn(
/home/charlie/skip-residual/gpt-fast/tmp5nh44j9e/main.c:422:1: fatal error: error writing to /tmp/ccwRywby.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpe1tcq41e/main.c:422:1: fatal error: error writing to /tmp/ccExRnu6.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpwnx25fjo/main.c:422:1: fatal error: error writing to /tmp/ccRJ54Ns.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmp7kuf4awp/main.c:422:1: fatal error: error writing to /tmp/cc5tLcWn.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpt9nsh9x2/main.c:422:1: fatal error: error writing to /tmp/cc5PbtdB.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpbefz6bhu/main.c:422:1: fatal error: error writing to /tmp/ccM7NrQa.s: No space left on device
  422 | }
      | ^
compilation terminated.
[rank0]: Traceback (most recent call last):
[rank0]:   File "/home/charlie/skip-residual/gpt-fast/benchmark.py", line 708, in <module>
[rank0]:     main(
[rank0]:   File "/home/charlie/skip-residual/gpt-fast/benchmark.py", line 622, in main
[rank0]:     y, decode_latency, prefill_latency = generate(
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
[rank0]:     return func(*args, **kwargs)
[rank0]:   File "/home/charlie/skip-residual/gpt-fast/benchmark.py", line 336, in generate
[rank0]:     next_token = prefill(model, prompt.view(batch_size, -1), input_pos, **sampling_kwargs)
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py", line 556, in _fn
[rank0]:     return fn(*args, **kwargs)
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 1395, in __call__
[rank0]:     return self._torchdynamo_orig_callable(
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 545, in __call__
[rank0]:     return _compile(
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 977, in _compile
[rank0]:     guarded_code = compile_inner(code, one_graph, hooks, transform)
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 706, in compile_inner
[rank0]:     return _compile_inner(code, one_graph, hooks, transform)
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_utils_internal.py", line 95, in wrapper_function
[rank0]:     return function(*args, **kwargs)
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 741, in _compile_inner
[rank0]:     out_code = transform_code_object(code, transform)
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/bytecode_transformation.py", line 1348, in transform_code_object
[rank0]:     transformations(instructions, code_options)
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 229, in _fn
[rank0]:     return fn(*args, **kwargs)
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 658, in transform
[rank0]:     tracer.run()
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 2912, in run
[rank0]:     super().run()
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 1120, in run
[rank0]:     while self.step():
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 1032, in step
[rank0]:     self.dispatch_table[inst.opcode](self, inst)
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 3103, in RETURN_VALUE
[rank0]:     self._return(inst)
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 3088, in _return
[rank0]:     self.output.compile_subgraph(
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/output_graph.py", line 1077, in compile_subgraph
[rank0]:     self.compile_and_call_fx_graph(tx, list(reversed(stack_values)), root)
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/output_graph.py", line 1346, in compile_and_call_fx_graph
[rank0]:     compiled_fn = self.call_user_compiler(gm)
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/output_graph.py", line 1396, in call_user_compiler
[rank0]:     return self._call_user_compiler(gm)
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/output_graph.py", line 1445, in _call_user_compiler
[rank0]:     raise BackendCompilerFailed(self.compiler_fn, e).with_traceback(
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/output_graph.py", line 1426, in _call_user_compiler
[rank0]:     compiled_fn = compiler_fn(gm, self.example_inputs())
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/repro/after_dynamo.py", line 130, in __call__
[rank0]:     compiled_gm = compiler_fn(gm, example_inputs)
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/repro/after_dynamo.py", line 130, in __call__
[rank0]:     compiled_gm = compiler_fn(gm, example_inputs)
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/__init__.py", line 2301, in __call__
[rank0]:     return compile_fx(model_, inputs_, config_patches=self.config)
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 1708, in compile_fx
[rank0]:     return aot_autograd(
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/backends/common.py", line 72, in __call__
[rank0]:     cg = aot_module_simplified(gm, example_inputs, **self.kwargs)
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 1103, in aot_module_simplified
[rank0]:     compiled_fn = dispatch_and_compile()
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 1079, in dispatch_and_compile
[rank0]:     compiled_fn, _ = create_aot_dispatcher_function(
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 527, in create_aot_dispatcher_function
[rank0]:     return _create_aot_dispatcher_function(
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 778, in _create_aot_dispatcher_function
[rank0]:     compiled_fn, fw_metadata = compiler_fn(
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py", line 197, in aot_dispatch_base
[rank0]:     compiled_fw = compiler(fw_module, updated_flat_args)
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 1525, in fw_compiler_base
[rank0]:     return _fw_compiler_base(model, example_inputs, is_inference)
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 1594, in _fw_compiler_base
[rank0]:     return inner_compile(
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 587, in compile_fx_inner
[rank0]:     return wrap_compiler_debug(_compile_fx_inner, compiler_name="inductor")(
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/repro/after_aot.py", line 102, in debug_wrapper
[rank0]:     inner_compiled_fn = compiler_fn(gm, example_inputs)
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 744, in _compile_fx_inner
[rank0]:     compiled_graph = FxGraphCache.load(
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 1515, in load
[rank0]:     compiled_graph = compile_fx_fn(
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 651, in codegen_and_compile
[rank0]:     compiled_graph = fx_codegen_and_compile(gm, example_inputs, **fx_kwargs)
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 962, in fx_codegen_and_compile
[rank0]:     compiled_fn = graph.compile_to_fn()
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/graph.py", line 2034, in compile_to_fn
[rank0]:     return self.compile_to_module().call
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/graph.py", line 1954, in compile_to_module
[rank0]:     return self._compile_to_module()
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/graph.py", line 1988, in _compile_to_module
[rank0]:     mod = PyCodeCache.load_by_key_path(
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 3058, in load_by_key_path
[rank0]:     mod = _reload_python_module(key, path)
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/runtime/compile_tasks.py", line 45, in _reload_python_module
[rank0]:     exec(code, mod.__dict__, mod.__dict__)
[rank0]:   File "/home/charlie/skip-residual/gpt-fast/torchinductor_charlie/cu/ccurmo732zacep4m7fvzs6mvepehgltxps4hkjv7xh6stjxndfwv.py", line 1713, in <module>
[rank0]:     async_compile.wait(globals())
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/async_compile.py", line 319, in wait
[rank0]:     scope[key] = result.result()
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 3535, in result
[rank0]:     result = self.future.result()
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/concurrent/futures/_base.py", line 458, in result
[rank0]:     return self.__get_result()
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
[rank0]:     raise self._exception
[rank0]: torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:
[rank0]: SubprocException: An exception occurred in a subprocess:

[rank0]: Traceback (most recent call last):
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_worker/subproc_pool.py", line 280, in do_job
[rank0]:     result = job()
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/runtime/compile_tasks.py", line 68, in _worker_compile_triton
[rank0]:     load_kernel().precompile(warm_cache_only=True)
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/runtime/compile_tasks.py", line 13, in _reload_triton_kernel_in_subproc
[rank0]:     return _module_to_triton_kernel(reload_module(), kernel_name)
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/runtime/compile_tasks.py", line 29, in _reload_python_module_in_subproc
[rank0]:     return codecache.PyCodeCache.load_by_key_path(key, path)
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 3058, in load_by_key_path
[rank0]:     mod = _reload_python_module(key, path)
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/runtime/compile_tasks.py", line 45, in _reload_python_module
[rank0]:     exec(code, mod.__dict__, mod.__dict__)
[rank0]:   File "/home/charlie/skip-residual/gpt-fast/torchinductor_charlie/vn/cvntjy4edguqq5fm27r3pvhpkzbtaux3bvhi5jcvktgyphzkuhhz.py", line 9, in <module>
[rank0]:     triton_helpers.set_driver_to_gpu()
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/runtime/triton_helpers.py", line 57, in set_driver_to_gpu
[rank0]:     driver.set_active(backend.driver())
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/triton/backends/nvidia/driver.py", line 371, in __init__
[rank0]:     self.utils = CudaUtils()  # TODO: make static
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/triton/backends/nvidia/driver.py", line 80, in __init__
[rank0]:     mod = compile_module_from_src(Path(os.path.join(dirname, "driver.c")).read_text(), "cuda_utils")
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/triton/backends/nvidia/driver.py", line 57, in compile_module_from_src
[rank0]:     so = _build(name, src_path, tmpdir, library_dirs(), include_dir, libraries)
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/triton/runtime/build.py", line 48, in _build
[rank0]:     ret = subprocess.check_call(cc_cmd)
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/subprocess.py", line 369, in check_call
[rank0]:     raise CalledProcessError(retcode, cmd)
[rank0]: subprocess.CalledProcessError: Command '['/usr/bin/gcc', '/home/charlie/skip-residual/gpt-fast/tmpe1tcq41e/main.c', '-O3', '-shared', '-fPIC', '-o', '/home/charlie/skip-residual/gpt-fast/tmpe1tcq41e/cuda_utils.cpython-310-x86_64-linux-gnu.so', '-lcuda', '-L/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/triton/backends/nvidia/lib', '-L/lib/x86_64-linux-gnu', '-I/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/triton/backends/nvidia/include', '-I/home/charlie/skip-residual/gpt-fast/tmpe1tcq41e', '-I/home/charlie/anaconda3/envs/gpt-fast/include/python3.10']' returned non-zero exit status 1.


[rank0]: Set TORCH_LOGS="+dynamo" and TORCHDYNAMO_VERBOSE=1 for more information


[rank0]: You can suppress this exception and fall back to eager by setting:
[rank0]:     import torch._dynamo
[rank0]:     torch._dynamo.config.suppress_errors = True

/home/charlie/skip-residual/gpt-fast/tmp3v9i4cju/main.c:422:1: fatal error: error writing to /tmp/ccVrxsfw.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpq71qfj9h/main.c:422:1: fatal error: error writing to /tmp/ccGAmsDY.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmp_5mzk4_5/main.c:422:1: fatal error: error writing to /tmp/ccM9C4Jf.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpv1yvj2wu/main.c:422:1: fatal error: error writing to /tmp/ccKIP0Fh.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmp50a6mgdz/main.c:422:1: fatal error: error writing to /tmp/cchVXnS7.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpfqc9yo5x/main.c:422:1: fatal error: error writing to /tmp/ccHnBhrq.s: No space left on device
  422 | }
      | ^
/home/charlie/skip-residual/gpt-fast/tmpsaq4lvee/main.c:422:1: fatal error: error writing to /tmp/cc71C3D3.s: No space left on device
  422 | }
      | ^
compilation terminated.
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpsfns3bkx/main.c:422:1: fatal error: error writing to /tmp/ccyGLsLo.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmp10h3wagf/main.c:422:1: fatal error: error writing to /tmp/ccXGWJV2.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmp_j27sp1p/main.c:422:1: fatal error: error writing to /tmp/ccWTvoGn.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpazckgmto/main.c:422:1: fatal error: error writing to /tmp/ccmTpIY2.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpz9cw18pz/main.c:422:1: fatal error: error writing to /tmp/cccmvL2D.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpirq4avy5/main.c:422:1: fatal error: error writing to /tmp/cc4LOHVa.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpf_05y0wd/main.c:422:1: fatal error: error writing to /tmp/cccAdWbW.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpwm46oolt/main.c:422:1: fatal error: error writing to /tmp/ccIyilxv.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpeqnoyhlh/main.c:422:1: fatal error: error writing to /tmp/cc3RxLd2.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmp0vu1tdid/main.c:422:1: fatal error: error writing to /tmp/ccMiXSUD.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpdafo8obg/main.c:422:1: fatal error: error writing to /tmp/cckJgLAP.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmp6pj81fm0/main.c:422:1: fatal error: error writing to /tmp/ccjaUXFa.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpwfmfkz3j/main.c:422:1: fatal error: error writing to /tmp/cc9mHYee.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpkp044yvw/main.c:422:1: fatal error: error writing to /tmp/cc93a6i3.s: No space left on device
  422 | }
      | ^
compilation terminated.
[rank5]: Traceback (most recent call last):
[rank5]:   File "/home/charlie/skip-residual/gpt-fast/benchmark.py", line 708, in <module>
[rank5]:     main(
[rank5]:   File "/home/charlie/skip-residual/gpt-fast/benchmark.py", line 622, in main
[rank5]:     y, decode_latency, prefill_latency = generate(
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
[rank5]:     return func(*args, **kwargs)
[rank5]:   File "/home/charlie/skip-residual/gpt-fast/benchmark.py", line 336, in generate
[rank5]:     next_token = prefill(model, prompt.view(batch_size, -1), input_pos, **sampling_kwargs)
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py", line 556, in _fn
[rank5]:     return fn(*args, **kwargs)
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 1395, in __call__
[rank5]:     return self._torchdynamo_orig_callable(
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 545, in __call__
[rank5]:     return _compile(
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 977, in _compile
[rank5]:     guarded_code = compile_inner(code, one_graph, hooks, transform)
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 706, in compile_inner
[rank5]:     return _compile_inner(code, one_graph, hooks, transform)
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_utils_internal.py", line 95, in wrapper_function
[rank5]:     return function(*args, **kwargs)
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 741, in _compile_inner
[rank5]:     out_code = transform_code_object(code, transform)
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/bytecode_transformation.py", line 1348, in transform_code_object
[rank5]:     transformations(instructions, code_options)
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 229, in _fn
[rank5]:     return fn(*args, **kwargs)
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 658, in transform
[rank5]:     tracer.run()
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 2912, in run
[rank5]:     super().run()
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 1120, in run
[rank5]:     while self.step():
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 1032, in step
[rank5]:     self.dispatch_table[inst.opcode](self, inst)
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 3103, in RETURN_VALUE
[rank5]:     self._return(inst)
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 3088, in _return
[rank5]:     self.output.compile_subgraph(
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/output_graph.py", line 1077, in compile_subgraph
[rank5]:     self.compile_and_call_fx_graph(tx, list(reversed(stack_values)), root)
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/output_graph.py", line 1346, in compile_and_call_fx_graph
[rank5]:     compiled_fn = self.call_user_compiler(gm)
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/output_graph.py", line 1396, in call_user_compiler
[rank5]:     return self._call_user_compiler(gm)
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/output_graph.py", line 1445, in _call_user_compiler
[rank5]:     raise BackendCompilerFailed(self.compiler_fn, e).with_traceback(
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/output_graph.py", line 1426, in _call_user_compiler
[rank5]:     compiled_fn = compiler_fn(gm, self.example_inputs())
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/repro/after_dynamo.py", line 130, in __call__
[rank5]:     compiled_gm = compiler_fn(gm, example_inputs)
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/repro/after_dynamo.py", line 130, in __call__
[rank5]:     compiled_gm = compiler_fn(gm, example_inputs)
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/__init__.py", line 2301, in __call__
[rank5]:     return compile_fx(model_, inputs_, config_patches=self.config)
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 1708, in compile_fx
[rank5]:     return aot_autograd(
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/backends/common.py", line 72, in __call__
[rank5]:     cg = aot_module_simplified(gm, example_inputs, **self.kwargs)
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 1103, in aot_module_simplified
[rank5]:     compiled_fn = dispatch_and_compile()
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 1079, in dispatch_and_compile
[rank5]:     compiled_fn, _ = create_aot_dispatcher_function(
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 527, in create_aot_dispatcher_function
[rank5]:     return _create_aot_dispatcher_function(
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 778, in _create_aot_dispatcher_function
[rank5]:     compiled_fn, fw_metadata = compiler_fn(
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py", line 197, in aot_dispatch_base
[rank5]:     compiled_fw = compiler(fw_module, updated_flat_args)
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 1525, in fw_compiler_base
[rank5]:     return _fw_compiler_base(model, example_inputs, is_inference)
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 1594, in _fw_compiler_base
[rank5]:     return inner_compile(
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 587, in compile_fx_inner
[rank5]:     return wrap_compiler_debug(_compile_fx_inner, compiler_name="inductor")(
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/repro/after_aot.py", line 102, in debug_wrapper
[rank5]:     inner_compiled_fn = compiler_fn(gm, example_inputs)
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 744, in _compile_fx_inner
[rank5]:     compiled_graph = FxGraphCache.load(
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 1515, in load
[rank5]:     compiled_graph = compile_fx_fn(
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 651, in codegen_and_compile
[rank5]:     compiled_graph = fx_codegen_and_compile(gm, example_inputs, **fx_kwargs)
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 962, in fx_codegen_and_compile
[rank5]:     compiled_fn = graph.compile_to_fn()
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/graph.py", line 2034, in compile_to_fn
[rank5]:     return self.compile_to_module().call
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/graph.py", line 1954, in compile_to_module
[rank5]:     return self._compile_to_module()
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/graph.py", line 1988, in _compile_to_module
[rank5]:     mod = PyCodeCache.load_by_key_path(
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 3058, in load_by_key_path
[rank5]:     mod = _reload_python_module(key, path)
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/runtime/compile_tasks.py", line 45, in _reload_python_module
[rank5]:     exec(code, mod.__dict__, mod.__dict__)
[rank5]:   File "/home/charlie/skip-residual/gpt-fast/torchinductor_charlie/zx/czx75leqszzr5cs6igsf6eziyspisxymc2fxbv3fzuullmt732y3.py", line 1713, in <module>
[rank5]:     async_compile.wait(globals())
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/async_compile.py", line 319, in wait
[rank5]:     scope[key] = result.result()
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 3535, in result
[rank5]:     result = self.future.result()
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/concurrent/futures/_base.py", line 458, in result
[rank5]:     return self.__get_result()
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
[rank5]:     raise self._exception
[rank5]: torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:
[rank5]: SubprocException: An exception occurred in a subprocess:

[rank5]: Traceback (most recent call last):
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_worker/subproc_pool.py", line 280, in do_job
[rank5]:     result = job()
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/runtime/compile_tasks.py", line 68, in _worker_compile_triton
[rank5]:     load_kernel().precompile(warm_cache_only=True)
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/runtime/compile_tasks.py", line 13, in _reload_triton_kernel_in_subproc
[rank5]:     return _module_to_triton_kernel(reload_module(), kernel_name)
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/runtime/compile_tasks.py", line 29, in _reload_python_module_in_subproc
[rank5]:     return codecache.PyCodeCache.load_by_key_path(key, path)
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 3058, in load_by_key_path
[rank5]:     mod = _reload_python_module(key, path)
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/runtime/compile_tasks.py", line 45, in _reload_python_module
[rank5]:     exec(code, mod.__dict__, mod.__dict__)
[rank5]:   File "/home/charlie/skip-residual/gpt-fast/torchinductor_charlie/dq/cdq3usxfxbsqlt4emqdn4lbrs32l3vfqcld7qq63o5yiutc4cxw2.py", line 9, in <module>
[rank5]:     triton_helpers.set_driver_to_gpu()
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/runtime/triton_helpers.py", line 57, in set_driver_to_gpu
[rank5]:     driver.set_active(backend.driver())
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/triton/backends/nvidia/driver.py", line 371, in __init__
[rank5]:     self.utils = CudaUtils()  # TODO: make static
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/triton/backends/nvidia/driver.py", line 80, in __init__
[rank5]:     mod = compile_module_from_src(Path(os.path.join(dirname, "driver.c")).read_text(), "cuda_utils")
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/triton/backends/nvidia/driver.py", line 57, in compile_module_from_src
[rank5]:     so = _build(name, src_path, tmpdir, library_dirs(), include_dir, libraries)
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/triton/runtime/build.py", line 48, in _build
[rank5]:     ret = subprocess.check_call(cc_cmd)
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/subprocess.py", line 369, in check_call
[rank5]:     raise CalledProcessError(retcode, cmd)
[rank5]: subprocess.CalledProcessError: Command '['/usr/bin/gcc', '/home/charlie/skip-residual/gpt-fast/tmp0vu1tdid/main.c', '-O3', '-shared', '-fPIC', '-o', '/home/charlie/skip-residual/gpt-fast/tmp0vu1tdid/cuda_utils.cpython-310-x86_64-linux-gnu.so', '-lcuda', '-L/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/triton/backends/nvidia/lib', '-L/lib/x86_64-linux-gnu', '-I/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/triton/backends/nvidia/include', '-I/home/charlie/skip-residual/gpt-fast/tmp0vu1tdid', '-I/home/charlie/anaconda3/envs/gpt-fast/include/python3.10']' returned non-zero exit status 1.


[rank5]: Set TORCH_LOGS="+dynamo" and TORCHDYNAMO_VERBOSE=1 for more information


[rank5]: You can suppress this exception and fall back to eager by setting:
[rank5]:     import torch._dynamo
[rank5]:     torch._dynamo.config.suppress_errors = True

/home/charlie/skip-residual/gpt-fast/tmp9guk8t_3/main.c:422:1: fatal error: error writing to /tmp/ccMOYKaC.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpl_ueenta/main.c:422:1: fatal error: error writing to /tmp/ccd37mu1.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpz2itv123/main.c:422:1: fatal error: error writing to /tmp/ccCVvi8D.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpwqgxj3yt/main.c:422:1: fatal error: error writing to /tmp/cctdlrKx.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpttfyk6wh/main.c:422:1: fatal error: error writing to /tmp/ccCfOLui.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpqlqzgou4/main.c:422:1: fatal error: error writing to /tmp/ccjHszjH.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpwtbjfr0w/main.c:422:1: fatal error: error writing to /tmp/cc5lW6WW.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpy891f1mo/main.c:422:1: fatal error: error writing to /tmp/ccDK0Ao7.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpnv1i6cd6/main.c:422:1: fatal error: error writing to /tmp/cctbBPJ1.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpp6_27ga3/main.c:422:1: fatal error: error writing to /tmp/ccxZvnY7.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmph6sepphu/main.c:422:1: fatal error: error writing to /tmp/ccgHlCZQ.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpnxb8rdnf/main.c:422:1: fatal error: error writing to /tmp/cc42a5yX.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpj1l1o7_3/main.c:422:1: fatal error: error writing to /tmp/ccoe01l3.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpcb7s6h7c/main.c:422:1: fatal error: error writing to /tmp/ccisfehY.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpdkz17mz8/main.c:422:1: fatal error: error writing to /tmp/ccWd5deB.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpjm09m3b8/main.c:422:1: fatal error: error writing to /tmp/ccKZirvz.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpve2qcod8/main.c:422:1: fatal error: error writing to /tmp/cc7Qjk3h.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmppwu6thrk/main.c:422:1: fatal error: error writing to /tmp/ccCPIa3g.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpl1el88gf/main.c:422:1: fatal error: error writing to /tmp/cc4uUpar.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpnk0oqkb3/main.c:422:1: fatal error: error writing to /tmp/cclo92mT.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmps0v9h6rc/main.c:422:1: fatal error: error writing to /tmp/ccxUt5v2.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpvbwrcsgo/main.c:422:1: fatal error: error writing to /tmp/cck2YZUx.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmp6_907zrz/main.c:422:1: fatal error: error writing to /tmp/ccDDGxpl.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmp_u1zu5xg/main.c:422:1: fatal error: error writing to /tmp/ccJuaKsp.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmprxhevdkc/main.c:422:1: fatal error: error writing to /tmp/ccyqkxeQ.s: No space left on device
  422 | }
      | ^
compilation terminated.
[rank2]: Traceback (most recent call last):
[rank2]:   File "/home/charlie/skip-residual/gpt-fast/benchmark.py", line 708, in <module>
[rank2]:     main(
[rank2]:   File "/home/charlie/skip-residual/gpt-fast/benchmark.py", line 622, in main
[rank2]:     y, decode_latency, prefill_latency = generate(
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
[rank2]:     return func(*args, **kwargs)
[rank2]:   File "/home/charlie/skip-residual/gpt-fast/benchmark.py", line 336, in generate
[rank2]:     next_token = prefill(model, prompt.view(batch_size, -1), input_pos, **sampling_kwargs)
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py", line 556, in _fn
[rank2]:     return fn(*args, **kwargs)
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 1395, in __call__
[rank2]:     return self._torchdynamo_orig_callable(
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 545, in __call__
[rank2]:     return _compile(
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 977, in _compile
[rank2]:     guarded_code = compile_inner(code, one_graph, hooks, transform)
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 706, in compile_inner
[rank2]:     return _compile_inner(code, one_graph, hooks, transform)
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_utils_internal.py", line 95, in wrapper_function
[rank2]:     return function(*args, **kwargs)
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 741, in _compile_inner
[rank2]:     out_code = transform_code_object(code, transform)
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/bytecode_transformation.py", line 1348, in transform_code_object
[rank2]:     transformations(instructions, code_options)
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 229, in _fn
[rank2]:     return fn(*args, **kwargs)
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 658, in transform
[rank2]:     tracer.run()
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 2912, in run
[rank2]:     super().run()
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 1120, in run
[rank2]:     while self.step():
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 1032, in step
[rank2]:     self.dispatch_table[inst.opcode](self, inst)
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 3103, in RETURN_VALUE
[rank2]:     self._return(inst)
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 3088, in _return
[rank2]:     self.output.compile_subgraph(
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/output_graph.py", line 1077, in compile_subgraph
[rank2]:     self.compile_and_call_fx_graph(tx, list(reversed(stack_values)), root)
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/output_graph.py", line 1346, in compile_and_call_fx_graph
[rank2]:     compiled_fn = self.call_user_compiler(gm)
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/output_graph.py", line 1396, in call_user_compiler
[rank2]:     return self._call_user_compiler(gm)
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/output_graph.py", line 1445, in _call_user_compiler
[rank2]:     raise BackendCompilerFailed(self.compiler_fn, e).with_traceback(
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/output_graph.py", line 1426, in _call_user_compiler
[rank2]:     compiled_fn = compiler_fn(gm, self.example_inputs())
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/repro/after_dynamo.py", line 130, in __call__
[rank2]:     compiled_gm = compiler_fn(gm, example_inputs)
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/repro/after_dynamo.py", line 130, in __call__
[rank2]:     compiled_gm = compiler_fn(gm, example_inputs)
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/__init__.py", line 2301, in __call__
[rank2]:     return compile_fx(model_, inputs_, config_patches=self.config)
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 1708, in compile_fx
[rank2]:     return aot_autograd(
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/backends/common.py", line 72, in __call__
[rank2]:     cg = aot_module_simplified(gm, example_inputs, **self.kwargs)
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 1103, in aot_module_simplified
[rank2]:     compiled_fn = dispatch_and_compile()
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 1079, in dispatch_and_compile
[rank2]:     compiled_fn, _ = create_aot_dispatcher_function(
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 527, in create_aot_dispatcher_function
[rank2]:     return _create_aot_dispatcher_function(
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 778, in _create_aot_dispatcher_function
[rank2]:     compiled_fn, fw_metadata = compiler_fn(
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py", line 197, in aot_dispatch_base
[rank2]:     compiled_fw = compiler(fw_module, updated_flat_args)
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 1525, in fw_compiler_base
[rank2]:     return _fw_compiler_base(model, example_inputs, is_inference)
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 1594, in _fw_compiler_base
[rank2]:     return inner_compile(
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 587, in compile_fx_inner
[rank2]:     return wrap_compiler_debug(_compile_fx_inner, compiler_name="inductor")(
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/repro/after_aot.py", line 102, in debug_wrapper
[rank2]:     inner_compiled_fn = compiler_fn(gm, example_inputs)
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 744, in _compile_fx_inner
[rank2]:     compiled_graph = FxGraphCache.load(
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 1515, in load
[rank2]:     compiled_graph = compile_fx_fn(
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 651, in codegen_and_compile
[rank2]:     compiled_graph = fx_codegen_and_compile(gm, example_inputs, **fx_kwargs)
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 962, in fx_codegen_and_compile
[rank2]:     compiled_fn = graph.compile_to_fn()
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/graph.py", line 2034, in compile_to_fn
[rank2]:     return self.compile_to_module().call
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/graph.py", line 1954, in compile_to_module
[rank2]:     return self._compile_to_module()
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/graph.py", line 1988, in _compile_to_module
[rank2]:     mod = PyCodeCache.load_by_key_path(
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 3058, in load_by_key_path
[rank2]:     mod = _reload_python_module(key, path)
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/runtime/compile_tasks.py", line 45, in _reload_python_module
[rank2]:     exec(code, mod.__dict__, mod.__dict__)
[rank2]:   File "/home/charlie/skip-residual/gpt-fast/torchinductor_charlie/ct/cct65umpn477pb6hdjy5dn3rqmtgzpnnmncqkjpfgxxupdi54adj.py", line 1713, in <module>
[rank2]:     async_compile.wait(globals())
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/async_compile.py", line 319, in wait
[rank2]:     scope[key] = result.result()
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 3535, in result
[rank2]:     result = self.future.result()
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/concurrent/futures/_base.py", line 458, in result
[rank2]:     return self.__get_result()
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
[rank2]:     raise self._exception
[rank2]: torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:
[rank2]: SubprocException: An exception occurred in a subprocess:

[rank2]: Traceback (most recent call last):
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_worker/subproc_pool.py", line 280, in do_job
[rank2]:     result = job()
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/runtime/compile_tasks.py", line 68, in _worker_compile_triton
[rank2]:     load_kernel().precompile(warm_cache_only=True)
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/runtime/compile_tasks.py", line 13, in _reload_triton_kernel_in_subproc
[rank2]:     return _module_to_triton_kernel(reload_module(), kernel_name)
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/runtime/compile_tasks.py", line 29, in _reload_python_module_in_subproc
[rank2]:     return codecache.PyCodeCache.load_by_key_path(key, path)
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 3058, in load_by_key_path
[rank2]:     mod = _reload_python_module(key, path)
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/runtime/compile_tasks.py", line 45, in _reload_python_module
[rank2]:     exec(code, mod.__dict__, mod.__dict__)
[rank2]:   File "/home/charlie/skip-residual/gpt-fast/torchinductor_charlie/gj/cgjcjzxuwteh2wkxts2zm6ntozheqikup26doyreoprqjyrjnhsf.py", line 9, in <module>
[rank2]:     triton_helpers.set_driver_to_gpu()
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/runtime/triton_helpers.py", line 57, in set_driver_to_gpu
[rank2]:     driver.set_active(backend.driver())
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/triton/backends/nvidia/driver.py", line 371, in __init__
[rank2]:     self.utils = CudaUtils()  # TODO: make static
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/triton/backends/nvidia/driver.py", line 80, in __init__
[rank2]:     mod = compile_module_from_src(Path(os.path.join(dirname, "driver.c")).read_text(), "cuda_utils")
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/triton/backends/nvidia/driver.py", line 57, in compile_module_from_src
[rank2]:     so = _build(name, src_path, tmpdir, library_dirs(), include_dir, libraries)
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/triton/runtime/build.py", line 48, in _build
[rank2]:     ret = subprocess.check_call(cc_cmd)
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/subprocess.py", line 369, in check_call
[rank2]:     raise CalledProcessError(retcode, cmd)
[rank2]: subprocess.CalledProcessError: Command '['/usr/bin/gcc', '/home/charlie/skip-residual/gpt-fast/tmpnk0oqkb3/main.c', '-O3', '-shared', '-fPIC', '-o', '/home/charlie/skip-residual/gpt-fast/tmpnk0oqkb3/cuda_utils.cpython-310-x86_64-linux-gnu.so', '-lcuda', '-L/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/triton/backends/nvidia/lib', '-L/lib/x86_64-linux-gnu', '-I/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/triton/backends/nvidia/include', '-I/home/charlie/skip-residual/gpt-fast/tmpnk0oqkb3', '-I/home/charlie/anaconda3/envs/gpt-fast/include/python3.10']' returned non-zero exit status 1.


[rank2]: Set TORCH_LOGS="+dynamo" and TORCHDYNAMO_VERBOSE=1 for more information


[rank2]: You can suppress this exception and fall back to eager by setting:
[rank2]:     import torch._dynamo
[rank2]:     torch._dynamo.config.suppress_errors = True

/home/charlie/skip-residual/gpt-fast/tmpdci9e6f0/main.c:422:1: fatal error: error writing to /tmp/ccoAbapG.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpxjvy9eso/main.c:422:1: fatal error: error writing to /tmp/ccdAOYot.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpnapw5g2i/main.c:422:1: fatal error: error writing to /tmp/ccxpIdOO.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmp3xk8zf3s/main.c:422:1: fatal error: error writing to /tmp/ccIRgwlx.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpcpz2ajm3/main.c:422:1: fatal error: error writing to /tmp/ccnaukEl.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpv8xz0962/main.c:422:1: fatal error: error writing to /tmp/ccOpWLg0.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpckfpuc60/main.c:422:1: fatal error: error writing to /tmp/ccm6LEhK.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmp6s9w0yey/main.c:422:1: fatal error: error writing to /tmp/cci71fqP.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmp3soxi8qa/main.c:422:1: fatal error: error writing to /tmp/cc8d9yKd.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmp7u6dw1zh/main.c:422:1: fatal error: error writing to /tmp/cc2XWOTp.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpgc6v01tu/main.c:422:1: fatal error: error writing to /tmp/ccaK0KTR.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmprdrknltp/main.c:422:1: fatal error: error writing to /tmp/ccWhQZ48.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpdicl6ba5/main.c:422:1: fatal error: error writing to /tmp/cczoHogV.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpgzune8b9/main.c:422:1: fatal error: error writing to /tmp/ccHanDpB.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpipv0c9fs/main.c:422:1: fatal error: error writing to /tmp/ccGm6oRu.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpjkmldyj_/main.c:422:1: fatal error: error writing to /tmp/ccvWFV7E.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmppr0j3mr7/main.c:422:1: fatal error: error writing to /tmp/ccYR2qpF.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpsb3l44ue/main.c:422:1: fatal error: error writing to /tmp/ccBouTLw.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmp1ryr5hc8/main.c:422:1: fatal error: error writing to /tmp/cccQ3e0R.s: No space left on device
  422 | }
      | ^
/home/charlie/skip-residual/gpt-fast/tmp4lqcg7ln/main.c:422:1: fatal error: error writing to /tmp/ccaMWmdX.s: No space left on device
  422 | }
      | ^
compilation terminated.
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmp2_48eid6/main.c:422:1: fatal error: error writing to /tmp/ccn0pGuf.s: No space left on device
  422 | }
      | ^
compilation terminated.
[rank6]: Traceback (most recent call last):
[rank6]:   File "/home/charlie/skip-residual/gpt-fast/benchmark.py", line 708, in <module>
[rank6]:     main(
[rank6]:   File "/home/charlie/skip-residual/gpt-fast/benchmark.py", line 622, in main
[rank6]:     y, decode_latency, prefill_latency = generate(
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
[rank6]:     return func(*args, **kwargs)
[rank6]:   File "/home/charlie/skip-residual/gpt-fast/benchmark.py", line 336, in generate
[rank6]:     next_token = prefill(model, prompt.view(batch_size, -1), input_pos, **sampling_kwargs)
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py", line 556, in _fn
[rank6]:     return fn(*args, **kwargs)
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 1395, in __call__
[rank6]:     return self._torchdynamo_orig_callable(
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 545, in __call__
[rank6]:     return _compile(
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 977, in _compile
[rank6]:     guarded_code = compile_inner(code, one_graph, hooks, transform)
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 706, in compile_inner
[rank6]:     return _compile_inner(code, one_graph, hooks, transform)
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_utils_internal.py", line 95, in wrapper_function
[rank6]:     return function(*args, **kwargs)
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 741, in _compile_inner
[rank6]:     out_code = transform_code_object(code, transform)
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/bytecode_transformation.py", line 1348, in transform_code_object
[rank6]:     transformations(instructions, code_options)
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 229, in _fn
[rank6]:     return fn(*args, **kwargs)
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 658, in transform
[rank6]:     tracer.run()
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 2912, in run
[rank6]:     super().run()
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 1120, in run
[rank6]:     while self.step():
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 1032, in step
[rank6]:     self.dispatch_table[inst.opcode](self, inst)
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 3103, in RETURN_VALUE
[rank6]:     self._return(inst)
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 3088, in _return
[rank6]:     self.output.compile_subgraph(
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/output_graph.py", line 1077, in compile_subgraph
[rank6]:     self.compile_and_call_fx_graph(tx, list(reversed(stack_values)), root)
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/output_graph.py", line 1346, in compile_and_call_fx_graph
[rank6]:     compiled_fn = self.call_user_compiler(gm)
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/output_graph.py", line 1396, in call_user_compiler
[rank6]:     return self._call_user_compiler(gm)
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/output_graph.py", line 1445, in _call_user_compiler
[rank6]:     raise BackendCompilerFailed(self.compiler_fn, e).with_traceback(
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/output_graph.py", line 1426, in _call_user_compiler
[rank6]:     compiled_fn = compiler_fn(gm, self.example_inputs())
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/repro/after_dynamo.py", line 130, in __call__
[rank6]:     compiled_gm = compiler_fn(gm, example_inputs)
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/repro/after_dynamo.py", line 130, in __call__
[rank6]:     compiled_gm = compiler_fn(gm, example_inputs)
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/__init__.py", line 2301, in __call__
[rank6]:     return compile_fx(model_, inputs_, config_patches=self.config)
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 1708, in compile_fx
[rank6]:     return aot_autograd(
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/backends/common.py", line 72, in __call__
[rank6]:     cg = aot_module_simplified(gm, example_inputs, **self.kwargs)
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 1103, in aot_module_simplified
[rank6]:     compiled_fn = dispatch_and_compile()
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 1079, in dispatch_and_compile
[rank6]:     compiled_fn, _ = create_aot_dispatcher_function(
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 527, in create_aot_dispatcher_function
[rank6]:     return _create_aot_dispatcher_function(
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 778, in _create_aot_dispatcher_function
[rank6]:     compiled_fn, fw_metadata = compiler_fn(
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py", line 197, in aot_dispatch_base
[rank6]:     compiled_fw = compiler(fw_module, updated_flat_args)
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 1525, in fw_compiler_base
[rank6]:     return _fw_compiler_base(model, example_inputs, is_inference)
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 1594, in _fw_compiler_base
[rank6]:     return inner_compile(
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 587, in compile_fx_inner
[rank6]:     return wrap_compiler_debug(_compile_fx_inner, compiler_name="inductor")(
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/repro/after_aot.py", line 102, in debug_wrapper
[rank6]:     inner_compiled_fn = compiler_fn(gm, example_inputs)
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 744, in _compile_fx_inner
[rank6]:     compiled_graph = FxGraphCache.load(
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 1515, in load
[rank6]:     compiled_graph = compile_fx_fn(
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 651, in codegen_and_compile
[rank6]:     compiled_graph = fx_codegen_and_compile(gm, example_inputs, **fx_kwargs)
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 962, in fx_codegen_and_compile
[rank6]:     compiled_fn = graph.compile_to_fn()
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/graph.py", line 2034, in compile_to_fn
[rank6]:     return self.compile_to_module().call
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/graph.py", line 1954, in compile_to_module
[rank6]:     return self._compile_to_module()
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/graph.py", line 1988, in _compile_to_module
[rank6]:     mod = PyCodeCache.load_by_key_path(
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 3058, in load_by_key_path
[rank6]:     mod = _reload_python_module(key, path)
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/runtime/compile_tasks.py", line 45, in _reload_python_module
[rank6]:     exec(code, mod.__dict__, mod.__dict__)
[rank6]:   File "/home/charlie/skip-residual/gpt-fast/torchinductor_charlie/vf/cvfd5vexcahsaw4mjccdf6dyceb64tm775d64ssue65ldevlp35d.py", line 1713, in <module>
[rank6]:     async_compile.wait(globals())
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/async_compile.py", line 319, in wait
[rank6]:     scope[key] = result.result()
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 3535, in result
[rank6]:     result = self.future.result()
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/concurrent/futures/_base.py", line 458, in result
[rank6]:     return self.__get_result()
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
[rank6]:     raise self._exception
[rank6]: torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:
[rank6]: SubprocException: An exception occurred in a subprocess:

[rank6]: Traceback (most recent call last):
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_worker/subproc_pool.py", line 280, in do_job
[rank6]:     result = job()
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/runtime/compile_tasks.py", line 68, in _worker_compile_triton
[rank6]:     load_kernel().precompile(warm_cache_only=True)
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/runtime/compile_tasks.py", line 13, in _reload_triton_kernel_in_subproc
[rank6]:     return _module_to_triton_kernel(reload_module(), kernel_name)
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/runtime/compile_tasks.py", line 29, in _reload_python_module_in_subproc
[rank6]:     return codecache.PyCodeCache.load_by_key_path(key, path)
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 3058, in load_by_key_path
[rank6]:     mod = _reload_python_module(key, path)
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/runtime/compile_tasks.py", line 45, in _reload_python_module
[rank6]:     exec(code, mod.__dict__, mod.__dict__)
[rank6]:   File "/home/charlie/skip-residual/gpt-fast/torchinductor_charlie/jm/cjmoixurfevy6gyadfeec7armpr3uu7rhl76vpfmfx2qcblquj73.py", line 9, in <module>
[rank6]:     triton_helpers.set_driver_to_gpu()
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/runtime/triton_helpers.py", line 57, in set_driver_to_gpu
[rank6]:     driver.set_active(backend.driver())
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/triton/backends/nvidia/driver.py", line 371, in __init__
[rank6]:     self.utils = CudaUtils()  # TODO: make static
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/triton/backends/nvidia/driver.py", line 80, in __init__
[rank6]:     mod = compile_module_from_src(Path(os.path.join(dirname, "driver.c")).read_text(), "cuda_utils")
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/triton/backends/nvidia/driver.py", line 57, in compile_module_from_src
[rank6]:     so = _build(name, src_path, tmpdir, library_dirs(), include_dir, libraries)
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/triton/runtime/build.py", line 48, in _build
[rank6]:     ret = subprocess.check_call(cc_cmd)
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/subprocess.py", line 369, in check_call
[rank6]:     raise CalledProcessError(retcode, cmd)
[rank6]: subprocess.CalledProcessError: Command '['/usr/bin/gcc', '/home/charlie/skip-residual/gpt-fast/tmp6s9w0yey/main.c', '-O3', '-shared', '-fPIC', '-o', '/home/charlie/skip-residual/gpt-fast/tmp6s9w0yey/cuda_utils.cpython-310-x86_64-linux-gnu.so', '-lcuda', '-L/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/triton/backends/nvidia/lib', '-L/lib/x86_64-linux-gnu', '-I/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/triton/backends/nvidia/include', '-I/home/charlie/skip-residual/gpt-fast/tmp6s9w0yey', '-I/home/charlie/anaconda3/envs/gpt-fast/include/python3.10']' returned non-zero exit status 1.


[rank6]: Set TORCH_LOGS="+dynamo" and TORCHDYNAMO_VERBOSE=1 for more information


[rank6]: You can suppress this exception and fall back to eager by setting:
[rank6]:     import torch._dynamo
[rank6]:     torch._dynamo.config.suppress_errors = True

/home/charlie/skip-residual/gpt-fast/tmp5c86rg1q/main.c:422:1: fatal error: error writing to /tmp/ccImdEdU.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpd3p4e58n/main.c:422:1: fatal error: error writing to /tmp/cc8x66Cb.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpzu2317ou/main.c:422:1: fatal error: error writing to /tmp/ccRy9iPd.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmptdc9d5mc/main.c:422:1: fatal error: error writing to /tmp/ccSy0fk9.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmp2ya9vrzx/main.c:422:1: fatal error: error writing to /tmp/ccP3yYvT.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmphsfn6py5/main.c:422:1: fatal error: error writing to /tmp/ccV0yLdm.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpch3pr1m9/main.c:422:1: fatal error: error writing to /tmp/ccK71HXj.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmprjby_ish/main.c:422:1: fatal error: error writing to /tmp/cchWjUDc.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpsk0r0a37/main.c:422:1: fatal error: error writing to /tmp/ccUSZliY.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpnm_fubg6/main.c:422:1: fatal error: error writing to /tmp/cc8eDlQ7.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpr_hilgwp/main.c:422:1: fatal error: error writing to /tmp/ccM5YXfI.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpf21pd72t/main.c:422:1: fatal error: error writing to /tmp/ccetb5kx.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpfb1zltwx/main.c:422:1: fatal error: error writing to /tmp/ccROmC7y.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpt6u5u9zz/main.c:422:1: fatal error: error writing to /tmp/ccekxUOd.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpq5h5dqhb/main.c:422:1: fatal error: error writing to /tmp/cccjJUhS.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmp0ny218sy/main.c:422:1: fatal error: error writing to /tmp/ccIdrO9U.s: No space left on device
  422 | }
      | ^
compilation terminated.
[rank7]: Traceback (most recent call last):
[rank7]:   File "/home/charlie/skip-residual/gpt-fast/benchmark.py", line 708, in <module>
[rank7]:     main(
[rank7]:   File "/home/charlie/skip-residual/gpt-fast/benchmark.py", line 622, in main
[rank7]:     y, decode_latency, prefill_latency = generate(
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
[rank7]:     return func(*args, **kwargs)
[rank7]:   File "/home/charlie/skip-residual/gpt-fast/benchmark.py", line 336, in generate
[rank7]:     next_token = prefill(model, prompt.view(batch_size, -1), input_pos, **sampling_kwargs)
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py", line 556, in _fn
[rank7]:     return fn(*args, **kwargs)
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 1395, in __call__
[rank7]:     return self._torchdynamo_orig_callable(
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 545, in __call__
[rank7]:     return _compile(
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 977, in _compile
[rank7]:     guarded_code = compile_inner(code, one_graph, hooks, transform)
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 706, in compile_inner
[rank7]:     return _compile_inner(code, one_graph, hooks, transform)
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_utils_internal.py", line 95, in wrapper_function
[rank7]:     return function(*args, **kwargs)
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 741, in _compile_inner
[rank7]:     out_code = transform_code_object(code, transform)
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/bytecode_transformation.py", line 1348, in transform_code_object
[rank7]:     transformations(instructions, code_options)
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 229, in _fn
[rank7]:     return fn(*args, **kwargs)
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 658, in transform
[rank7]:     tracer.run()
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 2912, in run
[rank7]:     super().run()
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 1120, in run
[rank7]:     while self.step():
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 1032, in step
[rank7]:     self.dispatch_table[inst.opcode](self, inst)
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 3103, in RETURN_VALUE
[rank7]:     self._return(inst)
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 3088, in _return
[rank7]:     self.output.compile_subgraph(
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/output_graph.py", line 1077, in compile_subgraph
[rank7]:     self.compile_and_call_fx_graph(tx, list(reversed(stack_values)), root)
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/output_graph.py", line 1346, in compile_and_call_fx_graph
[rank7]:     compiled_fn = self.call_user_compiler(gm)
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/output_graph.py", line 1396, in call_user_compiler
[rank7]:     return self._call_user_compiler(gm)
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/output_graph.py", line 1445, in _call_user_compiler
[rank7]:     raise BackendCompilerFailed(self.compiler_fn, e).with_traceback(
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/output_graph.py", line 1426, in _call_user_compiler
[rank7]:     compiled_fn = compiler_fn(gm, self.example_inputs())
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/repro/after_dynamo.py", line 130, in __call__
[rank7]:     compiled_gm = compiler_fn(gm, example_inputs)
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/repro/after_dynamo.py", line 130, in __call__
[rank7]:     compiled_gm = compiler_fn(gm, example_inputs)
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/__init__.py", line 2301, in __call__
[rank7]:     return compile_fx(model_, inputs_, config_patches=self.config)
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 1708, in compile_fx
[rank7]:     return aot_autograd(
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/backends/common.py", line 72, in __call__
[rank7]:     cg = aot_module_simplified(gm, example_inputs, **self.kwargs)
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 1103, in aot_module_simplified
[rank7]:     compiled_fn = dispatch_and_compile()
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 1079, in dispatch_and_compile
[rank7]:     compiled_fn, _ = create_aot_dispatcher_function(
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 527, in create_aot_dispatcher_function
[rank7]:     return _create_aot_dispatcher_function(
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 778, in _create_aot_dispatcher_function
[rank7]:     compiled_fn, fw_metadata = compiler_fn(
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py", line 197, in aot_dispatch_base
[rank7]:     compiled_fw = compiler(fw_module, updated_flat_args)
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 1525, in fw_compiler_base
[rank7]:     return _fw_compiler_base(model, example_inputs, is_inference)
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 1594, in _fw_compiler_base
[rank7]:     return inner_compile(
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 587, in compile_fx_inner
[rank7]:     return wrap_compiler_debug(_compile_fx_inner, compiler_name="inductor")(
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/repro/after_aot.py", line 102, in debug_wrapper
[rank7]:     inner_compiled_fn = compiler_fn(gm, example_inputs)
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 744, in _compile_fx_inner
[rank7]:     compiled_graph = FxGraphCache.load(
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 1515, in load
[rank7]:     compiled_graph = compile_fx_fn(
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 651, in codegen_and_compile
[rank7]:     compiled_graph = fx_codegen_and_compile(gm, example_inputs, **fx_kwargs)
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 962, in fx_codegen_and_compile
[rank7]:     compiled_fn = graph.compile_to_fn()
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/graph.py", line 2034, in compile_to_fn
[rank7]:     return self.compile_to_module().call
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/graph.py", line 1954, in compile_to_module
[rank7]:     return self._compile_to_module()
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/graph.py", line 1988, in _compile_to_module
[rank7]:     mod = PyCodeCache.load_by_key_path(
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 3058, in load_by_key_path
[rank7]:     mod = _reload_python_module(key, path)
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/runtime/compile_tasks.py", line 45, in _reload_python_module
[rank7]:     exec(code, mod.__dict__, mod.__dict__)
[rank7]:   File "/home/charlie/skip-residual/gpt-fast/torchinductor_charlie/of/cofmfa2tiuxl5w63y7gmjdqy4ubnrgznv36spmhugx73d6kvpqlg.py", line 1713, in <module>
[rank7]:     async_compile.wait(globals())
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/async_compile.py", line 319, in wait
[rank7]:     scope[key] = result.result()
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 3535, in result
[rank7]:     result = self.future.result()
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/concurrent/futures/_base.py", line 458, in result
[rank7]:     return self.__get_result()
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
[rank7]:     raise self._exception
[rank7]: torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:
[rank7]: SubprocException: An exception occurred in a subprocess:

[rank7]: Traceback (most recent call last):
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_worker/subproc_pool.py", line 280, in do_job
[rank7]:     result = job()
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/runtime/compile_tasks.py", line 68, in _worker_compile_triton
[rank7]:     load_kernel().precompile(warm_cache_only=True)
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/runtime/compile_tasks.py", line 13, in _reload_triton_kernel_in_subproc
[rank7]:     return _module_to_triton_kernel(reload_module(), kernel_name)
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/runtime/compile_tasks.py", line 29, in _reload_python_module_in_subproc
[rank7]:     return codecache.PyCodeCache.load_by_key_path(key, path)
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 3058, in load_by_key_path
[rank7]:     mod = _reload_python_module(key, path)
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/runtime/compile_tasks.py", line 45, in _reload_python_module
[rank7]:     exec(code, mod.__dict__, mod.__dict__)
[rank7]:   File "/home/charlie/skip-residual/gpt-fast/torchinductor_charlie/o2/co2oampe2hdoaowbn4ttktymyrnq5xv5zs67oj5px2orgur67tvz.py", line 9, in <module>
[rank7]:     triton_helpers.set_driver_to_gpu()
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/runtime/triton_helpers.py", line 57, in set_driver_to_gpu
[rank7]:     driver.set_active(backend.driver())
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/triton/backends/nvidia/driver.py", line 371, in __init__
[rank7]:     self.utils = CudaUtils()  # TODO: make static
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/triton/backends/nvidia/driver.py", line 80, in __init__
[rank7]:     mod = compile_module_from_src(Path(os.path.join(dirname, "driver.c")).read_text(), "cuda_utils")
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/triton/backends/nvidia/driver.py", line 57, in compile_module_from_src
[rank7]:     so = _build(name, src_path, tmpdir, library_dirs(), include_dir, libraries)
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/triton/runtime/build.py", line 48, in _build
[rank7]:     ret = subprocess.check_call(cc_cmd)
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/subprocess.py", line 369, in check_call
[rank7]:     raise CalledProcessError(retcode, cmd)
[rank7]: subprocess.CalledProcessError: Command '['/usr/bin/gcc', '/home/charlie/skip-residual/gpt-fast/tmpq5h5dqhb/main.c', '-O3', '-shared', '-fPIC', '-o', '/home/charlie/skip-residual/gpt-fast/tmpq5h5dqhb/cuda_utils.cpython-310-x86_64-linux-gnu.so', '-lcuda', '-L/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/triton/backends/nvidia/lib', '-L/lib/x86_64-linux-gnu', '-I/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/triton/backends/nvidia/include', '-I/home/charlie/skip-residual/gpt-fast/tmpq5h5dqhb', '-I/home/charlie/anaconda3/envs/gpt-fast/include/python3.10']' returned non-zero exit status 1.


[rank7]: Set TORCH_LOGS="+dynamo" and TORCHDYNAMO_VERBOSE=1 for more information


[rank7]: You can suppress this exception and fall back to eager by setting:
[rank7]:     import torch._dynamo
[rank7]:     torch._dynamo.config.suppress_errors = True

/home/charlie/skip-residual/gpt-fast/tmpacmfs9qx/main.c:422:1: fatal error: error writing to /tmp/ccCqKSXj.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpvqfx5t2m/main.c:422:1: fatal error: error writing to /tmp/cclxpwWk.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpacn3scu0/main.c:422:1: fatal error: error writing to /tmp/ccyk8PPs.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpw4pydxhb/main.c:422:1: fatal error: error writing to /tmp/ccksM3gx.s: No space left on device
  422 | }
      | ^
/home/charlie/skip-residual/gpt-fast/tmp096t12ak/main.c:422:1: fatal error: error writing to /tmp/cchVTehJ.s: No space left on device
  422 | }
      | ^
compilation terminated.
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmp6dn287og/main.c:422:1: fatal error: error writing to /tmp/ccmaIwmw.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmp2aeiyb5m/main.c:422:1: fatal error: error writing to /tmp/ccKA7ukv.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpvtvymlva/main.c:422:1: fatal error: error writing to /tmp/ccisYKRK.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpxj6crt61/main.c:422:1: fatal error: error writing to /tmp/cc9driqK.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpt1r4av25/main.c:422:1: fatal error: error writing to /tmp/ccmqg06D.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpw1dnrv82/main.c:422:1: fatal error: error writing to /tmp/ccpgJG7E.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpjr0k2hm6/main.c:422:1: fatal error: error writing to /tmp/ccyXHOFc.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmp_boqv7x3/main.c:422:1: fatal error: error writing to /tmp/cc6YFIfk.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpsg35aebi/main.c:422:1: fatal error: error writing to /tmp/cc9t8x6r.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmp541xciv5/main.c:422:1: fatal error: error writing to /tmp/ccL01Vgd.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpaf2a90t7/main.c:422:1: fatal error: error writing to /tmp/ccm8NaNh.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpjue3bodo/main.c:422:1: fatal error: error writing to /tmp/ccm7vuze.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpevrcz219/main.c:422:1: fatal error: error writing to /tmp/cc4gnkmn.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpnxsaa1md/main.c:422:1: fatal error: error writing to /tmp/cc4VGUer.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpy6enj4jd/main.c:422:1: fatal error: error writing to /tmp/ccDOwSJA.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpvcnvdk9c/main.c:422:1: fatal error: error writing to /tmp/ccn2U0x9.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmplfaglewc/main.c:422:1: fatal error: error writing to /tmp/ccty1zAT.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpywyd45jz/main.c:422:1: fatal error: error writing to /tmp/ccLqAwFm.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpspcos_x2/main.c:422:1: fatal error: error writing to /tmp/ccq40IMo.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpin42mdd0/main.c:422:1: fatal error: error writing to /tmp/ccPsJW4C.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpwccg30b4/main.c:422:1: fatal error: error writing to /tmp/ccQHNP30.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpz4xi_c4l/main.c:422:1: fatal error: error writing to /tmp/cccEh8il.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpvbtuhlzo/main.c:422:1: fatal error: error writing to /tmp/cc5w0nPe.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpr44ncrtw/main.c:422:1: fatal error: error writing to /tmp/ccPvDaVU.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpy87pjlp0/main.c:422:1: fatal error: error writing to /tmp/ccbtGEFQ.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmp7hup0vvz/main.c:422:1: fatal error: error writing to /tmp/ccMrNwhO.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpojopxpzh/main.c:422:1: fatal error: error writing to /tmp/cc0kLD9S.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpzx8p32z5/main.c:422:1: fatal error: error writing to /tmp/ccmoiCWY.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmptm62tqmc/main.c:422:1: fatal error: error writing to /tmp/cc2zWSgG.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpb6v8k72g/main.c:422:1: fatal error: error writing to /tmp/ccK1gwNy.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpvse7k6l4/main.c:422:1: fatal error: error writing to /tmp/cc6aPWKs.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmp4cb9zsji/main.c:422:1: fatal error: error writing to /tmp/ccHlYkBE.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpd44ycqza/main.c:422:1: fatal error: error writing to /tmp/ccnJz60p.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpc3e1asse/main.c:422:1: fatal error: error writing to /tmp/ccODdtuh.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpveg0uf14/main.c:422:1: fatal error: error writing to /tmp/ccoKZc1W.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmp9vsw9j4a/main.c:422:1: fatal error: error writing to /tmp/ccUHa2TE.s: No space left on device
  422 | }
      | ^
/home/charlie/skip-residual/gpt-fast/tmpnkxwu3md/main.c:422:1: fatal error: error writing to /tmp/ccMzSKvO.s: No space left on device
  422 | }
      | ^
compilation terminated.
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpl9vcbu76/main.c:422:1: fatal error: error writing to /tmp/cctVlFnx.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpvurecewo/main.c:422:1: fatal error: error writing to /tmp/ccSkWlZU.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpysp0vxxv/main.c:422:1: fatal error: error writing to /tmp/ccJ0aFKW.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmp_9ruqka3/main.c:422:1: fatal error: error writing to /tmp/ccHwzEjH.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpnw9w0oaz/main.c:422:1: fatal error: error writing to /tmp/ccsyHTpB.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmp2nfilofq/main.c:422:1: fatal error: error writing to /tmp/ccRW5eWA.s: No space left on device
  422 | }
      | ^
/home/charlie/skip-residual/gpt-fast/tmpp3le4b99/main.c:422:1: fatal error: error writing to /tmp/ccb6JGub.s: No space left on device
  422 | }
      | ^
compilation terminated.
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpdc022bxq/main.c:422:1: fatal error: error writing to /tmp/ccIXIXgk.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmp1jttgx4x/main.c:422:1: fatal error: error writing to /tmp/cceRvHqX.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmp9enbr3tr/main.c:422:1: fatal error: error writing to /tmp/ccGMsgE5.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmp4yzbse43/main.c:422:1: fatal error: error writing to /tmp/ccRrwMAv.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpeqazdtaa/main.c:422:1: fatal error: error writing to /tmp/ccsTwFUV.s: No space left on device
  422 | }
      | ^
/home/charlie/skip-residual/gpt-fast/tmp2dv60xus/main.c:422:1: fatal error: error writing to /tmp/cc0sBjo9.s: No space left on device
  422 | }
      | ^
compilation terminated.
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpnhu8zgr0/main.c:422:1: fatal error: error writing to /tmp/ccIK3wMS.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpfn3l5qqz/main.c:422:1: fatal error: error writing to /tmp/ccq3vkLN.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpbd0d04pj/main.c:422:1: fatal error: error writing to /tmp/ccWpgJca.s: No space left on device
  422 | }
      | ^
compilation terminated.
[rank3]: Traceback (most recent call last):
[rank3]:   File "/home/charlie/skip-residual/gpt-fast/benchmark.py", line 708, in <module>
[rank3]:     main(
[rank3]:   File "/home/charlie/skip-residual/gpt-fast/benchmark.py", line 622, in main
[rank3]:     y, decode_latency, prefill_latency = generate(
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
[rank3]:     return func(*args, **kwargs)
[rank3]:   File "/home/charlie/skip-residual/gpt-fast/benchmark.py", line 336, in generate
[rank3]:     next_token = prefill(model, prompt.view(batch_size, -1), input_pos, **sampling_kwargs)
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py", line 556, in _fn
[rank3]:     return fn(*args, **kwargs)
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 1395, in __call__
[rank3]:     return self._torchdynamo_orig_callable(
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 545, in __call__
[rank3]:     return _compile(
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 977, in _compile
[rank3]:     guarded_code = compile_inner(code, one_graph, hooks, transform)
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 706, in compile_inner
[rank3]:     return _compile_inner(code, one_graph, hooks, transform)
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_utils_internal.py", line 95, in wrapper_function
[rank3]:     return function(*args, **kwargs)
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 741, in _compile_inner
[rank3]:     out_code = transform_code_object(code, transform)
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/bytecode_transformation.py", line 1348, in transform_code_object
[rank3]:     transformations(instructions, code_options)
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 229, in _fn
[rank3]:     return fn(*args, **kwargs)
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 658, in transform
[rank3]:     tracer.run()
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 2912, in run
[rank3]:     super().run()
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 1120, in run
[rank3]:     while self.step():
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 1032, in step
[rank3]:     self.dispatch_table[inst.opcode](self, inst)
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 3103, in RETURN_VALUE
[rank3]:     self._return(inst)
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 3088, in _return
[rank3]:     self.output.compile_subgraph(
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/output_graph.py", line 1077, in compile_subgraph
[rank3]:     self.compile_and_call_fx_graph(tx, list(reversed(stack_values)), root)
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/output_graph.py", line 1346, in compile_and_call_fx_graph
[rank3]:     compiled_fn = self.call_user_compiler(gm)
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/output_graph.py", line 1396, in call_user_compiler
[rank3]:     return self._call_user_compiler(gm)
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/output_graph.py", line 1445, in _call_user_compiler
[rank3]:     raise BackendCompilerFailed(self.compiler_fn, e).with_traceback(
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/output_graph.py", line 1426, in _call_user_compiler
[rank3]:     compiled_fn = compiler_fn(gm, self.example_inputs())
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/repro/after_dynamo.py", line 130, in __call__
[rank3]:     compiled_gm = compiler_fn(gm, example_inputs)
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/repro/after_dynamo.py", line 130, in __call__
[rank3]:     compiled_gm = compiler_fn(gm, example_inputs)
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/__init__.py", line 2301, in __call__
[rank3]:     return compile_fx(model_, inputs_, config_patches=self.config)
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 1708, in compile_fx
[rank3]:     return aot_autograd(
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/backends/common.py", line 72, in __call__
[rank3]:     cg = aot_module_simplified(gm, example_inputs, **self.kwargs)
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 1103, in aot_module_simplified
[rank3]:     compiled_fn = dispatch_and_compile()
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 1079, in dispatch_and_compile
[rank3]:     compiled_fn, _ = create_aot_dispatcher_function(
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 527, in create_aot_dispatcher_function
[rank3]:     return _create_aot_dispatcher_function(
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 778, in _create_aot_dispatcher_function
[rank3]:     compiled_fn, fw_metadata = compiler_fn(
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py", line 197, in aot_dispatch_base
[rank3]:     compiled_fw = compiler(fw_module, updated_flat_args)
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 1525, in fw_compiler_base
[rank3]:     return _fw_compiler_base(model, example_inputs, is_inference)
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 1594, in _fw_compiler_base
[rank3]:     return inner_compile(
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 587, in compile_fx_inner
[rank3]:     return wrap_compiler_debug(_compile_fx_inner, compiler_name="inductor")(
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/repro/after_aot.py", line 102, in debug_wrapper
[rank3]:     inner_compiled_fn = compiler_fn(gm, example_inputs)
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 744, in _compile_fx_inner
[rank3]:     compiled_graph = FxGraphCache.load(
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 1515, in load
[rank3]:     compiled_graph = compile_fx_fn(
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 651, in codegen_and_compile
[rank3]:     compiled_graph = fx_codegen_and_compile(gm, example_inputs, **fx_kwargs)
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 962, in fx_codegen_and_compile
[rank3]:     compiled_fn = graph.compile_to_fn()
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/graph.py", line 2034, in compile_to_fn
[rank3]:     return self.compile_to_module().call
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/graph.py", line 1954, in compile_to_module
[rank3]:     return self._compile_to_module()
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/graph.py", line 1988, in _compile_to_module
[rank3]:     mod = PyCodeCache.load_by_key_path(
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 3058, in load_by_key_path
[rank3]:     mod = _reload_python_module(key, path)
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/runtime/compile_tasks.py", line 45, in _reload_python_module
[rank3]:     exec(code, mod.__dict__, mod.__dict__)
[rank3]:   File "/home/charlie/skip-residual/gpt-fast/torchinductor_charlie/5z/c5z3vz6uzcsripapxnkxih546nd5ildsfj7vbd3wnmkyt72awq2j.py", line 1713, in <module>
[rank3]:     async_compile.wait(globals())
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/async_compile.py", line 319, in wait
[rank3]:     scope[key] = result.result()
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 3535, in result
[rank3]:     result = self.future.result()
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/concurrent/futures/_base.py", line 458, in result
[rank3]:     return self.__get_result()
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
[rank3]:     raise self._exception
[rank3]: torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:
[rank3]: SubprocException: An exception occurred in a subprocess:

[rank3]: Traceback (most recent call last):
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_worker/subproc_pool.py", line 280, in do_job
[rank3]:     result = job()
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/runtime/compile_tasks.py", line 68, in _worker_compile_triton
[rank3]:     load_kernel().precompile(warm_cache_only=True)
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/runtime/compile_tasks.py", line 13, in _reload_triton_kernel_in_subproc
[rank3]:     return _module_to_triton_kernel(reload_module(), kernel_name)
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/runtime/compile_tasks.py", line 29, in _reload_python_module_in_subproc
[rank3]:     return codecache.PyCodeCache.load_by_key_path(key, path)
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 3058, in load_by_key_path
[rank3]:     mod = _reload_python_module(key, path)
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/runtime/compile_tasks.py", line 45, in _reload_python_module
[rank3]:     exec(code, mod.__dict__, mod.__dict__)
[rank3]:   File "/home/charlie/skip-residual/gpt-fast/torchinductor_charlie/5d/c5dik2skeg3nig3pcphffj4b5ga64dci4cflf4vgpex4zqgvyibp.py", line 9, in <module>
[rank3]:     triton_helpers.set_driver_to_gpu()
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/runtime/triton_helpers.py", line 57, in set_driver_to_gpu
[rank3]:     driver.set_active(backend.driver())
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/triton/backends/nvidia/driver.py", line 371, in __init__
[rank3]:     self.utils = CudaUtils()  # TODO: make static
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/triton/backends/nvidia/driver.py", line 80, in __init__
[rank3]:     mod = compile_module_from_src(Path(os.path.join(dirname, "driver.c")).read_text(), "cuda_utils")
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/triton/backends/nvidia/driver.py", line 57, in compile_module_from_src
[rank3]:     so = _build(name, src_path, tmpdir, library_dirs(), include_dir, libraries)
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/triton/runtime/build.py", line 48, in _build
[rank3]:     ret = subprocess.check_call(cc_cmd)
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/subprocess.py", line 369, in check_call
[rank3]:     raise CalledProcessError(retcode, cmd)
[rank3]: subprocess.CalledProcessError: Command '['/usr/bin/gcc', '/home/charlie/skip-residual/gpt-fast/tmpjr0k2hm6/main.c', '-O3', '-shared', '-fPIC', '-o', '/home/charlie/skip-residual/gpt-fast/tmpjr0k2hm6/cuda_utils.cpython-310-x86_64-linux-gnu.so', '-lcuda', '-L/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/triton/backends/nvidia/lib', '-L/lib/x86_64-linux-gnu', '-I/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/triton/backends/nvidia/include', '-I/home/charlie/skip-residual/gpt-fast/tmpjr0k2hm6', '-I/home/charlie/anaconda3/envs/gpt-fast/include/python3.10']' returned non-zero exit status 1.


[rank3]: Set TORCH_LOGS="+dynamo" and TORCHDYNAMO_VERBOSE=1 for more information


[rank3]: You can suppress this exception and fall back to eager by setting:
[rank3]:     import torch._dynamo
[rank3]:     torch._dynamo.config.suppress_errors = True

/home/charlie/skip-residual/gpt-fast/tmp56thnbin/main.c:422:1: fatal error: error writing to /tmp/ccyW379j.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmp73u6bi50/main.c:422:1: fatal error: error writing to /tmp/ccPmMwfK.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmph9pq208h/main.c:422:1: fatal error: error writing to /tmp/ccSmjv3l.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmp8nn_l6qk/main.c:422:1: fatal error: error writing to /tmp/cchi1845.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpo530h5at/main.c:422:1: fatal error: error writing to /tmp/cc7UI4v1.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpl98plswl/main.c:422:1: fatal error: error writing to /tmp/cc11ukrD.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmplpctr0_0/main.c:422:1: fatal error: error writing to /tmp/ccSNDQjS.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpz05xrqy_/main.c:422:1: fatal error: error writing to /tmp/ccT0UaRy.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmp3fe8t7hu/main.c:422:1: fatal error: error writing to /tmp/ccbCMp6t.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpfoysc764/main.c:422:1: fatal error: error writing to /tmp/ccW8w5tz.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpy15jd0sj/main.c:422:1: fatal error: error writing to /tmp/cc7VJ6uX.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpjcuvwdjm/main.c:422:1: fatal error: error writing to /tmp/ccigYKuQ.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpsfg8arei/main.c:422:1: fatal error: error writing to /tmp/ccukHXC3.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpja_31kae/main.c:422:1: fatal error: error writing to /tmp/ccLc4I7W.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpf9on4k71/main.c:422:1: fatal error: error writing to /tmp/ccZ8X82M.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpykv1cq52/main.c:422:1: fatal error: error writing to /tmp/cctz6FLB.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpqeh75vme/main.c:422:1: fatal error: error writing to /tmp/ccXVsE9d.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpyqgdcnu_/main.c:422:1: fatal error: error writing to /tmp/cc5KgZ6R.s: No space left on device
  422 | }
      | ^
compilation terminated.
[rank4]: Traceback (most recent call last):
[rank4]:   File "/home/charlie/skip-residual/gpt-fast/benchmark.py", line 708, in <module>
[rank4]:     main(
[rank4]:   File "/home/charlie/skip-residual/gpt-fast/benchmark.py", line 622, in main
[rank4]:     y, decode_latency, prefill_latency = generate(
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
[rank4]:     return func(*args, **kwargs)
[rank4]:   File "/home/charlie/skip-residual/gpt-fast/benchmark.py", line 336, in generate
[rank4]:     next_token = prefill(model, prompt.view(batch_size, -1), input_pos, **sampling_kwargs)
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py", line 556, in _fn
[rank4]:     return fn(*args, **kwargs)
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 1395, in __call__
[rank4]:     return self._torchdynamo_orig_callable(
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 545, in __call__
[rank4]:     return _compile(
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 977, in _compile
[rank4]:     guarded_code = compile_inner(code, one_graph, hooks, transform)
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 706, in compile_inner
[rank4]:     return _compile_inner(code, one_graph, hooks, transform)
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_utils_internal.py", line 95, in wrapper_function
[rank4]:     return function(*args, **kwargs)
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 741, in _compile_inner
[rank4]:     out_code = transform_code_object(code, transform)
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/bytecode_transformation.py", line 1348, in transform_code_object
[rank4]:     transformations(instructions, code_options)
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 229, in _fn
[rank4]:     return fn(*args, **kwargs)
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 658, in transform
[rank4]:     tracer.run()
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 2912, in run
[rank4]:     super().run()
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 1120, in run
[rank4]:     while self.step():
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 1032, in step
[rank4]:     self.dispatch_table[inst.opcode](self, inst)
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 3103, in RETURN_VALUE
[rank4]:     self._return(inst)
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 3088, in _return
[rank4]:     self.output.compile_subgraph(
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/output_graph.py", line 1077, in compile_subgraph
[rank4]:     self.compile_and_call_fx_graph(tx, list(reversed(stack_values)), root)
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/output_graph.py", line 1346, in compile_and_call_fx_graph
[rank4]:     compiled_fn = self.call_user_compiler(gm)
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/output_graph.py", line 1396, in call_user_compiler
[rank4]:     return self._call_user_compiler(gm)
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/output_graph.py", line 1445, in _call_user_compiler
[rank4]:     raise BackendCompilerFailed(self.compiler_fn, e).with_traceback(
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/output_graph.py", line 1426, in _call_user_compiler
[rank4]:     compiled_fn = compiler_fn(gm, self.example_inputs())
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/repro/after_dynamo.py", line 130, in __call__
[rank4]:     compiled_gm = compiler_fn(gm, example_inputs)
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/repro/after_dynamo.py", line 130, in __call__
[rank4]:     compiled_gm = compiler_fn(gm, example_inputs)
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/__init__.py", line 2301, in __call__
[rank4]:     return compile_fx(model_, inputs_, config_patches=self.config)
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 1708, in compile_fx
[rank4]:     return aot_autograd(
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/backends/common.py", line 72, in __call__
[rank4]:     cg = aot_module_simplified(gm, example_inputs, **self.kwargs)
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 1103, in aot_module_simplified
[rank4]:     compiled_fn = dispatch_and_compile()
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 1079, in dispatch_and_compile
[rank4]:     compiled_fn, _ = create_aot_dispatcher_function(
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 527, in create_aot_dispatcher_function
[rank4]:     return _create_aot_dispatcher_function(
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 778, in _create_aot_dispatcher_function
[rank4]:     compiled_fn, fw_metadata = compiler_fn(
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py", line 197, in aot_dispatch_base
[rank4]:     compiled_fw = compiler(fw_module, updated_flat_args)
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 1525, in fw_compiler_base
[rank4]:     return _fw_compiler_base(model, example_inputs, is_inference)
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 1594, in _fw_compiler_base
[rank4]:     return inner_compile(
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 587, in compile_fx_inner
[rank4]:     return wrap_compiler_debug(_compile_fx_inner, compiler_name="inductor")(
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/repro/after_aot.py", line 102, in debug_wrapper
[rank4]:     inner_compiled_fn = compiler_fn(gm, example_inputs)
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 744, in _compile_fx_inner
[rank4]:     compiled_graph = FxGraphCache.load(
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 1515, in load
[rank4]:     compiled_graph = compile_fx_fn(
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 651, in codegen_and_compile
[rank4]:     compiled_graph = fx_codegen_and_compile(gm, example_inputs, **fx_kwargs)
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 962, in fx_codegen_and_compile
[rank4]:     compiled_fn = graph.compile_to_fn()
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/graph.py", line 2034, in compile_to_fn
[rank4]:     return self.compile_to_module().call
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/graph.py", line 1954, in compile_to_module
[rank4]:     return self._compile_to_module()
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/graph.py", line 1988, in _compile_to_module
[rank4]:     mod = PyCodeCache.load_by_key_path(
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 3058, in load_by_key_path
[rank4]:     mod = _reload_python_module(key, path)
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/runtime/compile_tasks.py", line 45, in _reload_python_module
[rank4]:     exec(code, mod.__dict__, mod.__dict__)
[rank4]:   File "/home/charlie/skip-residual/gpt-fast/torchinductor_charlie/7p/c7prezew4lepupa6skg44zpq6azjnfmb2hnyn4pgx2qfuqqiwbxd.py", line 1713, in <module>
[rank4]:     async_compile.wait(globals())
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/async_compile.py", line 319, in wait
[rank4]:     scope[key] = result.result()
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 3535, in result
[rank4]:     result = self.future.result()
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/concurrent/futures/_base.py", line 458, in result
[rank4]:     return self.__get_result()
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
[rank4]:     raise self._exception
[rank4]: torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:
[rank4]: SubprocException: An exception occurred in a subprocess:

[rank4]: Traceback (most recent call last):
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_worker/subproc_pool.py", line 280, in do_job
[rank4]:     result = job()
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/runtime/compile_tasks.py", line 68, in _worker_compile_triton
[rank4]:     load_kernel().precompile(warm_cache_only=True)
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/runtime/compile_tasks.py", line 13, in _reload_triton_kernel_in_subproc
[rank4]:     return _module_to_triton_kernel(reload_module(), kernel_name)
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/runtime/compile_tasks.py", line 29, in _reload_python_module_in_subproc
[rank4]:     return codecache.PyCodeCache.load_by_key_path(key, path)
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 3058, in load_by_key_path
[rank4]:     mod = _reload_python_module(key, path)
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/runtime/compile_tasks.py", line 45, in _reload_python_module
[rank4]:     exec(code, mod.__dict__, mod.__dict__)
[rank4]:   File "/home/charlie/skip-residual/gpt-fast/torchinductor_charlie/5y/c5yibkmsag7hsr5pw7jihvrlv6sp2k75hm5hk26xrmojgegz5rgt.py", line 9, in <module>
[rank4]:     triton_helpers.set_driver_to_gpu()
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/runtime/triton_helpers.py", line 57, in set_driver_to_gpu
[rank4]:     driver.set_active(backend.driver())
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/triton/backends/nvidia/driver.py", line 371, in __init__
[rank4]:     self.utils = CudaUtils()  # TODO: make static
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/triton/backends/nvidia/driver.py", line 80, in __init__
[rank4]:     mod = compile_module_from_src(Path(os.path.join(dirname, "driver.c")).read_text(), "cuda_utils")
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/triton/backends/nvidia/driver.py", line 57, in compile_module_from_src
[rank4]:     so = _build(name, src_path, tmpdir, library_dirs(), include_dir, libraries)
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/triton/runtime/build.py", line 48, in _build
[rank4]:     ret = subprocess.check_call(cc_cmd)
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/subprocess.py", line 369, in check_call
[rank4]:     raise CalledProcessError(retcode, cmd)
[rank4]: subprocess.CalledProcessError: Command '['/usr/bin/gcc', '/home/charlie/skip-residual/gpt-fast/tmpz4xi_c4l/main.c', '-O3', '-shared', '-fPIC', '-o', '/home/charlie/skip-residual/gpt-fast/tmpz4xi_c4l/cuda_utils.cpython-310-x86_64-linux-gnu.so', '-lcuda', '-L/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/triton/backends/nvidia/lib', '-L/lib/x86_64-linux-gnu', '-I/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/triton/backends/nvidia/include', '-I/home/charlie/skip-residual/gpt-fast/tmpz4xi_c4l', '-I/home/charlie/anaconda3/envs/gpt-fast/include/python3.10']' returned non-zero exit status 1.


[rank4]: Set TORCH_LOGS="+dynamo" and TORCHDYNAMO_VERBOSE=1 for more information


[rank4]: You can suppress this exception and fall back to eager by setting:
[rank4]:     import torch._dynamo
[rank4]:     torch._dynamo.config.suppress_errors = True

/home/charlie/skip-residual/gpt-fast/tmp3kx0umxq/main.c:422:1: fatal error: error writing to /tmp/ccUat2Qs.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmp3i1a34k3/main.c:422:1: fatal error: error writing to /tmp/cc2Gt8u7.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpiv6qh9sb/main.c:422:1: fatal error: error writing to /tmp/ccXP4Hns.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmp7mzw0mi5/main.c:422:1: fatal error: error writing to /tmp/ccPxLSeY.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpzx2zia1s/main.c:422:1: fatal error: error writing to /tmp/cc8qrhkq.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmp84cx140v/main.c:422:1: fatal error: error writing to /tmp/ccfKUtd6.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmp0wdkgxfb/main.c:422:1: fatal error: error writing to /tmp/cc4H4dlM.s: No space left on device
  422 | }
      | ^
compilation terminated.
[rank1]: Traceback (most recent call last):
[rank1]:   File "/home/charlie/skip-residual/gpt-fast/benchmark.py", line 708, in <module>
[rank1]:     main(
[rank1]:   File "/home/charlie/skip-residual/gpt-fast/benchmark.py", line 622, in main
[rank1]:     y, decode_latency, prefill_latency = generate(
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
[rank1]:     return func(*args, **kwargs)
[rank1]:   File "/home/charlie/skip-residual/gpt-fast/benchmark.py", line 336, in generate
[rank1]:     next_token = prefill(model, prompt.view(batch_size, -1), input_pos, **sampling_kwargs)
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py", line 556, in _fn
[rank1]:     return fn(*args, **kwargs)
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 1395, in __call__
[rank1]:     return self._torchdynamo_orig_callable(
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 545, in __call__
[rank1]:     return _compile(
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 977, in _compile
[rank1]:     guarded_code = compile_inner(code, one_graph, hooks, transform)
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 706, in compile_inner
[rank1]:     return _compile_inner(code, one_graph, hooks, transform)
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_utils_internal.py", line 95, in wrapper_function
[rank1]:     return function(*args, **kwargs)
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 741, in _compile_inner
[rank1]:     out_code = transform_code_object(code, transform)
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/bytecode_transformation.py", line 1348, in transform_code_object
[rank1]:     transformations(instructions, code_options)
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 229, in _fn
[rank1]:     return fn(*args, **kwargs)
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 658, in transform
[rank1]:     tracer.run()
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 2912, in run
[rank1]:     super().run()
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 1120, in run
[rank1]:     while self.step():
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 1032, in step
[rank1]:     self.dispatch_table[inst.opcode](self, inst)
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 3103, in RETURN_VALUE
[rank1]:     self._return(inst)
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 3088, in _return
[rank1]:     self.output.compile_subgraph(
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/output_graph.py", line 1077, in compile_subgraph
[rank1]:     self.compile_and_call_fx_graph(tx, list(reversed(stack_values)), root)
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/output_graph.py", line 1346, in compile_and_call_fx_graph
[rank1]:     compiled_fn = self.call_user_compiler(gm)
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/output_graph.py", line 1396, in call_user_compiler
[rank1]:     return self._call_user_compiler(gm)
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/output_graph.py", line 1445, in _call_user_compiler
[rank1]:     raise BackendCompilerFailed(self.compiler_fn, e).with_traceback(
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/output_graph.py", line 1426, in _call_user_compiler
[rank1]:     compiled_fn = compiler_fn(gm, self.example_inputs())
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/repro/after_dynamo.py", line 130, in __call__
[rank1]:     compiled_gm = compiler_fn(gm, example_inputs)
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/repro/after_dynamo.py", line 130, in __call__
[rank1]:     compiled_gm = compiler_fn(gm, example_inputs)
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/__init__.py", line 2301, in __call__
[rank1]:     return compile_fx(model_, inputs_, config_patches=self.config)
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 1708, in compile_fx
[rank1]:     return aot_autograd(
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/backends/common.py", line 72, in __call__
[rank1]:     cg = aot_module_simplified(gm, example_inputs, **self.kwargs)
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 1103, in aot_module_simplified
[rank1]:     compiled_fn = dispatch_and_compile()
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 1079, in dispatch_and_compile
[rank1]:     compiled_fn, _ = create_aot_dispatcher_function(
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 527, in create_aot_dispatcher_function
[rank1]:     return _create_aot_dispatcher_function(
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 778, in _create_aot_dispatcher_function
[rank1]:     compiled_fn, fw_metadata = compiler_fn(
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py", line 197, in aot_dispatch_base
[rank1]:     compiled_fw = compiler(fw_module, updated_flat_args)
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 1525, in fw_compiler_base
[rank1]:     return _fw_compiler_base(model, example_inputs, is_inference)
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 1594, in _fw_compiler_base
[rank1]:     return inner_compile(
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 587, in compile_fx_inner
[rank1]:     return wrap_compiler_debug(_compile_fx_inner, compiler_name="inductor")(
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/repro/after_aot.py", line 102, in debug_wrapper
[rank1]:     inner_compiled_fn = compiler_fn(gm, example_inputs)
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 744, in _compile_fx_inner
[rank1]:     compiled_graph = FxGraphCache.load(
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 1515, in load
[rank1]:     compiled_graph = compile_fx_fn(
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 651, in codegen_and_compile
[rank1]:     compiled_graph = fx_codegen_and_compile(gm, example_inputs, **fx_kwargs)
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 962, in fx_codegen_and_compile
[rank1]:     compiled_fn = graph.compile_to_fn()
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/graph.py", line 2034, in compile_to_fn
[rank1]:     return self.compile_to_module().call
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/graph.py", line 1954, in compile_to_module
[rank1]:     return self._compile_to_module()
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/graph.py", line 1988, in _compile_to_module
[rank1]:     mod = PyCodeCache.load_by_key_path(
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 3058, in load_by_key_path
[rank1]:     mod = _reload_python_module(key, path)
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/runtime/compile_tasks.py", line 45, in _reload_python_module
[rank1]:     exec(code, mod.__dict__, mod.__dict__)
[rank1]:   File "/home/charlie/skip-residual/gpt-fast/torchinductor_charlie/6f/c6fnpsfkbur2fd52wgpbvexzajqupfk6gerpdeeupm6dqed2t3ig.py", line 1713, in <module>
[rank1]:     async_compile.wait(globals())
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/async_compile.py", line 319, in wait
[rank1]:     scope[key] = result.result()
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 3535, in result
[rank1]:     result = self.future.result()
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/concurrent/futures/_base.py", line 458, in result
[rank1]:     return self.__get_result()
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
[rank1]:     raise self._exception
[rank1]: torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:
[rank1]: SubprocException: An exception occurred in a subprocess:

[rank1]: Traceback (most recent call last):
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_worker/subproc_pool.py", line 280, in do_job
[rank1]:     result = job()
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/runtime/compile_tasks.py", line 68, in _worker_compile_triton
[rank1]:     load_kernel().precompile(warm_cache_only=True)
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/runtime/compile_tasks.py", line 13, in _reload_triton_kernel_in_subproc
[rank1]:     return _module_to_triton_kernel(reload_module(), kernel_name)
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/runtime/compile_tasks.py", line 29, in _reload_python_module_in_subproc
[rank1]:     return codecache.PyCodeCache.load_by_key_path(key, path)
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 3058, in load_by_key_path
[rank1]:     mod = _reload_python_module(key, path)
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/runtime/compile_tasks.py", line 45, in _reload_python_module
[rank1]:     exec(code, mod.__dict__, mod.__dict__)
[rank1]:   File "/home/charlie/skip-residual/gpt-fast/torchinductor_charlie/nb/cnbmgixuev4wxu6if63m6slu2v4j77cgwzqfiksvqws4jwgzfbpp.py", line 9, in <module>
[rank1]:     triton_helpers.set_driver_to_gpu()
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/runtime/triton_helpers.py", line 57, in set_driver_to_gpu
[rank1]:     driver.set_active(backend.driver())
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/triton/backends/nvidia/driver.py", line 371, in __init__
[rank1]:     self.utils = CudaUtils()  # TODO: make static
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/triton/backends/nvidia/driver.py", line 80, in __init__
[rank1]:     mod = compile_module_from_src(Path(os.path.join(dirname, "driver.c")).read_text(), "cuda_utils")
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/triton/backends/nvidia/driver.py", line 57, in compile_module_from_src
[rank1]:     so = _build(name, src_path, tmpdir, library_dirs(), include_dir, libraries)
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/triton/runtime/build.py", line 48, in _build
[rank1]:     ret = subprocess.check_call(cc_cmd)
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/subprocess.py", line 369, in check_call
[rank1]:     raise CalledProcessError(retcode, cmd)
[rank1]: subprocess.CalledProcessError: Command '['/usr/bin/gcc', '/home/charlie/skip-residual/gpt-fast/tmp2nfilofq/main.c', '-O3', '-shared', '-fPIC', '-o', '/home/charlie/skip-residual/gpt-fast/tmp2nfilofq/cuda_utils.cpython-310-x86_64-linux-gnu.so', '-lcuda', '-L/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/triton/backends/nvidia/lib', '-L/lib/x86_64-linux-gnu', '-I/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/triton/backends/nvidia/include', '-I/home/charlie/skip-residual/gpt-fast/tmp2nfilofq', '-I/home/charlie/anaconda3/envs/gpt-fast/include/python3.10']' returned non-zero exit status 1.


[rank1]: Set TORCH_LOGS="+dynamo" and TORCHDYNAMO_VERBOSE=1 for more information


[rank1]: You can suppress this exception and fall back to eager by setting:
[rank1]:     import torch._dynamo
[rank1]:     torch._dynamo.config.suppress_errors = True

/home/charlie/skip-residual/gpt-fast/tmpxwmsl28u/main.c:422:1: fatal error: error writing to /tmp/ccRTrqfN.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmp_9eyax3d/main.c:422:1: fatal error: error writing to /tmp/ccBmhKdW.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpc0igwy_3/main.c:422:1: fatal error: error writing to /tmp/ccDd8dzy.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpj77pxq_g/main.c:422:1: fatal error: error writing to /tmp/ccPJCFi9.s: No space left on device
  422 | }
      | ^
compilation terminated.
[rank0]:[W1201 11:32:55.828766062 ProcessGroupNCCL.cpp:1374] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
[rank5]:[W1201 11:32:55.896889862 ProcessGroupNCCL.cpp:1374] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
[rank2]:[W1201 11:32:56.441995622 ProcessGroupNCCL.cpp:1374] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
[rank7]:[W1201 11:32:56.711956819 ProcessGroupNCCL.cpp:1374] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
[rank3]:[W1201 11:32:56.002407282 ProcessGroupNCCL.cpp:1374] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
[rank4]:[W1201 11:32:57.283634560 ProcessGroupNCCL.cpp:1374] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
[rank6]:[W1201 11:32:57.326524086 ProcessGroupNCCL.cpp:1374] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
[rank1]:[W1201 11:32:57.906326147 ProcessGroupNCCL.cpp:1374] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
W1201 11:32:57.988000 467454 site-packages/torch/distributed/elastic/multiprocessing/api.py:897] Sending process 467524 closing signal SIGTERM
W1201 11:32:57.992000 467454 site-packages/torch/distributed/elastic/multiprocessing/api.py:897] Sending process 467525 closing signal SIGTERM
W1201 11:32:57.996000 467454 site-packages/torch/distributed/elastic/multiprocessing/api.py:897] Sending process 467526 closing signal SIGTERM
W1201 11:32:58.008000 467454 site-packages/torch/distributed/elastic/multiprocessing/api.py:897] Sending process 467527 closing signal SIGTERM
W1201 11:32:58.011000 467454 site-packages/torch/distributed/elastic/multiprocessing/api.py:897] Sending process 467528 closing signal SIGTERM
W1201 11:32:58.024000 467454 site-packages/torch/distributed/elastic/multiprocessing/api.py:897] Sending process 467529 closing signal SIGTERM
W1201 11:32:58.027000 467454 site-packages/torch/distributed/elastic/multiprocessing/api.py:897] Sending process 467530 closing signal SIGTERM
E1201 11:32:58.812000 467454 site-packages/torch/distributed/elastic/multiprocessing/api.py:869] failed (exitcode: 1) local_rank: 0 (pid: 467523) of binary: /home/charlie/anaconda3/envs/gpt-fast/bin/python
Traceback (most recent call last):
  File "/home/charlie/anaconda3/envs/gpt-fast/bin/torchrun", line 8, in <module>
    sys.exit(main())
  File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 355, in wrapper
    return f(*args, **kwargs)
  File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/distributed/run.py", line 919, in main
    run(args)
  File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/distributed/run.py", line 910, in run
    elastic_launch(
  File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 138, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 269, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
benchmark.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2024-12-01_11:32:57
  host      : mk-xii-22.cloud.together.ai
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 467523)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
