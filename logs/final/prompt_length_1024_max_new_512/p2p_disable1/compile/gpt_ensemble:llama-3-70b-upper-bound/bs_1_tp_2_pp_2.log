W1201 23:20:50.944000 1338116 site-packages/torch/distributed/run.py:793] 
W1201 23:20:50.944000 1338116 site-packages/torch/distributed/run.py:793] *****************************************
W1201 23:20:50.944000 1338116 site-packages/torch/distributed/run.py:793] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W1201 23:20:50.944000 1338116 site-packages/torch/distributed/run.py:793] *****************************************
DeviceMesh('cuda', [[0, 1], [2, 3]], mesh_dim_names=('pp', 'tp'))
DeviceMesh('cuda', [[0, 1], [2, 3]], mesh_dim_names=('pp', 'tp'))
DeviceMesh('cuda', [[0, 1], [2, 3]], mesh_dim_names=('pp', 'tp'))
DeviceMesh('cuda', [[0, 1], [2, 3]], mesh_dim_names=('pp', 'tp'))
Using device=cuda
Loading model ...
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
GPTEnsemble(
  (layers): ModuleList(
    (0-39): 40 x EnsembleTransformerBlock(
      semi_compiled = False
      (attention): Attention(
        (wqkv): Linear(in_features=8192, out_features=5120, bias=False)
        (wo): Linear(in_features=4096, out_features=8192, bias=False)
      )
      (feed_forward): FeedForward(
        (w1): Linear(in_features=8192, out_features=28672, bias=False)
        (w2): Linear(in_features=14336, out_features=8192, bias=False)
      )
      (ffn_norm): RMSNorm()
      (attention_norm): RMSNorm()
    )
  )
  (norm): RMSNorm()
  (output): Linear(in_features=8192, out_features=128256, bias=False)
)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
Time to load model: 1.13 seconds
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
Compiling prefill with dynamic=False
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
Prefill latency: 31.975295287906192 sec
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
Decode latency: 31.78572622302454 secCompilation time: 63.88 seconds

Compilation time: 63.96 seconds
Compilation time: 63.83 seconds
Compilation time: 63.76 seconds
Prefill latency: 0.1897703770082444 sec
Decode latency: 13.45540290500503 sec
Prefill latency: 0.1857137141050771 sec
Decode latency: 13.455750123946927 sec
Prefill latency: 0.18713099299930036 sec
Decode latency: 13.455618222011253 sec
Prefill latency: 0.18592238903511316 sec
Decode latency: 13.451956400997005 sec
Prefill latency: 0.18582350201904774 sec
Decode latency: 13.455966349109076 sec
Time for inference 1: 13.64 sec total, 37.53 tokens/sec
Decode latency: 13.46 sec
Prefill latency: 0.19 sec
Bandwidth achieved: 1363.27 GB/s
FLOPS achieved: 4.09 TF/s

Prefill latency: 0.18663136998657137 sec
Decode latency: 13.455871793092228 sec
Time for inference 2: 13.64 sec total, 37.52 tokens/sec
Decode latency: 13.46 sec
Prefill latency: 0.19 sec
Bandwidth achieved: 1363.19 GB/s
FLOPS achieved: 4.09 TF/s

Prefill latency: 0.18617420899681747 sec
Decode latency: 13.454869004082866 sec
Time for inference 3: 13.64 sec total, 37.53 tokens/sec
Decode latency: 13.45 sec
Prefill latency: 0.19 sec
Bandwidth achieved: 1363.32 GB/s
FLOPS achieved: 4.09 TF/s

Prefill latency: 0.18636200902983546 sec
Decode latency: 13.45576806308236 sec
Time for inference 4: 13.64 sec total, 37.53 tokens/sec
Decode latency: 13.46 sec
Prefill latency: 0.19 sec
Bandwidth achieved: 1363.23 GB/s
FLOPS achieved: 4.09 TF/s

Prefill latency: 0.18587770697195083 sec
Decode latency: 13.456925573991612 sec
Time for inference 5: 13.64 sec total, 37.52 tokens/sec
Decode latency: 13.46 sec
Prefill latency: 0.19 sec
Bandwidth achieved: 1363.16 GB/s
FLOPS achieved: 4.09 TF/s

Prefill latency: 0.18823199591133744 sec
Decode latency: 13.455111113958992 sec
Time for inference 6: 13.65 sec total, 37.52 tokens/sec
Decode latency: 13.46 sec
Prefill latency: 0.19 sec
Bandwidth achieved: 1363.13 GB/s
FLOPS achieved: 4.09 TF/s

Prefill latency: 0.1857807250926271 sec
Decode latency: 13.455958672915585 sec
Time for inference 7: 13.64 sec total, 37.53 tokens/sec
Decode latency: 13.46 sec
Prefill latency: 0.19 sec
Bandwidth achieved: 1363.26 GB/s
FLOPS achieved: 4.09 TF/s

Prefill latency: 0.18953030498232692 sec
Decode latency: 13.459454435040243 sec
Time for inference 8: 13.65 sec total, 37.50 tokens/sec
Decode latency: 13.46 sec
Prefill latency: 0.19 sec
Bandwidth achieved: 1362.46 GB/s
FLOPS achieved: 4.09 TF/s

Prefill latency: 0.18521752103697509 sec
Decode latency: 13.45383207499981 sec
Time for inference 9: 13.64 sec total, 37.53 tokens/sec
Decode latency: 13.45 sec
Prefill latency: 0.19 sec
Bandwidth achieved: 1363.54 GB/s
FLOPS achieved: 4.09 TF/s

Prefill latency: 0.18800427799578756 sec
Decode latency: 13.455100139020942 sec
Time for inference 10: 13.65 sec total, 37.52 tokens/sec
Decode latency: 13.46 sec
Prefill latency: 0.19 sec
Bandwidth achieved: 1363.13 GB/s
FLOPS achieved: 4.09 TF/s

==========
Batch Size: 1
Prompt Length: 1024
Generated tokens: 512
Average decode latency: 13.4559 sec
Average prefill latency: 0.1868 sec
Average tokens/sec: 37.52
Memory used: 37.63 GB
Done. we are killing the process
[rank0]:[W1201 23:25:11.655823849 ProcessGroupNCCL.cpp:1374] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
[rank1]:[W1201 23:25:11.786154011 ProcessGroupNCCL.cpp:1374] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
[rank2]:[W1201 23:25:12.207032880 ProcessGroupNCCL.cpp:1374] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
