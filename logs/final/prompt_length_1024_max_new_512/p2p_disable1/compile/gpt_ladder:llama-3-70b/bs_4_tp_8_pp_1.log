W1201 11:20:07.194000 455452 site-packages/torch/distributed/run.py:793] 
W1201 11:20:07.194000 455452 site-packages/torch/distributed/run.py:793] *****************************************
W1201 11:20:07.194000 455452 site-packages/torch/distributed/run.py:793] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W1201 11:20:07.194000 455452 site-packages/torch/distributed/run.py:793] *****************************************
DeviceMesh('cuda', [[0, 1, 2, 3, 4, 5, 6, 7]], mesh_dim_names=('pp', 'tp'))
Using device=cuda
Loading model ...
DeviceMesh('cuda', [[0, 1, 2, 3, 4, 5, 6, 7]], mesh_dim_names=('pp', 'tp'))
DeviceMesh('cuda', [[0, 1, 2, 3, 4, 5, 6, 7]], mesh_dim_names=('pp', 'tp'))
DeviceMesh('cuda', [[0, 1, 2, 3, 4, 5, 6, 7]], mesh_dim_names=('pp', 'tp'))
DeviceMesh('cuda', [[0, 1, 2, 3, 4, 5, 6, 7]], mesh_dim_names=('pp', 'tp'))
DeviceMesh('cuda', [[0, 1, 2, 3, 4, 5, 6, 7]], mesh_dim_names=('pp', 'tp'))
DeviceMesh('cuda', [[0, 1, 2, 3, 4, 5, 6, 7]], mesh_dim_names=('pp', 'tp'))
DeviceMesh('cuda', [[0, 1, 2, 3, 4, 5, 6, 7]], mesh_dim_names=('pp', 'tp'))
GPTLadder(
  (tok_embeddings): Embedding(128256, 8192)
  (layers): ModuleList(
    (0-79): 80 x LadderTransformerBlock(
      semi_compiled = False
      (attention): Attention(
        (wqkv): Linear(in_features=8192, out_features=1280, bias=False)
        (wo): Linear(in_features=1024, out_features=8192, bias=False)
      )
      (feed_forward): FeedForward(
        (w1): Linear(in_features=8192, out_features=7168, bias=False)
        (w2): Linear(in_features=3584, out_features=8192, bias=False)
      )
      (ffn_norm): RMSNorm()
      (attention_norm): RMSNorm()
    )
  )
  (norm): RMSNorm()
  (output): Linear(in_features=8192, out_features=128256, bias=False)
)
Time to load model: 0.68 seconds
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
Compiling prefill with dynamic=False
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py:222: UserWarning: TensorFloat32 tensor cores for float32 matrix multiplication available but not enabled. Consider setting `torch.set_float32_matmul_precision('high')` for better performance.
  warnings.warn(
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py:222: UserWarning: TensorFloat32 tensor cores for float32 matrix multiplication available but not enabled. Consider setting `torch.set_float32_matmul_precision('high')` for better performance.
  warnings.warn(
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py:222: UserWarning: TensorFloat32 tensor cores for float32 matrix multiplication available but not enabled. Consider setting `torch.set_float32_matmul_precision('high')` for better performance.
  warnings.warn(
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py:222: UserWarning: TensorFloat32 tensor cores for float32 matrix multiplication available but not enabled. Consider setting `torch.set_float32_matmul_precision('high')` for better performance.
  warnings.warn(
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py:222: UserWarning: TensorFloat32 tensor cores for float32 matrix multiplication available but not enabled. Consider setting `torch.set_float32_matmul_precision('high')` for better performance.
  warnings.warn(
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py:222: UserWarning: TensorFloat32 tensor cores for float32 matrix multiplication available but not enabled. Consider setting `torch.set_float32_matmul_precision('high')` for better performance.
  warnings.warn(
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py:222: UserWarning: TensorFloat32 tensor cores for float32 matrix multiplication available but not enabled. Consider setting `torch.set_float32_matmul_precision('high')` for better performance.
  warnings.warn(
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py:222: UserWarning: TensorFloat32 tensor cores for float32 matrix multiplication available but not enabled. Consider setting `torch.set_float32_matmul_precision('high')` for better performance.
  warnings.warn(
/home/charlie/skip-residual/gpt-fast/tmpl_sxqfrv/main.c:422:1: fatal error: error writing to /tmp/cczrVfAr.s: No space left on device
  422 | }
      | ^
/home/charlie/skip-residual/gpt-fast/tmp36vi_z2k/main.c:422:1: fatal error: error writing to /tmp/ccdkdGNc.s: No space left on device
  422 | }
      | ^
compilation terminated.
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmptbmibmlx/main.c:422:1: fatal error: error writing to /tmp/ccJGCebm.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmptog4oto5/main.c:422:1: fatal error: error writing to /tmp/cclzHCuQ.s: No space left on device
  422 | }
      | ^
compilation terminated.
[rank0]: Traceback (most recent call last):
[rank0]:   File "/home/charlie/skip-residual/gpt-fast/benchmark.py", line 708, in <module>
[rank0]:     main(
[rank0]:   File "/home/charlie/skip-residual/gpt-fast/benchmark.py", line 622, in main
[rank0]:     y, decode_latency, prefill_latency = generate(
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
[rank0]:     return func(*args, **kwargs)
[rank0]:   File "/home/charlie/skip-residual/gpt-fast/benchmark.py", line 332, in generate
[rank0]:     next_token = prefill_ladder(
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py", line 556, in _fn
[rank0]:     return fn(*args, **kwargs)
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 1395, in __call__
[rank0]:     return self._torchdynamo_orig_callable(
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 545, in __call__
[rank0]:     return _compile(
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 977, in _compile
[rank0]:     guarded_code = compile_inner(code, one_graph, hooks, transform)
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 706, in compile_inner
[rank0]:     return _compile_inner(code, one_graph, hooks, transform)
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_utils_internal.py", line 95, in wrapper_function
[rank0]:     return function(*args, **kwargs)
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 741, in _compile_inner
[rank0]:     out_code = transform_code_object(code, transform)
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/bytecode_transformation.py", line 1348, in transform_code_object
[rank0]:     transformations(instructions, code_options)
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 229, in _fn
[rank0]:     return fn(*args, **kwargs)
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 658, in transform
[rank0]:     tracer.run()
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 2912, in run
[rank0]:     super().run()
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 1120, in run
[rank0]:     while self.step():
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 1032, in step
[rank0]:     self.dispatch_table[inst.opcode](self, inst)
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 3103, in RETURN_VALUE
[rank0]:     self._return(inst)
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 3088, in _return
[rank0]:     self.output.compile_subgraph(
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/output_graph.py", line 1077, in compile_subgraph
[rank0]:     self.compile_and_call_fx_graph(tx, list(reversed(stack_values)), root)
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/output_graph.py", line 1346, in compile_and_call_fx_graph
[rank0]:     compiled_fn = self.call_user_compiler(gm)
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/output_graph.py", line 1396, in call_user_compiler
[rank0]:     return self._call_user_compiler(gm)
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/output_graph.py", line 1445, in _call_user_compiler
[rank0]:     raise BackendCompilerFailed(self.compiler_fn, e).with_traceback(
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/output_graph.py", line 1426, in _call_user_compiler
[rank0]:     compiled_fn = compiler_fn(gm, self.example_inputs())
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/repro/after_dynamo.py", line 130, in __call__
[rank0]:     compiled_gm = compiler_fn(gm, example_inputs)
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/repro/after_dynamo.py", line 130, in __call__
[rank0]:     compiled_gm = compiler_fn(gm, example_inputs)
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/__init__.py", line 2301, in __call__
[rank0]:     return compile_fx(model_, inputs_, config_patches=self.config)
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 1708, in compile_fx
[rank0]:     return aot_autograd(
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/backends/common.py", line 72, in __call__
[rank0]:     cg = aot_module_simplified(gm, example_inputs, **self.kwargs)
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 1103, in aot_module_simplified
[rank0]:     compiled_fn = dispatch_and_compile()
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 1079, in dispatch_and_compile
[rank0]:     compiled_fn, _ = create_aot_dispatcher_function(
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 527, in create_aot_dispatcher_function
[rank0]:     return _create_aot_dispatcher_function(
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 778, in _create_aot_dispatcher_function
[rank0]:     compiled_fn, fw_metadata = compiler_fn(
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py", line 197, in aot_dispatch_base
[rank0]:     compiled_fw = compiler(fw_module, updated_flat_args)
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 1525, in fw_compiler_base
[rank0]:     return _fw_compiler_base(model, example_inputs, is_inference)
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 1594, in _fw_compiler_base
[rank0]:     return inner_compile(
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 587, in compile_fx_inner
[rank0]:     return wrap_compiler_debug(_compile_fx_inner, compiler_name="inductor")(
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/repro/after_aot.py", line 102, in debug_wrapper
[rank0]:     inner_compiled_fn = compiler_fn(gm, example_inputs)
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 744, in _compile_fx_inner
[rank0]:     compiled_graph = FxGraphCache.load(
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 1504, in load
[rank0]:     compiled_graph = compile_fx_fn(
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 651, in codegen_and_compile
[rank0]:     compiled_graph = fx_codegen_and_compile(gm, example_inputs, **fx_kwargs)
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 962, in fx_codegen_and_compile
[rank0]:     compiled_fn = graph.compile_to_fn()
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/graph.py", line 2034, in compile_to_fn
[rank0]:     return self.compile_to_module().call
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/graph.py", line 1954, in compile_to_module
[rank0]:     return self._compile_to_module()
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/graph.py", line 1988, in _compile_to_module
[rank0]:     mod = PyCodeCache.load_by_key_path(
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 3058, in load_by_key_path
[rank0]:     mod = _reload_python_module(key, path)
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/runtime/compile_tasks.py", line 45, in _reload_python_module
[rank0]:     exec(code, mod.__dict__, mod.__dict__)
[rank0]:   File "/home/charlie/skip-residual/gpt-fast/torchinductor_charlie/ha/cha6ajqocfrvt3bwcby3ty6jwgyxfsqpmfxxayoxcbhlaaqiryer.py", line 1162, in <module>
[rank0]:     async_compile.wait(globals())
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/async_compile.py", line 319, in wait
[rank0]:     scope[key] = result.result()
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 3535, in result
[rank0]:     result = self.future.result()
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/concurrent/futures/_base.py", line 458, in result
[rank0]:     return self.__get_result()
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
[rank0]:     raise self._exception
[rank0]: torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:
[rank0]: SubprocException: An exception occurred in a subprocess:

[rank0]: Traceback (most recent call last):
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_worker/subproc_pool.py", line 280, in do_job
[rank0]:     result = job()
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/runtime/compile_tasks.py", line 68, in _worker_compile_triton
[rank0]:     load_kernel().precompile(warm_cache_only=True)
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/runtime/compile_tasks.py", line 13, in _reload_triton_kernel_in_subproc
[rank0]:     return _module_to_triton_kernel(reload_module(), kernel_name)
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/runtime/compile_tasks.py", line 29, in _reload_python_module_in_subproc
[rank0]:     return codecache.PyCodeCache.load_by_key_path(key, path)
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 3058, in load_by_key_path
[rank0]:     mod = _reload_python_module(key, path)
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/runtime/compile_tasks.py", line 45, in _reload_python_module
[rank0]:     exec(code, mod.__dict__, mod.__dict__)
[rank0]:   File "/home/charlie/skip-residual/gpt-fast/torchinductor_charlie/rg/crgdhhesvgeo7no5lynnukn25dfzv3aujbhbsqavhj3vrjhpicb4.py", line 9, in <module>
[rank0]:     triton_helpers.set_driver_to_gpu()
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/runtime/triton_helpers.py", line 57, in set_driver_to_gpu
[rank0]:     driver.set_active(backend.driver())
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/triton/backends/nvidia/driver.py", line 371, in __init__
[rank0]:     self.utils = CudaUtils()  # TODO: make static
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/triton/backends/nvidia/driver.py", line 80, in __init__
[rank0]:     mod = compile_module_from_src(Path(os.path.join(dirname, "driver.c")).read_text(), "cuda_utils")
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/triton/backends/nvidia/driver.py", line 57, in compile_module_from_src
[rank0]:     so = _build(name, src_path, tmpdir, library_dirs(), include_dir, libraries)
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/triton/runtime/build.py", line 48, in _build
[rank0]:     ret = subprocess.check_call(cc_cmd)
[rank0]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/subprocess.py", line 369, in check_call
[rank0]:     raise CalledProcessError(retcode, cmd)
[rank0]: subprocess.CalledProcessError: Command '['/usr/bin/gcc', '/home/charlie/skip-residual/gpt-fast/tmpl_sxqfrv/main.c', '-O3', '-shared', '-fPIC', '-o', '/home/charlie/skip-residual/gpt-fast/tmpl_sxqfrv/cuda_utils.cpython-310-x86_64-linux-gnu.so', '-lcuda', '-L/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/triton/backends/nvidia/lib', '-L/lib/x86_64-linux-gnu', '-I/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/triton/backends/nvidia/include', '-I/home/charlie/skip-residual/gpt-fast/tmpl_sxqfrv', '-I/home/charlie/anaconda3/envs/gpt-fast/include/python3.10']' returned non-zero exit status 1.


[rank0]: Set TORCH_LOGS="+dynamo" and TORCHDYNAMO_VERBOSE=1 for more information


[rank0]: You can suppress this exception and fall back to eager by setting:
[rank0]:     import torch._dynamo
[rank0]:     torch._dynamo.config.suppress_errors = True

/home/charlie/skip-residual/gpt-fast/tmpf0xxzvem/main.c:422:1: fatal error: error writing to /tmp/ccMuWSSc.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmp9y_461w3/main.c:422:1: fatal error: error writing to /tmp/cctTgLLA.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmp79gj9_8r/main.c:422:1: fatal error: error writing to /tmp/ccAaLb34.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmp09qvc8hf/main.c:422:1: fatal error: error writing to /tmp/ccDZpxML.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpmm4w2hob/main.c:422:1: fatal error: error writing to /tmp/ccgJDsT0.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmp2j5ta4_5/main.c:422:1: fatal error: error writing to /tmp/cc3mOOnu.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpqtrifa3f/main.c:422:1: fatal error: error writing to /tmp/cckSuboc.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmp018j8wsf/main.c:422:1: fatal error: error writing to /tmp/cc5BaJe3.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmp96h18zr7/main.c:422:1: fatal error: error writing to /tmp/ccxhsQgp.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmp596ewshz/main.c:422:1: fatal error: error writing to /tmp/ccO7iiHi.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpxjf31php/main.c:422:1: fatal error: error writing to /tmp/ccSfr7Cp.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpnsm61v_q/main.c:422:1: fatal error: error writing to /tmp/ccTWuTT8.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmp66764sup/main.c:422:1: fatal error: error writing to /tmp/ccCmNM8R.s: No space left on device
  422 | }
      | ^
compilation terminated.
[rank3]: Traceback (most recent call last):
[rank3]:   File "/home/charlie/skip-residual/gpt-fast/benchmark.py", line 708, in <module>
[rank3]:     main(
[rank3]:   File "/home/charlie/skip-residual/gpt-fast/benchmark.py", line 622, in main
[rank3]:     y, decode_latency, prefill_latency = generate(
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
[rank3]:     return func(*args, **kwargs)
[rank3]:   File "/home/charlie/skip-residual/gpt-fast/benchmark.py", line 332, in generate
[rank3]:     next_token = prefill_ladder(
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py", line 556, in _fn
[rank3]:     return fn(*args, **kwargs)
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 1395, in __call__
[rank3]:     return self._torchdynamo_orig_callable(
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 545, in __call__
[rank3]:     return _compile(
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 977, in _compile
[rank3]:     guarded_code = compile_inner(code, one_graph, hooks, transform)
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 706, in compile_inner
[rank3]:     return _compile_inner(code, one_graph, hooks, transform)
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_utils_internal.py", line 95, in wrapper_function
[rank3]:     return function(*args, **kwargs)
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 741, in _compile_inner
[rank3]:     out_code = transform_code_object(code, transform)
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/bytecode_transformation.py", line 1348, in transform_code_object
[rank3]:     transformations(instructions, code_options)
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 229, in _fn
[rank3]:     return fn(*args, **kwargs)
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 658, in transform
[rank3]:     tracer.run()
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 2912, in run
[rank3]:     super().run()
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 1120, in run
[rank3]:     while self.step():
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 1032, in step
[rank3]:     self.dispatch_table[inst.opcode](self, inst)
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 3103, in RETURN_VALUE
[rank3]:     self._return(inst)
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 3088, in _return
[rank3]:     self.output.compile_subgraph(
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/output_graph.py", line 1077, in compile_subgraph
[rank3]:     self.compile_and_call_fx_graph(tx, list(reversed(stack_values)), root)
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/output_graph.py", line 1346, in compile_and_call_fx_graph
[rank3]:     compiled_fn = self.call_user_compiler(gm)
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/output_graph.py", line 1396, in call_user_compiler
[rank3]:     return self._call_user_compiler(gm)
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/output_graph.py", line 1445, in _call_user_compiler
[rank3]:     raise BackendCompilerFailed(self.compiler_fn, e).with_traceback(
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/output_graph.py", line 1426, in _call_user_compiler
[rank3]:     compiled_fn = compiler_fn(gm, self.example_inputs())
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/repro/after_dynamo.py", line 130, in __call__
[rank3]:     compiled_gm = compiler_fn(gm, example_inputs)
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/repro/after_dynamo.py", line 130, in __call__
[rank3]:     compiled_gm = compiler_fn(gm, example_inputs)
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/__init__.py", line 2301, in __call__
[rank3]:     return compile_fx(model_, inputs_, config_patches=self.config)
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 1708, in compile_fx
[rank3]:     return aot_autograd(
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/backends/common.py", line 72, in __call__
[rank3]:     cg = aot_module_simplified(gm, example_inputs, **self.kwargs)
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 1103, in aot_module_simplified
[rank3]:     compiled_fn = dispatch_and_compile()
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 1079, in dispatch_and_compile
[rank3]:     compiled_fn, _ = create_aot_dispatcher_function(
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 527, in create_aot_dispatcher_function
[rank3]:     return _create_aot_dispatcher_function(
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 778, in _create_aot_dispatcher_function
[rank3]:     compiled_fn, fw_metadata = compiler_fn(
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py", line 197, in aot_dispatch_base
[rank3]:     compiled_fw = compiler(fw_module, updated_flat_args)
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 1525, in fw_compiler_base
[rank3]:     return _fw_compiler_base(model, example_inputs, is_inference)
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 1594, in _fw_compiler_base
[rank3]:     return inner_compile(
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 587, in compile_fx_inner
[rank3]:     return wrap_compiler_debug(_compile_fx_inner, compiler_name="inductor")(
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/repro/after_aot.py", line 102, in debug_wrapper
[rank3]:     inner_compiled_fn = compiler_fn(gm, example_inputs)
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 744, in _compile_fx_inner
[rank3]:     compiled_graph = FxGraphCache.load(
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 1504, in load
[rank3]:     compiled_graph = compile_fx_fn(
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 651, in codegen_and_compile
[rank3]:     compiled_graph = fx_codegen_and_compile(gm, example_inputs, **fx_kwargs)
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 962, in fx_codegen_and_compile
[rank3]:     compiled_fn = graph.compile_to_fn()
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/graph.py", line 2034, in compile_to_fn
[rank3]:     return self.compile_to_module().call
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/graph.py", line 1954, in compile_to_module
[rank3]:     return self._compile_to_module()
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/graph.py", line 1988, in _compile_to_module
[rank3]:     mod = PyCodeCache.load_by_key_path(
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 3058, in load_by_key_path
[rank3]:     mod = _reload_python_module(key, path)
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/runtime/compile_tasks.py", line 45, in _reload_python_module
[rank3]:     exec(code, mod.__dict__, mod.__dict__)
[rank3]:   File "/home/charlie/skip-residual/gpt-fast/torchinductor_charlie/yo/cyosxetfh5utc4vszdaqeids4ztn3skvqkhgumqhw77xi5mlvcq3.py", line 1162, in <module>
[rank3]:     async_compile.wait(globals())
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/async_compile.py", line 319, in wait
[rank3]:     scope[key] = result.result()
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 3535, in result
[rank3]:     result = self.future.result()
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/concurrent/futures/_base.py", line 458, in result
[rank3]:     return self.__get_result()
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
[rank3]:     raise self._exception
[rank3]: torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:
[rank3]: SubprocException: An exception occurred in a subprocess:

[rank3]: Traceback (most recent call last):
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_worker/subproc_pool.py", line 280, in do_job
[rank3]:     result = job()
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/runtime/compile_tasks.py", line 68, in _worker_compile_triton
[rank3]:     load_kernel().precompile(warm_cache_only=True)
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/runtime/compile_tasks.py", line 13, in _reload_triton_kernel_in_subproc
[rank3]:     return _module_to_triton_kernel(reload_module(), kernel_name)
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/runtime/compile_tasks.py", line 29, in _reload_python_module_in_subproc
[rank3]:     return codecache.PyCodeCache.load_by_key_path(key, path)
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 3058, in load_by_key_path
[rank3]:     mod = _reload_python_module(key, path)
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/runtime/compile_tasks.py", line 45, in _reload_python_module
[rank3]:     exec(code, mod.__dict__, mod.__dict__)
[rank3]:   File "/home/charlie/skip-residual/gpt-fast/torchinductor_charlie/ty/ctyppxuoopaja2rpsu5sevwyccv4eatrgf24s73t3bh35s3utkzk.py", line 9, in <module>
[rank3]:     triton_helpers.set_driver_to_gpu()
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/runtime/triton_helpers.py", line 57, in set_driver_to_gpu
[rank3]:     driver.set_active(backend.driver())
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/triton/backends/nvidia/driver.py", line 371, in __init__
[rank3]:     self.utils = CudaUtils()  # TODO: make static
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/triton/backends/nvidia/driver.py", line 80, in __init__
[rank3]:     mod = compile_module_from_src(Path(os.path.join(dirname, "driver.c")).read_text(), "cuda_utils")
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/triton/backends/nvidia/driver.py", line 57, in compile_module_from_src
[rank3]:     so = _build(name, src_path, tmpdir, library_dirs(), include_dir, libraries)
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/triton/runtime/build.py", line 48, in _build
[rank3]:     ret = subprocess.check_call(cc_cmd)
[rank3]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/subprocess.py", line 369, in check_call
[rank3]:     raise CalledProcessError(retcode, cmd)
[rank3]: subprocess.CalledProcessError: Command '['/usr/bin/gcc', '/home/charlie/skip-residual/gpt-fast/tmpqtrifa3f/main.c', '-O3', '-shared', '-fPIC', '-o', '/home/charlie/skip-residual/gpt-fast/tmpqtrifa3f/cuda_utils.cpython-310-x86_64-linux-gnu.so', '-lcuda', '-L/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/triton/backends/nvidia/lib', '-L/lib/x86_64-linux-gnu', '-I/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/triton/backends/nvidia/include', '-I/home/charlie/skip-residual/gpt-fast/tmpqtrifa3f', '-I/home/charlie/anaconda3/envs/gpt-fast/include/python3.10']' returned non-zero exit status 1.


[rank3]: Set TORCH_LOGS="+dynamo" and TORCHDYNAMO_VERBOSE=1 for more information


[rank3]: You can suppress this exception and fall back to eager by setting:
[rank3]:     import torch._dynamo
[rank3]:     torch._dynamo.config.suppress_errors = True

/home/charlie/skip-residual/gpt-fast/tmpmvjm6_az/main.c:422:1: fatal error: error writing to /tmp/cc3UxSyu.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmp0mwj2jl5/main.c:422:1: fatal error: error writing to /tmp/ccmKC2Qf.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpm80g6ela/main.c:422:1: fatal error: error writing to /tmp/ccibrxQ1.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmp21uw6fwt/main.c:422:1: fatal error: error writing to /tmp/ccFPJ755.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpk0h9my_x/main.c:422:1: fatal error: error writing to /tmp/ccF0M4NQ.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpmrtvj3fq/main.c:422:1: fatal error: error writing to /tmp/ccgj9u9z.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmp9rjp1rhm/main.c:422:1: fatal error: error writing to /tmp/ccLrcCLr.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmp0r3e48wl/main.c:422:1: fatal error: error writing to /tmp/ccHCPqAS.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpwa59ronl/main.c:422:1: fatal error: error writing to /tmp/ccqxUuiB.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpr5x8wisi/main.c:422:1: fatal error: error writing to /tmp/ccwmju3h.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmp9ygyit_m/main.c:422:1: fatal error: error writing to /tmp/ccZOf6Qp.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmp1pvqv2bg/main.c:422:1: fatal error: error writing to /tmp/cccg6Gva.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmp2k_ed_ir/main.c:422:1: fatal error: error writing to /tmp/ccdbD6sn.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmp4ibedz1u/main.c:422:1: fatal error: error writing to /tmp/ccqKjBCp.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpj2kjl6j_/main.c:422:1: fatal error: error writing to /tmp/ccbRcmZk.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpucrsogv1/main.c:422:1: fatal error: error writing to /tmp/ccfR813f.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmp7xg38uhm/main.c:422:1: fatal error: error writing to /tmp/ccboH9Oq.s: No space left on device
  422 | }
      | ^
compilation terminated.
[rank6]: Traceback (most recent call last):
[rank6]:   File "/home/charlie/skip-residual/gpt-fast/benchmark.py", line 708, in <module>
[rank6]:     main(
[rank6]:   File "/home/charlie/skip-residual/gpt-fast/benchmark.py", line 622, in main
[rank6]:     y, decode_latency, prefill_latency = generate(
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
[rank6]:     return func(*args, **kwargs)
[rank6]:   File "/home/charlie/skip-residual/gpt-fast/benchmark.py", line 332, in generate
[rank6]:     next_token = prefill_ladder(
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py", line 556, in _fn
[rank6]:     return fn(*args, **kwargs)
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 1395, in __call__
[rank6]:     return self._torchdynamo_orig_callable(
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 545, in __call__
[rank6]:     return _compile(
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 977, in _compile
[rank6]:     guarded_code = compile_inner(code, one_graph, hooks, transform)
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 706, in compile_inner
[rank6]:     return _compile_inner(code, one_graph, hooks, transform)
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_utils_internal.py", line 95, in wrapper_function
[rank6]:     return function(*args, **kwargs)
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 741, in _compile_inner
[rank6]:     out_code = transform_code_object(code, transform)
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/bytecode_transformation.py", line 1348, in transform_code_object
[rank6]:     transformations(instructions, code_options)
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 229, in _fn
[rank6]:     return fn(*args, **kwargs)
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 658, in transform
[rank6]:     tracer.run()
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 2912, in run
[rank6]:     super().run()
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 1120, in run
[rank6]:     while self.step():
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 1032, in step
[rank6]:     self.dispatch_table[inst.opcode](self, inst)
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 3103, in RETURN_VALUE
[rank6]:     self._return(inst)
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 3088, in _return
[rank6]:     self.output.compile_subgraph(
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/output_graph.py", line 1077, in compile_subgraph
[rank6]:     self.compile_and_call_fx_graph(tx, list(reversed(stack_values)), root)
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/output_graph.py", line 1346, in compile_and_call_fx_graph
[rank6]:     compiled_fn = self.call_user_compiler(gm)
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/output_graph.py", line 1396, in call_user_compiler
[rank6]:     return self._call_user_compiler(gm)
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/output_graph.py", line 1445, in _call_user_compiler
[rank6]:     raise BackendCompilerFailed(self.compiler_fn, e).with_traceback(
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/output_graph.py", line 1426, in _call_user_compiler
[rank6]:     compiled_fn = compiler_fn(gm, self.example_inputs())
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/repro/after_dynamo.py", line 130, in __call__
[rank6]:     compiled_gm = compiler_fn(gm, example_inputs)
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/repro/after_dynamo.py", line 130, in __call__
[rank6]:     compiled_gm = compiler_fn(gm, example_inputs)
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/__init__.py", line 2301, in __call__
[rank6]:     return compile_fx(model_, inputs_, config_patches=self.config)
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 1708, in compile_fx
[rank6]:     return aot_autograd(
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/backends/common.py", line 72, in __call__
[rank6]:     cg = aot_module_simplified(gm, example_inputs, **self.kwargs)
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 1103, in aot_module_simplified
[rank6]:     compiled_fn = dispatch_and_compile()
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 1079, in dispatch_and_compile
[rank6]:     compiled_fn, _ = create_aot_dispatcher_function(
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 527, in create_aot_dispatcher_function
[rank6]:     return _create_aot_dispatcher_function(
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 778, in _create_aot_dispatcher_function
[rank6]:     compiled_fn, fw_metadata = compiler_fn(
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py", line 197, in aot_dispatch_base
[rank6]:     compiled_fw = compiler(fw_module, updated_flat_args)
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 1525, in fw_compiler_base
[rank6]:     return _fw_compiler_base(model, example_inputs, is_inference)
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 1594, in _fw_compiler_base
[rank6]:     return inner_compile(
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 587, in compile_fx_inner
[rank6]:     return wrap_compiler_debug(_compile_fx_inner, compiler_name="inductor")(
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/repro/after_aot.py", line 102, in debug_wrapper
[rank6]:     inner_compiled_fn = compiler_fn(gm, example_inputs)
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 744, in _compile_fx_inner
[rank6]:     compiled_graph = FxGraphCache.load(
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 1504, in load
[rank6]:     compiled_graph = compile_fx_fn(
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 651, in codegen_and_compile
[rank6]:     compiled_graph = fx_codegen_and_compile(gm, example_inputs, **fx_kwargs)
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 962, in fx_codegen_and_compile
[rank6]:     compiled_fn = graph.compile_to_fn()
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/graph.py", line 2034, in compile_to_fn
[rank6]:     return self.compile_to_module().call
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/graph.py", line 1954, in compile_to_module
[rank6]:     return self._compile_to_module()
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/graph.py", line 1988, in _compile_to_module
[rank6]:     mod = PyCodeCache.load_by_key_path(
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 3058, in load_by_key_path
[rank6]:     mod = _reload_python_module(key, path)
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/runtime/compile_tasks.py", line 45, in _reload_python_module
[rank6]:     exec(code, mod.__dict__, mod.__dict__)
[rank6]:   File "/home/charlie/skip-residual/gpt-fast/torchinductor_charlie/cx/ccxakmbgvn7gbm7xtfqkmyvtayx4gnhk572h4snhpvuuyqkspb47.py", line 1162, in <module>
[rank6]:     async_compile.wait(globals())
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/async_compile.py", line 319, in wait
[rank6]:     scope[key] = result.result()
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 3535, in result
[rank6]:     result = self.future.result()
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/concurrent/futures/_base.py", line 458, in result
[rank6]:     return self.__get_result()
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
[rank6]:     raise self._exception
[rank6]: torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:
[rank6]: SubprocException: An exception occurred in a subprocess:

[rank6]: Traceback (most recent call last):
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_worker/subproc_pool.py", line 280, in do_job
[rank6]:     result = job()
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/runtime/compile_tasks.py", line 68, in _worker_compile_triton
[rank6]:     load_kernel().precompile(warm_cache_only=True)
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/runtime/compile_tasks.py", line 13, in _reload_triton_kernel_in_subproc
[rank6]:     return _module_to_triton_kernel(reload_module(), kernel_name)
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/runtime/compile_tasks.py", line 29, in _reload_python_module_in_subproc
[rank6]:     return codecache.PyCodeCache.load_by_key_path(key, path)
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 3058, in load_by_key_path
[rank6]:     mod = _reload_python_module(key, path)
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/runtime/compile_tasks.py", line 45, in _reload_python_module
[rank6]:     exec(code, mod.__dict__, mod.__dict__)
[rank6]:   File "/home/charlie/skip-residual/gpt-fast/torchinductor_charlie/3w/c3wbzukfxathna55irjbjnet5wcrdwvci35a7wcve7sldtd4bjbg.py", line 9, in <module>
[rank6]:     triton_helpers.set_driver_to_gpu()
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/runtime/triton_helpers.py", line 57, in set_driver_to_gpu
[rank6]:     driver.set_active(backend.driver())
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/triton/backends/nvidia/driver.py", line 371, in __init__
[rank6]:     self.utils = CudaUtils()  # TODO: make static
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/triton/backends/nvidia/driver.py", line 80, in __init__
[rank6]:     mod = compile_module_from_src(Path(os.path.join(dirname, "driver.c")).read_text(), "cuda_utils")
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/triton/backends/nvidia/driver.py", line 57, in compile_module_from_src
[rank6]:     so = _build(name, src_path, tmpdir, library_dirs(), include_dir, libraries)
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/triton/runtime/build.py", line 48, in _build
[rank6]:     ret = subprocess.check_call(cc_cmd)
[rank6]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/subprocess.py", line 369, in check_call
[rank6]:     raise CalledProcessError(retcode, cmd)
[rank6]: subprocess.CalledProcessError: Command '['/usr/bin/gcc', '/home/charlie/skip-residual/gpt-fast/tmpucrsogv1/main.c', '-O3', '-shared', '-fPIC', '-o', '/home/charlie/skip-residual/gpt-fast/tmpucrsogv1/cuda_utils.cpython-310-x86_64-linux-gnu.so', '-lcuda', '-L/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/triton/backends/nvidia/lib', '-L/lib/x86_64-linux-gnu', '-I/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/triton/backends/nvidia/include', '-I/home/charlie/skip-residual/gpt-fast/tmpucrsogv1', '-I/home/charlie/anaconda3/envs/gpt-fast/include/python3.10']' returned non-zero exit status 1.


[rank6]: Set TORCH_LOGS="+dynamo" and TORCHDYNAMO_VERBOSE=1 for more information


[rank6]: You can suppress this exception and fall back to eager by setting:
[rank6]:     import torch._dynamo
[rank6]:     torch._dynamo.config.suppress_errors = True

/home/charlie/skip-residual/gpt-fast/tmpcwaay1h9/main.c:422:1: fatal error: error writing to /tmp/cckEMvzJ.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpz722hapm/main.c:422:1: fatal error: error writing to /tmp/ccRgwh9M.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmp699n_9dx/main.c:422:1: fatal error: error writing to /tmp/ccxWdf5f.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpednuu8ft/main.c:422:1: fatal error: error writing to /tmp/ccvz6J4b.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpxn6afa04/main.c:422:1: fatal error: error writing to /tmp/cc4SYsEr.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpqd6dwm2y/main.c:422:1: fatal error: error writing to /tmp/cc2BpHZX.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmp3py9a99w/main.c:422:1: fatal error: error writing to /tmp/ccAgMC1N.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmplfsdw5rw/main.c:422:1: fatal error: error writing to /tmp/ccSUGygi.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpc0tv3wd7/main.c:422:1: fatal error: error writing to /tmp/cciFgZbA.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmphrx4laiz/main.c:422:1: fatal error: error writing to /tmp/ccDPEKCe.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmp7_6pjogh/main.c:422:1: fatal error: error writing to /tmp/ccCq3eGE.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpo0zxnebd/main.c:422:1: fatal error: error writing to /tmp/ccNPSo1B.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmp87l0_3p8/main.c:422:1: fatal error: error writing to /tmp/ccIe6M9G.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmp5szdmf2b/main.c:422:1: fatal error: error writing to /tmp/ccKjHBh6.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmp0xs89a38/main.c:422:1: fatal error: error writing to /tmp/cczdFNUa.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmp92trl0y2/main.c:422:1: fatal error: error writing to /tmp/ccaFYQO5.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpulfspzgf/main.c:422:1: fatal error: error writing to /tmp/ccELF167.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpoknea583/main.c:422:1: fatal error: error writing to /tmp/cc29PQa1.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmp8yx17mrm/main.c:422:1: fatal error: error writing to /tmp/ccXgkeT1.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpd5q8sgaf/main.c:422:1: fatal error: error writing to /tmp/ccG2i77G.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpgdll016p/main.c:422:1: fatal error: error writing to /tmp/cc0R35fI.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmp9qcax6l8/main.c:422:1: fatal error: error writing to /tmp/ccY8dLTE.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmp_hk0kbl1/main.c:422:1: fatal error: error writing to /tmp/ccHDnXGg.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpzc0ik0zu/main.c:422:1: fatal error: error writing to /tmp/ccubCcBw.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpjq7kwf41/main.c:422:1: fatal error: error writing to /tmp/ccUKscqT.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpqygkhtw2/main.c:422:1: fatal error: error writing to /tmp/cch6Bbek.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpsi8birz2/main.c:422:1: fatal error: error writing to /tmp/cci64S8n.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpbqss10xu/main.c:422:1: fatal error: error writing to /tmp/cc8raFsb.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpsg278ab_/main.c:422:1: fatal error: error writing to /tmp/ccxlg0hT.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmph4rcw2ca/main.c:422:1: fatal error: error writing to /tmp/ccJvduCv.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpoi1a1rgs/main.c:422:1: fatal error: error writing to /tmp/cc9ZQ3xE.s: No space left on device
  422 | }
      | ^
compilation terminated.
[rank2]: Traceback (most recent call last):
[rank2]:   File "/home/charlie/skip-residual/gpt-fast/benchmark.py", line 708, in <module>
[rank2]:     main(
[rank2]:   File "/home/charlie/skip-residual/gpt-fast/benchmark.py", line 622, in main
[rank2]:     y, decode_latency, prefill_latency = generate(
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
[rank2]:     return func(*args, **kwargs)
[rank2]:   File "/home/charlie/skip-residual/gpt-fast/benchmark.py", line 332, in generate
[rank2]:     next_token = prefill_ladder(
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py", line 556, in _fn
[rank2]:     return fn(*args, **kwargs)
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 1395, in __call__
[rank2]:     return self._torchdynamo_orig_callable(
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 545, in __call__
[rank2]:     return _compile(
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 977, in _compile
[rank2]:     guarded_code = compile_inner(code, one_graph, hooks, transform)
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 706, in compile_inner
[rank2]:     return _compile_inner(code, one_graph, hooks, transform)
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_utils_internal.py", line 95, in wrapper_function
[rank2]:     return function(*args, **kwargs)
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 741, in _compile_inner
[rank2]:     out_code = transform_code_object(code, transform)
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/bytecode_transformation.py", line 1348, in transform_code_object
[rank2]:     transformations(instructions, code_options)
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 229, in _fn
[rank2]:     return fn(*args, **kwargs)
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 658, in transform
[rank2]:     tracer.run()
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 2912, in run
[rank2]:     super().run()
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 1120, in run
[rank2]:     while self.step():
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 1032, in step
[rank2]:     self.dispatch_table[inst.opcode](self, inst)
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 3103, in RETURN_VALUE
[rank2]:     self._return(inst)
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 3088, in _return
[rank2]:     self.output.compile_subgraph(
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/output_graph.py", line 1077, in compile_subgraph
[rank2]:     self.compile_and_call_fx_graph(tx, list(reversed(stack_values)), root)
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/output_graph.py", line 1346, in compile_and_call_fx_graph
[rank2]:     compiled_fn = self.call_user_compiler(gm)
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/output_graph.py", line 1396, in call_user_compiler
[rank2]:     return self._call_user_compiler(gm)
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/output_graph.py", line 1445, in _call_user_compiler
[rank2]:     raise BackendCompilerFailed(self.compiler_fn, e).with_traceback(
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/output_graph.py", line 1426, in _call_user_compiler
[rank2]:     compiled_fn = compiler_fn(gm, self.example_inputs())
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/repro/after_dynamo.py", line 130, in __call__
[rank2]:     compiled_gm = compiler_fn(gm, example_inputs)
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/repro/after_dynamo.py", line 130, in __call__
[rank2]:     compiled_gm = compiler_fn(gm, example_inputs)
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/__init__.py", line 2301, in __call__
[rank2]:     return compile_fx(model_, inputs_, config_patches=self.config)
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 1708, in compile_fx
[rank2]:     return aot_autograd(
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/backends/common.py", line 72, in __call__
[rank2]:     cg = aot_module_simplified(gm, example_inputs, **self.kwargs)
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 1103, in aot_module_simplified
[rank2]:     compiled_fn = dispatch_and_compile()
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 1079, in dispatch_and_compile
[rank2]:     compiled_fn, _ = create_aot_dispatcher_function(
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 527, in create_aot_dispatcher_function
[rank2]:     return _create_aot_dispatcher_function(
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 778, in _create_aot_dispatcher_function
[rank2]:     compiled_fn, fw_metadata = compiler_fn(
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py", line 197, in aot_dispatch_base
[rank2]:     compiled_fw = compiler(fw_module, updated_flat_args)
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 1525, in fw_compiler_base
[rank2]:     return _fw_compiler_base(model, example_inputs, is_inference)
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 1594, in _fw_compiler_base
[rank2]:     return inner_compile(
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 587, in compile_fx_inner
[rank2]:     return wrap_compiler_debug(_compile_fx_inner, compiler_name="inductor")(
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/repro/after_aot.py", line 102, in debug_wrapper
[rank2]:     inner_compiled_fn = compiler_fn(gm, example_inputs)
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 744, in _compile_fx_inner
[rank2]:     compiled_graph = FxGraphCache.load(
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 1504, in load
[rank2]:     compiled_graph = compile_fx_fn(
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 651, in codegen_and_compile
[rank2]:     compiled_graph = fx_codegen_and_compile(gm, example_inputs, **fx_kwargs)
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 962, in fx_codegen_and_compile
[rank2]:     compiled_fn = graph.compile_to_fn()
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/graph.py", line 2034, in compile_to_fn
[rank2]:     return self.compile_to_module().call
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/graph.py", line 1954, in compile_to_module
[rank2]:     return self._compile_to_module()
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/graph.py", line 1988, in _compile_to_module
[rank2]:     mod = PyCodeCache.load_by_key_path(
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 3058, in load_by_key_path
[rank2]:     mod = _reload_python_module(key, path)
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/runtime/compile_tasks.py", line 45, in _reload_python_module
[rank2]:     exec(code, mod.__dict__, mod.__dict__)
[rank2]:   File "/home/charlie/skip-residual/gpt-fast/torchinductor_charlie/rr/crrketrznl7uhz2dmmfixa6rbjd57lehayqnngrbujxv3zekjuzb.py", line 1162, in <module>
[rank2]:     async_compile.wait(globals())
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/async_compile.py", line 319, in wait
[rank2]:     scope[key] = result.result()
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 3535, in result
[rank2]:     result = self.future.result()
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/concurrent/futures/_base.py", line 458, in result
[rank2]:     return self.__get_result()
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
[rank2]:     raise self._exception
[rank2]: torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:
[rank2]: SubprocException: An exception occurred in a subprocess:

[rank2]: Traceback (most recent call last):
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_worker/subproc_pool.py", line 280, in do_job
[rank2]:     result = job()
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/runtime/compile_tasks.py", line 68, in _worker_compile_triton
[rank2]:     load_kernel().precompile(warm_cache_only=True)
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/runtime/compile_tasks.py", line 13, in _reload_triton_kernel_in_subproc
[rank2]:     return _module_to_triton_kernel(reload_module(), kernel_name)
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/runtime/compile_tasks.py", line 29, in _reload_python_module_in_subproc
[rank2]:     return codecache.PyCodeCache.load_by_key_path(key, path)
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 3058, in load_by_key_path
[rank2]:     mod = _reload_python_module(key, path)
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/runtime/compile_tasks.py", line 45, in _reload_python_module
[rank2]:     exec(code, mod.__dict__, mod.__dict__)
[rank2]:   File "/home/charlie/skip-residual/gpt-fast/torchinductor_charlie/jw/cjwzefot3flcx6yp2xgvlzrqkszhbqfmou44ebsfv5cqr2ghgpam.py", line 9, in <module>
[rank2]:     triton_helpers.set_driver_to_gpu()
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/runtime/triton_helpers.py", line 57, in set_driver_to_gpu
[rank2]:     driver.set_active(backend.driver())
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/triton/backends/nvidia/driver.py", line 371, in __init__
[rank2]:     self.utils = CudaUtils()  # TODO: make static
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/triton/backends/nvidia/driver.py", line 80, in __init__
[rank2]:     mod = compile_module_from_src(Path(os.path.join(dirname, "driver.c")).read_text(), "cuda_utils")
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/triton/backends/nvidia/driver.py", line 57, in compile_module_from_src
[rank2]:     so = _build(name, src_path, tmpdir, library_dirs(), include_dir, libraries)
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/triton/runtime/build.py", line 48, in _build
[rank2]:     ret = subprocess.check_call(cc_cmd)
[rank2]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/subprocess.py", line 369, in check_call
[rank2]:     raise CalledProcessError(retcode, cmd)
[rank2]: subprocess.CalledProcessError: Command '['/usr/bin/gcc', '/home/charlie/skip-residual/gpt-fast/tmpjq7kwf41/main.c', '-O3', '-shared', '-fPIC', '-o', '/home/charlie/skip-residual/gpt-fast/tmpjq7kwf41/cuda_utils.cpython-310-x86_64-linux-gnu.so', '-lcuda', '-L/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/triton/backends/nvidia/lib', '-L/lib/x86_64-linux-gnu', '-I/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/triton/backends/nvidia/include', '-I/home/charlie/skip-residual/gpt-fast/tmpjq7kwf41', '-I/home/charlie/anaconda3/envs/gpt-fast/include/python3.10']' returned non-zero exit status 1.


[rank2]: Set TORCH_LOGS="+dynamo" and TORCHDYNAMO_VERBOSE=1 for more information


[rank2]: You can suppress this exception and fall back to eager by setting:
[rank2]:     import torch._dynamo
[rank2]:     torch._dynamo.config.suppress_errors = True

/home/charlie/skip-residual/gpt-fast/tmpgousmelm/main.c:422:1: fatal error: error writing to /tmp/ccTgz4Ic.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpafwbx2a8/main.c:422:1: fatal error: error writing to /tmp/ccfHeJr3.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmp3tvmvmof/main.c:422:1: fatal error: error writing to /tmp/ccu96ZUV.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpfjph63yd/main.c:422:1: fatal error: error writing to /tmp/ccQydXTP.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpvd7exhzr/main.c:422:1: fatal error: error writing to /tmp/ccIY2JuJ.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmp7nvc1ae4/main.c:422:1: fatal error: error writing to /tmp/cck6Ew42.s: No space left on device
  422 | }
      | ^
/home/charlie/skip-residual/gpt-fast/tmpkworjuv0/main.c:422:1: fatal error: error writing to /tmp/ccDV2D7a.s: No space left on device
  422 | }
      | ^
compilation terminated.
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmp3zyz12y8/main.c:422:1: fatal error: error writing to /tmp/ccsvHt1N.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpay001swk/main.c:422:1: fatal error: error writing to /tmp/ccm9ODBi.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmp6nxksd_s/main.c:422:1: fatal error: error writing to /tmp/ccLMiCUo.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmp64hd86mr/main.c:422:1: fatal error: error writing to /tmp/ccBdWJFJ.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpz0cbbcpj/main.c:422:1: fatal error: error writing to /tmp/ccNvxl67.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmp_zv8stdk/main.c:422:1: fatal error: error writing to /tmp/ccC6TBr0.s: No space left on device
  422 | }
      | ^
compilation terminated.
[rank4]: Traceback (most recent call last):
[rank4]:   File "/home/charlie/skip-residual/gpt-fast/benchmark.py", line 708, in <module>
[rank4]:     main(
[rank4]:   File "/home/charlie/skip-residual/gpt-fast/benchmark.py", line 622, in main
[rank4]:     y, decode_latency, prefill_latency = generate(
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
[rank4]:     return func(*args, **kwargs)
[rank4]:   File "/home/charlie/skip-residual/gpt-fast/benchmark.py", line 332, in generate
[rank4]:     next_token = prefill_ladder(
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py", line 556, in _fn
[rank4]:     return fn(*args, **kwargs)
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 1395, in __call__
[rank4]:     return self._torchdynamo_orig_callable(
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 545, in __call__
[rank4]:     return _compile(
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 977, in _compile
[rank4]:     guarded_code = compile_inner(code, one_graph, hooks, transform)
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 706, in compile_inner
[rank4]:     return _compile_inner(code, one_graph, hooks, transform)
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_utils_internal.py", line 95, in wrapper_function
[rank4]:     return function(*args, **kwargs)
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 741, in _compile_inner
[rank4]:     out_code = transform_code_object(code, transform)
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/bytecode_transformation.py", line 1348, in transform_code_object
[rank4]:     transformations(instructions, code_options)
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 229, in _fn
[rank4]:     return fn(*args, **kwargs)
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 658, in transform
[rank4]:     tracer.run()
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 2912, in run
[rank4]:     super().run()
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 1120, in run
[rank4]:     while self.step():
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 1032, in step
[rank4]:     self.dispatch_table[inst.opcode](self, inst)
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 3103, in RETURN_VALUE
[rank4]:     self._return(inst)
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 3088, in _return
[rank4]:     self.output.compile_subgraph(
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/output_graph.py", line 1077, in compile_subgraph
[rank4]:     self.compile_and_call_fx_graph(tx, list(reversed(stack_values)), root)
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/output_graph.py", line 1346, in compile_and_call_fx_graph
[rank4]:     compiled_fn = self.call_user_compiler(gm)
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/output_graph.py", line 1396, in call_user_compiler
[rank4]:     return self._call_user_compiler(gm)
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/output_graph.py", line 1445, in _call_user_compiler
[rank4]:     raise BackendCompilerFailed(self.compiler_fn, e).with_traceback(
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/output_graph.py", line 1426, in _call_user_compiler
[rank4]:     compiled_fn = compiler_fn(gm, self.example_inputs())
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/repro/after_dynamo.py", line 130, in __call__
[rank4]:     compiled_gm = compiler_fn(gm, example_inputs)
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/repro/after_dynamo.py", line 130, in __call__
[rank4]:     compiled_gm = compiler_fn(gm, example_inputs)
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/__init__.py", line 2301, in __call__
[rank4]:     return compile_fx(model_, inputs_, config_patches=self.config)
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 1708, in compile_fx
[rank4]:     return aot_autograd(
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/backends/common.py", line 72, in __call__
[rank4]:     cg = aot_module_simplified(gm, example_inputs, **self.kwargs)
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 1103, in aot_module_simplified
[rank4]:     compiled_fn = dispatch_and_compile()
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 1079, in dispatch_and_compile
[rank4]:     compiled_fn, _ = create_aot_dispatcher_function(
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 527, in create_aot_dispatcher_function
[rank4]:     return _create_aot_dispatcher_function(
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 778, in _create_aot_dispatcher_function
[rank4]:     compiled_fn, fw_metadata = compiler_fn(
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py", line 197, in aot_dispatch_base
[rank4]:     compiled_fw = compiler(fw_module, updated_flat_args)
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 1525, in fw_compiler_base
[rank4]:     return _fw_compiler_base(model, example_inputs, is_inference)
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 1594, in _fw_compiler_base
[rank4]:     return inner_compile(
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 587, in compile_fx_inner
[rank4]:     return wrap_compiler_debug(_compile_fx_inner, compiler_name="inductor")(
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/repro/after_aot.py", line 102, in debug_wrapper
[rank4]:     inner_compiled_fn = compiler_fn(gm, example_inputs)
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 744, in _compile_fx_inner
[rank4]:     compiled_graph = FxGraphCache.load(
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 1504, in load
[rank4]:     compiled_graph = compile_fx_fn(
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 651, in codegen_and_compile
[rank4]:     compiled_graph = fx_codegen_and_compile(gm, example_inputs, **fx_kwargs)
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 962, in fx_codegen_and_compile
[rank4]:     compiled_fn = graph.compile_to_fn()
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/graph.py", line 2034, in compile_to_fn
[rank4]:     return self.compile_to_module().call
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/graph.py", line 1954, in compile_to_module
[rank4]:     return self._compile_to_module()
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/graph.py", line 1988, in _compile_to_module
[rank4]:     mod = PyCodeCache.load_by_key_path(
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 3058, in load_by_key_path
[rank4]:     mod = _reload_python_module(key, path)
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/runtime/compile_tasks.py", line 45, in _reload_python_module
[rank4]:     exec(code, mod.__dict__, mod.__dict__)
[rank4]:   File "/home/charlie/skip-residual/gpt-fast/torchinductor_charlie/eh/cehjc4ncnc3pm6rj6fb6ztsiork54rbr7z6c457iesz6ixzbazvk.py", line 1162, in <module>
[rank4]:     async_compile.wait(globals())
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/async_compile.py", line 319, in wait
[rank4]:     scope[key] = result.result()
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 3535, in result
[rank4]:     result = self.future.result()
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/concurrent/futures/_base.py", line 458, in result
[rank4]:     return self.__get_result()
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
[rank4]:     raise self._exception
[rank4]: torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:
[rank4]: SubprocException: An exception occurred in a subprocess:

[rank4]: Traceback (most recent call last):
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_worker/subproc_pool.py", line 280, in do_job
[rank4]:     result = job()
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/runtime/compile_tasks.py", line 68, in _worker_compile_triton
[rank4]:     load_kernel().precompile(warm_cache_only=True)
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/runtime/compile_tasks.py", line 13, in _reload_triton_kernel_in_subproc
[rank4]:     return _module_to_triton_kernel(reload_module(), kernel_name)
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/runtime/compile_tasks.py", line 29, in _reload_python_module_in_subproc
[rank4]:     return codecache.PyCodeCache.load_by_key_path(key, path)
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 3058, in load_by_key_path
[rank4]:     mod = _reload_python_module(key, path)
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/runtime/compile_tasks.py", line 45, in _reload_python_module
[rank4]:     exec(code, mod.__dict__, mod.__dict__)
[rank4]:   File "/home/charlie/skip-residual/gpt-fast/torchinductor_charlie/df/cdfdub6f2o5brznmt3tjxzoh3j2j5asyf5y5oeev5ulz2gvqo5do.py", line 9, in <module>
[rank4]:     triton_helpers.set_driver_to_gpu()
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/runtime/triton_helpers.py", line 57, in set_driver_to_gpu
[rank4]:     driver.set_active(backend.driver())
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/triton/backends/nvidia/driver.py", line 371, in __init__
[rank4]:     self.utils = CudaUtils()  # TODO: make static
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/triton/backends/nvidia/driver.py", line 80, in __init__
[rank4]:     mod = compile_module_from_src(Path(os.path.join(dirname, "driver.c")).read_text(), "cuda_utils")
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/triton/backends/nvidia/driver.py", line 57, in compile_module_from_src
[rank4]:     so = _build(name, src_path, tmpdir, library_dirs(), include_dir, libraries)
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/triton/runtime/build.py", line 48, in _build
[rank4]:     ret = subprocess.check_call(cc_cmd)
[rank4]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/subprocess.py", line 369, in check_call
[rank4]:     raise CalledProcessError(retcode, cmd)
[rank4]: subprocess.CalledProcessError: Command '['/usr/bin/gcc', '/home/charlie/skip-residual/gpt-fast/tmp64hd86mr/main.c', '-O3', '-shared', '-fPIC', '-o', '/home/charlie/skip-residual/gpt-fast/tmp64hd86mr/cuda_utils.cpython-310-x86_64-linux-gnu.so', '-lcuda', '-L/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/triton/backends/nvidia/lib', '-L/lib/x86_64-linux-gnu', '-I/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/triton/backends/nvidia/include', '-I/home/charlie/skip-residual/gpt-fast/tmp64hd86mr', '-I/home/charlie/anaconda3/envs/gpt-fast/include/python3.10']' returned non-zero exit status 1.


[rank4]: Set TORCH_LOGS="+dynamo" and TORCHDYNAMO_VERBOSE=1 for more information


[rank4]: You can suppress this exception and fall back to eager by setting:
[rank4]:     import torch._dynamo
[rank4]:     torch._dynamo.config.suppress_errors = True

/home/charlie/skip-residual/gpt-fast/tmplqb90ymo/main.c:422:1: fatal error: error writing to /tmp/ccfxNUye.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmp8aohppzk/main.c:422:1: fatal error: error writing to /tmp/cctQfGuu.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpv3prx2l6/main.c:422:1: fatal error: error writing to /tmp/cc80Apwk.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpjig2575e/main.c:422:1: fatal error: error writing to /tmp/ccaZZEYz.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpodudx8fd/main.c:422:1: fatal error: error writing to /tmp/ccwRyxnq.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmp7t9gj9ys/main.c:422:1: fatal error: error writing to /tmp/ccQrgJc3.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpx7qaqrfs/main.c:422:1: fatal error: error writing to /tmp/cc3VeTW3.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpma31ixf8/main.c:422:1: fatal error: error writing to /tmp/ccUt5MKn.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmple0yz_fi/main.c:422:1: fatal error: error writing to /tmp/ccNewuRe.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpw_q04id_/main.c:422:1: fatal error: error writing to /tmp/ccFhIa8E.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpuriuxa1z/main.c:422:1: fatal error: error writing to /tmp/ccoSBWEd.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpkg0zlm6n/main.c:422:1: fatal error: error writing to /tmp/cc7Em3BD.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpqalj7o82/main.c:422:1: fatal error: error writing to /tmp/ccfpL79c.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpmozddt5j/main.c:422:1: fatal error: error writing to /tmp/ccJnvPEy.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpx7veel7p/main.c:422:1: fatal error: error writing to /tmp/ccd2yHCU.s: No space left on device
  422 | }
      | ^
compilation terminated.
[rank5]: Traceback (most recent call last):
[rank5]:   File "/home/charlie/skip-residual/gpt-fast/benchmark.py", line 708, in <module>
[rank5]:     main(
[rank5]:   File "/home/charlie/skip-residual/gpt-fast/benchmark.py", line 622, in main
[rank5]:     y, decode_latency, prefill_latency = generate(
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
[rank5]:     return func(*args, **kwargs)
[rank5]:   File "/home/charlie/skip-residual/gpt-fast/benchmark.py", line 332, in generate
[rank5]:     next_token = prefill_ladder(
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py", line 556, in _fn
[rank5]:     return fn(*args, **kwargs)
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 1395, in __call__
[rank5]:     return self._torchdynamo_orig_callable(
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 545, in __call__
[rank5]:     return _compile(
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 977, in _compile
[rank5]:     guarded_code = compile_inner(code, one_graph, hooks, transform)
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 706, in compile_inner
[rank5]:     return _compile_inner(code, one_graph, hooks, transform)
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_utils_internal.py", line 95, in wrapper_function
[rank5]:     return function(*args, **kwargs)
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 741, in _compile_inner
[rank5]:     out_code = transform_code_object(code, transform)
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/bytecode_transformation.py", line 1348, in transform_code_object
[rank5]:     transformations(instructions, code_options)
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 229, in _fn
[rank5]:     return fn(*args, **kwargs)
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 658, in transform
[rank5]:     tracer.run()
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 2912, in run
[rank5]:     super().run()
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 1120, in run
[rank5]:     while self.step():
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 1032, in step
[rank5]:     self.dispatch_table[inst.opcode](self, inst)
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 3103, in RETURN_VALUE
[rank5]:     self._return(inst)
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 3088, in _return
[rank5]:     self.output.compile_subgraph(
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/output_graph.py", line 1077, in compile_subgraph
[rank5]:     self.compile_and_call_fx_graph(tx, list(reversed(stack_values)), root)
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/output_graph.py", line 1346, in compile_and_call_fx_graph
[rank5]:     compiled_fn = self.call_user_compiler(gm)
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/output_graph.py", line 1396, in call_user_compiler
[rank5]:     return self._call_user_compiler(gm)
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/output_graph.py", line 1445, in _call_user_compiler
[rank5]:     raise BackendCompilerFailed(self.compiler_fn, e).with_traceback(
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/output_graph.py", line 1426, in _call_user_compiler
[rank5]:     compiled_fn = compiler_fn(gm, self.example_inputs())
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/repro/after_dynamo.py", line 130, in __call__
[rank5]:     compiled_gm = compiler_fn(gm, example_inputs)
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/repro/after_dynamo.py", line 130, in __call__
[rank5]:     compiled_gm = compiler_fn(gm, example_inputs)
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/__init__.py", line 2301, in __call__
[rank5]:     return compile_fx(model_, inputs_, config_patches=self.config)
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 1708, in compile_fx
[rank5]:     return aot_autograd(
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/backends/common.py", line 72, in __call__
[rank5]:     cg = aot_module_simplified(gm, example_inputs, **self.kwargs)
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 1103, in aot_module_simplified
[rank5]:     compiled_fn = dispatch_and_compile()
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 1079, in dispatch_and_compile
[rank5]:     compiled_fn, _ = create_aot_dispatcher_function(
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 527, in create_aot_dispatcher_function
[rank5]:     return _create_aot_dispatcher_function(
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 778, in _create_aot_dispatcher_function
[rank5]:     compiled_fn, fw_metadata = compiler_fn(
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py", line 197, in aot_dispatch_base
[rank5]:     compiled_fw = compiler(fw_module, updated_flat_args)
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 1525, in fw_compiler_base
[rank5]:     return _fw_compiler_base(model, example_inputs, is_inference)
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 1594, in _fw_compiler_base
[rank5]:     return inner_compile(
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 587, in compile_fx_inner
[rank5]:     return wrap_compiler_debug(_compile_fx_inner, compiler_name="inductor")(
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/repro/after_aot.py", line 102, in debug_wrapper
[rank5]:     inner_compiled_fn = compiler_fn(gm, example_inputs)
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 744, in _compile_fx_inner
[rank5]:     compiled_graph = FxGraphCache.load(
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 1504, in load
[rank5]:     compiled_graph = compile_fx_fn(
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 651, in codegen_and_compile
[rank5]:     compiled_graph = fx_codegen_and_compile(gm, example_inputs, **fx_kwargs)
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 962, in fx_codegen_and_compile
[rank5]:     compiled_fn = graph.compile_to_fn()
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/graph.py", line 2034, in compile_to_fn
[rank5]:     return self.compile_to_module().call
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/graph.py", line 1954, in compile_to_module
[rank5]:     return self._compile_to_module()
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/graph.py", line 1988, in _compile_to_module
[rank5]:     mod = PyCodeCache.load_by_key_path(
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 3058, in load_by_key_path
[rank5]:     mod = _reload_python_module(key, path)
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/runtime/compile_tasks.py", line 45, in _reload_python_module
[rank5]:     exec(code, mod.__dict__, mod.__dict__)
[rank5]:   File "/home/charlie/skip-residual/gpt-fast/torchinductor_charlie/26/c26lsqoj3yjrn637acr43qischfstyoqyo7peoth776ncosfy46a.py", line 1162, in <module>
[rank5]:     async_compile.wait(globals())
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/async_compile.py", line 319, in wait
[rank5]:     scope[key] = result.result()
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 3535, in result
[rank5]:     result = self.future.result()
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/concurrent/futures/_base.py", line 458, in result
[rank5]:     return self.__get_result()
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
[rank5]:     raise self._exception
[rank5]: torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:
[rank5]: SubprocException: An exception occurred in a subprocess:

[rank5]: Traceback (most recent call last):
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_worker/subproc_pool.py", line 280, in do_job
[rank5]:     result = job()
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/runtime/compile_tasks.py", line 68, in _worker_compile_triton
[rank5]:     load_kernel().precompile(warm_cache_only=True)
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/runtime/compile_tasks.py", line 13, in _reload_triton_kernel_in_subproc
[rank5]:     return _module_to_triton_kernel(reload_module(), kernel_name)
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/runtime/compile_tasks.py", line 29, in _reload_python_module_in_subproc
[rank5]:     return codecache.PyCodeCache.load_by_key_path(key, path)
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 3058, in load_by_key_path
[rank5]:     mod = _reload_python_module(key, path)
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/runtime/compile_tasks.py", line 45, in _reload_python_module
[rank5]:     exec(code, mod.__dict__, mod.__dict__)
[rank5]:   File "/home/charlie/skip-residual/gpt-fast/torchinductor_charlie/ae/caeidisvkiefgd2wwphjflccsuaikycrlem5f32pnn7xw75vpog3.py", line 9, in <module>
[rank5]:     triton_helpers.set_driver_to_gpu()
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/runtime/triton_helpers.py", line 57, in set_driver_to_gpu
[rank5]:     driver.set_active(backend.driver())
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/triton/backends/nvidia/driver.py", line 371, in __init__
[rank5]:     self.utils = CudaUtils()  # TODO: make static
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/triton/backends/nvidia/driver.py", line 80, in __init__
[rank5]:     mod = compile_module_from_src(Path(os.path.join(dirname, "driver.c")).read_text(), "cuda_utils")
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/triton/backends/nvidia/driver.py", line 57, in compile_module_from_src
[rank5]:     so = _build(name, src_path, tmpdir, library_dirs(), include_dir, libraries)
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/triton/runtime/build.py", line 48, in _build
[rank5]:     ret = subprocess.check_call(cc_cmd)
[rank5]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/subprocess.py", line 369, in check_call
[rank5]:     raise CalledProcessError(retcode, cmd)
[rank5]: subprocess.CalledProcessError: Command '['/usr/bin/gcc', '/home/charlie/skip-residual/gpt-fast/tmpma31ixf8/main.c', '-O3', '-shared', '-fPIC', '-o', '/home/charlie/skip-residual/gpt-fast/tmpma31ixf8/cuda_utils.cpython-310-x86_64-linux-gnu.so', '-lcuda', '-L/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/triton/backends/nvidia/lib', '-L/lib/x86_64-linux-gnu', '-I/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/triton/backends/nvidia/include', '-I/home/charlie/skip-residual/gpt-fast/tmpma31ixf8', '-I/home/charlie/anaconda3/envs/gpt-fast/include/python3.10']' returned non-zero exit status 1.


[rank5]: Set TORCH_LOGS="+dynamo" and TORCHDYNAMO_VERBOSE=1 for more information


[rank5]: You can suppress this exception and fall back to eager by setting:
[rank5]:     import torch._dynamo
[rank5]:     torch._dynamo.config.suppress_errors = True

/home/charlie/skip-residual/gpt-fast/tmpwyddpdft/main.c:422:1: fatal error: error writing to /tmp/cc4b989F.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpnzbypxew/main.c:422:1: fatal error: error writing to /tmp/ccpgWCw0.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpz2_2fj36/main.c:422:1: fatal error: error writing to /tmp/cc0c60DZ.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpjoojpukz/main.c:422:1: fatal error: error writing to /tmp/ccoBvtcW.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpp5lsjbpm/main.c:422:1: fatal error: error writing to /tmp/cc5wF7dm.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpz6nxtt6b/main.c:422:1: fatal error: error writing to /tmp/ccyV0D19.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpau5nxpcx/main.c:422:1: fatal error: error writing to /tmp/cc5x83XS.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpr_hq2q9b/main.c:422:1: fatal error: error writing to /tmp/cc6r3Dw8.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmp7a_sic51/main.c:422:1: fatal error: error writing to /tmp/ccA9X3JK.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmph6ssjzns/main.c:422:1: fatal error: error writing to /tmp/cc2UvT9D.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmptftcl68u/main.c:422:1: fatal error: error writing to /tmp/ccJ1jAsa.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpbhbcnyc6/main.c:422:1: fatal error: error writing to /tmp/cc1DHx7t.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmp9pyy0iu3/main.c:422:1: fatal error: error writing to /tmp/ccmBQiHF.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmp3y28nbyg/main.c:422:1: fatal error: error writing to /tmp/cc6nYX2g.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpioi_ysv3/main.c:422:1: fatal error: error writing to /tmp/ccWgLcx8.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmp3emeggld/main.c:422:1: fatal error: error writing to /tmp/ccFTOXFv.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmp1cy5yqq_/main.c:422:1: fatal error: error writing to /tmp/ccIxd2mZ.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpkv4hgyl6/main.c:422:1: fatal error: error writing to /tmp/ccaNhaM2.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpiccdsk2e/main.c:422:1: fatal error: error writing to /tmp/ccErP9dt.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpsdz9apwa/main.c:422:1: fatal error: error writing to /tmp/ccXBZ4VV.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpalaebufn/main.c:422:1: fatal error: error writing to /tmp/ccsIXTRU.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmp9807ol9u/main.c:422:1: fatal error: error writing to /tmp/ccUcuSiV.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmp3wr0nwgz/main.c:422:1: fatal error: error writing to /tmp/ccdh3r2E.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmp67frxjn7/main.c:422:1: fatal error: error writing to /tmp/ccekdPPs.s: No space left on device
  422 | }
      | ^
compilation terminated.
[rank1]: Traceback (most recent call last):
[rank1]:   File "/home/charlie/skip-residual/gpt-fast/benchmark.py", line 708, in <module>
[rank1]:     main(
[rank1]:   File "/home/charlie/skip-residual/gpt-fast/benchmark.py", line 622, in main
[rank1]:     y, decode_latency, prefill_latency = generate(
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
[rank1]:     return func(*args, **kwargs)
[rank1]:   File "/home/charlie/skip-residual/gpt-fast/benchmark.py", line 332, in generate
[rank1]:     next_token = prefill_ladder(
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py", line 556, in _fn
[rank1]:     return fn(*args, **kwargs)
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 1395, in __call__
[rank1]:     return self._torchdynamo_orig_callable(
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 545, in __call__
[rank1]:     return _compile(
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 977, in _compile
[rank1]:     guarded_code = compile_inner(code, one_graph, hooks, transform)
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 706, in compile_inner
[rank1]:     return _compile_inner(code, one_graph, hooks, transform)
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_utils_internal.py", line 95, in wrapper_function
[rank1]:     return function(*args, **kwargs)
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 741, in _compile_inner
[rank1]:     out_code = transform_code_object(code, transform)
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/bytecode_transformation.py", line 1348, in transform_code_object
[rank1]:     transformations(instructions, code_options)
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 229, in _fn
[rank1]:     return fn(*args, **kwargs)
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 658, in transform
[rank1]:     tracer.run()
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 2912, in run
[rank1]:     super().run()
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 1120, in run
[rank1]:     while self.step():
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 1032, in step
[rank1]:     self.dispatch_table[inst.opcode](self, inst)
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 3103, in RETURN_VALUE
[rank1]:     self._return(inst)
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 3088, in _return
[rank1]:     self.output.compile_subgraph(
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/output_graph.py", line 1077, in compile_subgraph
[rank1]:     self.compile_and_call_fx_graph(tx, list(reversed(stack_values)), root)
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/output_graph.py", line 1346, in compile_and_call_fx_graph
[rank1]:     compiled_fn = self.call_user_compiler(gm)
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/output_graph.py", line 1396, in call_user_compiler
[rank1]:     return self._call_user_compiler(gm)
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/output_graph.py", line 1445, in _call_user_compiler
[rank1]:     raise BackendCompilerFailed(self.compiler_fn, e).with_traceback(
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/output_graph.py", line 1426, in _call_user_compiler
[rank1]:     compiled_fn = compiler_fn(gm, self.example_inputs())
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/repro/after_dynamo.py", line 130, in __call__
[rank1]:     compiled_gm = compiler_fn(gm, example_inputs)
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/repro/after_dynamo.py", line 130, in __call__
[rank1]:     compiled_gm = compiler_fn(gm, example_inputs)
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/__init__.py", line 2301, in __call__
[rank1]:     return compile_fx(model_, inputs_, config_patches=self.config)
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 1708, in compile_fx
[rank1]:     return aot_autograd(
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/backends/common.py", line 72, in __call__
[rank1]:     cg = aot_module_simplified(gm, example_inputs, **self.kwargs)
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 1103, in aot_module_simplified
[rank1]:     compiled_fn = dispatch_and_compile()
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 1079, in dispatch_and_compile
[rank1]:     compiled_fn, _ = create_aot_dispatcher_function(
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 527, in create_aot_dispatcher_function
[rank1]:     return _create_aot_dispatcher_function(
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 778, in _create_aot_dispatcher_function
[rank1]:     compiled_fn, fw_metadata = compiler_fn(
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py", line 197, in aot_dispatch_base
[rank1]:     compiled_fw = compiler(fw_module, updated_flat_args)
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 1525, in fw_compiler_base
[rank1]:     return _fw_compiler_base(model, example_inputs, is_inference)
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 1594, in _fw_compiler_base
[rank1]:     return inner_compile(
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 587, in compile_fx_inner
[rank1]:     return wrap_compiler_debug(_compile_fx_inner, compiler_name="inductor")(
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/repro/after_aot.py", line 102, in debug_wrapper
[rank1]:     inner_compiled_fn = compiler_fn(gm, example_inputs)
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 744, in _compile_fx_inner
[rank1]:     compiled_graph = FxGraphCache.load(
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 1504, in load
[rank1]:     compiled_graph = compile_fx_fn(
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 651, in codegen_and_compile
[rank1]:     compiled_graph = fx_codegen_and_compile(gm, example_inputs, **fx_kwargs)
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 962, in fx_codegen_and_compile
[rank1]:     compiled_fn = graph.compile_to_fn()
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/graph.py", line 2034, in compile_to_fn
[rank1]:     return self.compile_to_module().call
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/graph.py", line 1954, in compile_to_module
[rank1]:     return self._compile_to_module()
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/graph.py", line 1988, in _compile_to_module
[rank1]:     mod = PyCodeCache.load_by_key_path(
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 3058, in load_by_key_path
[rank1]:     mod = _reload_python_module(key, path)
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/runtime/compile_tasks.py", line 45, in _reload_python_module
[rank1]:     exec(code, mod.__dict__, mod.__dict__)
[rank1]:   File "/home/charlie/skip-residual/gpt-fast/torchinductor_charlie/at/catmfr7upjvs3wvy4lmpeno5cdh7ntlchy6jprvz6rgzmkyk2oq7.py", line 1162, in <module>
[rank1]:     async_compile.wait(globals())
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/async_compile.py", line 319, in wait
[rank1]:     scope[key] = result.result()
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 3535, in result
[rank1]:     result = self.future.result()
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/concurrent/futures/_base.py", line 458, in result
[rank1]:     return self.__get_result()
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
[rank1]:     raise self._exception
[rank1]: torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:
[rank1]: SubprocException: An exception occurred in a subprocess:

[rank1]: Traceback (most recent call last):
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_worker/subproc_pool.py", line 280, in do_job
[rank1]:     result = job()
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/runtime/compile_tasks.py", line 68, in _worker_compile_triton
[rank1]:     load_kernel().precompile(warm_cache_only=True)
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/runtime/compile_tasks.py", line 13, in _reload_triton_kernel_in_subproc
[rank1]:     return _module_to_triton_kernel(reload_module(), kernel_name)
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/runtime/compile_tasks.py", line 29, in _reload_python_module_in_subproc
[rank1]:     return codecache.PyCodeCache.load_by_key_path(key, path)
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 3058, in load_by_key_path
[rank1]:     mod = _reload_python_module(key, path)
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/runtime/compile_tasks.py", line 45, in _reload_python_module
[rank1]:     exec(code, mod.__dict__, mod.__dict__)
[rank1]:   File "/home/charlie/skip-residual/gpt-fast/torchinductor_charlie/or/cormmxyw4rrzs53rnh5t7z52phjw4qqs7dhbgmwn3pwouo5ouk23.py", line 9, in <module>
[rank1]:     triton_helpers.set_driver_to_gpu()
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/runtime/triton_helpers.py", line 57, in set_driver_to_gpu
[rank1]:     driver.set_active(backend.driver())
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/triton/backends/nvidia/driver.py", line 371, in __init__
[rank1]:     self.utils = CudaUtils()  # TODO: make static
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/triton/backends/nvidia/driver.py", line 80, in __init__
[rank1]:     mod = compile_module_from_src(Path(os.path.join(dirname, "driver.c")).read_text(), "cuda_utils")
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/triton/backends/nvidia/driver.py", line 57, in compile_module_from_src
[rank1]:     so = _build(name, src_path, tmpdir, library_dirs(), include_dir, libraries)
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/triton/runtime/build.py", line 48, in _build
[rank1]:     ret = subprocess.check_call(cc_cmd)
[rank1]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/subprocess.py", line 369, in check_call
[rank1]:     raise CalledProcessError(retcode, cmd)
[rank1]: subprocess.CalledProcessError: Command '['/usr/bin/gcc', '/home/charlie/skip-residual/gpt-fast/tmpr_hq2q9b/main.c', '-O3', '-shared', '-fPIC', '-o', '/home/charlie/skip-residual/gpt-fast/tmpr_hq2q9b/cuda_utils.cpython-310-x86_64-linux-gnu.so', '-lcuda', '-L/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/triton/backends/nvidia/lib', '-L/lib/x86_64-linux-gnu', '-I/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/triton/backends/nvidia/include', '-I/home/charlie/skip-residual/gpt-fast/tmpr_hq2q9b', '-I/home/charlie/anaconda3/envs/gpt-fast/include/python3.10']' returned non-zero exit status 1.


[rank1]: Set TORCH_LOGS="+dynamo" and TORCHDYNAMO_VERBOSE=1 for more information


[rank1]: You can suppress this exception and fall back to eager by setting:
[rank1]:     import torch._dynamo
[rank1]:     torch._dynamo.config.suppress_errors = True

/home/charlie/skip-residual/gpt-fast/tmpuef5vcgj/main.c:422:1: fatal error: error writing to /tmp/ccVNie1i.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmp64xkchy5/main.c:422:1: fatal error: error writing to /tmp/ccJR37yy.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpdj133qr3/main.c:422:1: fatal error: error writing to /tmp/ccDu8CFt.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpa7mkc0u4/main.c:422:1: fatal error: error writing to /tmp/ccasazk6.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpaeeiu10a/main.c:422:1: fatal error: error writing to /tmp/ccqJaGhh.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpl7ei7d55/main.c:422:1: fatal error: error writing to /tmp/ccNr8A6C.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpxpg6xqgd/main.c:422:1: fatal error: error writing to /tmp/ccij6zj0.s: No space left on device
  422 | }
      | ^
compilation terminated.
[rank7]: Traceback (most recent call last):
[rank7]:   File "/home/charlie/skip-residual/gpt-fast/benchmark.py", line 708, in <module>
[rank7]:     main(
[rank7]:   File "/home/charlie/skip-residual/gpt-fast/benchmark.py", line 622, in main
[rank7]:     y, decode_latency, prefill_latency = generate(
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
[rank7]:     return func(*args, **kwargs)
[rank7]:   File "/home/charlie/skip-residual/gpt-fast/benchmark.py", line 332, in generate
[rank7]:     next_token = prefill_ladder(
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py", line 556, in _fn
[rank7]:     return fn(*args, **kwargs)
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 1395, in __call__
[rank7]:     return self._torchdynamo_orig_callable(
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 545, in __call__
[rank7]:     return _compile(
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 977, in _compile
[rank7]:     guarded_code = compile_inner(code, one_graph, hooks, transform)
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 706, in compile_inner
[rank7]:     return _compile_inner(code, one_graph, hooks, transform)
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_utils_internal.py", line 95, in wrapper_function
[rank7]:     return function(*args, **kwargs)
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 741, in _compile_inner
[rank7]:     out_code = transform_code_object(code, transform)
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/bytecode_transformation.py", line 1348, in transform_code_object
[rank7]:     transformations(instructions, code_options)
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 229, in _fn
[rank7]:     return fn(*args, **kwargs)
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 658, in transform
[rank7]:     tracer.run()
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 2912, in run
[rank7]:     super().run()
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 1120, in run
[rank7]:     while self.step():
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 1032, in step
[rank7]:     self.dispatch_table[inst.opcode](self, inst)
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 3103, in RETURN_VALUE
[rank7]:     self._return(inst)
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 3088, in _return
[rank7]:     self.output.compile_subgraph(
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/output_graph.py", line 1077, in compile_subgraph
[rank7]:     self.compile_and_call_fx_graph(tx, list(reversed(stack_values)), root)
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/output_graph.py", line 1346, in compile_and_call_fx_graph
[rank7]:     compiled_fn = self.call_user_compiler(gm)
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/output_graph.py", line 1396, in call_user_compiler
[rank7]:     return self._call_user_compiler(gm)
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/output_graph.py", line 1445, in _call_user_compiler
[rank7]:     raise BackendCompilerFailed(self.compiler_fn, e).with_traceback(
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/output_graph.py", line 1426, in _call_user_compiler
[rank7]:     compiled_fn = compiler_fn(gm, self.example_inputs())
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/repro/after_dynamo.py", line 130, in __call__
[rank7]:     compiled_gm = compiler_fn(gm, example_inputs)
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/repro/after_dynamo.py", line 130, in __call__
[rank7]:     compiled_gm = compiler_fn(gm, example_inputs)
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/__init__.py", line 2301, in __call__
[rank7]:     return compile_fx(model_, inputs_, config_patches=self.config)
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 1708, in compile_fx
[rank7]:     return aot_autograd(
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/backends/common.py", line 72, in __call__
[rank7]:     cg = aot_module_simplified(gm, example_inputs, **self.kwargs)
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 1103, in aot_module_simplified
[rank7]:     compiled_fn = dispatch_and_compile()
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 1079, in dispatch_and_compile
[rank7]:     compiled_fn, _ = create_aot_dispatcher_function(
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 527, in create_aot_dispatcher_function
[rank7]:     return _create_aot_dispatcher_function(
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 778, in _create_aot_dispatcher_function
[rank7]:     compiled_fn, fw_metadata = compiler_fn(
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py", line 197, in aot_dispatch_base
[rank7]:     compiled_fw = compiler(fw_module, updated_flat_args)
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 1525, in fw_compiler_base
[rank7]:     return _fw_compiler_base(model, example_inputs, is_inference)
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 1594, in _fw_compiler_base
[rank7]:     return inner_compile(
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 587, in compile_fx_inner
[rank7]:     return wrap_compiler_debug(_compile_fx_inner, compiler_name="inductor")(
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/repro/after_aot.py", line 102, in debug_wrapper
[rank7]:     inner_compiled_fn = compiler_fn(gm, example_inputs)
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 744, in _compile_fx_inner
[rank7]:     compiled_graph = FxGraphCache.load(
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 1504, in load
[rank7]:     compiled_graph = compile_fx_fn(
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 651, in codegen_and_compile
[rank7]:     compiled_graph = fx_codegen_and_compile(gm, example_inputs, **fx_kwargs)
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 962, in fx_codegen_and_compile
[rank7]:     compiled_fn = graph.compile_to_fn()
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/graph.py", line 2034, in compile_to_fn
[rank7]:     return self.compile_to_module().call
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/graph.py", line 1954, in compile_to_module
[rank7]:     return self._compile_to_module()
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/graph.py", line 1988, in _compile_to_module
[rank7]:     mod = PyCodeCache.load_by_key_path(
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 3058, in load_by_key_path
[rank7]:     mod = _reload_python_module(key, path)
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/runtime/compile_tasks.py", line 45, in _reload_python_module
[rank7]:     exec(code, mod.__dict__, mod.__dict__)
[rank7]:   File "/home/charlie/skip-residual/gpt-fast/torchinductor_charlie/ro/croh4jctc7p55wpcjimbvu5y6c37qubpb4owdpjy4eac55n63rps.py", line 1162, in <module>
[rank7]:     async_compile.wait(globals())
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/async_compile.py", line 319, in wait
[rank7]:     scope[key] = result.result()
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 3535, in result
[rank7]:     result = self.future.result()
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/concurrent/futures/_base.py", line 458, in result
[rank7]:     return self.__get_result()
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
[rank7]:     raise self._exception
[rank7]: torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:
[rank7]: SubprocException: An exception occurred in a subprocess:

[rank7]: Traceback (most recent call last):
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_worker/subproc_pool.py", line 280, in do_job
[rank7]:     result = job()
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/runtime/compile_tasks.py", line 68, in _worker_compile_triton
[rank7]:     load_kernel().precompile(warm_cache_only=True)
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/runtime/compile_tasks.py", line 13, in _reload_triton_kernel_in_subproc
[rank7]:     return _module_to_triton_kernel(reload_module(), kernel_name)
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/runtime/compile_tasks.py", line 29, in _reload_python_module_in_subproc
[rank7]:     return codecache.PyCodeCache.load_by_key_path(key, path)
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 3058, in load_by_key_path
[rank7]:     mod = _reload_python_module(key, path)
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/runtime/compile_tasks.py", line 45, in _reload_python_module
[rank7]:     exec(code, mod.__dict__, mod.__dict__)
[rank7]:   File "/home/charlie/skip-residual/gpt-fast/torchinductor_charlie/7a/c7a7efb5ff5rkysvdjosyuqufh674u5xrzfwukjrnt7gj3xu2wqu.py", line 9, in <module>
[rank7]:     triton_helpers.set_driver_to_gpu()
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/runtime/triton_helpers.py", line 57, in set_driver_to_gpu
[rank7]:     driver.set_active(backend.driver())
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/triton/backends/nvidia/driver.py", line 371, in __init__
[rank7]:     self.utils = CudaUtils()  # TODO: make static
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/triton/backends/nvidia/driver.py", line 80, in __init__
[rank7]:     mod = compile_module_from_src(Path(os.path.join(dirname, "driver.c")).read_text(), "cuda_utils")
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/triton/backends/nvidia/driver.py", line 57, in compile_module_from_src
[rank7]:     so = _build(name, src_path, tmpdir, library_dirs(), include_dir, libraries)
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/triton/runtime/build.py", line 48, in _build
[rank7]:     ret = subprocess.check_call(cc_cmd)
[rank7]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/subprocess.py", line 369, in check_call
[rank7]:     raise CalledProcessError(retcode, cmd)
[rank7]: subprocess.CalledProcessError: Command '['/usr/bin/gcc', '/home/charlie/skip-residual/gpt-fast/tmp3y28nbyg/main.c', '-O3', '-shared', '-fPIC', '-o', '/home/charlie/skip-residual/gpt-fast/tmp3y28nbyg/cuda_utils.cpython-310-x86_64-linux-gnu.so', '-lcuda', '-L/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/triton/backends/nvidia/lib', '-L/lib/x86_64-linux-gnu', '-I/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/triton/backends/nvidia/include', '-I/home/charlie/skip-residual/gpt-fast/tmp3y28nbyg', '-I/home/charlie/anaconda3/envs/gpt-fast/include/python3.10']' returned non-zero exit status 1.


[rank7]: Set TORCH_LOGS="+dynamo" and TORCHDYNAMO_VERBOSE=1 for more information


[rank7]: You can suppress this exception and fall back to eager by setting:
[rank7]:     import torch._dynamo
[rank7]:     torch._dynamo.config.suppress_errors = True

/home/charlie/skip-residual/gpt-fast/tmp8onixo0r/main.c:422:1: fatal error: error writing to /tmp/ccEPVomv.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmp770cil51/main.c:422:1: fatal error: error writing to /tmp/ccJPtPXr.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmp379giekf/main.c:422:1: fatal error: error writing to /tmp/ccpU31RJ.s: No space left on device
  422 | }
      | ^
/home/charlie/skip-residual/gpt-fast/tmpj3_gydbf/main.c:422:1: fatal error: error writing to /tmp/cc8FWEHO.s: No space left on device
  422 | }
      | ^
compilation terminated.
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmp8e0b42dz/main.c:422:1: fatal error: error writing to /tmp/ccWN6hX9.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpbi7zruoy/main.c:422:1: fatal error: error writing to /tmp/ccZU4mN8.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmp4mcnxtnb/main.c:422:1: fatal error: error writing to /tmp/ccN4QlwC.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpxur97fxy/main.c:422:1: fatal error: error writing to /tmp/ccg06Rtd.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmps9nvlpxu/main.c:422:1: fatal error: error writing to /tmp/cc4PST0N.s: No space left on device
  422 | }
      | ^
/home/charlie/skip-residual/gpt-fast/tmpyp9mthct/main.c:422:1: fatal error: error writing to /tmp/ccDHoDX9.s: No space left on device
  422 | }
      | ^
compilation terminated.
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpfuktdakj/main.c:422:1: fatal error: error writing to /tmp/cckOTVui.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpch3ia204/main.c:422:1: fatal error: error writing to /tmp/cckOOboR.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpxtcwfi9k/main.c:422:1: fatal error: error writing to /tmp/ccbpjiFo.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmp_yf99e7f/main.c:422:1: fatal error: error writing to /tmp/cceRfCMo.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmp4tevr78x/main.c:422:1: fatal error: error writing to /tmp/ccYXzQaO.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmp4va36y4_/main.c:422:1: fatal error: error writing to /tmp/ccgqEm8b.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmp7njlgflg/main.c:422:1: fatal error: error writing to /tmp/cc8PJhMG.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpts7iove5/main.c:422:1: fatal error: error writing to /tmp/ccTYaNYP.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpeeetg3l0/main.c:422:1: fatal error: error writing to /tmp/cclIEnq7.s: No space left on device
  422 | }
      | ^
compilation terminated.
/home/charlie/skip-residual/gpt-fast/tmpuunu__dd/main.c:422:1: fatal error: error writing to /tmp/cc2NItdJ.s: No space left on device
  422 | }
      | ^
compilation terminated.
[rank0]:[W1201 11:21:29.905363625 ProcessGroupNCCL.cpp:1374] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
[rank3]:[W1201 11:21:29.109441890 ProcessGroupNCCL.cpp:1374] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
[rank6]:[W1201 11:21:30.227159534 ProcessGroupNCCL.cpp:1374] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
[rank5]:[W1201 11:21:31.308763206 ProcessGroupNCCL.cpp:1374] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
[rank1]:[W1201 11:21:31.679756755 ProcessGroupNCCL.cpp:1374] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
[rank4]:[W1201 11:21:32.237871776 ProcessGroupNCCL.cpp:1374] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
W1201 11:21:32.078000 455452 site-packages/torch/distributed/elastic/multiprocessing/api.py:897] Sending process 455523 closing signal SIGTERM
[rank2]:[W1201 11:21:32.260439829 ProcessGroupNCCL.cpp:1374] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
W1201 11:21:32.082000 455452 site-packages/torch/distributed/elastic/multiprocessing/api.py:897] Sending process 455524 closing signal SIGTERM
W1201 11:21:32.085000 455452 site-packages/torch/distributed/elastic/multiprocessing/api.py:897] Sending process 455525 closing signal SIGTERM
W1201 11:21:32.086000 455452 site-packages/torch/distributed/elastic/multiprocessing/api.py:897] Sending process 455526 closing signal SIGTERM
W1201 11:21:32.090000 455452 site-packages/torch/distributed/elastic/multiprocessing/api.py:897] Sending process 455527 closing signal SIGTERM
W1201 11:21:32.092000 455452 site-packages/torch/distributed/elastic/multiprocessing/api.py:897] Sending process 455528 closing signal SIGTERM
W1201 11:21:32.096000 455452 site-packages/torch/distributed/elastic/multiprocessing/api.py:897] Sending process 455529 closing signal SIGTERM
E1201 11:21:32.804000 455452 site-packages/torch/distributed/elastic/multiprocessing/api.py:869] failed (exitcode: 1) local_rank: 0 (pid: 455522) of binary: /home/charlie/anaconda3/envs/gpt-fast/bin/python
Traceback (most recent call last):
  File "/home/charlie/anaconda3/envs/gpt-fast/bin/torchrun", line 8, in <module>
    sys.exit(main())
  File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 355, in wrapper
    return f(*args, **kwargs)
  File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/distributed/run.py", line 919, in main
    run(args)
  File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/distributed/run.py", line 910, in run
    elastic_launch(
  File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 138, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 269, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
benchmark.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2024-12-01_11:21:32
  host      : mk-xii-22.cloud.together.ai
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 455522)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
