W0920 10:44:09.237000 22968871102272 torch/distributed/run.py:779] 
W0920 10:44:09.237000 22968871102272 torch/distributed/run.py:779] *****************************************
W0920 10:44:09.237000 22968871102272 torch/distributed/run.py:779] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W0920 10:44:09.237000 22968871102272 torch/distributed/run.py:779] *****************************************
flash_kv_decode is set to False
Using device=cuda
Loading model ...
GPTParallel(
  (tok_embeddings): Embedding(128256, 4096)
  (layers): ModuleList(
    (0-31): 32 x ParallelTransformerBlock(
      semi_compiled = False
      (attention): Attention(
        (wqkv): Linear(in_features=4096, out_features=1536, bias=False)
        (wo): Linear(in_features=1024, out_features=4096, bias=False)
      )
      (feed_forward): FeedForward(
        (w1): Linear(in_features=4096, out_features=7168, bias=False)
        (w2): Linear(in_features=3584, out_features=4096, bias=False)
      )
      (ffn_norm): RMSNorm()
      (attention_norm): RMSNorm()
    )
  )
  (norm): RMSNorm()
  (output): Linear(in_features=4096, out_features=128256, bias=False)
)
Time to load model: 1.00 seconds
Compiling prefill with dynamic=False
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
[rank3]:W0920 10:44:40.887000 22797793318720 torch/fx/experimental/symbolic_shapes.py:4449] [0/0] xindex is not in var_ranges, defaulting to unknown range.
[rank2]:W0920 10:44:41.000000 22896212428608 torch/fx/experimental/symbolic_shapes.py:4449] [0/0] xindex is not in var_ranges, defaulting to unknown range.
[rank0]:W0920 10:44:41.043000 23046705637184 torch/fx/experimental/symbolic_shapes.py:4449] [0/0] xindex is not in var_ranges, defaulting to unknown range.
[rank1]:W0920 10:44:41.088000 23387018385216 torch/fx/experimental/symbolic_shapes.py:4449] [0/0] xindex is not in var_ranges, defaulting to unknown range.
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
Prefill latency: 55.68253785299021 sec
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
[rank1]:W0920 10:45:36.095000 23387018385216 torch/fx/experimental/symbolic_shapes.py:4449] [1/0] xindex is not in var_ranges, defaulting to unknown range.
[rank0]:W0920 10:45:36.185000 23046705637184 torch/fx/experimental/symbolic_shapes.py:4449] [1/0] xindex is not in var_ranges, defaulting to unknown range.
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
[rank2]:W0920 10:45:48.804000 22896212428608 torch/fx/experimental/symbolic_shapes.py:4449] [1/0] xindex is not in var_ranges, defaulting to unknown range.
[rank3]:W0920 10:45:49.190000 22797793318720 torch/fx/experimental/symbolic_shapes.py:4449] [1/0] xindex is not in var_ranges, defaulting to unknown range.
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
Decode latency: 65.15957328502554 sec
Compilation time: 120.82 seconds
Compilation time: 120.84 seconds
Compilation time: 120.81 seconds
Compilation time: 120.83 seconds
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
Prefill latency: 1.1856324589753058 sec
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
Decode latency: 1.149995288986247 sec
Prefill latency: 0.18319177298690192 sec
Decode latency: 1.149504311993951 sec
Prefill latency: 0.1813444159924984 sec
Decode latency: 1.1504236239998136 sec
Prefill latency: 0.18311516800895333 sec
Decode latency: 1.149802085972624 sec
Prefill latency: 0.1814459529996384 sec
Decode latency: 1.1505128479911946 sec
Time for inference 1: 1.33 sec total, 3072.81 tokens/sec
Decode latency: 1.15 sec
Prefill latency: 0.18 sec
Bandwidth achieved: 13953.22 GB/s
FLOPS achieved: 69.77 TF/s

Prefill latency: 0.18275797498063184 sec
Decode latency: 1.150274766026996 sec
Time for inference 2: 1.33 sec total, 3070.49 tokens/sec
Decode latency: 1.15 sec
Prefill latency: 0.18 sec
Bandwidth achieved: 13942.67 GB/s
FLOPS achieved: 69.71 TF/s

Prefill latency: 0.183107911987463 sec
Decode latency: 1.1497865589917637 sec
Time for inference 3: 1.33 sec total, 3070.93 tokens/sec
Decode latency: 1.15 sec
Prefill latency: 0.18 sec
Bandwidth achieved: 13944.69 GB/s
FLOPS achieved: 69.72 TF/s

Prefill latency: 0.18224996599019505 sec
Decode latency: 1.1498784110008273 sec
Time for inference 4: 1.33 sec total, 3072.68 tokens/sec
Decode latency: 1.15 sec
Prefill latency: 0.18 sec
Bandwidth achieved: 13952.65 GB/s
FLOPS achieved: 69.76 TF/s

Prefill latency: 0.18190905600204132 sec
Decode latency: 1.1503621349984314 sec
Time for inference 5: 1.33 sec total, 3072.45 tokens/sec
Decode latency: 1.15 sec
Prefill latency: 0.18 sec
Bandwidth achieved: 13951.60 GB/s
FLOPS achieved: 69.76 TF/s

Prefill latency: 0.18333042101585306 sec
Decode latency: 1.1505789060029201 sec
Time for inference 6: 1.34 sec total, 3067.87 tokens/sec
Decode latency: 1.15 sec
Prefill latency: 0.18 sec
Bandwidth achieved: 13930.77 GB/s
FLOPS achieved: 69.65 TF/s

Prefill latency: 0.18265616899589077 sec
Decode latency: 1.1506306740047876 sec
Time for inference 7: 1.33 sec total, 3068.83 tokens/sec
Decode latency: 1.15 sec
Prefill latency: 0.18 sec
Bandwidth achieved: 13935.16 GB/s
FLOPS achieved: 69.68 TF/s

Prefill latency: 0.18347711200476624 sec
Decode latency: 1.149961830000393 sec
Time for inference 8: 1.33 sec total, 3069.29 tokens/sec
Decode latency: 1.15 sec
Prefill latency: 0.18 sec
Bandwidth achieved: 13937.22 GB/s
FLOPS achieved: 69.69 TF/s

Prefill latency: 0.18304904701653868 sec
Decode latency: 1.1498485019837972 sec
Time for inference 9: 1.33 sec total, 3070.97 tokens/sec
Decode latency: 1.15 sec
Prefill latency: 0.18 sec
Bandwidth achieved: 13944.85 GB/s
FLOPS achieved: 69.72 TF/s

Prefill latency: 0.1818222450092435 sec
Decode latency: 1.1504329720046371 sec
Time for inference 10: 1.33 sec total, 3072.38 tokens/sec
Decode latency: 1.15 sec
Prefill latency: 0.18 sec
Bandwidth achieved: 13951.28 GB/s
FLOPS achieved: 69.76 TF/s

==========
Batch Size: 16
Prompt Length: 1024
Generated tokens: 256
Average decode latency: 1.1502 sec
Average prefill latency: 0.1826 sec
Average tokens/sec: 3070.87
Memory used: 14.09 GB
[rank0]:[E920 10:56:35.521011186 ProcessGroupNCCL.cpp:1076] [PG 0 (default_pg) Rank 0] Future for ProcessGroup abort timed out after 600000 ms
[rank1]:[E920 10:56:35.521031066 ProcessGroupNCCL.cpp:1076] [PG 0 (default_pg) Rank 1] Future for ProcessGroup abort timed out after 600000 ms
[rank2]:[E920 10:56:35.521048344 ProcessGroupNCCL.cpp:1076] [PG 0 (default_pg) Rank 2] Future for ProcessGroup abort timed out after 600000 ms
[rank3]:[E920 10:56:35.521074547 ProcessGroupNCCL.cpp:1076] [PG 0 (default_pg) Rank 3] Future for ProcessGroup abort timed out after 600000 ms
[rank2]:[E920 11:04:13.866817203 ProcessGroupNCCL.cpp:1375] [PG 0 (default_pg) Rank 2] First PG on this rank that detected no heartbeat of its watchdog.
[rank2]:[E920 11:04:13.866904516 ProcessGroupNCCL.cpp:1413] [PG 0 (default_pg) Rank 2] Heartbeat monitor timed out! Process will be terminated after dumping debug info. workMetaList_.size()=0
[rank1]:[E920 11:04:13.867697536 ProcessGroupNCCL.cpp:1375] [PG 0 (default_pg) Rank 1] First PG on this rank that detected no heartbeat of its watchdog.
[rank1]:[E920 11:04:13.867760823 ProcessGroupNCCL.cpp:1413] [PG 0 (default_pg) Rank 1] Heartbeat monitor timed out! Process will be terminated after dumping debug info. workMetaList_.size()=0
[rank3]:[E920 11:04:13.880148191 ProcessGroupNCCL.cpp:1375] [PG 0 (default_pg) Rank 3] First PG on this rank that detected no heartbeat of its watchdog.
[rank3]:[E920 11:04:13.880212525 ProcessGroupNCCL.cpp:1413] [PG 0 (default_pg) Rank 3] Heartbeat monitor timed out! Process will be terminated after dumping debug info. workMetaList_.size()=0
[rank0]:[E920 11:04:13.882701811 ProcessGroupNCCL.cpp:1375] [PG 0 (default_pg) Rank 0] First PG on this rank that detected no heartbeat of its watchdog.
[rank0]:[E920 11:04:13.882762211 ProcessGroupNCCL.cpp:1413] [PG 0 (default_pg) Rank 0] Heartbeat monitor timed out! Process will be terminated after dumping debug info. workMetaList_.size()=0
