W0925 09:47:53.486000 23445361944384 torch/distributed/run.py:779] 
W0925 09:47:53.486000 23445361944384 torch/distributed/run.py:779] *****************************************
W0925 09:47:53.486000 23445361944384 torch/distributed/run.py:779] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W0925 09:47:53.486000 23445361944384 torch/distributed/run.py:779] *****************************************
flash_kv_decode is set to False
Using device=cuda
Loading model ...
GPTEnsemble(
  (tok_embeddings): Embedding(128256, 4096)
  (layers): ModuleList(
    (0-31): 32 x EnsembleTransformerBlock(
      semi_compiled = False
      (attention): Attention(
        (wqkv): Linear(in_features=4096, out_features=1536, bias=False)
        (wo): Linear(in_features=1024, out_features=4096, bias=False)
      )
      (feed_forward): FeedForward(
        (w1): Linear(in_features=4096, out_features=7168, bias=False)
        (w2): Linear(in_features=3584, out_features=4096, bias=False)
      )
      (ffn_norm): RMSNorm()
      (attention_norm): RMSNorm()
    )
  )
  (norm): RMSNorm()
  (output): Linear(in_features=4096, out_features=128256, bias=False)
)
Time to load model: 0.90 seconds
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
Compiling prefill with dynamic=False
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
[rank3]:W0925 09:48:18.116000 22438853027648 torch/fx/experimental/symbolic_shapes.py:4449] [0/0] xindex is not in var_ranges, defaulting to unknown range.
[rank1]:W0925 09:48:18.121000 23431506765632 torch/fx/experimental/symbolic_shapes.py:4449] [0/0] xindex is not in var_ranges, defaulting to unknown range.
[rank0]:W0925 09:48:18.229000 22434686175040 torch/fx/experimental/symbolic_shapes.py:4449] [0/0] xindex is not in var_ranges, defaulting to unknown range.
[rank2]:W0925 09:48:18.310000 23050171369280 torch/fx/experimental/symbolic_shapes.py:4449] [0/0] xindex is not in var_ranges, defaulting to unknown range.
Prefill latency: 47.18689698446542 sec
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
[rank0]:W0925 09:49:07.070000 22434686175040 torch/fx/experimental/symbolic_shapes.py:4449] [1/0] xindex is not in var_ranges, defaulting to unknown range.
[rank1]:W0925 09:49:07.132000 23431506765632 torch/fx/experimental/symbolic_shapes.py:4449] [1/0] xindex is not in var_ranges, defaulting to unknown range.
[rank3]:W0925 09:49:14.205000 22438853027648 torch/fx/experimental/symbolic_shapes.py:4449] [1/0] xindex is not in var_ranges, defaulting to unknown range.
[rank2]:W0925 09:49:15.453000 23050171369280 torch/fx/experimental/symbolic_shapes.py:4449] [1/0] xindex is not in var_ranges, defaulting to unknown range.
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
Decode latency: 72.94992568716407 sec
Compilation time: 120.17 seconds
Compilation time: 120.18 seconds
Compilation time: 120.14 seconds
Compilation time: 120.14 seconds
Prefill latency: 0.8742707697674632 sec
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
Decode latency: 0.6804855186492205 sec
Prefill latency: 0.012772168964147568 sec
Decode latency: 0.6800963981077075 sec
Prefill latency: 0.013008072040975094 sec
Decode latency: 0.6799622317776084 sec
Prefill latency: 0.013078127056360245 sec
Decode latency: 0.6799526894465089 sec
Prefill latency: 0.013065807521343231 sec
Decode latency: 0.6799682751297951 sec
Time for inference 1: 0.69 sec total, 368.64 tokens/sec
Decode latency: 0.68 sec
Prefill latency: 0.01 sec
Bandwidth achieved: 1673.93 GB/s
FLOPS achieved: 8.37 TF/s

Prefill latency: 0.012864037416875362 sec
Decode latency: 0.6800001440569758 sec
Time for inference 2: 0.69 sec total, 368.89 tokens/sec
Decode latency: 0.68 sec
Prefill latency: 0.01 sec
Bandwidth achieved: 1675.08 GB/s
FLOPS achieved: 8.38 TF/s

Prefill latency: 0.012426028028130531 sec
Decode latency: 0.6798678999766707 sec
Time for inference 3: 0.69 sec total, 369.32 tokens/sec
Decode latency: 0.68 sec
Prefill latency: 0.01 sec
Bandwidth achieved: 1677.04 GB/s
FLOPS achieved: 8.39 TF/s

Prefill latency: 0.012269417755305767 sec
Decode latency: 0.6799920471385121 sec
Time for inference 4: 0.69 sec total, 369.38 tokens/sec
Decode latency: 0.68 sec
Prefill latency: 0.01 sec
Bandwidth achieved: 1677.31 GB/s
FLOPS achieved: 8.39 TF/s

Prefill latency: 0.012874923646450043 sec
Decode latency: 0.6800777669996023 sec
Time for inference 5: 0.69 sec total, 368.98 tokens/sec
Decode latency: 0.68 sec
Prefill latency: 0.01 sec
Bandwidth achieved: 1675.49 GB/s
FLOPS achieved: 8.38 TF/s

Prefill latency: 0.012866760604083538 sec
Decode latency: 0.6799915302544832 sec
Time for inference 6: 0.69 sec total, 369.05 tokens/sec
Decode latency: 0.68 sec
Prefill latency: 0.01 sec
Bandwidth achieved: 1675.80 GB/s
FLOPS achieved: 8.38 TF/s

Prefill latency: 0.01254016812890768 sec
Decode latency: 0.6799635477364063 sec
Time for inference 7: 0.69 sec total, 369.25 tokens/sec
Decode latency: 0.68 sec
Prefill latency: 0.01 sec
Bandwidth achieved: 1676.70 GB/s
FLOPS achieved: 8.38 TF/s

Prefill latency: 0.012863480485975742 sec
Decode latency: 0.6800435120239854 sec
Time for inference 8: 0.69 sec total, 368.99 tokens/sec
Decode latency: 0.68 sec
Prefill latency: 0.01 sec
Bandwidth achieved: 1675.53 GB/s
FLOPS achieved: 8.38 TF/s

Prefill latency: 0.01270788349211216 sec
Decode latency: 0.6794279329478741 sec
Time for inference 9: 0.69 sec total, 369.34 tokens/sec
Decode latency: 0.68 sec
Prefill latency: 0.01 sec
Bandwidth achieved: 1677.14 GB/s
FLOPS achieved: 8.39 TF/s

Prefill latency: 0.012437108904123306 sec
Decode latency: 0.6794329509139061 sec
Time for inference 10: 0.69 sec total, 369.55 tokens/sec
Decode latency: 0.68 sec
Prefill latency: 0.01 sec
Bandwidth achieved: 1678.10 GB/s
FLOPS achieved: 8.39 TF/s

==========
Batch Size: 1
Prompt Length: 1024
Generated tokens: 256
Average decode latency: 0.6799 sec
Average prefill latency: 0.0127 sec
Average tokens/sec: 369.14
Memory used: 6.56 GB
[rank1]:[E925 10:00:09.966688027 ProcessGroupNCCL.cpp:1076] [PG 0 (default_pg) Rank 1] Future for ProcessGroup abort timed out after 600000 ms
[rank0]:[E925 10:00:09.966812656 ProcessGroupNCCL.cpp:1076] [PG 0 (default_pg) Rank 0] Future for ProcessGroup abort timed out after 600000 ms
[rank3]:[E925 10:00:09.966934666 ProcessGroupNCCL.cpp:1076] [PG 0 (default_pg) Rank 3] Future for ProcessGroup abort timed out after 600000 ms
[rank2]:[E925 10:00:09.967355821 ProcessGroupNCCL.cpp:1076] [PG 0 (default_pg) Rank 2] Future for ProcessGroup abort timed out after 600000 ms
[rank1]:[E925 10:07:57.261968020 ProcessGroupNCCL.cpp:1375] [PG 0 (default_pg) Rank 1] First PG on this rank that detected no heartbeat of its watchdog.
[rank1]:[E925 10:07:57.262020185 ProcessGroupNCCL.cpp:1413] [PG 0 (default_pg) Rank 1] Heartbeat monitor timed out! Process will be terminated after dumping debug info. workMetaList_.size()=0
[rank2]:[E925 10:07:57.264131943 ProcessGroupNCCL.cpp:1375] [PG 0 (default_pg) Rank 2] First PG on this rank that detected no heartbeat of its watchdog.
[rank2]:[E925 10:07:57.264180281 ProcessGroupNCCL.cpp:1413] [PG 0 (default_pg) Rank 2] Heartbeat monitor timed out! Process will be terminated after dumping debug info. workMetaList_.size()=0
[rank0]:[E925 10:07:57.265103792 ProcessGroupNCCL.cpp:1375] [PG 0 (default_pg) Rank 0] First PG on this rank that detected no heartbeat of its watchdog.
[rank0]:[E925 10:07:57.265148524 ProcessGroupNCCL.cpp:1413] [PG 0 (default_pg) Rank 0] Heartbeat monitor timed out! Process will be terminated after dumping debug info. workMetaList_.size()=0
[rank3]:[E925 10:07:57.266958355 ProcessGroupNCCL.cpp:1375] [PG 0 (default_pg) Rank 3] First PG on this rank that detected no heartbeat of its watchdog.
[rank3]:[E925 10:07:57.267002779 ProcessGroupNCCL.cpp:1413] [PG 0 (default_pg) Rank 3] Heartbeat monitor timed out! Process will be terminated after dumping debug info. workMetaList_.size()=0
