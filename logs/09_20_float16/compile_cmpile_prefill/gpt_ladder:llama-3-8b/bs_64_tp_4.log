W0920 09:10:45.459000 23372607498048 torch/distributed/run.py:779] 
W0920 09:10:45.459000 23372607498048 torch/distributed/run.py:779] *****************************************
W0920 09:10:45.459000 23372607498048 torch/distributed/run.py:779] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W0920 09:10:45.459000 23372607498048 torch/distributed/run.py:779] *****************************************
flash_kv_decode is set to False
Using device=cuda
Loading model ...
GPTLadder(
  (tok_embeddings): Embedding(128256, 4096)
  (layers): ModuleList(
    (0-31): 32 x LadderTransformerBlock(
      semi_compiled = False
      (attention): Attention(
        (wqkv): Linear(in_features=4096, out_features=1536, bias=False)
        (wo): Linear(in_features=1024, out_features=4096, bias=False)
      )
      (feed_forward): FeedForward(
        (w1): Linear(in_features=4096, out_features=7168, bias=False)
        (w2): Linear(in_features=3584, out_features=4096, bias=False)
      )
      (ffn_norm): RMSNorm()
      (attention_norm): RMSNorm()
    )
  )
  (norm): RMSNorm()
  (output): Linear(in_features=4096, out_features=128256, bias=False)
)
Time to load model: 0.07 seconds
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
Compiling prefill with dynamic=False
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
[rank3]:W0920 09:11:16.877000 23378893793088 torch/fx/experimental/symbolic_shapes.py:4449] [0/0] xindex is not in var_ranges, defaulting to unknown range.
[rank0]:W0920 09:11:17.152000 23449638291264 torch/fx/experimental/symbolic_shapes.py:4449] [0/0] xindex is not in var_ranges, defaulting to unknown range.
[rank2]:W0920 09:11:17.288000 23039125370688 torch/fx/experimental/symbolic_shapes.py:4449] [0/0] xindex is not in var_ranges, defaulting to unknown range.
[rank1]:W0920 09:11:17.456000 23413202147136 torch/fx/experimental/symbolic_shapes.py:4449] [0/0] xindex is not in var_ranges, defaulting to unknown range.
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
Prefill latency: 57.325466934998985 sec
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
[rank1]:W0920 09:12:14.307000 23413202147136 torch/fx/experimental/symbolic_shapes.py:4449] [1/0] xindex is not in var_ranges, defaulting to unknown range.
[rank0]:W0920 09:12:14.334000 23449638291264 torch/fx/experimental/symbolic_shapes.py:4449] [1/0] xindex is not in var_ranges, defaulting to unknown range.
[rank3]:W0920 09:12:24.558000 23378893793088 torch/fx/experimental/symbolic_shapes.py:4449] [1/0] xindex is not in var_ranges, defaulting to unknown range.
[rank2]:W0920 09:12:25.426000 23039125370688 torch/fx/experimental/symbolic_shapes.py:4449] [1/0] xindex is not in var_ranges, defaulting to unknown range.
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
Decode latency: 81.18657764498494 sec
Compilation time: 138.56 seconds
Compilation time: 138.55 seconds
Compilation time: 138.56 seconds
Compilation time: 138.51 seconds
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
Prefill latency: 1.8468476030102465 sec
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
Decode latency: 1.9193507689924445 sec
Prefill latency: 0.7542440909892321 sec
Decode latency: 1.9203602289780974 sec
Prefill latency: 0.7537150639982428 sec
Decode latency: 1.9227409239974804 sec
Prefill latency: 0.75151166098658 sec
Decode latency: 1.9203343490080442 sec
Prefill latency: 0.7558713709877338 sec
Decode latency: 1.9184148219937924 sec
Time for inference 1: 2.68 sec total, 6124.04 tokens/sec
Decode latency: 1.92 sec
Prefill latency: 0.76 sec
Bandwidth achieved: 27808.47 GB/s
FLOPS achieved: 139.04 TF/s

Prefill latency: 0.7566593519877642 sec
Decode latency: 1.9189462990034372 sec
Time for inference 2: 2.68 sec total, 6121.15 tokens/sec
Decode latency: 1.92 sec
Prefill latency: 0.76 sec
Bandwidth achieved: 27795.32 GB/s
FLOPS achieved: 138.98 TF/s

Prefill latency: 0.7531768209883012 sec
Decode latency: 1.9216402820020448 sec
Time for inference 3: 2.68 sec total, 6122.98 tokens/sec
Decode latency: 1.92 sec
Prefill latency: 0.75 sec
Bandwidth achieved: 27803.64 GB/s
FLOPS achieved: 139.02 TF/s

Prefill latency: 0.7565497360192239 sec
Decode latency: 1.9200121680041775 sec
Time for inference 4: 2.68 sec total, 6117.82 tokens/sec
Decode latency: 1.92 sec
Prefill latency: 0.76 sec
Bandwidth achieved: 27780.19 GB/s
FLOPS achieved: 138.90 TF/s

Prefill latency: 0.7556635449873284 sec
Decode latency: 1.920122245006496 sec
Time for inference 5: 2.68 sec total, 6120.21 tokens/sec
Decode latency: 1.92 sec
Prefill latency: 0.76 sec
Bandwidth achieved: 27791.05 GB/s
FLOPS achieved: 138.96 TF/s

Prefill latency: 0.7548521120043006 sec
Decode latency: 1.917685070016887 sec
Time for inference 6: 2.67 sec total, 6127.90 tokens/sec
Decode latency: 1.92 sec
Prefill latency: 0.75 sec
Bandwidth achieved: 27825.96 GB/s
FLOPS achieved: 139.13 TF/s

Prefill latency: 0.7549392100190744 sec
Decode latency: 1.9217408319818787 sec
Time for inference 7: 2.68 sec total, 6118.52 tokens/sec
Decode latency: 1.92 sec
Prefill latency: 0.75 sec
Bandwidth achieved: 27783.37 GB/s
FLOPS achieved: 138.92 TF/s

Prefill latency: 0.7561549429956358 sec
Decode latency: 1.9205412679875735 sec
Time for inference 8: 2.68 sec total, 6118.45 tokens/sec
Decode latency: 1.92 sec
Prefill latency: 0.76 sec
Bandwidth achieved: 27783.06 GB/s
FLOPS achieved: 138.92 TF/s

Prefill latency: 0.7555479820002802 sec
Decode latency: 1.9193897540098988 sec
Time for inference 9: 2.68 sec total, 6122.51 tokens/sec
Decode latency: 1.92 sec
Prefill latency: 0.76 sec
Bandwidth achieved: 27801.51 GB/s
FLOPS achieved: 139.01 TF/s

Prefill latency: 0.7579991100064944 sec
Decode latency: 1.9174414470035117 sec
Time for inference 10: 2.68 sec total, 6121.22 tokens/sec
Decode latency: 1.92 sec
Prefill latency: 0.76 sec
Bandwidth achieved: 27795.62 GB/s
FLOPS achieved: 138.98 TF/s

==========
Batch Size: 64
Prompt Length: 1024
Generated tokens: 256
Average decode latency: 1.9196 sec
Average prefill latency: 0.7557 sec
Average tokens/sec: 6121.48
Memory used: 38.68 GB
