W0920 16:45:50.516000 23300121798464 torch/distributed/run.py:779] 
W0920 16:45:50.516000 23300121798464 torch/distributed/run.py:779] *****************************************
W0920 16:45:50.516000 23300121798464 torch/distributed/run.py:779] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W0920 16:45:50.516000 23300121798464 torch/distributed/run.py:779] *****************************************
flash_kv_decode is set to False
Using device=cuda
Loading model ...
GPTEnsemble(
  (tok_embeddings): Embedding(128256, 4096)
  (layers): ModuleList(
    (0-31): 32 x EnsembleTransformerBlock(
      semi_compiled = False
      (attention): Attention(
        (wqkv): Linear(in_features=4096, out_features=3072, bias=False)
        (wo): Linear(in_features=2048, out_features=4096, bias=False)
      )
      (feed_forward): FeedForward(
        (w1): Linear(in_features=4096, out_features=14336, bias=False)
        (w2): Linear(in_features=7168, out_features=4096, bias=False)
      )
      (ffn_norm): RMSNorm()
      (attention_norm): RMSNorm()
    )
  )
  (norm): RMSNorm()
  (output): Linear(in_features=4096, out_features=128256, bias=False)
)
Time to load model: 0.80 seconds
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
Compiling prefill with dynamic=False
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
[rank1]:W0920 16:46:16.926000 22763529504576 torch/fx/experimental/symbolic_shapes.py:4449] [0/0] xindex is not in var_ranges, defaulting to unknown range.
[rank0]:W0920 16:46:17.227000 22706582198080 torch/fx/experimental/symbolic_shapes.py:4449] [0/0] xindex is not in var_ranges, defaulting to unknown range.
Prefill latency: 25.386781856417656 sec
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
[rank0]:W0920 16:46:42.023000 22706582198080 torch/fx/experimental/symbolic_shapes.py:4449] [1/0] xindex is not in var_ranges, defaulting to unknown range.
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
Decode latency: 24.795700173825026 sec
Compilation time: 50.18 seconds
Prefill latency: 0.6848311722278595 sec
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
Decode latency: 1.3035529498010874 sec
Prefill latency: 0.13610130175948143 sec
Decode latency: 1.3038506284356117 sec
Prefill latency: 0.13616048730909824 sec
Decode latency: 1.3032035659998655 sec
Prefill latency: 0.13475812412798405 sec
Decode latency: 1.3028744589537382 sec
Prefill latency: 0.1358395256102085 sec
Decode latency: 1.3029483165591955 sec
Time for inference 1: 1.44 sec total, 1422.64 tokens/sec
Decode latency: 1.30 sec
Prefill latency: 0.14 sec
Bandwidth achieved: 11424.56 GB/s
FLOPS achieved: 57.12 TF/s

Prefill latency: 0.13561076298356056 sec
Decode latency: 1.3030400704592466 sec
Time for inference 2: 1.44 sec total, 1422.82 tokens/sec
Decode latency: 1.30 sec
Prefill latency: 0.14 sec
Bandwidth achieved: 11425.97 GB/s
FLOPS achieved: 57.13 TF/s

Prefill latency: 0.13520392775535583 sec
Decode latency: 1.3034572452306747 sec
Time for inference 3: 1.44 sec total, 1422.69 tokens/sec
Decode latency: 1.30 sec
Prefill latency: 0.14 sec
Bandwidth achieved: 11424.94 GB/s
FLOPS achieved: 57.12 TF/s

Prefill latency: 0.13464310951530933 sec
Decode latency: 1.303371623158455 sec
Time for inference 4: 1.44 sec total, 1422.83 tokens/sec
Decode latency: 1.30 sec
Prefill latency: 0.13 sec
Bandwidth achieved: 11426.09 GB/s
FLOPS achieved: 57.13 TF/s

Prefill latency: 0.13494913466274738 sec
[rank1]:W0920 16:47:01.122000 22763529504576 torch/fx/experimental/symbolic_shapes.py:4449] [1/0] xindex is not in var_ranges, defaulting to unknown range.
Decode latency: 1.3031800389289856 sec
Time for inference 5: 1.44 sec total, 1423.06 tokens/sec
Decode latency: 1.30 sec
Prefill latency: 0.13 sec
Bandwidth achieved: 11427.92 GB/s
FLOPS achieved: 57.14 TF/s

Prefill latency: 0.1348879411816597 sec
Decode latency: 1.3027102816849947 sec
Time for inference 6: 1.44 sec total, 1423.71 tokens/sec
Decode latency: 1.30 sec
Prefill latency: 0.13 sec
Bandwidth achieved: 11433.12 GB/s
FLOPS achieved: 57.17 TF/s

Prefill latency: 0.1365555953234434 sec
Decode latency: 1.3027257081121206 sec
Time for inference 7: 1.44 sec total, 1422.09 tokens/sec
Decode latency: 1.30 sec
Prefill latency: 0.14 sec
Bandwidth achieved: 11420.15 GB/s
FLOPS achieved: 57.10 TF/s

Prefill latency: 0.13697287999093533 sec
Decode latency: 1.3030826225876808 sec
Time for inference 8: 1.44 sec total, 1420.82 tokens/sec
Decode latency: 1.30 sec
Prefill latency: 0.14 sec
Bandwidth achieved: 11409.94 GB/s
FLOPS achieved: 57.05 TF/s

Prefill latency: 0.1357058361172676 sec
Decode latency: 1.3029521889984608 sec
Time for inference 9: 1.44 sec total, 1422.33 tokens/sec
Decode latency: 1.30 sec
Prefill latency: 0.14 sec
Bandwidth achieved: 11422.08 GB/s
FLOPS achieved: 57.11 TF/s

Prefill latency: 0.1372525952756405 sec
Decode latency: 1.3032654002308846 sec
Time for inference 10: 1.44 sec total, 1420.56 tokens/sec
Decode latency: 1.30 sec
Prefill latency: 0.14 sec
Bandwidth achieved: 11407.83 GB/s
FLOPS achieved: 57.04 TF/s

==========
Batch Size: 8
Prompt Length: 1024
Generated tokens: 256
Average decode latency: 1.3031 sec
Average prefill latency: 0.1358 sec
Average tokens/sec: 1422.35
Memory used: 14.43 GB
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
Compilation time: 80.98 seconds
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
