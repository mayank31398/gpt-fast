W1119 17:01:25.203000 3025163 site-packages/torch/distributed/run.py:793] 
W1119 17:01:25.203000 3025163 site-packages/torch/distributed/run.py:793] *****************************************
W1119 17:01:25.203000 3025163 site-packages/torch/distributed/run.py:793] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W1119 17:01:25.203000 3025163 site-packages/torch/distributed/run.py:793] *****************************************
rank: 1, global_rank: 1, world_size: 2, global_world_size: 2
rank: 0, global_rank: 0, world_size: 2, global_world_size: 2
rank: 0, global_rank: 0, world_size: 2, global_world_size: 2
rank: 0, global_rank: 0, world_size: 2, global_world_size: 2
rank: 0, global_rank: 0, world_size: 2, global_world_size: 2
rank: 0, global_rank: 0, world_size: 2, global_world_size: 2
flash_kv_decode is set to True
rank: 0, global_rank: 0, world_size: 2, global_world_size: 2
our world size=2
Using device=cuda
Loading model ...
rank: 1, global_rank: 1, world_size: 2, global_world_size: 2
rank: 1, global_rank: 1, world_size: 2, global_world_size: 2
rank: 1, global_rank: 1, world_size: 2, global_world_size: 2
rank: 1, global_rank: 1, world_size: 2, global_world_size: 2
rank: 1, global_rank: 1, world_size: 2, global_world_size: 2
GPTEnsemble(
  (tok_embeddings): Embedding(128256, 8192)
  (layers): ModuleList(
    (0-79): 80 x EnsembleTransformerBlock(
      semi_compiled = False
      (attention): Attention(
        (wqkv): Linear(in_features=8192, out_features=5120, bias=False)
        (wo): Linear(in_features=4096, out_features=8192, bias=False)
      )
      (feed_forward): FeedForward(
        (w1): Linear(in_features=8192, out_features=28672, bias=False)
        (w2): Linear(in_features=14336, out_features=8192, bias=False)
      )
      (ffn_norm): RMSNorm()
      (attention_norm): RMSNorm()
    )
  )
  (norm): RMSNorm()
  (output): Linear(in_features=8192, out_features=128256, bias=False)
)
Time to load model: 1.21 seconds
CUDA_GRAPH are activate
Prefill latency: 2.263543425826356 sec
Compilation time: 3.31 seconds
Decode latency: 1.0497934410814196 sec
Compilation time: 3.31 seconds
Prefill latency: 2.264631255995482 sec
Decode latency: 1.0487319650128484 sec
Prefill latency: 2.264182497980073 sec
Decode latency: 1.0491466000676155 sec
Prefill latency: 2.264759120065719 sec
Decode latency: 1.0493032559752464 sec
Prefill latency: 2.263319591060281 sec
Decode latency: 1.0484744650311768 sec
Prefill latency: 2.2688175479415804 sec
Decode latency: 1.0482173869386315 sec
Time for inference 1: 3.32 sec total, 154.33 tokens/sec
Decode latency: 1.05 sec
Prefill latency: 2.27 sec
Bandwidth achieved: 10888.73 GB/s
FLOPS achieved: 359.33 TF/s

Prefill latency: 2.26022472884506 sec
Decode latency: 1.0486420870292932 sec
Time for inference 2: 3.31 sec total, 154.71 tokens/sec
Decode latency: 1.05 sec
Prefill latency: 2.26 sec
Bandwidth achieved: 10915.57 GB/s
FLOPS achieved: 360.21 TF/s

Prefill latency: 2.2641651248559356 sec
Decode latency: 1.0478219620417804 sec
Time for inference 3: 3.31 sec total, 154.57 tokens/sec
Decode latency: 1.05 sec
Prefill latency: 2.26 sec
Bandwidth achieved: 10905.38 GB/s
FLOPS achieved: 359.88 TF/s

Prefill latency: 2.2628622110933065 sec
Decode latency: 1.0486723550129682 sec
Time for inference 4: 3.31 sec total, 154.58 tokens/sec
Decode latency: 1.05 sec
Prefill latency: 2.26 sec
Bandwidth achieved: 10906.75 GB/s
FLOPS achieved: 359.92 TF/s

Prefill latency: 2.263405857840553 sec
Decode latency: 1.0419642028864473 sec
Time for inference 5: 3.31 sec total, 154.87 tokens/sec
Decode latency: 1.04 sec
Prefill latency: 2.26 sec
Bandwidth achieved: 10927.09 GB/s
FLOPS achieved: 360.59 TF/s

Prefill latency: 2.267162607051432 sec
Decode latency: 1.0489041570108384 sec
Time for inference 6: 3.32 sec total, 154.38 tokens/sec
Decode latency: 1.05 sec
Prefill latency: 2.27 sec
Bandwidth achieved: 10891.96 GB/s
FLOPS achieved: 359.43 TF/s

Prefill latency: 2.2623378951102495 sec
Decode latency: 1.0495133211370558 sec
Time for inference 7: 3.31 sec total, 154.57 tokens/sec
Decode latency: 1.05 sec
Prefill latency: 2.26 sec
Bandwidth achieved: 10905.87 GB/s
FLOPS achieved: 359.89 TF/s

Prefill latency: 2.264379807980731 sec
Decode latency: 1.047908344073221 sec
Time for inference 8: 3.31 sec total, 154.55 tokens/sec
Decode latency: 1.05 sec
Prefill latency: 2.26 sec
Bandwidth achieved: 10904.28 GB/s
FLOPS achieved: 359.84 TF/s

Prefill latency: 2.2685854551382363 sec
Decode latency: 1.048873248975724 sec
Time for inference 9: 3.32 sec total, 154.31 tokens/sec
Decode latency: 1.05 sec
Prefill latency: 2.27 sec
Bandwidth achieved: 10887.41 GB/s
FLOPS achieved: 359.28 TF/s

Prefill latency: 2.266226687002927 sec
[rank1]:[W1119 17:02:27.382702373 ProcessGroupNCCL.cpp:4393] [PG ID 0 PG GUID 0 Rank 1]  using GPU 1 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.
Decode latency: 1.04869146598503 sec
Time for inference 10: 3.32 sec total, 154.43 tokens/sec
Decode latency: 1.05 sec
Prefill latency: 2.27 sec
Bandwidth achieved: 10895.77 GB/s
FLOPS achieved: 359.56 TF/s

==========
Batch Size: 16
Prompt Length: 1024
Generated tokens: 32
Average decode latency: 1.0479 sec
Average prefill latency: 2.2648 sec
Average tokens/sec: 154.53
Memory used: 83.71 GB
[rank0]:[W1119 17:02:27.474153914 ProcessGroupNCCL.cpp:4393] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.
Done. we are killing the process
[rank0]:[W1119 17:02:29.764958155 ProcessGroupNCCL.cpp:1374] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
