W1119 17:00:20.794000 3023542 site-packages/torch/distributed/run.py:793] 
W1119 17:00:20.794000 3023542 site-packages/torch/distributed/run.py:793] *****************************************
W1119 17:00:20.794000 3023542 site-packages/torch/distributed/run.py:793] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W1119 17:00:20.794000 3023542 site-packages/torch/distributed/run.py:793] *****************************************
rank: 2, global_rank: 2, world_size: 4, global_world_size: 4rank: 3, global_rank: 3, world_size: 4, global_world_size: 4

rank: 0, global_rank: 0, world_size: 4, global_world_size: 4
rank: 1, global_rank: 1, world_size: 4, global_world_size: 4
rank: 0, global_rank: 0, world_size: 4, global_world_size: 4
rank: 0, global_rank: 0, world_size: 4, global_world_size: 4
rank: 0, global_rank: 0, world_size: 4, global_world_size: 4
rank: 0, global_rank: 0, world_size: 4, global_world_size: 4
flash_kv_decode is set to True
rank: 0, global_rank: 0, world_size: 4, global_world_size: 4
our world size=4
Using device=cuda
Loading model ...
rank: 2, global_rank: 2, world_size: 4, global_world_size: 4
rank: 2, global_rank: 2, world_size: 4, global_world_size: 4
rank: 2, global_rank: 2, world_size: 4, global_world_size: 4
rank: 2, global_rank: 2, world_size: 4, global_world_size: 4
rank: 2, global_rank: 2, world_size: 4, global_world_size: 4
rank: 3, global_rank: 3, world_size: 4, global_world_size: 4
rank: 3, global_rank: 3, world_size: 4, global_world_size: 4
rank: 3, global_rank: 3, world_size: 4, global_world_size: 4
rank: 3, global_rank: 3, world_size: 4, global_world_size: 4
rank: 1, global_rank: 1, world_size: 4, global_world_size: 4
rank: 3, global_rank: 3, world_size: 4, global_world_size: 4
rank: 1, global_rank: 1, world_size: 4, global_world_size: 4
rank: 1, global_rank: 1, world_size: 4, global_world_size: 4
rank: 1, global_rank: 1, world_size: 4, global_world_size: 4
rank: 1, global_rank: 1, world_size: 4, global_world_size: 4
GPTEnsemble(
  (tok_embeddings): Embedding(128256, 8192)
  (layers): ModuleList(
    (0-79): 80 x EnsembleTransformerBlock(
      semi_compiled = False
      (attention): Attention(
        (wqkv): Linear(in_features=8192, out_features=2560, bias=False)
        (wo): Linear(in_features=2048, out_features=8192, bias=False)
      )
      (feed_forward): FeedForward(
        (w1): Linear(in_features=8192, out_features=14336, bias=False)
        (w2): Linear(in_features=7168, out_features=8192, bias=False)
      )
      (ffn_norm): RMSNorm()
      (attention_norm): RMSNorm()
    )
  )
  (norm): RMSNorm()
  (output): Linear(in_features=8192, out_features=128256, bias=False)
)
Time to load model: 1.24 seconds
CUDA_GRAPH are activate
Prefill latency: 0.29494373919442296 sec
Decode latency: 0.6632280370686203 sec
Compilation time: 0.96 seconds
Compilation time: 0.96 seconds
Compilation time: 0.95 seconds
Prefill latency: 0.2959947190247476 sec
Compilation time: 0.95 seconds
Decode latency: 0.6632555420510471 sec
Prefill latency: 0.2935694439802319 sec
Decode latency: 0.6633006460033357 sec
Prefill latency: 0.2944604600779712 sec
Decode latency: 0.6633365829475224 sec
Prefill latency: 0.295810345094651 sec
Decode latency: 0.6628604808356613 sec
Prefill latency: 0.2923583700321615 sec
Decode latency: 0.663783275987953 sec
Time for inference 1: 0.96 sec total, 133.80 tokens/sec
Decode latency: 0.66 sec
Prefill latency: 0.29 sec
Bandwidth achieved: 4861.07 GB/s
FLOPS achieved: 160.42 TF/s

Prefill latency: 0.2947737770155072 sec
Decode latency: 0.6632061700802296 sec
Time for inference 2: 0.96 sec total, 133.55 tokens/sec
Decode latency: 0.66 sec
Prefill latency: 0.29 sec
Bandwidth achieved: 4851.80 GB/s
FLOPS achieved: 160.11 TF/s

Prefill latency: 0.29321765690110624 sec
Decode latency: 0.6383838609326631 sec
Time for inference 3: 0.93 sec total, 137.31 tokens/sec
Decode latency: 0.64 sec
Prefill latency: 0.29 sec
Bandwidth achieved: 4988.47 GB/s
FLOPS achieved: 164.62 TF/s

Prefill latency: 0.2936498129274696 sec
Decode latency: 0.6624954920262098 sec
Time for inference 4: 0.96 sec total, 133.77 tokens/sec
Decode latency: 0.66 sec
Prefill latency: 0.29 sec
Bandwidth achieved: 4859.94 GB/s
FLOPS achieved: 160.38 TF/s

Prefill latency: 0.2945854088757187 sec
Decode latency: 0.6632320370990783 sec
Time for inference 5: 0.96 sec total, 133.56 tokens/sec
Decode latency: 0.66 sec
Prefill latency: 0.29 sec
Bandwidth achieved: 4852.17 GB/s
FLOPS achieved: 160.12 TF/s

Prefill latency: 0.2957090169657022 sec
Decode latency: 0.6620753009337932 sec
Time for inference 6: 0.96 sec total, 133.57 tokens/sec
Decode latency: 0.66 sec
Prefill latency: 0.30 sec
Bandwidth achieved: 4852.66 GB/s
FLOPS achieved: 160.14 TF/s

Prefill latency: 0.2948326088953763 sec
Decode latency: 0.6628504109103233 sec
Time for inference 7: 0.96 sec total, 133.59 tokens/sec
Decode latency: 0.66 sec
Prefill latency: 0.29 sec
Bandwidth achieved: 4853.36 GB/s
FLOPS achieved: 160.16 TF/s

Prefill latency: 0.29433816694654524 sec
Decode latency: 0.6631377718877047 sec
Time for inference 8: 0.96 sec total, 133.62 tokens/sec
Decode latency: 0.66 sec
Prefill latency: 0.29 sec
Bandwidth achieved: 4854.45 GB/s
FLOPS achieved: 160.20 TF/s

Prefill latency: 0.2939760920125991 sec
Decode latency: 0.6631374061107635 sec
Time for inference 9: 0.96 sec total, 133.67 tokens/sec
Decode latency: 0.66 sec
Prefill latency: 0.29 sec
Bandwidth achieved: 4856.24 GB/s
FLOPS achieved: 160.26 TF/s

Prefill latency: 0.2946577938273549 sec
Decode latency: 0.6621523569338024 sec
Time for inference 10: 0.96 sec total, 133.71 tokens/sec
Decode latency: 0.66 sec
Prefill latency: 0.29 sec
Bandwidth achieved: 4857.77 GB/s
FLOPS achieved: 160.31 TF/s

==========
Batch Size: 4
Prompt Length: 1024
Generated tokens: 32
Average decode latency: 0.6604 sec
Average prefill latency: 0.2942 sec
Average tokens/sec: 134.02
Memory used: 40.64 GB
[rank0]:[W1119 17:00:43.634523903 ProcessGroupNCCL.cpp:4393] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.
[rank3]:[W1119 17:00:43.697069524 ProcessGroupNCCL.cpp:4393] [PG ID 0 PG GUID 0 Rank 3]  using GPU 3 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.
[rank1]:[W1119 17:00:43.803046076 ProcessGroupNCCL.cpp:4393] [PG ID 0 PG GUID 0 Rank 1]  using GPU 1 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.
[rank2]:[W1119 17:00:43.825933130 ProcessGroupNCCL.cpp:4393] [PG ID 0 PG GUID 0 Rank 2]  using GPU 2 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.
Done. we are killing the process
[rank0]:[W1119 17:00:45.218448573 ProcessGroupNCCL.cpp:1374] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
