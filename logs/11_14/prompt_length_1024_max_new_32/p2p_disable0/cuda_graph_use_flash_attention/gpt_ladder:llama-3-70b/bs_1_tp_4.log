W1119 16:27:28.194000 2998178 site-packages/torch/distributed/run.py:793] 
W1119 16:27:28.194000 2998178 site-packages/torch/distributed/run.py:793] *****************************************
W1119 16:27:28.194000 2998178 site-packages/torch/distributed/run.py:793] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W1119 16:27:28.194000 2998178 site-packages/torch/distributed/run.py:793] *****************************************
rank: 1, global_rank: 1, world_size: 4, global_world_size: 4rank: 3, global_rank: 3, world_size: 4, global_world_size: 4

rank: 0, global_rank: 0, world_size: 4, global_world_size: 4
rank: 2, global_rank: 2, world_size: 4, global_world_size: 4
rank: 0, global_rank: 0, world_size: 4, global_world_size: 4
rank: 0, global_rank: 0, world_size: 4, global_world_size: 4
rank: 0, global_rank: 0, world_size: 4, global_world_size: 4
rank: 0, global_rank: 0, world_size: 4, global_world_size: 4
flash_kv_decode is set to True
rank: 0, global_rank: 0, world_size: 4, global_world_size: 4
our world size=4
Using device=cuda
Loading model ...
rank: 1, global_rank: 1, world_size: 4, global_world_size: 4
rank: 1, global_rank: 1, world_size: 4, global_world_size: 4
rank: 1, global_rank: 1, world_size: 4, global_world_size: 4
rank: 1, global_rank: 1, world_size: 4, global_world_size: 4
rank: 1, global_rank: 1, world_size: 4, global_world_size: 4
rank: 3, global_rank: 3, world_size: 4, global_world_size: 4
rank: 3, global_rank: 3, world_size: 4, global_world_size: 4
rank: 3, global_rank: 3, world_size: 4, global_world_size: 4
rank: 3, global_rank: 3, world_size: 4, global_world_size: 4
rank: 3, global_rank: 3, world_size: 4, global_world_size: 4
rank: 2, global_rank: 2, world_size: 4, global_world_size: 4
rank: 2, global_rank: 2, world_size: 4, global_world_size: 4
rank: 2, global_rank: 2, world_size: 4, global_world_size: 4
rank: 2, global_rank: 2, world_size: 4, global_world_size: 4
rank: 2, global_rank: 2, world_size: 4, global_world_size: 4
GPTLadder(
  (tok_embeddings): Embedding(128256, 8192)
  (layers): ModuleList(
    (0-79): 80 x LadderTransformerBlock(
      semi_compiled = False
      (attention): Attention(
        (wqkv): Linear(in_features=8192, out_features=2560, bias=False)
        (wo): Linear(in_features=2048, out_features=8192, bias=False)
      )
      (feed_forward): FeedForward(
        (w1): Linear(in_features=8192, out_features=14336, bias=False)
        (w2): Linear(in_features=7168, out_features=8192, bias=False)
      )
      (ffn_norm): RMSNorm()
      (attention_norm): RMSNorm()
    )
  )
  (norm): RMSNorm()
  (output): Linear(in_features=8192, out_features=128256, bias=False)
)
Time to load model: 0.35 seconds
CUDA_GRAPH are activate
Prefill latency: 0.09750413685105741 sec
Decode latency: 0.6441979701630771 sec
Compilation time: 0.75 seconds
Compilation time: 0.78 seconds
Compilation time: 0.78 seconds
Compilation time: 0.74 seconds
Prefill latency: 0.09638055483810604 sec
Decode latency: 0.6442279149778187 sec
Prefill latency: 0.09644463588483632 sec
Decode latency: 0.6444570031017065 sec
Prefill latency: 0.09655293799005449 sec
Decode latency: 0.6442134801764041 sec
Prefill latency: 0.0966635390650481 sec
Decode latency: 0.6444175669457763 sec
Prefill latency: 0.09638612205162644 sec
Decode latency: 0.6441568869631737 sec
Time for inference 1: 0.74 sec total, 43.18 tokens/sec
Decode latency: 0.64 sec
Prefill latency: 0.10 sec
Bandwidth achieved: 1568.58 GB/s
FLOPS achieved: 51.76 TF/s

Prefill latency: 0.09659440000541508 sec
Decode latency: 0.6441325470805168 sec
Time for inference 2: 0.74 sec total, 43.17 tokens/sec
Decode latency: 0.64 sec
Prefill latency: 0.10 sec
Bandwidth achieved: 1568.19 GB/s
FLOPS achieved: 51.75 TF/s

Prefill latency: 0.09664834709838033 sec
Decode latency: 0.6441240860149264 sec
Time for inference 3: 0.74 sec total, 43.16 tokens/sec
Decode latency: 0.64 sec
Prefill latency: 0.10 sec
Bandwidth achieved: 1568.11 GB/s
FLOPS achieved: 51.75 TF/s

Prefill latency: 0.09655818110331893 sec
Decode latency: 0.6441614220384508 sec
Time for inference 4: 0.74 sec total, 43.16 tokens/sec
Decode latency: 0.64 sec
Prefill latency: 0.10 sec
Bandwidth achieved: 1567.98 GB/s
FLOPS achieved: 51.74 TF/s

Prefill latency: 0.09632219700142741 sec
Decode latency: 0.6440416560508311 sec
Time for inference 5: 0.74 sec total, 43.18 tokens/sec
Decode latency: 0.64 sec
Prefill latency: 0.10 sec
Bandwidth achieved: 1568.88 GB/s
FLOPS achieved: 51.77 TF/s

Prefill latency: 0.096392777049914 sec
Decode latency: 0.6441323941107839 sec
Time for inference 6: 0.74 sec total, 43.18 tokens/sec
Decode latency: 0.64 sec
Prefill latency: 0.10 sec
Bandwidth achieved: 1568.63 GB/s
FLOPS achieved: 51.76 TF/s

Prefill latency: 0.09659300302155316 sec
Decode latency: 0.6440012769307941 sec
Time for inference 7: 0.74 sec total, 43.18 tokens/sec
Decode latency: 0.64 sec
Prefill latency: 0.10 sec
Bandwidth achieved: 1568.58 GB/s
FLOPS achieved: 51.76 TF/s

Prefill latency: 0.09642614098265767 sec
Decode latency: 0.6438747858628631 sec
Time for inference 8: 0.74 sec total, 43.19 tokens/sec
Decode latency: 0.64 sec
Prefill latency: 0.10 sec
Bandwidth achieved: 1569.17 GB/s
FLOPS achieved: 51.78 TF/s

Prefill latency: 0.09664447605609894 sec
Decode latency: 0.6442120191641152 sec
Time for inference 9: 0.74 sec total, 43.16 tokens/sec
Decode latency: 0.64 sec
Prefill latency: 0.10 sec
Bandwidth achieved: 1567.94 GB/s
FLOPS achieved: 51.74 TF/s

Prefill latency: 0.096448885044083 sec
Decode latency: 0.6440371938515455 sec
Time for inference 10: 0.74 sec total, 43.17 tokens/sec
Decode latency: 0.64 sec
Prefill latency: 0.10 sec
Bandwidth achieved: 1568.47 GB/s
FLOPS achieved: 51.76 TF/s

==========
Batch Size: 1
Prompt Length: 1024
Generated tokens: 32
Average decode latency: 0.6441 sec
Average prefill latency: 0.0965 sec
Average tokens/sec: 43.17
Memory used: 42.72 GB
Done. we are killing the process
[rank0]:[W1119 16:27:48.410801682 ProcessGroupNCCL.cpp:1374] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
