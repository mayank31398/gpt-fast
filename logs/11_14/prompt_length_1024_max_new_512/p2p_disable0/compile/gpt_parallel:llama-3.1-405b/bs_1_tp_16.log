W1118 22:18:41.509000 2759528 site-packages/torch/distributed/run.py:793] 
W1118 22:18:41.509000 2759528 site-packages/torch/distributed/run.py:793] *****************************************
W1118 22:18:41.509000 2759528 site-packages/torch/distributed/run.py:793] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W1118 22:18:41.509000 2759528 site-packages/torch/distributed/run.py:793] *****************************************
rank: 7, global_rank: 7, world_size: 8, global_world_size: 16
rank: 5, global_rank: 5, world_size: 8, global_world_size: 16
rank: 4, global_rank: 4, world_size: 8, global_world_size: 16
rank: 0, global_rank: 0, world_size: 8, global_world_size: 16
rank: 6, global_rank: 6, world_size: 8, global_world_size: 16
rank: 3, global_rank: 3, world_size: 8, global_world_size: 16
rank: 2, global_rank: 2, world_size: 8, global_world_size: 16
rank: 1, global_rank: 1, world_size: 8, global_world_size: 16
rank: 0, global_rank: 0, world_size: 8, global_world_size: 16
rank: 0, global_rank: 0, world_size: 8, global_world_size: 16
rank: 0, global_rank: 0, world_size: 8, global_world_size: 16
rank: 0, global_rank: 0, world_size: 8, global_world_size: 16
flash_kv_decode is set to False
rank: 0, global_rank: 0, world_size: 8, global_world_size: 16
our world size=16
Using device=cuda
Loading model ...
rank: 4, global_rank: 4, world_size: 8, global_world_size: 16
rank: 4, global_rank: 4, world_size: 8, global_world_size: 16
rank: 4, global_rank: 4, world_size: 8, global_world_size: 16
rank: 4, global_rank: 4, world_size: 8, global_world_size: 16
rank: 3, global_rank: 3, world_size: 8, global_world_size: 16
rank: 4, global_rank: 4, world_size: 8, global_world_size: 16
rank: 5, global_rank: 5, world_size: 8, global_world_size: 16rank: 3, global_rank: 3, world_size: 8, global_world_size: 16

rank: 5, global_rank: 5, world_size: 8, global_world_size: 16
rank: 6, global_rank: 6, world_size: 8, global_world_size: 16
rank: 3, global_rank: 3, world_size: 8, global_world_size: 16
rank: 5, global_rank: 5, world_size: 8, global_world_size: 16
rank: 6, global_rank: 6, world_size: 8, global_world_size: 16
rank: 6, global_rank: 6, world_size: 8, global_world_size: 16
rank: 5, global_rank: 5, world_size: 8, global_world_size: 16
rank: 3, global_rank: 3, world_size: 8, global_world_size: 16
rank: 6, global_rank: 6, world_size: 8, global_world_size: 16
rank: 5, global_rank: 5, world_size: 8, global_world_size: 16
rank: 3, global_rank: 3, world_size: 8, global_world_size: 16
rank: 6, global_rank: 6, world_size: 8, global_world_size: 16
rank: 2, global_rank: 2, world_size: 8, global_world_size: 16
rank: 2, global_rank: 2, world_size: 8, global_world_size: 16
rank: 2, global_rank: 2, world_size: 8, global_world_size: 16
rank: 7, global_rank: 7, world_size: 8, global_world_size: 16
rank: 2, global_rank: 2, world_size: 8, global_world_size: 16
rank: 7, global_rank: 7, world_size: 8, global_world_size: 16
rank: 2, global_rank: 2, world_size: 8, global_world_size: 16
rank: 7, global_rank: 7, world_size: 8, global_world_size: 16
rank: 1, global_rank: 1, world_size: 8, global_world_size: 16
rank: 7, global_rank: 7, world_size: 8, global_world_size: 16
rank: 1, global_rank: 1, world_size: 8, global_world_size: 16
rank: 1, global_rank: 1, world_size: 8, global_world_size: 16
rank: 7, global_rank: 7, world_size: 8, global_world_size: 16
rank: 1, global_rank: 1, world_size: 8, global_world_size: 16
rank: 1, global_rank: 1, world_size: 8, global_world_size: 16
GPTParallel(
  (tok_embeddings): Embedding(128256, 16384)
  (layers): ModuleList(
    (0-125): 126 x ParallelTransformerBlock(
      semi_compiled = False
      (attention): FuseAttentionMLP(
        (wqkv1): Linear(in_features=16384, out_features=7936, bias=False)
        (wo): Linear(in_features=1024, out_features=16384, bias=False)
        (w2): Linear(in_features=3328, out_features=16384, bias=False)
      )
      (attention_norm): RMSr will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWar/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new contex/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
Compilation time: 135.71 secondsCompilation time: 135.72 seconds
Compilation time: 135.81 seconds

Compilation time: 135.70 seconds
Compilation time: 135.90 seconds
Compilation time: 135.71 seconds
Compilation time: 136.05 seconds
Compilation time: 135.74 seconds
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
[rank8]:[W1118 22:24:29.194150715 ProcessGroupNCCL.cpp:1374] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
                                                                                                                                                                                                                                                             Decode latency: 14.355027782032266 sec
Prefill latency: 0.18408532394096255 sec
Decode latency: 14.321940527996048 sec
Prefill latency: 0.18365561915561557 sec
Decode latency: 14.313938501058146 sec
Prefill latency: 0.18496001907624304 sec
Decode latency: 14.353359507163987 sec
Prefill latency: 0.1838352440390736 sec
Decode latency: 14.36994404788129 sec
Time for inference 1: 14.56 sec total, 35.17 tokens/sec
Decode latency: 14.37 sec
Prefill latency: 0.18 sec
Bandwidth achieved: 1932.50 GB/s
FLOPS achieved: 5.80 TF/s

Prefill latency: 0.1839791100937873 sec
Decode latency: 14.355432830983773 sec
Time for inference 2: 14.54 sec total, 35.21 tokens/sec
Decode latency: 14.36 sec
Prefill latency: 0.18 sec
Bandwidth achieved: 1934.40 GB/s
FLOPS achieved: 5.80 TF/s

Prefill latency: 0.18435079185292125 sec
Decode latency: 14.348411015002057 sec
Time for inference 3: 14.54 sec total, 35.22 tokens/sec
Decode latency: 14.35 sec
Prefill latency: 0.18 sec
Bandwidth achieved: 1935.28 GB/s
FLOPS achieved: 5.81 TF/s

Prefill latency: 0.18333482090383768 sec
Decode latency: 14.37802281905897 sec
Time for inference 4: 14.56 sec total, 35.16 tokens/sec
Decode latency: 14.38 sec
Prefill latency: 0.18 sec
Bandwidth achieved: 1931.47 GB/s
FLOPS achieved: 5.79 TF/s

Prefill latency: 0.1840889318846166 sec
Decode latency: 14.341018918901682 sec
Time for inference 5: 14.53 sec total, 35.24 tokens/sec
Decode latency: 14.34 sec
Prefill latency: 0.18 sec
Bandwidth achieved: 1936.30 GB/s
FLOPS achieved: 5.81 TF/s

Prefill latency: 0.18376916809938848 sec
Decode latency: 14.345988507149741 sec
Time for inference 6: 14.53 sec total, 35.23 tokens/sec
Decode latency: 14.35 sec
Prefill latency: 0.18 sec
Bandwidth achieved: 1935.69 GB/s
FLOPS achieved: 5.81 TF/s

Prefill latency: 0.18561015790328383 sec
Decode latency: 14.339693959103897 sec
Time for inference 7: 14.53 sec total, 35.24 tokens/sec
Decode latency: 14.34 sec
Prefill latency: 0.19 sec
Bandwidth achieved: 1936.27 GB/s
FLOPS achieved: 5.81 TF/s

Prefill latency: 0.18360313610173762 sec
Decode latency: 14.32252415199764 sec
Time for inference 8: 14.51 sec total, 35.29 tokens/sec
Decode latency: 14.32 sec
Prefill latency: 0.18 sec
Bandwidth achieved: 1938.65 GB/s
FLOPS achieved: 5.82 TF/s

Prefill latency: 0.1832940331660211 sec
Decode latency: 14.355959662934765 sec
Time for inference 9: 14.54 sec total, 35.21 tokens/sec
Decode latency: 14.36 sec
Prefill latency: 0.18 sec
Bandwidth achieved: 1934.40 GB/s
FLOPS achieved: 5.80 TF/s

Prefill latency: 0.18425218085758388 sec
Decode latency: 14.362789693055674 sec
Time for inference 10: 14.55 sec total, 35.19 tokens/sec
Decode latency: 14.36 sec
Prefill latency: 0.18 sec
Bandwidth achieved: 1933.37 GB/s
FLOPS achieved: 5.80 TF/s

==========
Batch Size: 1
Prompt Length: 1024
Generated tokens: 512
Average decode latency: 14.3520 sec
Average prefill latency: 0.1840 sec
Average tokens/sec: 35.22
Memory used: 60.53 GB
Done. we are killing the process
[rank0]:[W1118 22:24:28.521055779 ProcessGroupNCCL.cpp:1374] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
