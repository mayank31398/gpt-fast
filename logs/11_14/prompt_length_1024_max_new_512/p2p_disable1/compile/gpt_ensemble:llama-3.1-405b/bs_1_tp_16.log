W1118 16:09:09.409000 2859803 site-packages/torch/distributed/run.py:793] 
W1118 16:09:09.409000 2859803 site-packages/torch/distributed/run.py:793] *****************************************
W1118 16:09:09.409000 2859803 site-packages/torch/distributed/run.py:793] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W1118 16:09:09.409000 2859803 site-packages/torch/distributed/run.py:793] *****************************************
rank: 1, global_rank: 9, world_size: 8, global_world_size: 16
rank: 4, global_rank: 12, world_size: 8, global_world_size: 16
rank: 3, global_rank: 11, world_size: 8, global_world_size: 16
rank: 2, global_rank: 10, world_size: 8, global_world_size: 16
rank: 5, global_rank: 13, world_size: 8, global_world_size: 16
rank: 7, global_rank: 15, world_size: 8, global_world_size: 16
rank: 6, global_rank: 14, world_size: 8, global_world_size: 16
rank: 0, global_rank: 8, world_size: 8, global_world_size: 16
rank: 0, global_rank: 8, world_size: 8, global_world_size: 16
rank: 0, global_rank: 8, world_size: 8, global_world_size: 16
rank: 0, global_rank: 8, world_size: 8, global_world_size: 16
rank: 0, global_rank: 8, world_size: 8, global_world_size: 16
rank: 0, global_rank: 8, world_size: 8, global_world_size: 16
rank: 1, global_rank: 9, world_size: 8, global_world_size: 16
rank: 1, global_rank: 9, world_size: 8, global_world_size: 16
rank: 1, global_rank: 9, world_size: 8, global_world_size: 16
rank: 1, global_rank: 9, world_size: 8, global_world_size: 16
rank: 1, global_rank: 9, world_size: 8, global_world_size: 16
rank: 3, global_rank: 11, world_size: 8, global_world_size: 16
rank: 3, global_rank: 11, world_size: 8, global_world_size: 16
rank: 3, global_rank: 11, world_size: 8, global_world_size: 16
rank: 3, global_rank: 11, world_size: 8, global_world_size: 16
rank: 3, global_rank: 11, world_size: 8, global_world_size: 16
rank: 6, global_rank: 14, world_size: 8, global_world_size: 16
rank: 6, global_rank: 14, world_size: 8, global_world_size: 16
rank: 5, global_rank: 13, world_size: 8, global_world_size: 16
rank: 2, global_rank: 10, world_size: 8, global_world_size: 16
rank: 6, global_rank: 14, world_size: 8, global_world_size: 16
rank: 5, global_rank: 13, world_size: 8, global_world_size: 16
rank: 2, global_rank: 10, world_size: 8, global_world_size: 16
rank: 7, global_rank: 15, world_size: 8, global_world_size: 16
rank: 5, global_rank: 13, world_size: 8, global_world_size: 16
rank: 6, global_rank: 14, world_size: 8, global_world_size: 16
rank: 2, global_rank: 10, world_size: 8, global_world_size: 16
rank: 7, global_rank: 15, world_size: 8, global_world_size: 16
rank: 5, global_rank: 13, world_size: 8, global_world_size: 16
rank: 6, global_rank: 14, world_size: 8, global_world_size: 16
rank: 7, global_rank: 15, world_size: 8, global_world_size: 16
rank: 2, global_rank: 10, world_size: 8, global_world_size: 16
rank: 5, global_rank: 13, world_size: 8, global_world_size: 16
rank: 7, global_rank: 15, world_size: 8, global_world_size: 16
rank: 2, global_rank: 10, world_size: 8, global_world_size: 16
rank: 7, global_rank: 15, world_size: 8, global_world_size: 16
rank: 4, global_rank: 12, world_size: 8, global_world_size: 16
rank: 4, global_rank: 12, world_size: 8, global_world_size: 16
rank: 4, global_rank: 12, world_size: 8, global_world_size: 16
rank: 4, global_rank: 12, world_size: 8, global_world_size: 16
rank: 4, global_rank: 12, world_size: 8, global_world_size: 16
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
[rank9]: Traceback (most recent call last):
[rank9]:   File "/home/charlie/skip-residual/gpt-fast/benchmark.py", line 492, in <module>
[rank9]:     main(
[rank9]:   File "/home/charlie/skip-residual/gpt-fast/benchmark.py", line 419, in main
[rank9]:     y, decode_latency, prefill_latency = generate(
[rank9]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
[rank9]:     return func(*args, **kwargs)
[rank9]:   File "/home/charlie/skip-residual/gpt-fast/benchmark.py", line 140, in generate
[rank9]:     next_token = prefill(model, prompt.view(batch_size, -1), input_pos, **sampling_kwargs)
[rank9]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py", line 556, in _fn
[rank9]:     return fn(*args, **kwargs)
[rank9]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/external_utils.py", line 29, in inner
[rank9]:     @functools.wraps(fn)
[rank9]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py", line 721, in _fn
[rank9]:     return fn(*args, **kwargs)
[rank9]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 1132, in forward
[rank9]:     return compiled_fn(full_args)
[rank9]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 324, in runtime_wrapper
[rank9]:     all_outs = call_func_at_runtime_with_args(
[rank9]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/utils.py", line 126, in call_func_at_runtime_with_args
[rank9]:     out = normalize_as_list(f(args))
[rank9]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 673, in inner_fn
[rank9]:     outs = compiled_fn(args)
[rank9]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 491, in wrapper
[rank9]:     return compiled_fn(runtime_args)
[rank9]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 1686, in __call__
[rank9]:     return self.current_callable(inputs)
[rank9]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 1104, in run
[rank9]:     return compiled_fn(new_inputs)
[rank9]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/cudagraph_trees.py", line 398, in deferred_cudagraphify
[rank9]:     fn, out = cudagraphify(model, inputs, new_static_input_idxs, *args, **kwargs)
[rank9]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/cudagraph_trees.py", line 428, in cudagraphify
[rank9]:     return manager.add_function(
[rank9]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/cudagraph_trees.py", line 2235, in add_function
[rank9]:     return fn, fn(inputs)
[rank9]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/cudagraph_trees.py", line 1929, in run
[rank9]:     out = self._run(new_inputs, function_id)
[rank9]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/cudagraph_trees.py", line 2037, in _run
[rank9]:     out = self.run_eager(new_inputs, function_id)
[rank9]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/cudagraph_trees.py", line 2201, in run_eager
[rank9]:     return node.run(new_inputs)
[rank9]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/cudagraph_trees.py", line 644, in run
[rank9]:     out = self.wrapped_function.model(new_inputs)
[rank9]:   File "/tmp/torchinductor_charlie/gw/cgwpu24hp6g7fqhfybednlmhjbuzb54r3hcxpyjgkynbcwjoxdjb.py", line 2404, in call
[rank9]:     torch.ops._c10d_functional.all_reduce_.default(buf21, 'sum', '0')
[rank9]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_ops.py", line 723, in __call__
[rank9]:     return self._op(*args, **kwargs)
[rank9]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/utils/_device.py", line 106, in __torch_function__
[rank9]:     return func(*args, **kwargs)
[rank9]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_ops.py", line 723, in __call__
[rank9]:     return self._op(*args, **kwargs)
[rank9]: torch.distributed.DistBackendError: NCCL error in: ../torch/csrc/distributed/c10d/NCCLUtils.hpp:328, unhandled system error (run with NCCL_DEBUG=INFO for details), NCCL version 2.21.5
[rank9]: ncclSystemError: System call (e.g. socket, malloc) or external library call failed or device error. 
[rank9]: Last error:
[rank9]: socketStartConnect: Connect to 172.27.39.142<55315> failed : Software caused connection abort
[rank11]: Traceback (most recent call last):
[rank11]:   File "/home/charlie/skip-residual/gpt-fast/benchmark.py", line 492, in <module>
[rank11]:     main(
[rank11]:   File "/home/charlie/skip-residual/gpt-fast/benchmark.py", line 419, in main
[rank11]:     y, decode_latency, prefill_latency = generate(
[rank11]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
[rank11]:     return func(*args, **kwargs)
[rank11]:   File "/home/charlie/skip-residual/gpt-fast/benchmark.py", line 140, in generate
[rank11]:     next_token = prefill(model, prompt.view(batch_size, -1), input_pos, **sampling_kwargs)
[rank11]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py", line 556, in _fn
[rank11]:     return fn(*args, **kwargs)
[rank11]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/external_utils.py", line 29, in inner
[rank11]:     @functools.wraps(fn)
[rank11]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py", line 721, in _fn
[rank11]:     return fn(*args, **kwargs)
[rank11]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 1132, in forward
[rank11]:     return compiled_fn(full_args)
[rank11]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 324, in runtime_wrapper
[rank11]:     all_outs = call_func_at_runtime_with_args(
[rank11]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/utils.py", line 126, in call_func_at_runtime_with_args
[rank11]:     out = normalize_as_list(f(args))
[rank11]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 673, in inner_fn
[rank11]:     outs = compiled_fn(args)
[rank11]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 491, in wrapper
[rank11]:     return compiled_fn(runtime_args)
[rank11]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 1686, in __call__
[rank11]:     return self.current_callable(inputs)
[rank11]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 1104, in run
[rank11]:     return compiled_fn(new_inputs)
[rank11]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/cudagraph_trees.py", line 398, in deferred_cudagraphify
[rank11]:     fn, out = cudagraphify(model, inputs, new_static_input_idxs, *args, **kwargs)
[rank11]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/cudagraph_trees.py", line 428, in cudagraphify
[rank11]:     return manager.add_function(
[rank11]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/cudagraph_trees.py", line 2235, in add_function
[rank11]:     return fn, fn(inputs)
[rank11]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/cudagraph_trees.py", line 1929, in run
[rank11]:     out = self._run(new_inputs, function_id)
[rank11]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/cudagraph_trees.py", line 2037, in _run
[rank11]:     out = self.run_eager(new_inputs, function_id)
[rank11]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/cudagraph_trees.py", line 2201, in run_eager
[rank11]:     return node.run(new_inputs)
[rank11]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/cudagraph_trees.py", line 644, in run
[rank11]:     out = self.wrapped_function.model(new_inputs)
[rank11]:   File "/tmp/torchinductor_charlie/ah/cahbyq67jq5gpy7gm2fythb2vqqznvpydifhwkmxm55aqu74mmr2.py", line 2404, in call
[rank11]:     torch.ops._c10d_functional.all_reduce_.default(buf21, 'sum', '0')
[rank11]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_ops.py", line 723, in __call__
[rank11]:     return self._op(*args, **kwargs)
[rank11]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/utils/_device.py", line 106, in __torch_function__
[rank11]:     return func(*args, **kwargs)
[rank11]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_ops.py", line 723, in __call__
[rank11]:     return self._op(*args, **kwargs)
[rank11]: torch.distributed.DistBackendError: NCCL error in: ../torch/csrc/distributed/c10d/NCCLUtils.hpp:328, unhandled system error (run with NCCL_DEBUG=INFO for details), NCCL version 2.21.5
[rank11]: ncclSystemError: System call (e.g. socket, malloc) or external library call failed or device error. 
[rank11]: Last error:
[rank11]: socketStartConnect: Connect to 172.27.39.142<55315> failed : Software caused connection abort
[rank14]: Traceback (most recent call last):
[rank14]:   File "/home/charlie/skip-residual/gpt-fast/benchmark.py", line 492, in <module>
[rank14]:     main(
[rank14]:   File "/home/charlie/skip-residual/gpt-fast/benchmark.py", line 419, in main
[rank14]:     y, decode_latency, prefill_latency = generate(
[rank14]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
[rank14]:     return func(*args, **kwargs)
[rank14]:   File "/home/charlie/skip-residual/gpt-fast/benchmark.py", line 140, in generate
[rank14]:     next_token = prefill(model, prompt.view(batch_size, -1), input_pos, **sampling_kwargs)
[rank14]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py", line 556, in _fn
[rank14]:     return fn(*args, **kwargs)
[rank14]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/external_utils.py", line 29, in inner
[rank14]:     @functools.wraps(fn)
[rank14]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py", line 721, in _fn
[rank14]:     return fn(*args, **kwargs)
[rank14]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 1132, in forward
[rank14]:     return compiled_fn(full_args)
[rank14]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 324, in runtime_wrapper
[rank14]:     all_outs = call_func_at_runtime_with_args(
[rank14]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/utils.py", line 126, in call_func_at_runtime_with_args
[rank14]:     out = normalize_as_list(f(args))
[rank14]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 673, in inner_fn
[rank14]:     outs = compiled_fn(args)
[rank14]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 491, in wrapper
[rank14]:     return compiled_fn(runtime_args)
[rank14]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 1686, in __call__
[rank14]:     return self.current_callable(inputs)
[rank14]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 1104, in run
[rank14]:     return compiled_fn(new_inputs)
[rank14]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/cudagraph_trees.py", line 398, in deferred_cudagraphify
[rank14]:     fn, out = cudagraphify(model, inputs, new_static_input_idxs, *args, **kwargs)
[rank14]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/cudagraph_trees.py", line 428, in cudagraphify
[rank14]:     return manager.add_function(
[rank14]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/cudagraph_trees.py", line 2235, in add_function
[rank14]:     return fn, fn(inputs)
[rank14]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/cudagraph_trees.py", line 1929, in run
[rank14]:     out = self._run(new_inputs, function_id)
[rank14]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/cudagraph_trees.py", line 2037, in _run
[rank14]:     out = self.run_eager(new_inputs, function_id)
[rank14]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/cudagraph_trees.py", line 2201, in run_eager
[rank14]:     return node.run(new_inputs)
[rank14]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/cudagraph_trees.py", line 644, in run
[rank14]:     out = self.wrapped_function.model(new_inputs)
[rank14]:   File "/tmp/torchinductor_charlie/ub/cubqvi3wwztt4llrh6ux4vitfmkhir6dngttqjoluhbor3kdpmvy.py", line 2404, in call
[rank14]:     torch.ops._c10d_functional.all_reduce_.default(buf21, 'sum', '0')
[rank14]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_ops.py", line 723, in __call__
[rank14]:     return self._op(*args, **kwargs)
[rank14]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/utils/_device.py", line 106, in __torch_function__
[rank14]:     return func(*args, **kwargs)
[rank14]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_ops.py", line 723, in __call__
[rank14]:     return self._op(*args, **kwargs)
[rank14]: torch.distributed.DistBackendError: NCCL error in: ../torch/csrc/distributed/c10d/NCCLUtils.hpp:328, unhandled system error (run with NCCL_DEBUG=INFO for details), NCCL version 2.21.5
[rank14]: ncclSystemError: System call (e.g. socket, malloc) or external library call failed or device error. 
[rank14]: Last error:
[rank14]: socketStartConnect: Connect to 172.27.39.142<55315> failed : Software caused connection abort
[rank10]: Traceback (most recent call last):
[rank10]:   File "/home/charlie/skip-residual/gpt-fast/benchmark.py", line 492, in <module>
[rank10]:     main(
[rank10]:   File "/home/charlie/skip-residual/gpt-fast/benchmark.py", line 419, in main
[rank10]:     y, decode_latency, prefill_latency = generate(
[rank10]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
[rank10]:     return func(*args, **kwargs)
[rank10]:   File "/home/charlie/skip-residual/gpt-fast/benchmark.py", line 140, in generate
[rank10]:     next_token = prefill(model, prompt.view(batch_size, -1), input_pos, **sampling_kwargs)
[rank10]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py", line 556, in _fn
[rank10]:     return fn(*args, **kwargs)
[rank10]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/external_utils.py", line 29, in inner
[rank10]:     @functools.wraps(fn)
[rank10]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py", line 721, in _fn
[rank10]:     return fn(*args, **kwargs)
[rank10]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 1132, in forward
[rank10]:     return compiled_fn(full_args)
[rank10]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 324, in runtime_wrapper
[rank10]:     all_outs = call_func_at_runtime_with_args(
[rank10]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/utils.py", line 126, in call_func_at_runtime_with_args
[rank10]:     out = normalize_as_list(f(args))
[rank10]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 673, in inner_fn
[rank10]:     outs = compiled_fn(args)
[rank10]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 491, in wrapper
[rank10]:     return compiled_fn(runtime_args)
[rank10]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 1686, in __call__
[rank10]:     return self.current_callable(inputs)
[rank10]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 1104, in run
[rank10]:     return compiled_fn(new_inputs)
[rank10]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/cudagraph_trees.py", line 398, in deferred_cudagraphify
[rank10]:     fn, out = cudagraphify(model, inputs, new_static_input_idxs, *args, **kwargs)
[rank10]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/cudagraph_trees.py", line 428, in cudagraphify
[rank10]:     return manager.add_function(
[rank10]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/cudagraph_trees.py", line 2235, in add_function
[rank10]:     return fn, fn(inputs)
[rank10]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/cudagraph_trees.py", line 1929, in run
[rank10]:     out = self._run(new_inputs, function_id)
[rank10]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/cudagraph_trees.py", line 2037, in _run
[rank10]:     out = self.run_eager(new_inputs, function_id)
[rank10]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/cudagraph_trees.py", line 2201, in run_eager
[rank10]:     return node.run(new_inputs)
[rank10]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/cudagraph_trees.py", line 644, in run
[rank10]:     out = self.wrapped_function.model(new_inputs)
[rank10]:   File "/tmp/torchinductor_charlie/7h/c7h773bix7gy6jjbmst52mkwf57tezr66vc6dfigmhg3ilwopufd.py", line 2404, in call
[rank10]:     torch.ops._c10d_functional.all_reduce_.default(buf21, 'sum', '0')
[rank10]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_ops.py", line 723, in __call__
[rank10]:     return self._op(*args, **kwargs)
[rank10]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/utils/_device.py", line 106, in __torch_function__
[rank10]:     return func(*args, **kwargs)
[rank10]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_ops.py", line 723, in __call__
[rank10]:     return self._op(*args, **kwargs)
[rank10]: torch.distributed.DistBackendError: NCCL error in: ../torch/csrc/distributed/c10d/NCCLUtils.hpp:328, unhandled system error (run with NCCL_DEBUG=INFO for details), NCCL version 2.21.5
[rank10]: ncclSystemError: System call (e.g. socket, malloc) or external library call failed or device error. 
[rank10]: Last error:
[rank10]: socketStartConnect: Connect to 172.27.39.142<55315> failed : Software caused connection abort
[rank15]: Traceback (most recent call last):
[rank15]:   File "/home/charlie/skip-residual/gpt-fast/benchmark.py", line 492, in <module>
[rank15]:     main(
[rank15]:   File "/home/charlie/skip-residual/gpt-fast/benchmark.py", line 419, in main
[rank15]:     y, decode_latency, prefill_latency = generate(
[rank15]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
[rank15]:     return func(*args, **kwargs)
[rank15]:   File "/home/charlie/skip-residual/gpt-fast/benchmark.py", line 140, in generate
[rank15]:     next_token = prefill(model, prompt.view(batch_size, -1), input_pos, **sampling_kwargs)
[rank15]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py", line 556, in _fn
[rank15]:     return fn(*args, **kwargs)
[rank15]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/external_utils.py", line 29, in inner
[rank15]:     @functools.wraps(fn)
[rank15]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py", line 721, in _fn
[rank15]:     return fn(*args, **kwargs)
[rank15]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 1132, in forward
[rank15]:     return compiled_fn(full_args)
[rank15]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 324, in runtime_wrapper
[rank15]:     all_outs = call_func_at_runtime_with_args(
[rank15]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/utils.py", line 126, in call_func_at_runtime_with_args
[rank15]:     out = normalize_as_list(f(args))
[rank15]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 673, in inner_fn
[rank15]:     outs = compiled_fn(args)
[rank15]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 491, in wrapper
[rank15]:     return compiled_fn(runtime_args)
[rank15]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 1686, in __call__
[rank15]:     return self.current_callable(inputs)
[rank15]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 1104, in run
[rank15]:     return compiled_fn(new_inputs)
[rank15]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/cudagraph_trees.py", line 398, in deferred_cudagraphify
[rank15]:     fn, out = cudagraphify(model, inputs, new_static_input_idxs, *args, **kwargs)
[rank15]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/cudagraph_trees.py", line 428, in cudagraphify
[rank15]:     return manager.add_function(
[rank15]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/cudagraph_trees.py", line 2235, in add_function
[rank15]:     return fn, fn(inputs)
[rank15]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/cudagraph_trees.py", line 1929, in run
[rank15]:     out = self._run(new_inputs, function_id)
[rank15]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/cudagraph_trees.py", line 2037, in _run
[rank15]:     out = self.run_eager(new_inputs, function_id)
[rank15]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/cudagraph_trees.py", line 2201, in run_eager
[rank15]:     return node.run(new_inputs)
[rank15]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/cudagraph_trees.py", line 644, in run
[rank15]:     out = self.wrapped_function.model(new_inputs)
[rank15]:   File "/tmp/torchinductor_charlie/lq/clqufhaopnzrkm4uzs7egvtqfzoxio57sbhnjtjong6eqtwgnsok.py", line 2404, in call
[rank15]:     torch.ops._c10d_functional.all_reduce_.default(buf21, 'sum', '0')
[rank15]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_ops.py", line 723, in __call__
[rank15]:     return self._op(*args, **kwargs)
[rank15]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/utils/_device.py", line 106, in __torch_function__
[rank15]:     return func(*args, **kwargs)
[rank15]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_ops.py", line 723, in __call__
[rank15]:     return self._op(*args, **kwargs)
[rank15]: torch.distributed.DistBackendError: NCCL error in: ../torch/csrc/distributed/c10d/NCCLUtils.hpp:328, unhandled system error (run with NCCL_DEBUG=INFO for details), NCCL version 2.21.5
[rank15]: ncclSystemError: System call (e.g. socket, malloc) or external library call failed or device error. 
[rank15]: Last error:
[rank15]: socketStartConnect: Connect to 172.27.39.142<55315> failed : Software caused connection abort
[rank8]: Traceback (most recent call last):
[rank8]:   File "/home/charlie/skip-residual/gpt-fast/benchmark.py", line 492, in <module>
[rank8]:     main(
[rank8]:   File "/home/charlie/skip-residual/gpt-fast/benchmark.py", line 419, in main
[rank8]:     y, decode_latency, prefill_latency = generate(
[rank8]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
[rank8]:     return func(*args, **kwargs)
[rank8]:   File "/home/charlie/skip-residual/gpt-fast/benchmark.py", line 140, in generate
[rank8]:     next_token = prefill(model, prompt.view(batch_size, -1), input_pos, **sampling_kwargs)
[rank8]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py", line 556, in _fn
[rank8]:     return fn(*args, **kwargs)
[rank8]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/external_utils.py", line 29, in inner
[rank8]:     @functools.wraps(fn)
[rank8]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py", line 721, in _fn
[rank8]:     return fn(*args, **kwargs)
[rank8]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 1132, in forward
[rank8]:     return compiled_fn(full_args)
[rank8]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 324, in runtime_wrapper
[rank8]:     all_outs = call_func_at_runtime_with_args(
[rank8]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/utils.py", line 126, in call_func_at_runtime_with_args
[rank8]:     out = normalize_as_list(f(args))
[rank8]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 673, in inner_fn
[rank8]:     outs = compiled_fn(args)
[rank8]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 491, in wrapper
[rank8]:     return compiled_fn(runtime_args)
[rank8]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 1686, in __call__
[rank8]:     return self.current_callable(inputs)
[rank8]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 1104, in run
[rank8]:     return compiled_fn(new_inputs)
[rank8]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/cudagraph_trees.py", line 398, in deferred_cudagraphify
[rank8]:     fn, out = cudagraphify(model, inputs, new_static_input_idxs, *args, **kwargs)
[rank8]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/cudagraph_trees.py", line 428, in cudagraphify
[rank8]:     return manager.add_function(
[rank8]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/cudagraph_trees.py", line 2235, in add_function
[rank8]:     return fn, fn(inputs)
[rank8]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/cudagraph_trees.py", line 1929, in run
[rank8]:     out = self._run(new_inputs, function_id)
[rank8]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/cudagraph_trees.py", line 2037, in _run
[rank8]:     out = self.run_eager(new_inputs, function_id)
[rank8]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/cudagraph_trees.py", line 2201, in run_eager
[rank8]:     return node.run(new_inputs)
[rank8]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/cudagraph_trees.py", line 644, in run
[rank8]:     out = self.wrapped_function.model(new_inputs)
[rank8]:   File "/tmp/torchinductor_charlie/33/c33jfa6raw45bnoxzjq3rl4oj3l77uq3smosvjn22odbiysb2dry.py", line 2404, in call
[rank8]:     torch.ops._c10d_functional.all_reduce_.default(buf21, 'sum', '0')
[rank8]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_ops.py", line 723, in __call__
[rank8]:     return self._op(*args, **kwargs)
[rank8]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/utils/_device.py", line 106, in __torch_function__
[rank8]:     return func(*args, **kwargs)
[rank8]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_ops.py", line 723, in __call__
[rank8]:     return self._op(*args, **kwargs)
[rank8]: torch.distributed.DistBackendError: NCCL error in: ../torch/csrc/distributed/c10d/NCCLUtils.hpp:328, unhandled system error (run with NCCL_DEBUG=INFO for details), NCCL version 2.21.5
[rank8]: ncclSystemError: System call (e.g. socket, malloc) or external library call failed or device error. 
[rank8]: Last error:
[rank8]: socketStartConnect: Connect to 172.27.39.142<55315> failed : Software caused connection abort
[rank12]: Traceback (most recent call last):
[rank12]:   File "/home/charlie/skip-residual/gpt-fast/benchmark.py", line 492, in <module>
[rank12]:     main(
[rank12]:   File "/home/charlie/skip-residual/gpt-fast/benchmark.py", line 419, in main
[rank12]:     y, decode_latency, prefill_latency = generate(
[rank12]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
[rank12]:     return func(*args, **kwargs)
[rank12]:   File "/home/charlie/skip-residual/gpt-fast/benchmark.py", line 140, in generate
[rank12]:     next_token = prefill(model, prompt.view(batch_size, -1), input_pos, **sampling_kwargs)
[rank12]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py", line 556, in _fn
[rank12]:     return fn(*args, **kwargs)
[rank12]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/external_utils.py", line 29, in inner
[rank12]:     @functools.wraps(fn)
[rank12]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py", line 721, in _fn
[rank12]:     return fn(*args, **kwargs)
[rank12]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 1132, in forward
[rank12]:     return compiled_fn(full_args)
[rank12]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 324, in runtime_wrapper
[rank12]:     all_outs = call_func_at_runtime_with_args(
[rank12]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/utils.py", line 126, in call_func_at_runtime_with_args
[rank12]:     out = normalize_as_list(f(args))
[rank12]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 673, in inner_fn
[rank12]:     outs = compiled_fn(args)
[rank12]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 491, in wrapper
[rank12]:     return compiled_fn(runtime_args)
[rank12]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 1686, in __call__
[rank12]:     return self.current_callable(inputs)
[rank12]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 1104, in run
[rank12]:     return compiled_fn(new_inputs)
[rank12]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/cudagraph_trees.py", line 398, in deferred_cudagraphify
[rank12]:     fn, out = cudagraphify(model, inputs, new_static_input_idxs, *args, **kwargs)
[rank12]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/cudagraph_trees.py", line 428, in cudagraphify
[rank12]:     return manager.add_function(
[rank12]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/cudagraph_trees.py", line 2235, in add_function
[rank12]:     return fn, fn(inputs)
[rank12]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/cudagraph_trees.py", line 1929, in run
[rank12]:     out = self._run(new_inputs, function_id)
[rank12]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/cudagraph_trees.py", line 2037, in _run
[rank12]:     out = self.run_eager(new_inputs, function_id)
[rank12]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/cudagraph_trees.py", line 2201, in run_eager
[rank12]:     return node.run(new_inputs)
[rank12]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/cudagraph_trees.py", line 644, in run
[rank12]:     out = self.wrapped_function.model(new_inputs)
[rank12]:   File "/tmp/torchinductor_charlie/eb/cebqknolcdhy5yr2r6xo4vf4ushy32qijuxsjh4xqmddenh5xo4l.py", line 2404, in call
[rank12]:     torch.ops._c10d_functional.all_reduce_.default(buf21, 'sum', '0')
[rank12]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_ops.py", line 723, in __call__
[rank12]:     return self._op(*args, **kwargs)
[rank12]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/utils/_device.py", line 106, in __torch_function__
[rank12]:     return func(*args, **kwargs)
[rank12]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_ops.py", line 723, in __call__
[rank12]:     return self._op(*args, **kwargs)
[rank12]: torch.distributed.DistBackendError: NCCL error in: ../torch/csrc/distributed/c10d/NCCLUtils.hpp:328, unhandled system error (run with NCCL_DEBUG=INFO for details), NCCL version 2.21.5
[rank12]: ncclSystemError: System call (e.g. socket, malloc) or external library call failed or device error. 
[rank12]: Last error:
[rank12]: socketStartConnect: Connect to 172.27.39.142<55315> failed : Software caused connection abort
[rank13]: Traceback (most recent call last):
[rank13]:   File "/home/charlie/skip-residual/gpt-fast/benchmark.py", line 492, in <module>
[rank13]:     main(
[rank13]:   File "/home/charlie/skip-residual/gpt-fast/benchmark.py", line 419, in main
[rank13]:     y, decode_latency, prefill_latency = generate(
[rank13]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
[rank13]:     return func(*args, **kwargs)
[rank13]:   File "/home/charlie/skip-residual/gpt-fast/benchmark.py", line 140, in generate
[rank13]:     next_token = prefill(model, prompt.view(batch_size, -1), input_pos, **sampling_kwargs)
[rank13]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py", line 556, in _fn
[rank13]:     return fn(*args, **kwargs)
[rank13]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/external_utils.py", line 29, in inner
[rank13]:     @functools.wraps(fn)
[rank13]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py", line 721, in _fn
[rank13]:     return fn(*args, **kwargs)
[rank13]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 1132, in forward
[rank13]:     return compiled_fn(full_args)
[rank13]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 324, in runtime_wrapper
[rank13]:     all_outs = call_func_at_runtime_with_args(
[rank13]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/utils.py", line 126, in call_func_at_runtime_with_args
[rank13]:     out = normalize_as_list(f(args))
[rank13]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 673, in inner_fn
[rank13]:     outs = compiled_fn(args)
[rank13]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 491, in wrapper
[rank13]:     return compiled_fn(runtime_args)
[rank13]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 1686, in __call__
[rank13]:     return self.current_callable(inputs)
[rank13]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 1104, in run
[rank13]:     return compiled_fn(new_inputs)
[rank13]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/cudagraph_trees.py", line 398, in deferred_cudagraphify
[rank13]:     fn, out = cudagraphify(model, inputs, new_static_input_idxs, *args, **kwargs)
[rank13]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/cudagraph_trees.py", line 428, in cudagraphify
[rank13]:     return manager.add_function(
[rank13]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/cudagraph_trees.py", line 2235, in add_function
[rank13]:     return fn, fn(inputs)
[rank13]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/cudagraph_trees.py", line 1929, in run
[rank13]:     out = self._run(new_inputs, function_id)
[rank13]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/cudagraph_trees.py", line 2037, in _run
[rank13]:     out = self.run_eager(new_inputs, function_id)
[rank13]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/cudagraph_trees.py", line 2201, in run_eager
[rank13]:     return node.run(new_inputs)
[rank13]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/cudagraph_trees.py", line 644, in run
[rank13]:     out = self.wrapped_function.model(new_inputs)
[rank13]:   File "/tmp/torchinductor_charlie/ca/ccacl2epm37dcjfjckuy7djtjadesiw3nd2drdfob6efgbxe7aza.py", line 2404, in call
[rank13]:     torch.ops._c10d_functional.all_reduce_.default(buf21, 'sum', '0')
[rank13]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_ops.py", line 723, in __call__
[rank13]:     return self._op(*args, **kwargs)
[rank13]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/utils/_device.py", line 106, in __torch_function__
[rank13]:     return func(*args, **kwargs)
[rank13]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_ops.py", line 723, in __call__
[rank13]:     return self._op(*args, **kwargs)
[rank13]: torch.distributed.DistBackendError: NCCL error in: ../torch/csrc/distributed/c10d/NCCLUtils.hpp:328, unhandled system error (run with NCCL_DEBUG=INFO for details), NCCL version 2.21.5
[rank13]: ncclSystemError: System call (e.g. socket, malloc) or external library call failed or device error. 
[rank13]: Last error:
[rank13]: socketStartConnect: Connect to 172.27.39.142<55315> failed : Software caused connection abort
W1118 16:09:53.715000 2859803 site-packages/torch/distributed/elastic/multiprocessing/api.py:897] Sending process 2859871 closing signal SIGTERM
W1118 16:09:53.720000 2859803 site-packages/torch/distributed/elastic/multiprocessing/api.py:897] Sending process 2859872 closing signal SIGTERM
W1118 16:09:53.720000 2859803 site-packages/torch/distributed/elastic/multiprocessing/api.py:897] Sending process 2859873 closing signal SIGTERM
W1118 16:09:53.723000 2859803 site-packages/torch/distributed/elastic/multiprocessing/api.py:897] Sending process 2859875 closing signal SIGTERM
W1118 16:09:53.725000 2859803 site-packages/torch/distributed/elastic/multiprocessing/api.py:897] Sending process 2859876 closing signal SIGTERM
W1118 16:09:53.748000 2859803 site-packages/torch/distributed/elastic/multiprocessing/api.py:897] Sending process 2859877 closing signal SIGTERM
W1118 16:09:53.751000 2859803 site-packages/torch/distributed/elastic/multiprocessing/api.py:897] Sending process 2859878 closing signal SIGTERM
E1118 16:09:54.616000 2859803 site-packages/torch/distributed/elastic/multiprocessing/api.py:869] failed (exitcode: 1) local_rank: 3 (pid: 2859874) of binary: /home/charlie/anaconda3/envs/gpt-fast/bin/python
Traceback (most recent call last):
  File "/home/charlie/anaconda3/envs/gpt-fast/bin/torchrun", line 8, in <module>
    sys.exit(main())
  File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 355, in wrapper
    return f(*args, **kwargs)
  File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/distributed/run.py", line 919, in main
    run(args)
  File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/distributed/run.py", line 910, in run
    elastic_launch(
  File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 138, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 269, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
benchmark.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2024-11-18_16:09:53
  host      : mk-xii-06.cloud.together.ai
  rank      : 11 (local_rank: 3)
  exitcode  : 1 (pid: 2859874)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
