W1118 16:09:56.019000 2860994 site-packages/torch/distributed/run.py:793] 
W1118 16:09:56.019000 2860994 site-packages/torch/distributed/run.py:793] *****************************************
W1118 16:09:56.019000 2860994 site-packages/torch/distributed/run.py:793] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W1118 16:09:56.019000 2860994 site-packages/torch/distributed/run.py:793] *****************************************
rank: 5, global_rank: 13, world_size: 8, global_world_size: 16
rank: 3, global_rank: 11, world_size: 8, global_world_size: 16
rank: 2, global_rank: 10, world_size: 8, global_world_size: 16
rank: 0, global_rank: 8, world_size: 8, global_world_size: 16
rank: 6, global_rank: 14, world_size: 8, global_world_size: 16
rank: 1, global_rank: 9, world_size: 8, global_world_size: 16
rank: 4, global_rank: 12, world_size: 8, global_world_size: 16
rank: 7, global_rank: 15, world_size: 8, global_world_size: 16
rank: 0, global_rank: 8, world_size: 8, global_world_size: 16
rank: 0, global_rank: 8, world_size: 8, global_world_size: 16
rank: 0, global_rank: 8, world_size: 8, global_world_size: 16
rank: 0, global_rank: 8, world_size: 8, global_world_size: 16
rank: 0, global_rank: 8, world_size: 8, global_world_size: 16
rank: 6, global_rank: 14, world_size: 8, global_world_size: 16
rank: 6, global_rank: 14, world_size: 8, global_world_size: 16
rank: 6, global_rank: 14, world_size: 8, global_world_size: 16
rank: 6, global_rank: 14, world_size: 8, global_world_size: 16
rank: 6, global_rank: 14, world_size: 8, global_world_size: 16
rank: 5, global_rank: 13, world_size: 8, global_world_size: 16
rank: 1, global_rank: 9, world_size: 8, global_world_size: 16
rank: 5, global_rank: 13, world_size: 8, global_world_size: 16
rank: 1, global_rank: 9, world_size: 8, global_world_size: 16
rank: 1, global_rank: 9, world_size: 8, global_world_size: 16
rank: 5, global_rank: 13, world_size: 8, global_world_size: 16
rank: 5, global_rank: 13, world_size: 8, global_world_size: 16rank: 1, global_rank: 9, world_size: 8, global_world_size: 16

rank: 5, global_rank: 13, world_size: 8, global_world_size: 16rank: 1, global_rank: 9, world_size: 8, global_world_size: 16

rank: 3, global_rank: 11, world_size: 8, global_world_size: 16
rank: 3, global_rank: 11, world_size: 8, global_world_size: 16
rank: 3, global_rank: 11, world_size: 8, global_world_size: 16
rank: 4, global_rank: 12, world_size: 8, global_world_size: 16
rank: 3, global_rank: 11, world_size: 8, global_world_size: 16
rank: 4, global_rank: 12, world_size: 8, global_world_size: 16
rank: 3, global_rank: 11, world_size: 8, global_world_size: 16
rank: 7, global_rank: 15, world_size: 8, global_world_size: 16
rank: 4, global_rank: 12, world_size: 8, global_world_size: 16
rank: 2, global_rank: 10, world_size: 8, global_world_size: 16
rank: 7, global_rank: 15, world_size: 8, global_world_size: 16
rank: 2, global_rank: 10, world_size: 8, global_world_size: 16
rank: 4, global_rank: 12, world_size: 8, global_world_size: 16
rank: 7, global_rank: 15, world_size: 8, global_world_size: 16
rank: 2, global_rank: 10, world_size: 8, global_world_size: 16
rank: 4, global_rank: 12, world_size: 8, global_world_size: 16
rank: 7, global_rank: 15, world_size: 8, global_world_size: 16
rank: 2, global_rank: 10, world_size: 8, global_world_size: 16
rank: 7, global_rank: 15, world_size: 8, global_world_size: 16
rank: 2, global_rank: 10, world_size: 8, global_world_size: 16
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
[rank12]: Traceback (most recent call last):
[rank12]:   File "/home/charlie/skip-residual/gpt-fast/benchmark.py", line 492, in <module>
[rank12]:     main(
[rank12]:   File "/home/charlie/skip-residual/gpt-fast/benchmark.py", line 419, in main
[rank12]:     y, decode_latency, prefill_latency = generate(
[rank12]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
[rank12]:     return func(*args, **kwargs)
[rank12]:   File "/home/charlie/skip-residual/gpt-fast/benchmark.py", line 140, in generate
[rank12]:     next_token = prefill(model, prompt.view(batch_size, -1), input_pos, **sampling_kwargs)
[rank12]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py", line 556, in _fn
[rank12]:     return fn(*args, **kwargs)
[rank12]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/external_utils.py", line 29, in inner
[rank12]:     @functools.wraps(fn)
[rank12]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py", line 721, in _fn
[rank12]:     return fn(*args, **kwargs)
[rank12]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 1132, in forward
[rank12]:     return compiled_fn(full_args)
[rank12]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 324, in runtime_wrapper
[rank12]:     all_outs = call_func_at_runtime_with_args(
[rank12]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/utils.py", line 126, in call_func_at_runtime_with_args
[rank12]:     out = normalize_as_list(f(args))
[rank12]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 673, in inner_fn
[rank12]:     outs = compiled_fn(args)
[rank12]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 491, in wrapper
[rank12]:     return compiled_fn(runtime_args)
[rank12]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 1686, in __call__
[rank12]:     return self.current_callable(inputs)
[rank12]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 1104, in run
[rank12]:     return compiled_fn(new_inputs)
[rank12]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/cudagraph_trees.py", line 398, in deferred_cudagraphify
[rank12]:     fn, out = cudagraphify(model, inputs, new_static_input_idxs, *args, **kwargs)
[rank12]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/cudagraph_trees.py", line 428, in cudagraphify
[rank12]:     return manager.add_function(
[rank12]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/cudagraph_trees.py", line 2235, in add_function
[rank12]:     return fn, fn(inputs)
[rank12]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/cudagraph_trees.py", line 1929, in run
[rank12]:     out = self._run(new_inputs, function_id)
[rank12]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/cudagraph_trees.py", line 2037, in _run
[rank12]:     out = self.run_eager(new_inputs, function_id)
[rank12]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/cudagraph_trees.py", line 2201, in run_eager
[rank12]:     return node.run(new_inputs)
[rank12]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/cudagraph_trees.py", line 644, in run
[rank12]:     out = self.wrapped_function.model(new_inputs)
[rank12]:   File "/tmp/torchinductor_charlie/tg/ctggyxwwtp7kibvu7ayimonhx4q6m2646zvexa5fpcgavvpbadbl.py", line 2415, in call
[rank12]:     torch.ops._c10d_functional.all_reduce_.default(buf21, 'sum', '0')
[rank12]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_ops.py", line 723, in __call__
[rank12]:     return self._op(*args, **kwargs)
[rank12]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/utils/_device.py", line 106, in __torch_function__
[rank12]:     return func(*args, **kwargs)
[rank12]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_ops.py", line 723, in __call__
[rank12]:     return self._op(*args, **kwargs)
[rank12]: torch.distributed.DistBackendError: NCCL error in: ../torch/csrc/distributed/c10d/NCCLUtils.hpp:328, unhandled system error (run with NCCL_DEBUG=INFO for details), NCCL version 2.21.5
[rank12]: ncclSystemError: System call (e.g. socket, malloc) or external library call failed or device error. 
[rank12]: Last error:
[rank12]: socketStartConnect: Connect to 172.27.39.142<55315> failed : Software caused connection abort
[rank11]: Traceback (most recent call last):
[rank11]:   File "/home/charlie/skip-residual/gpt-fast/benchmark.py", line 492, in <module>
[rank11]:     main(
[rank11]:   File "/home/charlie/skip-residual/gpt-fast/benchmark.py", line 419, in main
[rank11]:     y, decode_latency, prefill_latency = generate(
[rank11]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
[rank11]:     return func(*args, **kwargs)
[rank11]:   File "/home/charlie/skip-residual/gpt-fast/benchmark.py", line 140, in generate
[rank11]:     next_token = prefill(model, prompt.view(batch_size, -1), input_pos, **sampling_kwargs)
[rank11]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py", line 556, in _fn
[rank11]:     return fn(*args, **kwargs)
[rank11]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/external_utils.py", line 29, in inner
[rank11]:     @functools.wraps(fn)
[rank11]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py", line 721, in _fn
[rank11]:     return fn(*args, **kwargs)
[rank11]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 1132, in forward
[rank11]:     return compiled_fn(full_args)
[rank11]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 324, in runtime_wrapper
[rank11]:     all_outs = call_func_at_runtime_with_args(
[rank11]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/utils.py", line 126, in call_func_at_runtime_with_args
[rank11]:     out = normalize_as_list(f(args))
[rank11]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 673, in inner_fn
[rank11]:     outs = compiled_fn(args)
[rank11]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 491, in wrapper
[rank11]:     return compiled_fn(runtime_args)
[rank11]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 1686, in __call__
[rank11]:     return self.current_callable(inputs)
[rank11]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 1104, in run
[rank11]:     return compiled_fn(new_inputs)
[rank11]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/cudagraph_trees.py", line 398, in deferred_cudagraphify
[rank11]:     fn, out = cudagraphify(model, inputs, new_static_input_idxs, *args, **kwargs)
[rank11]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/cudagraph_trees.py", line 428, in cudagraphify
[rank11]:     return manager.add_function(
[rank11]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/cudagraph_trees.py", line 2235, in add_function
[rank11]:     return fn, fn(inputs)
[rank11]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/cudagraph_trees.py", line 1929, in run
[rank11]:     out = self._run(new_inputs, function_id)
[rank11]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/cudagraph_trees.py", line 2037, in _run
[rank11]:     out = self.run_eager(new_inputs, function_id)
[rank11]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/cudagraph_trees.py", line 2201, in run_eager
[rank11]:     return node.run(new_inputs)
[rank11]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/cudagraph_trees.py", line 644, in run
[rank11]:     out = self.wrapped_function.model(new_inputs)
[rank11]:   File "/tmp/torchinductor_charlie/ho/cho6tvpblngpjcucqfdqmjdncy3t6zqw2pxttx2fjgjgdlx2lmpp.py", line 2415, in call
[rank11]:     torch.ops._c10d_functional.all_reduce_.default(buf21, 'sum', '0')
[rank11]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_ops.py", line 723, in __call__
[rank11]:     return self._op(*args, **kwargs)
[rank11]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/utils/_device.py", line 106, in __torch_function__
[rank11]:     return func(*args, **kwargs)
[rank11]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_ops.py", line 723, in __call__
[rank11]:     return self._op(*args, **kwargs)
[rank11]: torch.distributed.DistBackendError: NCCL error in: ../torch/csrc/distributed/c10d/NCCLUtils.hpp:328, unhandled system error (run with NCCL_DEBUG=INFO for details), NCCL version 2.21.5
[rank11]: ncclSystemError: System call (e.g. socket, malloc) or external library call failed or device error. 
[rank11]: Last error:
[rank11]: socketStartConnect: Connect to 172.27.39.142<55315> failed : Software caused connection abort
[rank9]: Traceback (most recent call last):
[rank9]:   File "/home/charlie/skip-residual/gpt-fast/benchmark.py", line 492, in <module>
[rank9]:     main(
[rank9]:   File "/home/charlie/skip-residual/gpt-fast/benchmark.py", line 419, in main
[rank9]:     y, decode_latency, prefill_latency = generate(
[rank9]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
[rank9]:     return func(*args, **kwargs)
[rank9]:   File "/home/charlie/skip-residual/gpt-fast/benchmark.py", line 140, in generate
[rank9]:     next_token = prefill(model, prompt.view(batch_size, -1), input_pos, **sampling_kwargs)
[rank9]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py", line 556, in _fn
[rank9]:     return fn(*args, **kwargs)
[rank9]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/external_utils.py", line 29, in inner
[rank9]:     @functools.wraps(fn)
[rank9]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py", line 721, in _fn
[rank9]:     return fn(*args, **kwargs)
[rank9]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 1132, in forward
[rank9]:     return compiled_fn(full_args)
[rank9]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 324, in runtime_wrapper
[rank9]:     all_outs = call_func_at_runtime_with_args(
[rank9]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/utils.py", line 126, in call_func_at_runtime_with_args
[rank9]:     out = normalize_as_list(f(args))
[rank9]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 673, in inner_fn
[rank9]:     outs = compiled_fn(args)
[rank9]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 491, in wrapper
[rank9]:     return compiled_fn(runtime_args)
[rank9]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 1686, in __call__
[rank9]:     return self.current_callable(inputs)
[rank9]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 1104, in run
[rank9]:     return compiled_fn(new_inputs)
[rank9]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/cudagraph_trees.py", line 398, in deferred_cudagraphify
[rank9]:     fn, out = cudagraphify(model, inputs, new_static_input_idxs, *args, **kwargs)
[rank9]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/cudagraph_trees.py", line 428, in cudagraphify
[rank9]:     return manager.add_function(
[rank9]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/cudagraph_trees.py", line 2235, in add_function
[rank9]:     return fn, fn(inputs)
[rank9]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/cudagraph_trees.py", line 1929, in run
[rank9]:     out = self._run(new_inputs, function_id)
[rank9]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/cudagraph_trees.py", line 2037, in _run
[rank9]:     out = self.run_eager(new_inputs, function_id)
[rank9]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/cudagraph_trees.py", line 2201, in run_eager
[rank9]:     return node.run(new_inputs)
[rank9]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/cudagraph_trees.py", line 644, in run
[rank9]:     out = self.wrapped_function.model(new_inputs)
[rank9]:   File "/tmp/torchinductor_charlie/lp/clphejdg7tupm32qnel2x5wwjqycs6afvafryh5t6z7emlrq4zkr.py", line 2415, in call
[rank9]:     torch.ops._c10d_functional.all_reduce_.default(buf21, 'sum', '0')
[rank9]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_ops.py", line 723, in __call__
[rank9]:     return self._op(*args, **kwargs)
[rank9]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/utils/_device.py", line 106, in __torch_function__
[rank9]:     return func(*args, **kwargs)
[rank9]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_ops.py", line 723, in __call__
[rank9]:     return self._op(*args, **kwargs)
[rank9]: torch.distributed.DistBackendError: NCCL error in: ../torch/csrc/distributed/c10d/NCCLUtils.hpp:328, unhandled system error (run with NCCL_DEBUG=INFO for details), NCCL version 2.21.5
[rank9]: ncclSystemError: System call (e.g. socket, malloc) or external library call failed or device error. 
[rank9]: Last error:
[rank9]: socketStartConnect: Connect to 172.27.39.142<55315> failed : Software caused connection abort
[rank15]: Traceback (most recent call last):
[rank15]:   File "/home/charlie/skip-residual/gpt-fast/benchmark.py", line 492, in <module>
[rank15]:     main(
[rank15]:   File "/home/charlie/skip-residual/gpt-fast/benchmark.py", line 419, in main
[rank15]:     y, decode_latency, prefill_latency = generate(
[rank15]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
[rank15]:     return func(*args, **kwargs)
[rank15]:   File "/home/charlie/skip-residual/gpt-fast/benchmark.py", line 140, in generate
[rank15]:     next_token = prefill(model, prompt.view(batch_size, -1), input_pos, **sampling_kwargs)
[rank15]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py", line 556, in _fn
[rank15]:     return fn(*args, **kwargs)
[rank15]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/external_utils.py", line 29, in inner
[rank15]:     @functools.wraps(fn)
[rank15]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py", line 721, in _fn
[rank15]:     return fn(*args, **kwargs)
[rank15]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 1132, in forward
[rank15]:     return compiled_fn(full_args)
[rank15]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 324, in runtime_wrapper
[rank15]:     all_outs = call_func_at_runtime_with_args(
[rank15]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/utils.py", line 126, in call_func_at_runtime_with_args
[rank15]:     out = normalize_as_list(f(args))
[rank15]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 673, in inner_fn
[rank15]:     outs = compiled_fn(args)
[rank15]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 491, in wrapper
[rank15]:     return compiled_fn(runtime_args)
[rank15]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 1686, in __call__
[rank15]:     return self.current_callable(inputs)
[rank15]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 1104, in run
[rank15]:     return compiled_fn(new_inputs)
[rank15]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/cudagraph_trees.py", line 398, in deferred_cudagraphify
[rank15]:     fn, out = cudagraphify(model, inputs, new_static_input_idxs, *args, **kwargs)
[rank15]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/cudagraph_trees.py", line 428, in cudagraphify
[rank15]:     return manager.add_function(
[rank15]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/cudagraph_trees.py", line 2235, in add_function
[rank15]:     return fn, fn(inputs)
[rank15]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/cudagraph_trees.py", line 1929, in run
[rank15]:     out = self._run(new_inputs, function_id)
[rank15]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/cudagraph_trees.py", line 2037, in _run
[rank15]:     out = self.run_eager(new_inputs, function_id)
[rank15]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/cudagraph_trees.py", line 2201, in run_eager
[rank15]:     return node.run(new_inputs)
[rank15]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/cudagraph_trees.py", line 644, in run
[rank15]:     out = self.wrapped_function.model(new_inputs)
[rank15]:   File "/tmp/torchinductor_charlie/62/c62fkgfnkn2gqngoqvjk6neivliv5da7rvcpw4iqjy5vqo3wqa3f.py", line 2415, in call
[rank15]:     torch.ops._c10d_functional.all_reduce_.default(buf21, 'sum', '0')
[rank15]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_ops.py", line 723, in __call__
[rank15]:     return self._op(*args, **kwargs)
[rank15]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/utils/_device.py", line 106, in __torch_function__
[rank15]:     return func(*args, **kwargs)
[rank15]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_ops.py", line 723, in __call__
[rank15]:     return self._op(*args, **kwargs)
[rank15]: torch.distributed.DistBackendError: NCCL error in: ../torch/csrc/distributed/c10d/NCCLUtils.hpp:328, unhandled system error (run with NCCL_DEBUG=INFO for details), NCCL version 2.21.5
[rank15]: ncclSystemError: System call (e.g. socket, malloc) or external library call failed or device error. 
[rank15]: Last error:
[rank15]: socketStartConnect: Connect to 172.27.39.142<55315> failed : Software caused connection abort
[rank10]: Traceback (most recent call last):
[rank10]:   File "/home/charlie/skip-residual/gpt-fast/benchmark.py", line 492, in <module>
[rank10]:     main(
[rank10]:   File "/home/charlie/skip-residual/gpt-fast/benchmark.py", line 419, in main
[rank10]:     y, decode_latency, prefill_latency = generate(
[rank10]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
[rank10]:     return func(*args, **kwargs)
[rank10]:   File "/home/charlie/skip-residual/gpt-fast/benchmark.py", line 140, in generate
[rank10]:     next_token = prefill(model, prompt.view(batch_size, -1), input_pos, **sampling_kwargs)
[rank10]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py", line 556, in _fn
[rank10]:     return fn(*args, **kwargs)
[rank10]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/external_utils.py", line 29, in inner
[rank10]:     @functools.wraps(fn)
[rank10]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py", line 721, in _fn
[rank10]:     return fn(*args, **kwargs)
[rank10]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 1132, in forward
[rank10]:     return compiled_fn(full_args)
[rank10]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 324, in runtime_wrapper
[rank10]:     all_outs = call_func_at_runtime_with_args(
[rank10]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/utils.py", line 126, in call_func_at_runtime_with_args
[rank10]:     out = normalize_as_list(f(args))
[rank10]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 673, in inner_fn
[rank10]:     outs = compiled_fn(args)
[rank10]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 491, in wrapper
[rank10]:     return compiled_fn(runtime_args)
[rank10]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 1686, in __call__
[rank10]:     return self.current_callable(inputs)
[rank10]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 1104, in run
[rank10]:     return compiled_fn(new_inputs)
[rank10]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/cudagraph_trees.py", line 398, in deferred_cudagraphify
[rank10]:     fn, out = cudagraphify(model, inputs, new_static_input_idxs, *args, **kwargs)
[rank10]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/cudagraph_trees.py", line 428, in cudagraphify
[rank10]:     return manager.add_function(
[rank10]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/cudagraph_trees.py", line 2235, in add_function
[rank10]:     return fn, fn(inputs)
[rank10]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/cudagraph_trees.py", line 1929, in run
[rank10]:     out = self._run(new_inputs, function_id)
[rank10]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/cudagraph_trees.py", line 2037, in _run
[rank10]:     out = self.run_eager(new_inputs, function_id)
[rank10]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/cudagraph_trees.py", line 2201, in run_eager
[rank10]:     return node.run(new_inputs)
[rank10]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/cudagraph_trees.py", line 644, in run
[rank10]:     out = self.wrapped_function.model(new_inputs)
[rank10]:   File "/tmp/torchinductor_charlie/fx/cfxz5vzewgvsqv3k4ozshqg2h3d6krifhslg3445lfx6bvork4qp.py", line 2415, in call
[rank10]:     torch.ops._c10d_functional.all_reduce_.default(buf21, 'sum', '0')
[rank10]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_ops.py", line 723, in __call__
[rank10]:     return self._op(*args, **kwargs)
[rank10]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/utils/_device.py", line 106, in __torch_function__
[rank10]:     return func(*args, **kwargs)
[rank10]:   File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_ops.py", line 723, in __call__
[rank10]:     return self._op(*args, **kwargs)
[rank10]: torch.distributed.DistBackendError: NCCL error in: ../torch/csrc/distributed/c10d/NCCLUtils.hpp:328, unhandled system error (run with NCCL_DEBUG=INFO for details), NCCL version 2.21.5
[rank10]: ncclSystemError: System call (e.g. socket, malloc) or external library call failed or device error. 
[rank10]: Last error:
[rank10]: socketStartConnect: Connect to 172.27.39.142<55315> failed : Software caused connection abort
W1118 16:10:39.027000 2860994 site-packages/torch/distributed/elastic/multiprocessing/api.py:897] Sending process 2861060 closing signal SIGTERM
W1118 16:10:39.031000 2860994 site-packages/torch/distributed/elastic/multiprocessing/api.py:897] Sending process 2861061 closing signal SIGTERM
W1118 16:10:39.035000 2860994 site-packages/torch/distributed/elastic/multiprocessing/api.py:897] Sending process 2861062 closing signal SIGTERM
W1118 16:10:39.040000 2860994 site-packages/torch/distributed/elastic/multiprocessing/api.py:897] Sending process 2861063 closing signal SIGTERM
W1118 16:10:39.041000 2860994 site-packages/torch/distributed/elastic/multiprocessing/api.py:897] Sending process 2861065 closing signal SIGTERM
W1118 16:10:39.047000 2860994 site-packages/torch/distributed/elastic/multiprocessing/api.py:897] Sending process 2861066 closing signal SIGTERM
W1118 16:10:39.053000 2860994 site-packages/torch/distributed/elastic/multiprocessing/api.py:897] Sending process 2861067 closing signal SIGTERM
E1118 16:10:39.982000 2860994 site-packages/torch/distributed/elastic/multiprocessing/api.py:869] failed (exitcode: 1) local_rank: 4 (pid: 2861064) of binary: /home/charlie/anaconda3/envs/gpt-fast/bin/python
Traceback (most recent call last):
  File "/home/charlie/anaconda3/envs/gpt-fast/bin/torchrun", line 8, in <module>
    sys.exit(main())
  File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 355, in wrapper
    return f(*args, **kwargs)
  File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/distributed/run.py", line 919, in main
    run(args)
  File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/distributed/run.py", line 910, in run
    elastic_launch(
  File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 138, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 269, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
benchmark.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2024-11-18_16:10:39
  host      : mk-xii-06.cloud.together.ai
  rank      : 12 (local_rank: 4)
  exitcode  : 1 (pid: 2861064)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
