W1118 23:51:41.679000 2818803 site-packages/torch/distributed/run.py:793] 
W1118 23:51:41.679000 2818803 site-packages/torch/distributed/run.py:793] *****************************************
W1118 23:51:41.679000 2818803 site-packages/torch/distributed/run.py:793] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W1118 23:51:41.679000 2818803 site-packages/torch/distributed/run.py:793] *****************************************
rank: 5, global_rank: 5, world_size: 8, global_world_size: 16
rank: 7, global_rank: 7, world_size: 8, global_world_size: 16
rank: 3, global_rank: 3, world_size: 8, global_world_size: 16
rank: 1, global_rank: 1, world_size: 8, global_world_size: 16
rank: 6, global_rank: 6, world_size: 8, global_world_size: 16
rank: 2, global_rank: 2, world_size: 8, global_world_size: 16
rank: 0, global_rank: 0, world_size: 8, global_world_size: 16
rank: 4, global_rank: 4, world_size: 8, global_world_size: 16
rank: 0, global_rank: 0, world_size: 8, global_world_size: 16
rank: 0, global_rank: 0, world_size: 8, global_world_size: 16
rank: 0, global_rank: 0, world_size: 8, global_world_size: 16
rank: 0, global_rank: 0, world_size: 8, global_world_size: 16
flash_kv_decode is set to False
rank: 0, global_rank: 0, world_size: 8, global_world_size: 16
our world size=16
Using device=cuda
Loading model ...
rank: 6, global_rank: 6, world_size: 8, global_world_size: 16
rank: 6, global_rank: 6, world_size: 8, global_world_size: 16
rank: 6, global_rank: 6, world_size: 8, global_world_size: 16
rank: 6, global_rank: 6, world_size: 8, global_world_size: 16
rank: 6, global_rank: 6, world_size: 8, global_world_size: 16
rank: 7, global_rank: 7, world_size: 8, global_world_size: 16
rank: 7, global_rank: 7, world_size: 8, global_world_size: 16
rank: 7, global_rank: 7, world_size: 8, global_world_size: 16
rank: 7, global_rank: 7, world_size: 8, global_world_size: 16
rank: 7, global_rank: 7, world_size: 8, global_world_size: 16
rank: 3, global_rank: 3, world_size: 8, global_world_size: 16
rank: 3, global_rank: 3, world_size: 8, global_world_size: 16
rank: 3, global_rank: 3, world_size: 8, global_world_size: 16
rank: 3, global_rank: 3, world_size: 8, global_world_size: 16
rank: 3, global_rank: 3, world_size: 8, global_world_size: 16
rank: 1, global_rank: 1, world_size: 8, global_world_size: 16
rank: 1, global_rank: 1, world_size: 8, global_world_size: 16
rank: 1, global_rank: 1, world_size: 8, global_world_size: 16
rank: 1, global_rank: 1, world_size: 8, global_world_size: 16
rank: 1, global_rank: 1, world_size: 8, global_world_size: 16
rank: 2, global_rank: 2, world_size: 8, global_world_size: 16
rank: 5, global_rank: 5, world_size: 8, global_world_size: 16
rank: 4, global_rank: 4, world_size: 8, global_world_size: 16
rank: 2, global_rank: 2, world_size: 8, global_world_size: 16
rank: 5, global_rank: 5, world_size: 8, global_world_size: 16
rank: 4, global_rank: 4, world_size: 8, global_world_size: 16
rank: 2, global_rank: 2, world_size: 8, global_world_size: 16
rank: 5, global_rank: 5, world_size: 8, global_world_size: 16
rank: 4, global_rank: 4, world_size: 8, global_world_size: 16
rank: 5, global_rank: 5, world_size: 8, global_world_size: 16rank: 2, global_rank: 2, world_size: 8, global_world_size: 16

rank: 4, global_rank: 4, world_size: 8, global_world_size: 16
rank: 2, global_rank: 2, world_size: 8, global_world_size: 16
rank: 5, global_rank: 5, world_size: 8, global_world_size: 16
rank: 4, global_rank: 4, world_size: 8, global_world_size: 16
GPTParallel(
  (tok_embeddings): Embedding(128256, 16384)
  (layers): ModuleList(
    (0-125): 126 x ParallelTransformerBlock(
      semi_compiled = False
      (attention): FuseAttentionMLP(
        (wqkv1): Linear(in_features=16384, out_features=7936, bias=False)
        (wo): Linear(in_features=1024, out_features=16384, bias=False)
        (w2): Linear(in_features=3328, out_features=16384, bias=False)
      )
      (attention_norm): RMSr will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWar/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new contex/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
Compilation time: 136.64 seconds
Compilation time: 136.55 seconds
Compilation time: 136.64 seconds
Compilation time: 136.68 seconds
Compilation time: 136.56 seconds
Compilation time: 136.74 seconds
Compilation time: 136.56 seconds
Compilation time: 136.55 seconds
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
[rank8]:[W1118 23:59:45.729021042 ProcessGroupNCCL.cpp:1374] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
                                                                                                                                                                                                                                                            Decode latency: 22.835081084864214 sec
Prefill latency: 1.370183888124302 sec
Decode latency: 22.89597658603452 sec
Prefill latency: 1.3705443390645087 sec
Decode latency: 22.822250906843692 sec
Prefill latency: 1.3699602610431612 sec
Decode latency: 22.86237248708494 sec
Prefill latency: 1.3725058250129223 sec
Decode latency: 22.819646045099944 sec
Time for inference 1: 24.19 sec total, 169.29 tokens/sec
Decode latency: 22.82 sec
Prefill latency: 1.37 sec
Bandwidth achieved: 9301.05 GB/s
FLOPS achieved: 27.90 TF/s

Prefill latency: 1.3733461201190948 sec
Decode latency: 22.854043372906744 sec
Time for inference 2: 24.23 sec total, 169.05 tokens/sec
Decode latency: 22.85 sec
Prefill latency: 1.37 sec
Bandwidth achieved: 9287.54 GB/s
FLOPS achieved: 27.86 TF/s

Prefill latency: 1.373254565987736 sec
Decode latency: 22.901864792918786 sec
Time for inference 3: 24.28 sec total, 168.71 tokens/sec
Decode latency: 22.90 sec
Prefill latency: 1.37 sec
Bandwidth achieved: 9269.30 GB/s
FLOPS achieved: 27.81 TF/s

Prefill latency: 1.3722203348297626 sec
Decode latency: 22.919389464892447 sec
Time for inference 4: 24.29 sec total, 168.60 tokens/sec
Decode latency: 22.92 sec
Prefill latency: 1.37 sec
Bandwidth achieved: 9263.01 GB/s
FLOPS achieved: 27.79 TF/s

Prefill latency: 1.3716004090383649 sec
Decode latency: 22.92465620301664 sec
Time for inference 5: 24.30 sec total, 168.57 tokens/sec
Decode latency: 22.92 sec
Prefill latency: 1.37 sec
Bandwidth achieved: 9261.20 GB/s
FLOPS achieved: 27.78 TF/s

Prefill latency: 1.3730692190583795 sec
Decode latency: 22.866976927034557 sec
Time for inference 6: 24.24 sec total, 168.96 tokens/sec
Decode latency: 22.87 sec
Prefill latency: 1.37 sec
Bandwidth achieved: 9282.68 GB/s
FLOPS achieved: 27.85 TF/s

Prefill latency: 1.37139624892734 sec
Decode latency: 22.860125310951844 sec
Time for inference 7: 24.23 sec total, 169.02 tokens/sec
Decode latency: 22.86 sec
Prefill latency: 1.37 sec
Bandwidth achieved: 9286.01 GB/s
FLOPS achieved: 27.86 TF/s

Prefill latency: 1.3726261227857322 sec
Decode latency: 22.83008938608691 sec
Time for inference 8: 24.21 sec total, 169.22 tokens/sec
Decode latency: 22.83 sec
Prefill latency: 1.37 sec
Bandwidth achieved: 9297.01 GB/s
FLOPS achieved: 27.89 TF/s

Prefill latency: 1.3705146459396929 sec
Decode latency: 22.834800119977444 sec
Time for inference 9: 24.21 sec total, 169.20 tokens/sec
Decode latency: 22.83 sec
Prefill latency: 1.37 sec
Bandwidth achieved: 9296.09 GB/s
FLOPS achieved: 27.89 TF/s

Prefill latency: 1.371532215969637 sec
Decode latency: 22.852229957003146 sec
Time for inference 10: 24.23 sec total, 169.07 tokens/sec
Decode latency: 22.85 sec
Prefill latency: 1.37 sec
Bandwidth achieved: 9288.95 GB/s
FLOPS achieved: 27.87 TF/s

==========
Batch Size: 8
Prompt Length: 1024
Generated tokens: 512
Average decode latency: 22.8664 sec
Average prefill latency: 1.3722 sec
Average tokens/sec: 168.97
Memory used: 65.76 GB
Done. we are killing the process
[rank0]:[W1118 23:59:46.591458366 ProcessGroupNCCL.cpp:1374] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
