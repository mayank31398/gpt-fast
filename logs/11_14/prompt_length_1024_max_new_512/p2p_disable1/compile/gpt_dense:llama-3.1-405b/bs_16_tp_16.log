W1119 15:38:19.823000 72171 site-packages/torch/distributed/run.py:793] 
W1119 15:38:19.823000 72171 site-packages/torch/distributed/run.py:793] *****************************************
W1119 15:38:19.823000 72171 site-packages/torch/distributed/run.py:793] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W1119 15:38:19.823000 72171 site-packages/torch/distributed/run.py:793] *****************************************
rank: 6, global_rank: 14, world_size: 8, global_world_size: 16
rank: 0, global_rank: 8, world_size: 8, global_world_size: 16
rank: 5, global_rank: 13, world_size: 8, global_world_size: 16
rank: 1, global_rank: 9, world_size: 8, global_world_size: 16
rank: 2, global_rank: 10, world_size: 8, global_world_size: 16
rank: 3, global_rank: 11, world_size: 8, global_world_size: 16
rank: 4, global_rank: 12, world_size: 8, global_world_size: 16
rank: 7, global_rank: 15, world_size: 8, global_world_size: 16
rank: 0, global_rank: 8, world_size: 8, global_world_size: 16
rank: 0, global_rank: 8, world_size: 8, global_world_size: 16
rank: 0, global_rank: 8, world_size: 8, global_world_size: 16
rank: 0, global_rank: 8, world_size: 8, global_world_size: 16
rank: 0, global_rank: 8, world_size: 8, global_world_size: 16
rank: 5, global_rank: 13, world_size: 8, global_world_size: 16
rank: 5, global_rank: 13, world_size: 8, global_world_size: 16
rank: 5, global_rank: 13, world_size: 8, global_world_size: 16
rank: 5, global_rank: 13, world_size: 8, global_world_size: 16
rank: 5, global_rank: 13, world_size: 8, global_world_size: 16
rank: 1, global_rank: 9, world_size: 8, global_world_size: 16
rank: 1, global_rank: 9, world_size: 8, global_world_size: 16
rank: 1, global_rank: 9, world_size: 8, global_world_size: 16
rank: 1, global_rank: 9, world_size: 8, global_world_size: 16
rank: 1, global_rank: 9, world_size: 8, global_world_size: 16
rank: 3, global_rank: 11, world_size: 8, global_world_size: 16
rank: 7, global_rank: 15, world_size: 8, global_world_size: 16
rank: 3, global_rank: 11, world_size: 8, global_world_size: 16
rank: 7, global_rank: 15, world_size: 8, global_world_size: 16
rank: 3, global_rank: 11, world_size: 8, global_world_size: 16
rank: 7, global_rank: 15, world_size: 8, global_world_size: 16
rank: 3, global_rank: 11, world_size: 8, global_world_size: 16
rank: 4, global_rank: 12, world_size: 8, global_world_size: 16
rank: 7, global_rank: 15, world_size: 8, global_world_size: 16
rank: 3, global_rank: 11, world_size: 8, global_world_size: 16
rank: 4, global_rank: 12, world_size: 8, global_world_size: 16
rank: 7, global_rank: 15, world_size: 8, global_world_size: 16
rank: 4, global_rank: 12, world_size: 8, global_world_size: 16
rank: 4, global_rank: 12, world_size: 8, global_world_size: 16
rank: 4, global_rank: 12, world_size: 8, global_world_size: 16
rank: 2, global_rank: 10, world_size: 8, global_world_size: 16
rank: 6, global_rank: 14, world_size: 8, global_world_size: 16
rank: 6, global_rank: 14, world_size: 8, global_world_size: 16
rank: 2, global_rank: 10, world_size: 8, global_world_size: 16
rank: 6, global_rank: 14, world_size: 8, global_world_size: 16
rank: 2, global_rank: 10, world_size: 8, global_world_size: 16
rank: 6, global_rank: 14, world_size: 8, global_world_size: 16
rank: 2, global_rank: 10, world_size: 8, global_world_size: 16
rank: 6, global_rank: 14, world_size: 8, global_world_size: 16
rank: 2, global_rank: 10, world_size: 8, global_world_size: 16
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will b  (w2): Linear(in_features=3328, out_features=16384, bias=False)
      )
      (ffn_norm): RMSNorm()
      (attention_norm): RMSNorm()
    )
  )
  (norm): RMSNorm()
  (output): Linear(in_features=16384, out_features=128256, bias=False)
)
Time to load model: 1.53 seconds
Compiling prefill with dynamic=False
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this /home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `tw context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
Prefill latency: 87.98550436482765 sec
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
Compilation time: 338.15 secondsCompilation time: 338.04 seconds

Compilation time: 338.46 seconds
Compilation time: 337.98 seconds
Compilation time: 338.21 seconds
Compilation time: 338.09 seconds
Compilation time: 338.08 seconds
Compilation time: 338.06 seconds
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
harlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/li[rank8]:[W1119 15:53:16.966759043 ProcessGroupNCCL.cpp:1374] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
 manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
Decode latency: 33.80345213599503 sec
Prefill latency: 3.6221379758790135 sec
Decode latency: 33.75987052009441 sec
Prefill latency: 3.623939403798431 sec
Decode latency: 33.80815767496824 sec
Prefill latency: 3.62662303308025 sec
Decode latency: 33.6827390328981 sec
Prefill latency: 3.629351526964456 sec
Decode latency: 33.760832795873284 sec
Time for inference 1: 37.39 sec total, 219.08 tokens/sec
Decode latency: 33.76 sec
Prefill latency: 3.63 sec
Bandwidth achieved: 12037.18 GB/s
FLOPS achieved: 36.11 TF/s

Prefill latency: 3.63007083395496 sec
Decode latency: 33.75174736906774 sec
Time for inference 2: 37.38 sec total, 219.13 tokens/sec
Decode latency: 33.75 sec
Prefill latency: 3.63 sec
Bandwidth achieved: 12039.91 GB/s
FLOPS achieved: 36.12 TF/s

Prefill latency: 3.6261580439750105 sec
Decode latency: 33.77750907512382 sec
Time for inference 3: 37.41 sec total, 219.00 tokens/sec
Decode latency: 33.78 sec
Prefill latency: 3.63 sec
Bandwidth achieved: 12032.97 GB/s
FLOPS achieved: 36.10 TF/s

Prefill latency: 3.6244208889547735 sec
Decode latency: 33.70951768709347 sec
Time for inference 4: 37.34 sec total, 219.41 tokens/sec
Decode latency: 33.71 sec
Prefill latency: 3.62 sec
Bandwidth achieved: 12055.40 GB/s
FLOPS achieved: 36.17 TF/s

Prefill latency: 3.63689441094175 sec
Decode latency: 33.7539206428919 sec
Time for inference 5: 37.39 sec total, 219.07 tokens/sec
Decode latency: 33.75 sec
Prefill latency: 3.64 sec
Bandwidth achieved: 12037.02 GB/s
FLOPS achieved: 36.11 TF/s

Prefill latency: 3.6298259110189974 sec
Decode latency: 33.79926291597076 sec
Time for inference 6: 37.43 sec total, 218.85 tokens/sec
Decode latency: 33.80 sec
Prefill latency: 3.63 sec
Bandwidth achieved: 12024.72 GB/s
FLOPS achieved: 36.07 TF/s

Prefill latency: 3.6252844179980457 sec
Decode latency: 33.73257601400837 sec
Time for inference 7: 37.36 sec total, 219.27 tokens/sec
Decode latency: 33.73 sec
Prefill latency: 3.63 sec
Bandwidth achieved: 12047.68 GB/s
FLOPS achieved: 36.14 TF/s

Prefill latency: 3.624713101889938 sec
Decode latency: 33.69927774905227 sec
Time for inference 8: 37.33 sec total, 219.46 tokens/sec
Decode latency: 33.70 sec
Prefill latency: 3.62 sec
Bandwidth achieved: 12058.56 GB/s
FLOPS achieved: 36.18 TF/s

Prefill latency: 3.631065870868042 sec
Decode latency: 33.80651324801147 sec
Time for inference 9: 37.44 sec total, 218.80 tokens/sec
Decode latency: 33.81 sec
Prefill latency: 3.63 sec
Bandwidth achieved: 12022.05 GB/s
FLOPS achieved: 36.07 TF/s

Prefill latency: 3.626051084836945 sec
Decode latency: 33.769315040903166 sec
Time for inference 10: 37.40 sec total, 219.05 tokens/sec
Decode latency: 33.77 sec
Prefill latency: 3.63 sec
Bandwidth achieved: 12035.56 GB/s
FLOPS achieved: 36.11 TF/s

==========
Batch Size: 16
Prompt Length: 1024
Generated tokens: 512
Average decode latency: 33.7561 sec
Average prefill latency: 3.6284 sec
Average tokens/sec: 219.11
Memory used: 72.21 GB
Done. we are killing the process
[rank0]:[W1119 15:53:14.730006601 ProcessGroupNCCL.cpp:1374] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
