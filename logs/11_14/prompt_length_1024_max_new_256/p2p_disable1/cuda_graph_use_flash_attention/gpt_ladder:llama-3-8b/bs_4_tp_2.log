W1113 12:07:15.415000 1450836 site-packages/torch/distributed/run.py:793] 
W1113 12:07:15.415000 1450836 site-packages/torch/distributed/run.py:793] *****************************************
W1113 12:07:15.415000 1450836 site-packages/torch/distributed/run.py:793] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W1113 12:07:15.415000 1450836 site-packages/torch/distributed/run.py:793] *****************************************
flash_kv_decode is set to True
Using device=cuda
Loading model ...
GPTLadder(
  (tok_embeddings): Embedding(128256, 4096)
  (layers): ModuleList(
    (0-31): 32 x LadderTransformerBlock(
      semi_compiled = False
      (attention): Attention(
        (wqkv): Linear(in_features=4096, out_features=3072, bias=False)
        (wo): Linear(in_features=2048, out_features=4096, bias=False)
      )
      (feed_forward): FeedForward(
        (w1): Linear(in_features=4096, out_features=14336, bias=False)
        (w2): Linear(in_features=7168, out_features=4096, bias=False)
      )
      (ffn_norm): RMSNorm()
      (attention_norm): RMSNorm()
    )
  )
  (norm): RMSNorm()
  (output): Linear(in_features=4096, out_features=128256, bias=False)
)
Time to load model: 0.53 seconds
CUDA_GRAPH are activate
[rank0]:[W1113 12:07:23.329057985 CUDAGraph.cpp:133] Warning: Waiting for pending NCCL work to finish before starting graph capture. (function operator())
[rank1]:[W1113 12:07:23.329889600 CUDAGraph.cpp:133] Warning: Waiting for pending NCCL work to finish before starting graph capture. (function operator())
Prefill latency: 0.17984013445675373 sec
Decode latency: 1.7487939968705177 sec
Compilation time: 1.94 seconds
Compilation time: 1.96 seconds
Prefill latency: 0.1694521177560091 sec
Decode latency: 1.7475537490099669 sec
Prefill latency: 0.16926725208759308 sec
Decode latency: 1.7475422881543636 sec
Prefill latency: 0.1692262962460518 sec
Decode latency: 1.7478640601038933 sec
Prefill latency: 0.16951153427362442 sec
Decode latency: 1.747551754117012 sec
Prefill latency: 0.1691900845617056 sec
Decode latency: 1.747097473591566 sec
Time for inference 1: 1.92 sec total, 534.19 tokens/sec
Decode latency: 1.75 sec
Prefill latency: 0.17 sec
Bandwidth achieved: 4289.83 GB/s
FLOPS achieved: 21.45 TF/s

Prefill latency: 0.16945833154022694 sec
Decode latency: 1.747018838301301 sec
Time for inference 2: 1.92 sec total, 534.13 tokens/sec
Decode latency: 1.75 sec
Prefill latency: 0.17 sec
Bandwidth achieved: 4289.36 GB/s
FLOPS achieved: 21.45 TF/s

Prefill latency: 0.16910299472510815 sec
Decode latency: 1.7463817559182644 sec
Time for inference 3: 1.92 sec total, 534.42 tokens/sec
Decode latency: 1.75 sec
Prefill latency: 0.17 sec
Bandwidth achieved: 4291.70 GB/s
FLOPS achieved: 21.46 TF/s

Prefill latency: 0.1692724134773016 sec
Decode latency: 1.7478328105062246 sec
Time for inference 4: 1.92 sec total, 533.96 tokens/sec
Decode latency: 1.75 sec
Prefill latency: 0.17 sec
Bandwidth achieved: 4287.98 GB/s
FLOPS achieved: 21.44 TF/s

Prefill latency: 0.1687113121151924 sec
Decode latency: 1.7471070364117622 sec
Time for inference 5: 1.92 sec total, 534.32 tokens/sec
Decode latency: 1.75 sec
Prefill latency: 0.17 sec
Bandwidth achieved: 4290.89 GB/s
FLOPS achieved: 21.45 TF/s

Prefill latency: 0.16882017999887466 sec
Decode latency: 1.7470424212515354 sec
Time for inference 6: 1.92 sec total, 534.30 tokens/sec
Decode latency: 1.75 sec
Prefill latency: 0.17 sec
Bandwidth achieved: 4290.73 GB/s
FLOPS achieved: 21.45 TF/s

Prefill latency: 0.16891473159193993 sec
Decode latency: 1.7465743478387594 sec
Time for inference 7: 1.92 sec total, 534.42 tokens/sec
Decode latency: 1.75 sec
Prefill latency: 0.17 sec
Bandwidth achieved: 4291.69 GB/s
FLOPS achieved: 21.46 TF/s

Prefill latency: 0.1692494247108698 sec
Decode latency: 1.7473548389971256 sec
Time for inference 8: 1.92 sec total, 534.07 tokens/sec
Decode latency: 1.75 sec
Prefill latency: 0.17 sec
Bandwidth achieved: 4288.86 GB/s
FLOPS achieved: 21.44 TF/s

Prefill latency: 0.16944832354784012 sec
Decode latency: 1.7477647345513105 sec
Time for inference 9: 1.92 sec total, 533.93 tokens/sec
Decode latency: 1.75 sec
Prefill latency: 0.17 sec
Bandwidth achieved: 4287.71 GB/s
FLOPS achieved: 21.44 TF/s

Prefill latency: 0.1690247356891632 sec
Decode latency: 1.7481334581971169 sec
Time for inference 10: 1.92 sec total, 533.95 tokens/sec
Decode latency: 1.75 sec
Prefill latency: 0.17 sec
Bandwidth achieved: 4287.94 GB/s
FLOPS achieved: 21.44 TF/s

==========
Batch Size: 4
Prompt Length: 1024
Generated tokens: 256
Average decode latency: 1.7472 sec
Average prefill latency: 0.1691 sec
Average tokens/sec: 534.17
Memory used: 14.64 GB
Done. we are killing the process
[rank0]:[W1113 12:07:52.683726340 ProcessGroupNCCL.cpp:1374] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
