W1113 12:08:33.509000 1452032 site-packages/torch/distributed/run.py:793] 
W1113 12:08:33.509000 1452032 site-packages/torch/distributed/run.py:793] *****************************************
W1113 12:08:33.509000 1452032 site-packages/torch/distributed/run.py:793] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W1113 12:08:33.509000 1452032 site-packages/torch/distributed/run.py:793] *****************************************
flash_kv_decode is set to True
Using device=cuda
Loading model ...
GPTLadder(
  (tok_embeddings): Embedding(128256, 4096)
  (layers): ModuleList(
    (0-31): 32 x LadderTransformerBlock(
      semi_compiled = False
      (attention): Attention(
        (wqkv): Linear(in_features=4096, out_features=768, bias=False)
        (wo): Linear(in_features=512, out_features=4096, bias=False)
      )
      (feed_forward): FeedForward(
        (w1): Linear(in_features=4096, out_features=3584, bias=False)
        (w2): Linear(in_features=1792, out_features=4096, bias=False)
      )
      (ffn_norm): RMSNorm()
      (attention_norm): RMSNorm()
    )
  )
  (norm): RMSNorm()
  (output): Linear(in_features=4096, out_features=128256, bias=False)
)
Time to load model: 1.29 seconds
CUDA_GRAPH are activate
[rank0]:[W1113 12:08:52.369787958 CUDAGraph.cpp:133] Warning: Waiting for pending NCCL work to finish before starting graph capture. (function operator())
[rank1]:[W1113 12:08:53.086586501 CUDAGraph.cpp:133] Warning: Waiting for pending NCCL work to finish before starting graph capture. (function operator())
Prefill latency: 0.0606553815305233 sec
Decode latency: 1.474202649667859 sec
Compilation time: 1.52 seconds
Compilation time: 1.52 seconds
Compilation time: 1.54 seconds
Compilation time: 1.54 secondsCompilation time: 1.53 seconds

Compilation time: 1.51 seconds
Compilation time: 1.52 seconds
Compilation time: 1.54 seconds
Prefill latency: 0.04473420977592468 sec
Decode latency: 1.4669054970145226 sec
Prefill latency: 0.03935171104967594 sec
Decode latency: 1.458985846489668 sec
Prefill latency: 0.04090232215821743 sec
Decode latency: 1.4653610028326511 sec
Prefill latency: 0.03861795738339424 sec
Decode latency: 1.4753104764968157 sec
Prefill latency: 0.037285326048731804 sec
Decode latency: 1.4714884962886572 sec
Time for inference 1: 1.51 sec total, 678.25 tokens/sec
Decode latency: 1.47 sec
Prefill latency: 0.04 sec
Bandwidth achieved: 1896.42 GB/s
FLOPS achieved: 9.48 TF/s

Prefill latency: 0.040479158982634544 sec
Decode latency: 1.462252739816904 sec
Time for inference 2: 1.50 sec total, 681.03 tokens/sec
Decode latency: 1.46 sec
Prefill latency: 0.04 sec
Bandwidth achieved: 1904.20 GB/s
FLOPS achieved: 9.52 TF/s

Prefill latency: 0.037776872515678406 sec
Decode latency: 1.4732677731662989 sec
Time for inference 3: 1.51 sec total, 677.28 tokens/sec
Decode latency: 1.47 sec
Prefill latency: 0.04 sec
Bandwidth achieved: 1893.71 GB/s
FLOPS achieved: 9.47 TF/s

Prefill latency: 0.03756552189588547 sec
Decode latency: 1.4591607116162777 sec
Time for inference 4: 1.50 sec total, 683.78 tokens/sec
Decode latency: 1.46 sec
Prefill latency: 0.04 sec
Bandwidth achieved: 1911.88 GB/s
FLOPS achieved: 9.56 TF/s

Prefill latency: 0.03794029541313648 sec
Decode latency: 1.4610819444060326 sec
Time for inference 5: 1.50 sec total, 682.78 tokens/sec
Decode latency: 1.46 sec
Prefill latency: 0.04 sec
Bandwidth achieved: 1909.08 GB/s
FLOPS achieved: 9.55 TF/s

Prefill latency: 0.037863655015826225 sec
Decode latency: 1.4733085166662931 sec
Time for inference 6: 1.51 sec total, 677.18 tokens/sec
Decode latency: 1.47 sec
Prefill latency: 0.04 sec
Bandwidth achieved: 1893.43 GB/s
FLOPS achieved: 9.47 TF/s

Prefill latency: 0.03763473220169544 sec
Decode latency: 1.4873612485826015 sec
Time for inference 7: 1.53 sec total, 671.09 tokens/sec
Decode latency: 1.49 sec
Prefill latency: 0.04 sec
Bandwidth achieved: 1876.40 GB/s
FLOPS achieved: 9.38 TF/s

Prefill latency: 0.038259001448750496 sec
Decode latency: 1.465466933324933 sec
Time for inference 8: 1.50 sec total, 680.66 tokens/sec
Decode latency: 1.47 sec
Prefill latency: 0.04 sec
Bandwidth achieved: 1903.16 GB/s
FLOPS achieved: 9.52 TF/s

Prefill latency: 0.04103614017367363 sec
Decode latency: 1.4631744138896465 sec
Time for inference 9: 1.51 sec total, 680.38 tokens/sec
Decode latency: 1.46 sec
Prefill latency: 0.04 sec
Bandwidth achieved: 1902.37 GB/s
FLOPS achieved: 9.51 TF/s

Prefill latency: 0.04019716754555702 sec
Decode latency: 1.4627324379980564 sec
Time for inference 10: 1.50 sec total, 680.86 tokens/sec
Decode latency: 1.46 sec
Prefill latency: 0.04 sec
Bandwidth achieved: 1903.70 GB/s
FLOPS achieved: 9.52 TF/s

==========
Batch Size: 4
Prompt Length: 1024
Generated tokens: 256
Average decode latency: 1.4679 sec
Average prefill latency: 0.0386 sec
Average tokens/sec: 679.33
Memory used: 7.44 GB
Done. we are killing the process
[rank0]:[W1113 12:09:16.473439844 ProcessGroupNCCL.cpp:1374] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
