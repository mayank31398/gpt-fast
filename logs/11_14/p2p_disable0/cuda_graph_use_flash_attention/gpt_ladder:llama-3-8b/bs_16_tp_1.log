flash_kv_decode is set to True
Using device=cuda
Loading model ...
GPTLadder(
  (tok_embeddings): Embedding(128256, 4096)
  (layers): ModuleList(
    (0-31): 32 x LadderTransformerBlock(
      semi_compiled = False
      (attention): Attention(
        (wqkv): Linear(in_features=4096, out_features=6144, bias=False)
        (wo): Linear(in_features=4096, out_features=4096, bias=False)
      )
      (feed_forward): FeedForward(
        (w1): Linear(in_features=4096, out_features=28672, bias=False)
        (w2): Linear(in_features=14336, out_features=4096, bias=False)
      )
      (ffn_norm): RMSNorm()
      (attention_norm): RMSNorm()
    )
  )
  (norm): RMSNorm()
  (output): Linear(in_features=4096, out_features=128256, bias=False)
)
Time to load model: 0.88 seconds
CUDA_GRAPH are activate
[rank0]:[W1113 10:52:09.396784308 CUDAGraph.cpp:150] Warning: Waiting for pending NCCL work to finish before starting graph capture. (function operator())
Prefill latency: 0.5247694849967957 sec
Decode latency: 2.6090743355453014 sec
Compilation time: 3.13 seconds
Prefill latency: 0.5283636804670095 sec
Decode latency: 2.6069277115166187 sec
Prefill latency: 0.5265941191464663 sec
Decode latency: 2.60785405151546 sec
Prefill latency: 0.5270974095910788 sec
Decode latency: 2.60636168345809 sec
Prefill latency: 0.5291265696287155 sec
Decode latency: 2.606594832614064 sec
Prefill latency: 0.5279163643717766 sec
Decode latency: 2.605739751830697 sec
Time for inference 1: 3.13 sec total, 1306.76 tokens/sec
Decode latency: 2.61 sec
Prefill latency: 0.53 sec
Bandwidth achieved: 19614.27 GB/s
FLOPS achieved: 98.07 TF/s

Prefill latency: 0.5291774682700634 sec
Decode latency: 2.606599647551775 sec
Time for inference 2: 3.14 sec total, 1305.90 tokens/sec
Decode latency: 2.61 sec
Prefill latency: 0.53 sec
Bandwidth achieved: 19601.33 GB/s
FLOPS achieved: 98.01 TF/s

Prefill latency: 0.5293365623801947 sec
Decode latency: 2.6061645839363337 sec
Time for inference 3: 3.14 sec total, 1306.03 tokens/sec
Decode latency: 2.61 sec
Prefill latency: 0.53 sec
Bandwidth achieved: 19603.30 GB/s
FLOPS achieved: 98.02 TF/s

Prefill latency: 0.5292523633688688 sec
Decode latency: 2.605827445164323 sec
Time for inference 4: 3.14 sec total, 1306.26 tokens/sec
Decode latency: 2.61 sec
Prefill latency: 0.53 sec
Bandwidth achieved: 19606.69 GB/s
FLOPS achieved: 98.03 TF/s

Prefill latency: 0.5275098010897636 sec
Decode latency: 2.605190297588706 sec
Time for inference 5: 3.13 sec total, 1307.24 tokens/sec
Decode latency: 2.61 sec
Prefill latency: 0.53 sec
Bandwidth achieved: 19621.53 GB/s
FLOPS achieved: 98.11 TF/s

Prefill latency: 0.5297723449766636 sec
Decode latency: 2.606839921325445 sec
Time for inference 6: 3.14 sec total, 1305.60 tokens/sec
Decode latency: 2.61 sec
Prefill latency: 0.53 sec
Bandwidth achieved: 19596.87 GB/s
FLOPS achieved: 97.98 TF/s

Prefill latency: 0.527839433401823 sec
Decode latency: 2.606239266693592 sec
Time for inference 7: 3.13 sec total, 1306.66 tokens/sec
Decode latency: 2.61 sec
Prefill latency: 0.53 sec
Bandwidth achieved: 19612.79 GB/s
FLOPS achieved: 98.06 TF/s

Prefill latency: 0.5279629547148943 sec
Decode latency: 2.606676612049341 sec
Time for inference 8: 3.14 sec total, 1306.45 tokens/sec
Decode latency: 2.61 sec
Prefill latency: 0.53 sec
Bandwidth achieved: 19609.55 GB/s
FLOPS achieved: 98.05 TF/s

Prefill latency: 0.5299554411321878 sec
Decode latency: 2.6068239212036133 sec
Time for inference 9: 3.14 sec total, 1305.54 tokens/sec
Decode latency: 2.61 sec
Prefill latency: 0.53 sec
Bandwidth achieved: 19595.95 GB/s
FLOPS achieved: 97.98 TF/s

Prefill latency: 0.5293712746351957 sec
Decode latency: 2.608283143490553 sec
Time for inference 10: 3.14 sec total, 1305.09 tokens/sec
Decode latency: 2.61 sec
Prefill latency: 0.53 sec
Bandwidth achieved: 19589.14 GB/s
FLOPS achieved: 97.95 TF/s

==========
Batch Size: 16
Prompt Length: 1024
Generated tokens: 256
Average decode latency: 2.6064 sec
Average prefill latency: 0.5288 sec
Average tokens/sec: 1306.15
Memory used: 35.41 GB
Done. we are killing the process
