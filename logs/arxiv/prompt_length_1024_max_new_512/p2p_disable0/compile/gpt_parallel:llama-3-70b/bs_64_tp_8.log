W1210 15:04:40.366000 1067371 site-packages/torch/distributed/run.py:793] 
W1210 15:04:40.366000 1067371 site-packages/torch/distributed/run.py:793] *****************************************
W1210 15:04:40.366000 1067371 site-packages/torch/distributed/run.py:793] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W1210 15:04:40.366000 1067371 site-packages/torch/distributed/run.py:793] *****************************************
rank: 7, global_rank: 7, world_size: 8, global_world_size: 8rank: 1, global_rank: 1, world_size: 8, global_world_size: 8

rank: 2, global_rank: 2, world_size: 8, global_world_size: 8
rank: 0, global_rank: 0, world_size: 8, global_world_size: 8
rank: 3, global_rank: 3, world_size: 8, global_world_size: 8
rank: 4, global_rank: 4, world_size: 8, global_world_size: 8
rank: 6, global_rank: 6, world_size: 8, global_world_size: 8
rank: 5, global_rank: 5, world_size: 8, global_world_size: 8
rank: 0, global_rank: 0, world_size: 8, global_world_size: 8
rank: 0, global_rank: 0, world_size: 8, global_world_size: 8
rank: 0, global_rank: 0, world_size: 8, global_world_size: 8
rank: 0, global_rank: 0, world_size: 8, global_world_size: 8
flash_kv_decode is set to False
rank: 0, global_rank: 0, world_size: 8, global_world_size: 8
our world size=8
Using device=cuda
Loading model ...
rank: 7, global_rank: 7, world_size: 8, global_world_size: 8
rank: 7, global_rank: 7, world_size: 8, global_world_size: 8
rank: 7, global_rank: 7, world_size: 8, global_world_size: 8
rank: 5, global_rank: 5, world_size: 8, global_world_size: 8
rank: 5, global_rank: 5, world_size: 8, global_world_size: 8
rank: 7, global_rank: 7, world_size: 8, global_world_size: 8
rank: 5, global_rank: 5, world_size: 8, global_world_size: 8
rank: 7, global_rank: 7, world_size: 8, global_world_size: 8
rank: 5, global_rank: 5, world_size: 8, global_world_size: 8
rank: 5, global_rank: 5, world_size: 8, global_world_size: 8
rank: 6, global_rank: 6, world_size: 8, global_world_size: 8
rank: 6, global_rank: 6, world_size: 8, global_world_size: 8
rank: 6, global_rank: 6, world_size: 8, global_world_size: 8
rank: 6, global_rank: 6, world_size: 8, global_world_size: 8
rank: 6, global_rank: 6, world_size: 8, global_world_size: 8
rank: 4, global_rank: 4, world_size: 8, global_world_size: 8
rank: 2, global_rank: 2, world_size: 8, global_world_size: 8
rank: 4, global_rank: 4, world_size: 8, global_world_size: 8
rank: 2, global_rank: 2, world_size: 8, global_world_size: 8
rank: 4, global_rank: 4, world_size: 8, global_world_size: 8
rank: 2, global_rank: 2, world_size: 8, global_world_size: 8
rank: 4, global_rank: 4, world_size: 8, global_world_size: 8
rank: 2, global_rank: 2, world_size: 8, global_world_size: 8
rank: 4, global_rank: 4, world_size: 8, global_world_size: 8
rank: 2, global_rank: 2, world_size: 8, global_world_size: 8
rank: 3, global_rank: 3, world_size: 8, global_world_size: 8
rank: 1, global_rank: 1, world_size: 8, global_world_size: 8
rank: 3, global_rank: 3, world_size: 8, global_world_size: 8
rank: 1, global_rank: 1, world_size: 8, global_world_size: 8
rank: 3, global_rank: 3, world_size: 8, global_world_size: 8
rank: 1, global_rank: 1, world_size: 8, global_world_size: 8
rank: 1, global_rank: 1, world_size: 8, global_world_size: 8rank: 3, global_rank: 3, world_size: 8, global_world_size: 8

rank: 1, global_rank: 1, world_size: 8, global_world_size: 8rank: 3, global_rank: 3, world_size: 8, global_world_size: 8

/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
GPTParallel(
  (tok_embeddings): Embedding(128256, 8192)
  (layers): ModuleList(
    (0-79): 80 x ParallelTransformerBlock(
      semi_compiled = False
      (attention): FuseAttentionMLP(
        (wqkv1): Linear(in_features=8192, out_features=8448, bias=False)
        (wo): Linear(in_features=1024, out_features=8192, bias=False)
        (w2): Linear(in_features=3584, out_features=8192, bias=False)
      )
      (attention_norm): RMSNorm()
    )
  )
  (norm): RMSNorm()
  (output): Linear(in_features=8192, out_features=128256, bias=False)
)
Time to load model: 1.77 seconds
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
Compiling prefill with dynamic=False
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
Prefill latency: 41.562066216021776 sec
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
Decode latency: 38.90511032938957 sec
Compilation time: 80.64 secondsCompilation time: 80.47 seconds

Compilation time: 80.52 seconds
Compilation time: 80.63 seconds
Compilation time: 80.56 seconds
Compilation time: 80.57 seconds
Compilation time: 80.58 seconds
Compilation time: 80.52 seconds
Prefill latency: 3.6579395411536098 sec
Decode latency: 10.831830917857587 sec
Prefill latency: 3.6640105210244656 sec
Decode latency: 10.82840955350548 sec
Prefill latency: 3.6653056303039193 sec
Decode latency: 10.831375560723245 sec
Prefill latency: 3.6708927610889077 sec
Decode latency: 10.828891172073781 sec
Prefill latency: 3.670726926997304 sec
Decode latency: 10.827476996928453 sec
Time for inference 1: 14.50 sec total, 2259.86 tokens/sec
Decode latency: 10.83 sec
Prefill latency: 3.67 sec
Bandwidth achieved: 43424.21 GB/s
FLOPS achieved: 130.27 TF/s

Prefill latency: 3.6703209467232227 sec
Decode latency: 10.827749371528625 sec
Time for inference 2: 14.50 sec total, 2259.87 tokens/sec
Decode latency: 10.83 sec
Prefill latency: 3.67 sec
Bandwidth achieved: 43424.45 GB/s
FLOPS achieved: 130.27 TF/s

Prefill latency: 3.6706706611439586 sec
Decode latency: 10.82754466868937 sec
Time for inference 3: 14.50 sec total, 2259.86 tokens/sec
Decode latency: 10.83 sec
Prefill latency: 3.67 sec
Bandwidth achieved: 43424.18 GB/s
FLOPS achieved: 130.27 TF/s

Prefill latency: 3.670351185835898 sec
Decode latency: 10.830660495907068 sec
Time for inference 4: 14.50 sec total, 2259.40 tokens/sec
Decode latency: 10.83 sec
Prefill latency: 3.67 sec
Bandwidth achieved: 43415.40 GB/s
FLOPS achieved: 130.25 TF/s

Prefill latency: 3.667045312933624 sec
Decode latency: 10.827395075000823 sec
Time for inference 5: 14.50 sec total, 2260.43 tokens/sec
Decode latency: 10.83 sec
Prefill latency: 3.67 sec
Bandwidth achieved: 43435.09 GB/s
FLOPS achieved: 130.31 TF/s

Prefill latency: 3.674134870991111 sec
Decode latency: 10.831175116822124 sec
Time for inference 6: 14.51 sec total, 2258.72 tokens/sec
Decode latency: 10.83 sec
Prefill latency: 3.67 sec
Bandwidth achieved: 43402.29 GB/s
FLOPS achieved: 130.21 TF/s

Prefill latency: 3.675114205107093 sec
Decode latency: 10.829830149188638 sec
Time for inference 7: 14.51 sec total, 2258.80 tokens/sec
Decode latency: 10.83 sec
Prefill latency: 3.68 sec
Bandwidth achieved: 43403.89 GB/s
FLOPS achieved: 130.21 TF/s

Prefill latency: 3.673923888243735 sec
Decode latency: 10.828002250753343 sec
Time for inference 8: 14.50 sec total, 2259.27 tokens/sec
Decode latency: 10.83 sec
Prefill latency: 3.67 sec
Bandwidth achieved: 43412.87 GB/s
FLOPS achieved: 130.24 TF/s

Prefill latency: 3.672422356903553 sec
Decode latency: 10.83200604096055 sec
Time for inference 9: 14.51 sec total, 2258.89 tokens/sec
Decode latency: 10.83 sec
Prefill latency: 3.67 sec
Bandwidth achieved: 43405.62 GB/s
FLOPS achieved: 130.22 TF/s

Prefill latency: 3.675328695215285 sec
Decode latency: 10.830390414223075 sec
Time for inference 10: 14.51 sec total, 2258.68 tokens/sec
Decode latency: 10.83 sec
Prefill latency: 3.68 sec
Bandwidth achieved: 43401.43 GB/s
FLOPS achieved: 130.20 TF/s

==========
Batch Size: 64
Prompt Length: 1024
Generated tokens: 512
Average decode latency: 10.8292 sec
Average prefill latency: 3.6720 sec
Average tokens/sec: 2259.38
Memory used: 62.86 GB
Done. we are killing the process
[rank0]:[W1210 15:09:31.864067402 ProcessGroupNCCL.cpp:1374] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
