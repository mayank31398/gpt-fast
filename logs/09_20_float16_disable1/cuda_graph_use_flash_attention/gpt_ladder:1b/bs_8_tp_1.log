flash_kv_decode is set to True
Using device=cuda
Loading model ...
GPTLadder(
  (tok_embeddings): Embedding(49152, 1536)
  (layers): ModuleList(
    (0-39): 40 x LadderTransformerBlock(
      semi_compiled = False
      (attention): Attention(
        (wqkv): Linear(in_features=1536, out_features=2560, bias=False)
        (wo): Linear(in_features=1536, out_features=1536, bias=False)
      )
      (feed_forward): FeedForward(
        (w1): Linear(in_features=1536, out_features=8192, bias=False)
        (w2): Linear(in_features=4096, out_features=1536, bias=False)
      )
      (ffn_norm): RMSNorm()
      (attention_norm): RMSNorm()
    )
  )
  (norm): RMSNorm()
  (output): Linear(in_features=1536, out_features=49152, bias=False)
)
Time to load model: 0.14 seconds
[rank0]:[W930 20:01:35.923315306 CUDAGraph.cpp:150] Warning: Waiting for pending NCCL work to finish before starting graph capture. (function operator())
Prefill latency: 0.09301258902996778 sec
Decode latency: 3.0089532849378884 sec
Compilation time: 3.10 seconds
Prefill latency: 0.09271612402517349 sec
Decode latency: 3.0074322670698166 sec
Prefill latency: 0.09273004007991403 sec
Decode latency: 3.0095469360239804 sec
Prefill latency: 0.09269614797085524 sec
Decode latency: 3.010162723949179 sec
Prefill latency: 0.09278191206976771 sec
Decode latency: 3.0099685090826824 sec
Prefill latency: 0.09275283303577453 sec
Decode latency: 3.0080184490652755 sec
Time for inference 1: 3.10 sec total, 660.30 tokens/sec
Decode latency: 3.01 sec
Prefill latency: 0.09 sec
Bandwidth achieved: 1429.23 GB/s
FLOPS achieved: 7.15 TF/s

Prefill latency: 0.09274155599996448 sec
Decode latency: 3.002547628013417 sec
Time for inference 2: 3.10 sec total, 661.49 tokens/sec
Decode latency: 3.00 sec
Prefill latency: 0.09 sec
Bandwidth achieved: 1431.79 GB/s
FLOPS achieved: 7.16 TF/s

Prefill latency: 0.0924387100385502 sec
Decode latency: 3.0015089630614966 sec
Time for inference 3: 3.09 sec total, 661.79 tokens/sec
Decode latency: 3.00 sec
Prefill latency: 0.09 sec
Bandwidth achieved: 1432.44 GB/s
FLOPS achieved: 7.16 TF/s

Prefill latency: 0.0925276440102607 sec
Decode latency: 3.0021579889580607 sec
Time for inference 4: 3.10 sec total, 661.61 tokens/sec
Decode latency: 3.00 sec
Prefill latency: 0.09 sec
Bandwidth achieved: 1432.07 GB/s
FLOPS achieved: 7.16 TF/s

Prefill latency: 0.09251980599947274 sec
Decode latency: 3.00200106902048 sec
Time for inference 5: 3.10 sec total, 661.65 tokens/sec
Decode latency: 3.00 sec
Prefill latency: 0.09 sec
Bandwidth achieved: 1432.14 GB/s
FLOPS achieved: 7.16 TF/s

Prefill latency: 0.09252632490824908 sec
Decode latency: 3.0021919780410826 sec
Time for inference 6: 3.10 sec total, 661.61 tokens/sec
Decode latency: 3.00 sec
Prefill latency: 0.09 sec
Bandwidth achieved: 1432.06 GB/s
FLOPS achieved: 7.16 TF/s

Prefill latency: 0.09253655199427158 sec
Decode latency: 3.002332215080969 sec
Time for inference 7: 3.10 sec total, 661.57 tokens/sec
Decode latency: 3.00 sec
Prefill latency: 0.09 sec
Bandwidth achieved: 1431.97 GB/s
FLOPS achieved: 7.16 TF/s

Prefill latency: 0.09258698299527168 sec
Decode latency: 3.0020105950534344 sec
Time for inference 8: 3.10 sec total, 661.64 tokens/sec
Decode latency: 3.00 sec
Prefill latency: 0.09 sec
Bandwidth achieved: 1432.12 GB/s
FLOPS achieved: 7.16 TF/s

Prefill latency: 0.0925333610503003 sec
Decode latency: 3.002475172979757 sec
Time for inference 9: 3.10 sec total, 661.54 tokens/sec
Decode latency: 3.00 sec
Prefill latency: 0.09 sec
Bandwidth achieved: 1431.90 GB/s
FLOPS achieved: 7.16 TF/s

Prefill latency: 0.09255852305795997 sec
Decode latency: 3.001983652007766 sec
Time for inference 10: 3.10 sec total, 661.64 tokens/sec
Decode latency: 3.00 sec
Prefill latency: 0.09 sec
Bandwidth achieved: 1432.12 GB/s
FLOPS achieved: 7.16 TF/s

==========
Batch Size: 8
Prompt Length: 1024
Generated tokens: 256
Average decode latency: 3.0027 sec
Average prefill latency: 0.0926 sec
Average tokens/sec: 661.48
Memory used: 7.30 GB
Done. we are killing the process
