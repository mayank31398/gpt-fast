W0930 20:07:54.874000 23383375132480 torch/distributed/run.py:779] 
W0930 20:07:54.874000 23383375132480 torch/distributed/run.py:779] *****************************************
W0930 20:07:54.874000 23383375132480 torch/distributed/run.py:779] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W0930 20:07:54.874000 23383375132480 torch/distributed/run.py:779] *****************************************
flash_kv_decode is set to True
Using device=cuda
Loading model ...
GPTLadder(
  (tok_embeddings): Embedding(49152, 1536)
  (layers): ModuleList(
    (0-39): 40 x LadderTransformerBlock(
      semi_compiled = False
      (attention): Attention(
        (wqkv): Linear(in_features=1536, out_features=320, bias=False)
        (wo): Linear(in_features=192, out_features=1536, bias=False)
      )
      (feed_forward): FeedForward(
        (w1): Linear(in_features=1536, out_features=1024, bias=False)
        (w2): Linear(in_features=512, out_features=1536, bias=False)
      )
      (ffn_norm): RMSNorm()
      (attention_norm): RMSNorm()
    )
  )
  (norm): RMSNorm()
  (output): Linear(in_features=1536, out_features=49152, bias=False)
)
Time to load model: 0.19 seconds
[rank0]:[W930 20:08:08.993846848 CUDAGraph.cpp:150] Warning: Waiting for pending NCCL work to finish before starting graph capture. (function operator())
[rank6]:[W930 20:08:08.000058155 CUDAGraph.cpp:150] Warning: Waiting for pending NCCL work to finish before starting graph capture. (function operator())
Prefill latency: 0.08266807405743748 sec
Decode latency: 2.8081504079746082 sec
Compilation time: 2.90 seconds
Compilation time: 2.89 seconds
Compilation time: 2.87 secondsCompilation time: 2.89 seconds

Compilation time: 2.89 seconds
Compilation time: 2.89 seconds
Compilation time: 2.89 seconds
Compilation time: 2.89 seconds
Prefill latency: 0.05398911004886031 sec
Decode latency: 2.7957362240413204 sec
Prefill latency: 0.05269711895380169 sec
Decode latency: 2.7940892149927095 sec
Prefill latency: 0.05535886704456061 sec
Decode latency: 2.808635232038796 sec
Prefill latency: 0.05262328707613051 sec
Decode latency: 2.7956547550857067 sec
Prefill latency: 0.0527571199927479 sec
Decode latency: 2.7987550999969244 sec
Time for inference 1: 2.85 sec total, 1435.91 tokens/sec
Decode latency: 2.80 sec
Prefill latency: 0.05 sec
Bandwidth achieved: 578.53 GB/s
FLOPS achieved: 2.89 TF/s

Prefill latency: 0.05683921801391989 sec
Decode latency: 2.7959861969575286 sec
Time for inference 2: 2.85 sec total, 1435.28 tokens/sec
Decode latency: 2.80 sec
Prefill latency: 0.06 sec
Bandwidth achieved: 578.28 GB/s
FLOPS achieved: 2.89 TF/s

Prefill latency: 0.05261730495840311 sec
Decode latency: 2.822513159015216 sec
Time for inference 3: 2.88 sec total, 1424.17 tokens/sec
Decode latency: 2.82 sec
Prefill latency: 0.05 sec
Bandwidth achieved: 573.80 GB/s
FLOPS achieved: 2.87 TF/s

Prefill latency: 0.05299057194497436 sec
Decode latency: 2.8059231170918792 sec
Time for inference 4: 2.86 sec total, 1432.22 tokens/sec
Decode latency: 2.81 sec
Prefill latency: 0.05 sec
Bandwidth achieved: 577.05 GB/s
FLOPS achieved: 2.89 TF/s

Prefill latency: 0.05267589504364878 sec
Decode latency: 2.8004243950126693 sec
Time for inference 5: 2.85 sec total, 1435.04 tokens/sec
Decode latency: 2.80 sec
Prefill latency: 0.05 sec
Bandwidth achieved: 578.18 GB/s
FLOPS achieved: 2.89 TF/s

Prefill latency: 0.052468654001131654 sec
Decode latency: 2.799600638099946 sec
Time for inference 6: 2.85 sec total, 1435.65 tokens/sec
Decode latency: 2.80 sec
Prefill latency: 0.05 sec
Bandwidth achieved: 578.43 GB/s
FLOPS achieved: 2.89 TF/s

Prefill latency: 0.055209478945471346 sec
Decode latency: 2.828222454059869 sec
Time for inference 7: 2.88 sec total, 1419.95 tokens/sec
Decode latency: 2.83 sec
Prefill latency: 0.06 sec
Bandwidth achieved: 572.10 GB/s
FLOPS achieved: 2.86 TF/s

Prefill latency: 0.052819119999185205 sec
Decode latency: 2.7989759880583733 sec
Time for inference 8: 2.85 sec total, 1435.77 tokens/sec
Decode latency: 2.80 sec
Prefill latency: 0.05 sec
Bandwidth achieved: 578.47 GB/s
FLOPS achieved: 2.89 TF/s

Prefill latency: 0.052565691992640495 sec
Decode latency: 2.7977925339946523 sec
Time for inference 9: 2.85 sec total, 1436.53 tokens/sec
Decode latency: 2.80 sec
Prefill latency: 0.05 sec
Bandwidth achieved: 578.78 GB/s
FLOPS achieved: 2.89 TF/s

Prefill latency: 0.05513851600699127 sec
Decode latency: 2.804942319053225 sec
Time for inference 10: 2.86 sec total, 1431.66 tokens/sec
Decode latency: 2.80 sec
Prefill latency: 0.06 sec
Bandwidth achieved: 576.82 GB/s
FLOPS achieved: 2.88 TF/s

==========
Batch Size: 16
Prompt Length: 1024
Generated tokens: 256
Average decode latency: 2.8053 sec
Average prefill latency: 0.0536 sec
Average tokens/sec: 1432.22
Memory used: 6.83 GB
Done. we are killing the process
