W0930 20:11:53.695000 22604537349952 torch/distributed/run.py:779] 
W0930 20:11:53.695000 22604537349952 torch/distributed/run.py:779] *****************************************
W0930 20:11:53.695000 22604537349952 torch/distributed/run.py:779] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W0930 20:11:53.695000 22604537349952 torch/distributed/run.py:779] *****************************************
flash_kv_decode is set to True
Using device=cuda
Loading model ...
GPTLadder(
  (tok_embeddings): Embedding(49152, 1536)
  (layers): ModuleList(
    (0-39): 40 x LadderTransformerBlock(
      semi_compiled = False
      (attention): Attention(
        (wqkv): Linear(in_features=1536, out_features=1280, bias=False)
        (wo): Linear(in_features=768, out_features=1536, bias=False)
      )
      (feed_forward): FeedForward(
        (w1): Linear(in_features=1536, out_features=4096, bias=False)
        (w2): Linear(in_features=2048, out_features=1536, bias=False)
      )
      (ffn_norm): RMSNorm()
      (attention_norm): RMSNorm()
    )
  )
  (norm): RMSNorm()
  (output): Linear(in_features=1536, out_features=49152, bias=False)
)
Time to load model: 0.14 seconds
Prefill latency: 1.2714904400054365 sec
Decode latency: 6.573590132058598 sec
Compilation time: 7.85 seconds
Compilation time: 7.84 seconds
Prefill latency: 1.2139649549499154 sec
Decode latency: 6.572398794000037 sec
Prefill latency: 1.191831809002906 sec
Decode latency: 6.572724172961898 sec
Prefill latency: 1.2154628089629114 sec
Decode latency: 6.5716730509884655 sec
Prefill latency: 1.2040121339960024 sec
Decode latency: 6.574554817983881 sec
Prefill latency: 1.205457259900868 sec
Decode latency: 6.57514077599626 sec
Time for inference 1: 7.78 sec total, 2105.49 tokens/sec
Decode latency: 6.58 sec
Prefill latency: 1.21 sec
Bandwidth achieved: 2437.90 GB/s
FLOPS achieved: 12.19 TF/s

Prefill latency: 1.20762358000502 sec
Decode latency: 6.573008832987398 sec
Time for inference 2: 7.78 sec total, 2105.46 tokens/sec
Decode latency: 6.57 sec
Prefill latency: 1.21 sec
Bandwidth achieved: 2437.86 GB/s
FLOPS achieved: 12.19 TF/s

Prefill latency: 1.2055509219644591 sec
Decode latency: 6.571075359010138 sec
Time for inference 3: 7.78 sec total, 2106.56 tokens/sec
Decode latency: 6.57 sec
Prefill latency: 1.21 sec
Bandwidth achieved: 2439.14 GB/s
FLOPS achieved: 12.20 TF/s

Prefill latency: 1.2106902670348063 sec
Decode latency: 6.570581127074547 sec
Time for inference 4: 7.78 sec total, 2105.33 tokens/sec
Decode latency: 6.57 sec
Prefill latency: 1.21 sec
Bandwidth achieved: 2437.71 GB/s
FLOPS achieved: 12.19 TF/s

Prefill latency: 1.2016451499657705 sec
Decode latency: 6.5701466569444165 sec
Time for inference 5: 7.77 sec total, 2107.83 tokens/sec
Decode latency: 6.57 sec
Prefill latency: 1.20 sec
Bandwidth achieved: 2440.61 GB/s
FLOPS achieved: 12.20 TF/s

Prefill latency: 1.2069600650575012 sec
Decode latency: 6.56932698294986 sec
Time for inference 6: 7.78 sec total, 2106.60 tokens/sec
Decode latency: 6.57 sec
Prefill latency: 1.21 sec
Bandwidth achieved: 2439.18 GB/s
FLOPS achieved: 12.20 TF/s

Prefill latency: 1.193328982917592 sec
Decode latency: 6.567719280952588 sec
Time for inference 7: 7.76 sec total, 2110.81 tokens/sec
Decode latency: 6.57 sec
Prefill latency: 1.19 sec
Bandwidth achieved: 2444.05 GB/s
FLOPS achieved: 12.22 TF/s

Prefill latency: 1.2127292280783877 sec
Decode latency: 6.567435542936437 sec
Time for inference 8: 7.78 sec total, 2105.63 tokens/sec
Decode latency: 6.57 sec
Prefill latency: 1.21 sec
Bandwidth achieved: 2438.06 GB/s
FLOPS achieved: 12.19 TF/s

Prefill latency: 1.201965037966147 sec
Decode latency: 6.568420787923969 sec
Time for inference 9: 7.77 sec total, 2108.26 tokens/sec
Decode latency: 6.57 sec
Prefill latency: 1.20 sec
Bandwidth achieved: 2441.11 GB/s
FLOPS achieved: 12.21 TF/s

Prefill latency: 1.2102966390084475 sec
Decode latency: 6.566884248983115 sec
Time for inference 10: 7.78 sec total, 2106.44 tokens/sec
Decode latency: 6.57 sec
Prefill latency: 1.21 sec
Bandwidth achieved: 2438.99 GB/s
FLOPS achieved: 12.19 TF/s

==========
Batch Size: 64
Prompt Length: 1024
Generated tokens: 256
Average decode latency: 6.5700 sec
Average prefill latency: 1.2056 sec
Average tokens/sec: 2106.84
Memory used: 34.78 GB
Done. we are killing the process
