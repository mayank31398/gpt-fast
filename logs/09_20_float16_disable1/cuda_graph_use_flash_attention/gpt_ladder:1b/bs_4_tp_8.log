W0930 19:58:44.666000 23213506578240 torch/distributed/run.py:779] 
W0930 19:58:44.666000 23213506578240 torch/distributed/run.py:779] *****************************************
W0930 19:58:44.666000 23213506578240 torch/distributed/run.py:779] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W0930 19:58:44.666000 23213506578240 torch/distributed/run.py:779] *****************************************
flash_kv_decode is set to True
Using device=cuda
Loading model ...
GPTLadder(
  (tok_embeddings): Embedding(49152, 1536)
  (layers): ModuleList(
    (0-39): 40 x LadderTransformerBlock(
      semi_compiled = False
      (attention): Attention(
        (wqkv): Linear(in_features=1536, out_features=320, bias=False)
        (wo): Linear(in_features=192, out_features=1536, bias=False)
      )
      (feed_forward): FeedForward(
        (w1): Linear(in_features=1536, out_features=1024, bias=False)
        (w2): Linear(in_features=512, out_features=1536, bias=False)
      )
      (ffn_norm): RMSNorm()
      (attention_norm): RMSNorm()
    )
  )
  (norm): RMSNorm()
  (output): Linear(in_features=1536, out_features=49152, bias=False)
)
Time to load model: 0.21 seconds
[rank2]:[W930 19:59:36.017323691 CUDAGraph.cpp:150] Warning: Waiting for pending NCCL work to finish before starting graph capture. (function operator())
[rank1]:[W930 19:59:36.019054167 CUDAGraph.cpp:150] Warning: Waiting for pending NCCL work to finish before starting graph capture. (function operator())
[rank7]:[W930 19:59:36.023144745 CUDAGraph.cpp:150] Warning: Waiting for pending NCCL work to finish before starting graph capture. (function operator())
[rank4]:[W930 19:59:36.030718008 CUDAGraph.cpp:150] Warning: Waiting for pending NCCL work to finish before starting graph capture. (function operator())
Prefill latency: 0.02909465995617211 sec
Decode latency: 2.1246206420473754 sec
Compilation time: 2.15 seconds
Compilation time: 2.19 seconds
Compilation time: 2.16 seconds
Compilation time: 2.18 seconds
Compilation time: 2.16 seconds
Compilation time: 2.16 seconds
Compilation time: 2.18 seconds
Compilation time: 2.16 seconds
Prefill latency: 0.02046939206775278 sec
Decode latency: 2.1426221979781985 sec
Prefill latency: 0.020216144039295614 sec
Decode latency: 2.1268242659280077 sec
Prefill latency: 0.02023565792478621 sec
Decode latency: 2.1424757059430704 sec
Prefill latency: 0.02036075503565371 sec
Decode latency: 2.1380206909962 sec
Prefill latency: 0.02074946800712496 sec
Decode latency: 2.140469316043891 sec
Time for inference 1: 2.16 sec total, 473.56 tokens/sec
Decode latency: 2.14 sec
Prefill latency: 0.02 sec
Bandwidth achieved: 190.80 GB/s
FLOPS achieved: 0.95 TF/s

Prefill latency: 0.021070993039757013 sec
Decode latency: 2.1571890549967065 sec
Time for inference 2: 2.18 sec total, 469.86 tokens/sec
Decode latency: 2.16 sec
Prefill latency: 0.02 sec
Bandwidth achieved: 189.31 GB/s
FLOPS achieved: 0.95 TF/s

Prefill latency: 0.021142645040526986 sec
Decode latency: 2.1439775250619277 sec
Time for inference 3: 2.17 sec total, 472.72 tokens/sec
Decode latency: 2.14 sec
Prefill latency: 0.02 sec
Bandwidth achieved: 190.46 GB/s
FLOPS achieved: 0.95 TF/s

Prefill latency: 0.020272245979867876 sec
Decode latency: 2.152400108985603 sec
Time for inference 4: 2.17 sec total, 471.12 tokens/sec
Decode latency: 2.15 sec
Prefill latency: 0.02 sec
Bandwidth achieved: 189.82 GB/s
FLOPS achieved: 0.95 TF/s

Prefill latency: 0.020852679037488997 sec
Decode latency: 2.1179718510247767 sec
Time for inference 5: 2.14 sec total, 478.54 tokens/sec
Decode latency: 2.12 sec
Prefill latency: 0.02 sec
Bandwidth achieved: 192.81 GB/s
FLOPS achieved: 0.96 TF/s

Prefill latency: 0.020326515892520547 sec
Decode latency: 2.136353895999491 sec
Time for inference 6: 2.16 sec total, 474.58 tokens/sec
Decode latency: 2.14 sec
Prefill latency: 0.02 sec
Bandwidth achieved: 191.21 GB/s
FLOPS achieved: 0.96 TF/s

Prefill latency: 0.02087388199288398 sec
Decode latency: 2.150565499905497 sec
Time for inference 7: 2.17 sec total, 471.38 tokens/sec
Decode latency: 2.15 sec
Prefill latency: 0.02 sec
Bandwidth achieved: 189.92 GB/s
FLOPS achieved: 0.95 TF/s

Prefill latency: 0.020533988950774074 sec
Decode latency: 2.1304428110597655 sec
Time for inference 8: 2.15 sec total, 475.88 tokens/sec
Decode latency: 2.13 sec
Prefill latency: 0.02 sec
Bandwidth achieved: 191.73 GB/s
FLOPS achieved: 0.96 TF/s

Prefill latency: 0.020231298985891044 sec
Decode latency: 2.1377328649396077 sec
Time for inference 9: 2.16 sec total, 474.34 tokens/sec
Decode latency: 2.14 sec
Prefill latency: 0.02 sec
Bandwidth achieved: 191.11 GB/s
FLOPS achieved: 0.96 TF/s

Prefill latency: 0.021661353996023536 sec
Decode latency: 2.147550406982191 sec
Time for inference 10: 2.17 sec total, 471.72 tokens/sec
Decode latency: 2.15 sec
Prefill latency: 0.02 sec
Bandwidth achieved: 190.06 GB/s
FLOPS achieved: 0.95 TF/s

==========
Batch Size: 4
Prompt Length: 1024
Generated tokens: 256
Average decode latency: 2.1415 sec
Average prefill latency: 0.0208 sec
Average tokens/sec: 473.37
Memory used: 2.26 GB
Done. we are killing the process
