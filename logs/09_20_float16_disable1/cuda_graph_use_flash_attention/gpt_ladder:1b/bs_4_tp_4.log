W1001 02:47:08.469000 22909064931136 torch/distributed/run.py:779] 
W1001 02:47:08.469000 22909064931136 torch/distributed/run.py:779] *****************************************
W1001 02:47:08.469000 22909064931136 torch/distributed/run.py:779] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W1001 02:47:08.469000 22909064931136 torch/distributed/run.py:779] *****************************************
flash_kv_decode is set to True
Using device=cuda
Loading model ...
GPTLadder(
  (tok_embeddings): Embedding(49152, 1536)
  (layers): ModuleList(
    (0-39): 40 x LadderTransformerBlock(
      semi_compiled = False
      (attention): Attention(
        (wqkv): Linear(in_features=1536, out_features=1152, bias=False)
        (wo): Linear(in_features=384, out_features=1536, bias=False)
      )
      (feed_forward): FeedForward(
        (w1): Linear(in_features=1536, out_features=2048, bias=False)
        (w2): Linear(in_features=1024, out_features=1536, bias=False)
      )
      (ffn_norm): RMSNorm()
      (attention_norm): RMSNorm()
    )
  )
  (norm): RMSNorm()
  (output): Linear(in_features=1536, out_features=49152, bias=False)
)
Time to load model: 0.14 seconds
[rank2]:[W1001 02:47:15.945838881 CUDAGraph.cpp:150] Warning: Waiting for pending NCCL work to finish before starting graph capture. (function operator())
[rank1]:[W1001 02:47:16.464799563 CUDAGraph.cpp:150] Warning: Waiting for pending NCCL work to finish before starting graph capture. (function operator())
[rank0]:[W1001 02:47:16.467432921 CUDAGraph.cpp:150] Warning: Waiting for pending NCCL work to finish before starting graph capture. (function operator())
[rank3]:[W1001 02:47:16.468065648 CUDAGraph.cpp:150] Warning: Waiting for pending NCCL work to finish before starting graph capture. (function operator())
Prefill latency: 0.0233916649594903 sec
Decode latency: 2.051134759094566 sec
Compilation time: 2.08 seconds
Compilation time: 2.08 seconds
Compilation time: 2.08 seconds
Compilation time: 2.08 seconds
Prefill latency: 0.02300886099692434 sec
Decode latency: 2.0503210009774193 sec
Prefill latency: 0.02300975506659597 sec
Decode latency: 2.049387782928534 sec
Prefill latency: 0.022932008025236428 sec
Decode latency: 2.0498279919847846 sec
Prefill latency: 0.023003658978268504 sec
Decode latency: 2.0483032149495557 sec
Prefill latency: 0.023036541999317706 sec
Decode latency: 2.048654554062523 sec
Time for inference 1: 2.07 sec total, 494.09 tokens/sec
Decode latency: 2.05 sec
Prefill latency: 0.02 sec
Bandwidth achieved: 354.50 GB/s
FLOPS achieved: 1.77 TF/s

Prefill latency: 0.023169444990344346 sec
Decode latency: 2.0478587079560384 sec
Time for inference 2: 2.07 sec total, 494.25 tokens/sec
Decode latency: 2.05 sec
Prefill latency: 0.02 sec
Bandwidth achieved: 354.61 GB/s
FLOPS achieved: 1.77 TF/s

Prefill latency: 0.02305342396721244 sec
Decode latency: 2.0486361380899325 sec
Time for inference 3: 2.07 sec total, 494.12 tokens/sec
Decode latency: 2.05 sec
Prefill latency: 0.02 sec
Bandwidth achieved: 354.52 GB/s
FLOPS achieved: 1.77 TF/s

Prefill latency: 0.02304992009885609 sec
Decode latency: 2.0473874520976096 sec
Time for inference 4: 2.07 sec total, 494.42 tokens/sec
Decode latency: 2.05 sec
Prefill latency: 0.02 sec
Bandwidth achieved: 354.73 GB/s
FLOPS achieved: 1.77 TF/s

Prefill latency: 0.02303176501300186 sec
Decode latency: 2.0477872060146183 sec
Time for inference 5: 2.07 sec total, 494.31 tokens/sec
Decode latency: 2.05 sec
Prefill latency: 0.02 sec
Bandwidth achieved: 354.66 GB/s
FLOPS achieved: 1.77 TF/s

Prefill latency: 0.023019950021989644 sec
Decode latency: 2.0477038309909403 sec
Time for inference 6: 2.07 sec total, 494.34 tokens/sec
Decode latency: 2.05 sec
Prefill latency: 0.02 sec
Bandwidth achieved: 354.68 GB/s
FLOPS achieved: 1.77 TF/s

Prefill latency: 0.0232473430223763 sec
Decode latency: 2.049356174073182 sec
Time for inference 7: 2.07 sec total, 493.85 tokens/sec
Decode latency: 2.05 sec
Prefill latency: 0.02 sec
Bandwidth achieved: 354.33 GB/s
FLOPS achieved: 1.77 TF/s

Prefill latency: 0.02298342203721404 sec
Decode latency: 2.0500391219975427 sec
Time for inference 8: 2.07 sec total, 493.75 tokens/sec
Decode latency: 2.05 sec
Prefill latency: 0.02 sec
Bandwidth achieved: 354.25 GB/s
FLOPS achieved: 1.77 TF/s

Prefill latency: 0.02293368603568524 sec
Decode latency: 2.048090482945554 sec
Time for inference 9: 2.07 sec total, 494.27 tokens/sec
Decode latency: 2.05 sec
Prefill latency: 0.02 sec
Bandwidth achieved: 354.62 GB/s
FLOPS achieved: 1.77 TF/s

Prefill latency: 0.023149205022491515 sec
Decode latency: 2.048541310010478 sec
Time for inference 10: 2.07 sec total, 494.03 tokens/sec
Decode latency: 2.05 sec
Prefill latency: 0.02 sec
Bandwidth achieved: 354.45 GB/s
FLOPS achieved: 1.77 TF/s

==========
Batch Size: 4
Prompt Length: 1024
Generated tokens: 256
Average decode latency: 2.0484 sec
Average prefill latency: 0.0231 sec
Average tokens/sec: 494.14
Memory used: 2.85 GB
Done. we are killing the process
