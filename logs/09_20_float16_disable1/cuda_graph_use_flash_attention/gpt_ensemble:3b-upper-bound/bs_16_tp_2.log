W1001 03:39:03.816000 22689027835712 torch/distributed/run.py:779] 
W1001 03:39:03.816000 22689027835712 torch/distributed/run.py:779] *****************************************
W1001 03:39:03.816000 22689027835712 torch/distributed/run.py:779] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W1001 03:39:03.816000 22689027835712 torch/distributed/run.py:779] *****************************************
flash_kv_decode is set to True
Using device=cuda
Loading model ...
GPTEnsemble(
  (tok_embeddings): Embedding(49152, 2304)
  (layers): ModuleList(
    (0-39): 40 x EnsembleTransformerBlock(
      semi_compiled = False
      (attention): Attention(
        (wqkv): Linear(in_features=2304, out_features=3456, bias=False)
        (wo): Linear(in_features=1152, out_features=2304, bias=False)
      )
      (feed_forward): FeedForward(
        (w1): Linear(in_features=2304, out_features=9216, bias=False)
        (w2): Linear(in_features=4608, out_features=2304, bias=False)
      )
      (ffn_norm): RMSNorm()
      (attention_norm): RMSNorm()
    )
  )
  (norm): RMSNorm()
  (output): Linear(in_features=2304, out_features=49152, bias=False)
)
Time to load model: 1.00 seconds
Prefill latency: 0.20881265599746257 sec
Compilation time: 3.43 seconds
Decode latency: 3.2063565120333806 sec
Compilation time: 3.42 seconds
Prefill latency: 0.2094470780575648 sec
Decode latency: 3.198036262067035 sec
Prefill latency: 0.20895996899344027 sec
Decode latency: 3.198626058991067 sec
Prefill latency: 0.20955858996603638 sec
Decode latency: 3.1975116200046614 sec
Prefill latency: 0.20927406405098736 sec
Decode latency: 3.200417389976792 sec
Prefill latency: 0.20988258894067258 sec
Decode latency: 3.1977960609365255 sec
Time for inference 1: 3.41 sec total, 1201.66 tokens/sec
Decode latency: 3.20 sec
Prefill latency: 0.21 sec
Bandwidth achieved: 4355.11 GB/s
FLOPS achieved: 21.78 TF/s

Prefill latency: 0.20925087109208107 sec
Decode latency: 3.1994856470264494 sec
Time for inference 2: 3.41 sec total, 1201.34 tokens/sec
Decode latency: 3.20 sec
Prefill latency: 0.21 sec
Bandwidth achieved: 4353.96 GB/s
FLOPS achieved: 21.77 TF/s

Prefill latency: 0.20904387696646154 sec
Decode latency: 3.198300685035065 sec
Time for inference 3: 3.41 sec total, 1201.86 tokens/sec
Decode latency: 3.20 sec
Prefill latency: 0.21 sec
Bandwidth achieved: 4355.84 GB/s
FLOPS achieved: 21.78 TF/s

Prefill latency: 0.2088753719581291 sec
Decode latency: 3.1977678660769016 sec
Time for inference 4: 3.41 sec total, 1202.12 tokens/sec
Decode latency: 3.20 sec
Prefill latency: 0.21 sec
Bandwidth achieved: 4356.77 GB/s
FLOPS achieved: 21.78 TF/s

Prefill latency: 0.20901903393678367 sec
Decode latency: 3.198350438964553 sec
Time for inference 5: 3.41 sec total, 1201.87 tokens/sec
Decode latency: 3.20 sec
Prefill latency: 0.21 sec
Bandwidth achieved: 4355.87 GB/s
FLOPS achieved: 21.78 TF/s

Prefill latency: 0.20949947996996343 sec
Decode latency: 3.1974701420404017 sec
Time for inference 6: 3.41 sec total, 1202.01 tokens/sec
Decode latency: 3.20 sec
Prefill latency: 0.21 sec
Bandwidth achieved: 4356.39 GB/s
FLOPS achieved: 21.78 TF/s

Prefill latency: 0.20932006801012903 sec
Decode latency: 3.19844023801852 sec
Time for inference 7: 3.41 sec total, 1201.66 tokens/sec
Decode latency: 3.20 sec
Prefill latency: 0.21 sec
Bandwidth achieved: 4355.12 GB/s
FLOPS achieved: 21.78 TF/s

Prefill latency: 0.2099186439299956 sec
Decode latency: 3.1970890909433365 sec
Time for inference 8: 3.41 sec total, 1201.96 tokens/sec
Decode latency: 3.20 sec
Prefill latency: 0.21 sec
Bandwidth achieved: 4356.19 GB/s
FLOPS achieved: 21.78 TF/s

Prefill latency: 0.2097506910795346 sec
Decode latency: 3.1979124459903687 sec
Time for inference 9: 3.41 sec total, 1201.75 tokens/sec
Decode latency: 3.20 sec
Prefill latency: 0.21 sec
Bandwidth achieved: 4355.46 GB/s
FLOPS achieved: 21.78 TF/s

Prefill latency: 0.2089034200180322 sec
Decode latency: 3.196810281020589 sec
Time for inference 10: 3.41 sec total, 1202.44 tokens/sec
Decode latency: 3.20 sec
Prefill latency: 0.21 sec
Bandwidth achieved: 4357.96 GB/s
FLOPS achieved: 21.79 TF/s

==========
Batch Size: 16
Prompt Length: 1024
Generated tokens: 256
Average decode latency: 3.1979 sec
Average prefill latency: 0.2093 sec
Average tokens/sec: 1201.87
Memory used: 11.04 GB
Done. we are killing the process
