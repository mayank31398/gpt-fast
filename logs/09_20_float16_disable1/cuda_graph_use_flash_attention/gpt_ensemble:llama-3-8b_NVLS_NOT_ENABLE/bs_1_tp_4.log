W0929 04:31:27.838000 22370164131648 torch/distributed/run.py:779] 
W0929 04:31:27.838000 22370164131648 torch/distributed/run.py:779] *****************************************
W0929 04:31:27.838000 22370164131648 torch/distributed/run.py:779] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W0929 04:31:27.838000 22370164131648 torch/distributed/run.py:779] *****************************************
flash_kv_decode is set to True
Using device=cuda
Loading model ...
GPTEnsemble(
  (tok_embeddings): Embedding(128256, 4096)
  (layers): ModuleList(
    (0-31): 32 x EnsembleTransformerBlock(
      semi_compiled = False
      (attention): Attention(
        (wqkv): Linear(in_features=4096, out_features=1536, bias=False)
        (wo): Linear(in_features=1024, out_features=4096, bias=False)
      )
      (feed_forward): FeedForward(
        (w1): Linear(in_features=4096, out_features=7168, bias=False)
        (w2): Linear(in_features=3584, out_features=4096, bias=False)
      )
      (ffn_norm): RMSNorm()
      (attention_norm): RMSNorm()
    )
  )
  (norm): RMSNorm()
  (output): Linear(in_features=4096, out_features=128256, bias=False)
)
Time to load model: 2.25 seconds
Prefill latency: 0.015869750059209764 sec
Decode latency: 1.7135153210256249 sec
Compilation time: 1.76 seconds
Compilation time: 1.73 seconds
Compilation time: 1.76 seconds
Compilation time: 1.73 seconds
Prefill latency: 0.015199120971374214 sec
Decode latency: 1.7116128660272807 sec
Prefill latency: 0.015136435977183282 sec
Decode latency: 1.7116344589740038 sec
Prefill latency: 0.015249981079250574 sec
Decode latency: 1.7137540320400149 sec
Prefill latency: 0.015201037982478738 sec
Decode latency: 1.7137263950426131 sec
Prefill latency: 0.015199256944470108 sec
Decode latency: 1.713794609066099 sec
Time for inference 1: 1.73 sec total, 147.99 tokens/sec
Decode latency: 1.71 sec
Prefill latency: 0.02 sec
Bandwidth achieved: 672.01 GB/s
FLOPS achieved: 3.36 TF/s

Prefill latency: 0.01529009803198278 sec
Decode latency: 1.7137892430182546 sec
Time for inference 2: 1.73 sec total, 147.99 tokens/sec
Decode latency: 1.71 sec
Prefill latency: 0.02 sec
Bandwidth achieved: 671.99 GB/s
FLOPS achieved: 3.36 TF/s

Prefill latency: 0.015147169935517013 sec
Decode latency: 1.7137010400183499 sec
Time for inference 3: 1.73 sec total, 148.02 tokens/sec
Decode latency: 1.71 sec
Prefill latency: 0.02 sec
Bandwidth achieved: 672.12 GB/s
FLOPS achieved: 3.36 TF/s

Prefill latency: 0.01523582509253174 sec
Decode latency: 1.7139636559877545 sec
Time for inference 4: 1.73 sec total, 147.99 tokens/sec
Decode latency: 1.71 sec
Prefill latency: 0.02 sec
Bandwidth achieved: 672.01 GB/s
FLOPS achieved: 3.36 TF/s

Prefill latency: 0.01523343101143837 sec
Decode latency: 1.7137305130017921 sec
Time for inference 5: 1.73 sec total, 148.00 tokens/sec
Decode latency: 1.71 sec
Prefill latency: 0.02 sec
Bandwidth achieved: 672.06 GB/s
FLOPS achieved: 3.36 TF/s

Prefill latency: 0.015187815995886922 sec
Decode latency: 1.7137506280560046 sec
Time for inference 6: 1.73 sec total, 147.99 tokens/sec
Decode latency: 1.71 sec
Prefill latency: 0.02 sec
Bandwidth achieved: 672.02 GB/s
FLOPS achieved: 3.36 TF/s

Prefill latency: 0.01507594098802656 sec
Decode latency: 1.7136817160062492 sec
Time for inference 7: 1.73 sec total, 148.01 tokens/sec
Decode latency: 1.71 sec
Prefill latency: 0.02 sec
Bandwidth achieved: 672.09 GB/s
FLOPS achieved: 3.36 TF/s

Prefill latency: 0.015098588075488806 sec
Decode latency: 1.713788297958672 sec
Time for inference 8: 1.73 sec total, 148.01 tokens/sec
Decode latency: 1.71 sec
Prefill latency: 0.02 sec
Bandwidth achieved: 672.08 GB/s
FLOPS achieved: 3.36 TF/s

Prefill latency: 0.015246782917529345 sec
Decode latency: 1.7138458390254527 sec
Time for inference 9: 1.73 sec total, 147.99 tokens/sec
Decode latency: 1.71 sec
Prefill latency: 0.02 sec
Bandwidth achieved: 672.01 GB/s
FLOPS achieved: 3.36 TF/s

Prefill latency: 0.01516234700102359 sec
Decode latency: 1.7136835110140964 sec
Time for inference 10: 1.73 sec total, 148.01 tokens/sec
Decode latency: 1.71 sec
Prefill latency: 0.02 sec
Bandwidth achieved: 672.08 GB/s
FLOPS achieved: 3.36 TF/s

==========
Batch Size: 1
Prompt Length: 1024
Generated tokens: 256
Average decode latency: 1.7138 sec
Average prefill latency: 0.0152 sec
Average tokens/sec: 148.00
Memory used: 6.14 GB
Done. we are killing the process
