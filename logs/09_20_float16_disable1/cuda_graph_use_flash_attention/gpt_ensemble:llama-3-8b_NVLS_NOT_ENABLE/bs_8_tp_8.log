W0929 04:39:17.919000 22488711325504 torch/distributed/run.py:779] 
W0929 04:39:17.919000 22488711325504 torch/distributed/run.py:779] *****************************************
W0929 04:39:17.919000 22488711325504 torch/distributed/run.py:779] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W0929 04:39:17.919000 22488711325504 torch/distributed/run.py:779] *****************************************
flash_kv_decode is set to True
Using device=cuda
Loading model ...
GPTEnsemble(
  (tok_embeddings): Embedding(128256, 4096)
  (layers): ModuleList(
    (0-31): 32 x EnsembleTransformerBlock(
      semi_compiled = False
      (attention): Attention(
        (wqkv): Linear(in_features=4096, out_features=768, bias=False)
        (wo): Linear(in_features=512, out_features=4096, bias=False)
      )
      (feed_forward): FeedForward(
        (w1): Linear(in_features=4096, out_features=3584, bias=False)
        (w2): Linear(in_features=1792, out_features=4096, bias=False)
      )
      (ffn_norm): RMSNorm()
      (attention_norm): RMSNorm()
    )
  )
  (norm): RMSNorm()
  (output): Linear(in_features=4096, out_features=128256, bias=False)
)
Time to load model: 1.14 seconds
Prefill latency: 0.10073613608255982 sec
Decode latency: 1.9310219569597393 sec
Compilation time: 2.03 seconds
Compilation time: 2.03 seconds
Compilation time: 2.03 seconds
Compilation time: 2.03 secondsCompilation time: 1.99 seconds
Compilation time: 2.01 seconds

Compilation time: 1.99 seconds
Compilation time: 2.01 seconds
Prefill latency: 0.056955798994749784 sec
Decode latency: 1.9255679619964212 sec
Prefill latency: 0.057022601016797125 sec
Decode latency: 1.9275061269290745 sec
Prefill latency: 0.056935824919492006 sec
Decode latency: 1.9309870059369132 sec
Prefill latency: 0.05686602904461324 sec
Decode latency: 1.924781097099185 sec
Prefill latency: 0.057038112077862024 sec
Decode latency: 1.9241206910228357 sec
Time for inference 1: 1.98 sec total, 1033.29 tokens/sec
Decode latency: 1.92 sec
Prefill latency: 0.06 sec
Bandwidth achieved: 2889.11 GB/s
FLOPS achieved: 14.45 TF/s

Prefill latency: 0.05671792000066489 sec
Decode latency: 1.9258221699856222 sec
Time for inference 2: 1.98 sec total, 1032.55 tokens/sec
Decode latency: 1.93 sec
Prefill latency: 0.06 sec
Bandwidth achieved: 2887.05 GB/s
FLOPS achieved: 14.44 TF/s

Prefill latency: 0.05687964509706944 sec
Decode latency: 1.9275282219750807 sec
Time for inference 3: 1.99 sec total, 1031.57 tokens/sec
Decode latency: 1.93 sec
Prefill latency: 0.06 sec
Bandwidth achieved: 2884.29 GB/s
FLOPS achieved: 14.42 TF/s

Prefill latency: 0.05688682699110359 sec
Decode latency: 1.9252428519539535 sec
Time for inference 4: 1.98 sec total, 1032.76 tokens/sec
Decode latency: 1.93 sec
Prefill latency: 0.06 sec
Bandwidth achieved: 2887.64 GB/s
FLOPS achieved: 14.44 TF/s

Prefill latency: 0.05669740599114448 sec
Decode latency: 1.926255180966109 sec
Time for inference 5: 1.98 sec total, 1032.36 tokens/sec
Decode latency: 1.93 sec
Prefill latency: 0.06 sec
Bandwidth achieved: 2886.53 GB/s
FLOPS achieved: 14.43 TF/s

Prefill latency: 0.05705721990671009 sec
Decode latency: 1.9253481719642878 sec
Time for inference 6: 1.98 sec total, 1032.60 tokens/sec
Decode latency: 1.93 sec
Prefill latency: 0.06 sec
Bandwidth achieved: 2887.18 GB/s
FLOPS achieved: 14.44 TF/s

Prefill latency: 0.05675289500504732 sec
Decode latency: 1.924603296094574 sec
Time for inference 7: 1.98 sec total, 1033.20 tokens/sec
Decode latency: 1.92 sec
Prefill latency: 0.06 sec
Bandwidth achieved: 2888.88 GB/s
FLOPS achieved: 14.44 TF/s

Prefill latency: 0.05699884006753564 sec
Decode latency: 1.9268225890118629 sec
Time for inference 8: 1.98 sec total, 1031.93 tokens/sec
Decode latency: 1.93 sec
Prefill latency: 0.06 sec
Bandwidth achieved: 2885.32 GB/s
FLOPS achieved: 14.43 TF/s

Prefill latency: 0.05697476305067539 sec
Decode latency: 1.9303831590805203 sec
Time for inference 9: 1.99 sec total, 1030.09 tokens/sec
Decode latency: 1.93 sec
Prefill latency: 0.06 sec
Bandwidth achieved: 2880.17 GB/s
FLOPS achieved: 14.40 TF/s

Prefill latency: 0.057013788959011436 sec
Decode latency: 1.9236540499841794 sec
Time for inference 10: 1.98 sec total, 1033.66 tokens/sec
Decode latency: 1.92 sec
Prefill latency: 0.06 sec
Bandwidth achieved: 2890.16 GB/s
FLOPS achieved: 14.45 TF/s

==========
Batch Size: 8
Prompt Length: 1024
Generated tokens: 256
Average decode latency: 1.9260 sec
Average prefill latency: 0.0569 sec
Average tokens/sec: 1032.40
Memory used: 6.82 GB
Done. we are killing the process
