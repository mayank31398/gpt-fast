W0928 18:20:53.706000 23180393535296 torch/distributed/run.py:779] 
W0928 18:20:53.706000 23180393535296 torch/distributed/run.py:779] *****************************************
W0928 18:20:53.706000 23180393535296 torch/distributed/run.py:779] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W0928 18:20:53.706000 23180393535296 torch/distributed/run.py:779] *****************************************
flash_kv_decode is set to True
Using device=cuda
Loading model ...
GPTLadder(
  (tok_embeddings): Embedding(128256, 4096)
  (layers): ModuleList(
    (0-31): 32 x LadderTransformerBlock(
      semi_compiled = False
      (attention): Attention(
        (wqkv): Linear(in_features=4096, out_features=768, bias=False)
        (wo): Linear(in_features=512, out_features=4096, bias=False)
      )
      (feed_forward): FeedForward(
        (w1): Linear(in_features=4096, out_features=3584, bias=False)
        (w2): Linear(in_features=1792, out_features=4096, bias=False)
      )
      (ffn_norm): RMSNorm()
      (attention_norm): RMSNorm()
    )
  )
  (norm): RMSNorm()
  (output): Linear(in_features=4096, out_features=128256, bias=False)
)
Time to load model: 0.18 seconds
[rank2]:[W928 18:21:06.579628778 CUDAGraph.cpp:150] Warning: Waiting for pending NCCL work to finish before starting graph capture. (function operator())
[rank1]:[W928 18:21:06.579952267 CUDAGraph.cpp:150] Warning: Waiting for pending NCCL work to finish before starting graph capture. (function operator())
Prefill latency: 0.05056664498988539 sec
Decode latency: 2.043351119966246 sec
Compilation time: 2.12 secondsCompilation time: 2.09 seconds

Compilation time: 2.12 secondsCompilation time: 2.11 seconds

Compilation time: 2.10 secondsCompilation time: 2.10 seconds

Compilation time: 2.13 seconds
Compilation time: 2.10 seconds
Prefill latency: 0.04350497602717951 sec
Decode latency: 2.040084859007038 sec
Prefill latency: 0.04059128800872713 sec
Decode latency: 2.068363242025953 sec
Prefill latency: 0.04095777700422332 sec
Decode latency: 2.04432403401006 sec
Prefill latency: 0.040519094036426395 sec
Decode latency: 2.04211577703245 sec
Prefill latency: 0.04290440201293677 sec
Decode latency: 2.0440982980071567 sec
Time for inference 1: 2.09 sec total, 490.40 tokens/sec
Decode latency: 2.04 sec
Prefill latency: 0.04 sec
Bandwidth achieved: 1371.19 GB/s
FLOPS achieved: 6.86 TF/s

Prefill latency: 0.040300527994986624 sec
Decode latency: 2.0415997450472787 sec
Time for inference 2: 2.08 sec total, 491.61 tokens/sec
Decode latency: 2.04 sec
Prefill latency: 0.04 sec
Bandwidth achieved: 1374.55 GB/s
FLOPS achieved: 6.87 TF/s

Prefill latency: 0.04089167300844565 sec
Decode latency: 2.037516789045185 sec
Time for inference 3: 2.08 sec total, 492.42 tokens/sec
Decode latency: 2.04 sec
Prefill latency: 0.04 sec
Bandwidth achieved: 1376.84 GB/s
FLOPS achieved: 6.88 TF/s

Prefill latency: 0.040394137031398714 sec
Decode latency: 2.0350371730164625 sec
Time for inference 4: 2.08 sec total, 493.15 tokens/sec
Decode latency: 2.04 sec
Prefill latency: 0.04 sec
Bandwidth achieved: 1378.88 GB/s
FLOPS achieved: 6.89 TF/s

Prefill latency: 0.04355277196737006 sec
Decode latency: 2.047586689994205 sec
Time for inference 5: 2.09 sec total, 489.48 tokens/sec
Decode latency: 2.05 sec
Prefill latency: 0.04 sec
Bandwidth achieved: 1368.61 GB/s
FLOPS achieved: 6.84 TF/s

Prefill latency: 0.0403227080241777 sec
Decode latency: 2.0337257930077612 sec
Time for inference 6: 2.08 sec total, 493.48 tokens/sec
Decode latency: 2.03 sec
Prefill latency: 0.04 sec
Bandwidth achieved: 1379.78 GB/s
FLOPS achieved: 6.90 TF/s

Prefill latency: 0.040548789023887366 sec
Decode latency: 2.0394369239802472 sec
Time for inference 7: 2.08 sec total, 492.10 tokens/sec
Decode latency: 2.04 sec
Prefill latency: 0.04 sec
Bandwidth achieved: 1375.93 GB/s
FLOPS achieved: 6.88 TF/s

Prefill latency: 0.0436883780057542 sec
Decode latency: 2.0397014759946615 sec
Time for inference 8: 2.08 sec total, 491.28 tokens/sec
Decode latency: 2.04 sec
Prefill latency: 0.04 sec
Bandwidth achieved: 1373.62 GB/s
FLOPS achieved: 6.87 TF/s

Prefill latency: 0.04027232795488089 sec
Decode latency: 2.0399590919842012 sec
Time for inference 9: 2.08 sec total, 492.02 tokens/sec
Decode latency: 2.04 sec
Prefill latency: 0.04 sec
Bandwidth achieved: 1375.71 GB/s
FLOPS achieved: 6.88 TF/s

Prefill latency: 0.04820101102814078 sec
Decode latency: 2.039575139991939 sec
Time for inference 10: 2.09 sec total, 490.30 tokens/sec
Decode latency: 2.04 sec
Prefill latency: 0.05 sec
Bandwidth achieved: 1370.88 GB/s
FLOPS achieved: 6.85 TF/s

==========
Batch Size: 4
Prompt Length: 1024
Generated tokens: 256
Average decode latency: 2.0398 sec
Average prefill latency: 0.0421 sec
Average tokens/sec: 491.62
Memory used: 7.46 GB
Done. we are killing the process
