W1001 03:23:58.357000 22465189328704 torch/distributed/run.py:779] 
W1001 03:23:58.357000 22465189328704 torch/distributed/run.py:779] *****************************************
W1001 03:23:58.357000 22465189328704 torch/distributed/run.py:779] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W1001 03:23:58.357000 22465189328704 torch/distributed/run.py:779] *****************************************
flash_kv_decode is set to True
Using device=cuda
Loading model ...
GPTDense(
  (tok_embeddings): Embedding(49152, 2304)
  (layers): ModuleList(
    (0-39): 40 x DenseTransformerBlock(
      semi_compiled = False
      (attention): Attention(
        (wqkv): Linear(in_features=2304, out_features=3456, bias=False)
        (wo): Linear(in_features=1152, out_features=2304, bias=False)
      )
      (feed_forward): FeedForward(
        (w1): Linear(in_features=2304, out_features=9216, bias=False)
        (w2): Linear(in_features=4608, out_features=2304, bias=False)
      )
      (ffn_norm): RMSNorm()
      (attention_norm): RMSNorm()
    )
  )
  (norm): RMSNorm()
  (output): Linear(in_features=2304, out_features=49152, bias=False)
)
Time to load model: 1.01 seconds
Prefill latency: 2.6936767359729856 sec
Decode latency: 8.547793961013667 sec
Compilation time: 11.24 seconds
Compilation time: 11.24 seconds
Prefill latency: 2.489207730977796 sec
Decode latency: 8.553015360957943 sec
Prefill latency: 2.477166813914664 sec
Decode latency: 8.544314378057607 sec
Prefill latency: 2.4920739780645818 sec
Decode latency: 8.545465454924852 sec
Prefill latency: 2.476598128094338 sec
Decode latency: 8.548125742934644 sec
Prefill latency: 2.4883087490452453 sec
Decode latency: 8.546789153013378 sec
Time for inference 1: 11.04 sec total, 1484.59 tokens/sec
Decode latency: 8.55 sec
Prefill latency: 2.49 sec
Bandwidth achieved: 5380.54 GB/s
FLOPS achieved: 26.90 TF/s

Prefill latency: 2.477070005959831 sec
Decode latency: 8.547012879978865 sec
Time for inference 2: 11.03 sec total, 1486.05 tokens/sec
Decode latency: 8.55 sec
Prefill latency: 2.48 sec
Bandwidth achieved: 5385.84 GB/s
FLOPS achieved: 26.93 TF/s

Prefill latency: 2.4908173410221934 sec
Decode latency: 8.54658711294178 sec
Time for inference 3: 11.04 sec total, 1484.28 tokens/sec
Decode latency: 8.55 sec
Prefill latency: 2.49 sec
Bandwidth achieved: 5379.42 GB/s
FLOPS achieved: 26.90 TF/s

Prefill latency: 2.4756805129582062 sec
Decode latency: 8.547397535992786 sec
Time for inference 4: 11.02 sec total, 1486.21 tokens/sec
Decode latency: 8.55 sec
Prefill latency: 2.48 sec
Bandwidth achieved: 5386.39 GB/s
FLOPS achieved: 26.93 TF/s

Prefill latency: 2.4986706170020625 sec
Decode latency: 8.54492349398788 sec
Time for inference 5: 11.04 sec total, 1483.43 tokens/sec
Decode latency: 8.54 sec
Prefill latency: 2.50 sec
Bandwidth achieved: 5376.32 GB/s
FLOPS achieved: 26.88 TF/s

Prefill latency: 2.471437027095817 sec
Decode latency: 8.545747051946819 sec
Time for inference 6: 11.02 sec total, 1487.01 tokens/sec
Decode latency: 8.55 sec
Prefill latency: 2.47 sec
Bandwidth achieved: 5389.28 GB/s
FLOPS achieved: 26.95 TF/s

Prefill latency: 2.4825877629918978 sec
Decode latency: 8.545981272007339 sec
Time for inference 7: 11.03 sec total, 1485.44 tokens/sec
Decode latency: 8.55 sec
Prefill latency: 2.48 sec
Bandwidth achieved: 5383.61 GB/s
FLOPS achieved: 26.92 TF/s

Prefill latency: 2.4730883109150454 sec
Decode latency: 8.546397486003116 sec
Time for inference 8: 11.02 sec total, 1486.68 tokens/sec
Decode latency: 8.55 sec
Prefill latency: 2.47 sec
Bandwidth achieved: 5388.11 GB/s
FLOPS achieved: 26.94 TF/s

Prefill latency: 2.4910945219453424 sec
Decode latency: 8.54666064796038 sec
Time for inference 9: 11.04 sec total, 1484.23 tokens/sec
Decode latency: 8.55 sec
Prefill latency: 2.49 sec
Bandwidth achieved: 5379.24 GB/s
FLOPS achieved: 26.90 TF/s

Prefill latency: 2.4822970810346305 sec
Decode latency: 8.547292836941779 sec
Time for inference 10: 11.03 sec total, 1485.31 tokens/sec
Decode latency: 8.55 sec
Prefill latency: 2.48 sec
Bandwidth achieved: 5383.14 GB/s
FLOPS achieved: 26.92 TF/s

==========
Batch Size: 64
Prompt Length: 1024
Generated tokens: 256
Average decode latency: 8.5465 sec
Average prefill latency: 2.4831 sec
Average tokens/sec: 1485.32
Memory used: 54.72 GB
Done. we are killing the process
