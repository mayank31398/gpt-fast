W1001 03:13:39.004000 22954299000640 torch/distributed/run.py:779] 
W1001 03:13:39.004000 22954299000640 torch/distributed/run.py:779] *****************************************
W1001 03:13:39.004000 22954299000640 torch/distributed/run.py:779] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W1001 03:13:39.004000 22954299000640 torch/distributed/run.py:779] *****************************************
flash_kv_decode is set to True
Using device=cuda
Loading model ...
GPTDense(
  (tok_embeddings): Embedding(49152, 2304)
  (layers): ModuleList(
    (0-39): 40 x DenseTransformerBlock(
      semi_compiled = False
      (attention): Attention(
        (wqkv): Linear(in_features=2304, out_features=3456, bias=False)
        (wo): Linear(in_features=1152, out_features=2304, bias=False)
      )
      (feed_forward): FeedForward(
        (w1): Linear(in_features=2304, out_features=9216, bias=False)
        (w2): Linear(in_features=4608, out_features=2304, bias=False)
      )
      (ffn_norm): RMSNorm()
      (attention_norm): RMSNorm()
    )
  )
  (norm): RMSNorm()
  (output): Linear(in_features=2304, out_features=49152, bias=False)
)
Time to load model: 1.05 seconds
Prefill latency: 0.3506455550668761 sec
Decode latency: 3.2390807569026947 sec
Compilation time: 3.58 seconds
Compilation time: 3.59 seconds
Prefill latency: 0.3152658180333674 sec
Decode latency: 3.239313761005178 sec
Prefill latency: 0.31565933499950916 sec
Decode latency: 3.234827817999758 sec
Prefill latency: 0.31666793499607593 sec
Decode latency: 3.2360392460832372 sec
Prefill latency: 0.31444691005162895 sec
Decode latency: 3.2327675299020484 sec
Prefill latency: 0.31565485801547766 sec
Decode latency: 3.2342667949851602 sec
Time for inference 1: 3.55 sec total, 576.79 tokens/sec
Decode latency: 3.23 sec
Prefill latency: 0.32 sec
Bandwidth achieved: 2090.44 GB/s
FLOPS achieved: 10.45 TF/s

Prefill latency: 0.31474920199252665 sec
Decode latency: 3.2332161620724946 sec
Time for inference 2: 3.55 sec total, 577.10 tokens/sec
Decode latency: 3.23 sec
Prefill latency: 0.31 sec
Bandwidth achieved: 2091.54 GB/s
FLOPS achieved: 10.46 TF/s

Prefill latency: 0.31604029703885317 sec
Decode latency: 3.2334807639708742 sec
Time for inference 3: 3.55 sec total, 576.85 tokens/sec
Decode latency: 3.23 sec
Prefill latency: 0.32 sec
Bandwidth achieved: 2090.64 GB/s
FLOPS achieved: 10.45 TF/s

Prefill latency: 0.3154211729997769 sec
Decode latency: 3.232691971003078 sec
Time for inference 4: 3.55 sec total, 577.09 tokens/sec
Decode latency: 3.23 sec
Prefill latency: 0.32 sec
Bandwidth achieved: 2091.53 GB/s
FLOPS achieved: 10.46 TF/s

Prefill latency: 0.31699298694729805 sec
Decode latency: 3.2346776770427823 sec
Time for inference 5: 3.55 sec total, 576.48 tokens/sec
Decode latency: 3.23 sec
Prefill latency: 0.32 sec
Bandwidth achieved: 2089.30 GB/s
FLOPS achieved: 10.45 TF/s

Prefill latency: 0.3147366850171238 sec
Decode latency: 3.233564157038927 sec
Time for inference 6: 3.55 sec total, 576.99 tokens/sec
Decode latency: 3.23 sec
Prefill latency: 0.31 sec
Bandwidth achieved: 2091.17 GB/s
FLOPS achieved: 10.46 TF/s

Prefill latency: 0.3155224369838834 sec
Decode latency: 3.2339790989644825 sec
Time for inference 7: 3.55 sec total, 576.82 tokens/sec
Decode latency: 3.23 sec
Prefill latency: 0.32 sec
Bandwidth achieved: 2090.55 GB/s
FLOPS achieved: 10.45 TF/s

Prefill latency: 0.3150021000765264 sec
Decode latency: 3.23235380591359 sec
Time for inference 8: 3.55 sec total, 577.20 tokens/sec
Decode latency: 3.23 sec
Prefill latency: 0.32 sec
Bandwidth achieved: 2091.91 GB/s
FLOPS achieved: 10.46 TF/s

Prefill latency: 0.31627007795032114 sec
Decode latency: 3.2333252310054377 sec
Time for inference 9: 3.55 sec total, 576.84 tokens/sec
Decode latency: 3.23 sec
Prefill latency: 0.32 sec
Bandwidth achieved: 2090.60 GB/s
FLOPS achieved: 10.45 TF/s

Prefill latency: 0.3150932230055332 sec
Decode latency: 3.2338277789531276 sec
Time for inference 10: 3.55 sec total, 576.96 tokens/sec
Decode latency: 3.23 sec
Prefill latency: 0.32 sec
Bandwidth achieved: 2091.05 GB/s
FLOPS achieved: 10.46 TF/s

==========
Batch Size: 8
Prompt Length: 1024
Generated tokens: 256
Average decode latency: 3.2335 sec
Average prefill latency: 0.3155 sec
Average tokens/sec: 576.91
Memory used: 10.66 GB
Done. we are killing the process
