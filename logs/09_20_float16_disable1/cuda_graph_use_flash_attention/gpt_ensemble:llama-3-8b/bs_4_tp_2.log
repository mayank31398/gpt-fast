W1001 00:40:21.183000 22946665985856 torch/distributed/run.py:779] 
W1001 00:40:21.183000 22946665985856 torch/distributed/run.py:779] *****************************************
W1001 00:40:21.183000 22946665985856 torch/distributed/run.py:779] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W1001 00:40:21.183000 22946665985856 torch/distributed/run.py:779] *****************************************
flash_kv_decode is set to True
Using device=cuda
Loading model ...
GPTEnsemble(
  (tok_embeddings): Embedding(128256, 4096)
  (layers): ModuleList(
    (0-31): 32 x EnsembleTransformerBlock(
      semi_compiled = False
      (attention): Attention(
        (wqkv): Linear(in_features=4096, out_features=3072, bias=False)
        (wo): Linear(in_features=2048, out_features=4096, bias=False)
      )
      (feed_forward): FeedForward(
        (w1): Linear(in_features=4096, out_features=14336, bias=False)
        (w2): Linear(in_features=7168, out_features=4096, bias=False)
      )
      (ffn_norm): RMSNorm()
      (attention_norm): RMSNorm()
    )
  )
  (norm): RMSNorm()
  (output): Linear(in_features=4096, out_features=128256, bias=False)
)
Time to load model: 0.90 seconds
Prefill latency: 0.1675375672057271 sec
Decode latency: 2.7745879413560033 sec
Compilation time: 2.94 seconds
Compilation time: 2.93 seconds
Prefill latency: 0.15228411927819252 sec
Decode latency: 2.7734906086698174 sec
Prefill latency: 0.1523235635831952 sec
Decode latency: 2.7739113019779325 sec
Prefill latency: 0.15229651145637035 sec
Decode latency: 2.7746982648968697 sec
Prefill latency: 0.1523167109116912 sec
Decode latency: 2.7741574393585324 sec
Prefill latency: 0.15234116092324257 sec
Decode latency: 2.7740938356146216 sec
Time for inference 1: 2.93 sec total, 349.83 tokens/sec
Decode latency: 2.77 sec
Prefill latency: 0.15 sec
Bandwidth achieved: 2809.29 GB/s
FLOPS achieved: 14.05 TF/s

Prefill latency: 0.15227132942527533 sec
Decode latency: 2.7743760207667947 sec
Time for inference 2: 2.93 sec total, 349.79 tokens/sec
Decode latency: 2.77 sec
Prefill latency: 0.15 sec
Bandwidth achieved: 2808.98 GB/s
FLOPS achieved: 14.04 TF/s

Prefill latency: 0.15209187101572752 sec
Decode latency: 2.774650424718857 sec
Time for inference 3: 2.93 sec total, 349.78 tokens/sec
Decode latency: 2.77 sec
Prefill latency: 0.15 sec
Bandwidth achieved: 2808.95 GB/s
FLOPS achieved: 14.04 TF/s

Prefill latency: 0.15239481814205647 sec
Decode latency: 2.774155174382031 sec
Time for inference 4: 2.93 sec total, 349.81 tokens/sec
Decode latency: 2.77 sec
Prefill latency: 0.15 sec
Bandwidth achieved: 2809.17 GB/s
FLOPS achieved: 14.05 TF/s

Prefill latency: 0.1523367539048195 sec
Decode latency: 2.773900625295937 sec
Time for inference 5: 2.93 sec total, 349.85 tokens/sec
Decode latency: 2.77 sec
Prefill latency: 0.15 sec
Bandwidth achieved: 2809.51 GB/s
FLOPS achieved: 14.05 TF/s

Prefill latency: 0.15234910231083632 sec
Decode latency: 2.7742480356246233 sec
Time for inference 6: 2.93 sec total, 349.80 tokens/sec
Decode latency: 2.77 sec
Prefill latency: 0.15 sec
Bandwidth achieved: 2809.09 GB/s
FLOPS achieved: 14.05 TF/s

Prefill latency: 0.1522141033783555 sec
Decode latency: 2.7738671731203794 sec
Time for inference 7: 2.93 sec total, 349.88 tokens/sec
Decode latency: 2.77 sec
Prefill latency: 0.15 sec
Bandwidth achieved: 2809.74 GB/s
FLOPS achieved: 14.05 TF/s

Prefill latency: 0.15239344164729118 sec
Decode latency: 2.773916579782963 sec
Time for inference 8: 2.93 sec total, 349.86 tokens/sec
Decode latency: 2.77 sec
Prefill latency: 0.15 sec
Bandwidth achieved: 2809.53 GB/s
FLOPS achieved: 14.05 TF/s

Prefill latency: 0.15224177483469248 sec
Decode latency: 2.773518887348473 sec
Time for inference 9: 2.93 sec total, 349.91 tokens/sec
Decode latency: 2.77 sec
Prefill latency: 0.15 sec
Bandwidth achieved: 2809.96 GB/s
FLOPS achieved: 14.05 TF/s

Prefill latency: 0.15259444620460272 sec
Decode latency: 2.774448619224131 sec
Time for inference 10: 2.93 sec total, 349.74 tokens/sec
Decode latency: 2.77 sec
Prefill latency: 0.15 sec
Bandwidth achieved: 2808.58 GB/s
FLOPS achieved: 14.04 TF/s

==========
Batch Size: 4
Prompt Length: 1024
Generated tokens: 256
Average decode latency: 2.7741 sec
Average prefill latency: 0.1523 sec
Average tokens/sec: 349.83
Memory used: 12.87 GB
Done. we are killing the process
