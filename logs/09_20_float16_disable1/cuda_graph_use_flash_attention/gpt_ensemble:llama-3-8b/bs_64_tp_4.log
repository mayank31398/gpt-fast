W0928 18:58:20.670000 22691695564608 torch/distributed/run.py:779] 
W0928 18:58:20.670000 22691695564608 torch/distributed/run.py:779] *****************************************
W0928 18:58:20.670000 22691695564608 torch/distributed/run.py:779] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W0928 18:58:20.670000 22691695564608 torch/distributed/run.py:779] *****************************************
flash_kv_decode is set to True
Using device=cuda
Loading model ...
GPTEnsemble(
  (tok_embeddings): Embedding(128256, 4096)
  (layers): ModuleList(
    (0-31): 32 x EnsembleTransformerBlock(
      semi_compiled = False
      (attention): Attention(
        (wqkv): Linear(in_features=4096, out_features=1536, bias=False)
        (wo): Linear(in_features=1024, out_features=4096, bias=False)
      )
      (feed_forward): FeedForward(
        (w1): Linear(in_features=4096, out_features=7168, bias=False)
        (w2): Linear(in_features=3584, out_features=4096, bias=False)
      )
      (ffn_norm): RMSNorm()
      (attention_norm): RMSNorm()
    )
  )
  (norm): RMSNorm()
  (output): Linear(in_features=4096, out_features=128256, bias=False)
)
Time to load model: 1.07 seconds
Prefill latency: 0.7270392654463649 sec
Decode latency: 5.783176708035171 sec
Compilation time: 6.51 seconds
Compilation time: 6.51 seconds
Compilation time: 6.51 seconds
Compilation time: 6.51 seconds
Prefill latency: 0.7239968506619334 sec
Decode latency: 5.782482105307281 sec
Prefill latency: 0.7266913410276175 sec
Decode latency: 5.784056191332638 sec
Prefill latency: 0.7284485790878534 sec
Decode latency: 5.784466767683625 sec
Prefill latency: 0.7325105601921678 sec
Decode latency: 5.78515849635005 sec
Prefill latency: 0.7320370208472013 sec
Decode latency: 5.785474399104714 sec
Time for inference 1: 6.52 sec total, 2513.48 tokens/sec
Decode latency: 5.79 sec
Prefill latency: 0.73 sec
Bandwidth achieved: 11413.40 GB/s
FLOPS achieved: 57.07 TF/s

Prefill latency: 0.7304139984771609 sec
Decode latency: 5.789722197689116 sec
Time for inference 2: 6.52 sec total, 2512.52 tokens/sec
Decode latency: 5.79 sec
Prefill latency: 0.73 sec
Bandwidth achieved: 11409.03 GB/s
FLOPS achieved: 57.05 TF/s

Prefill latency: 0.7324260668829083 sec
Decode latency: 5.785339166410267 sec
Time for inference 3: 6.52 sec total, 2513.44 tokens/sec
Decode latency: 5.79 sec
Prefill latency: 0.73 sec
Bandwidth achieved: 11413.20 GB/s
FLOPS achieved: 57.07 TF/s

Prefill latency: 0.7312052175402641 sec
Decode latency: 5.784862669184804 sec
Time for inference 4: 6.52 sec total, 2514.11 tokens/sec
Decode latency: 5.78 sec
Prefill latency: 0.73 sec
Bandwidth achieved: 11416.26 GB/s
FLOPS achieved: 57.08 TF/s

Prefill latency: 0.7290719877928495 sec
Decode latency: 5.7845633793622255 sec
Time for inference 5: 6.51 sec total, 2515.02 tokens/sec
Decode latency: 5.78 sec
Prefill latency: 0.73 sec
Bandwidth achieved: 11420.38 GB/s
FLOPS achieved: 57.10 TF/s

Prefill latency: 0.725630508735776 sec
Decode latency: 5.788183769211173 sec
Time for inference 6: 6.51 sec total, 2514.92 tokens/sec
Decode latency: 5.79 sec
Prefill latency: 0.73 sec
Bandwidth achieved: 11419.91 GB/s
FLOPS achieved: 57.10 TF/s

Prefill latency: 0.7307232832536101 sec
Decode latency: 5.785924472846091 sec
Time for inference 7: 6.52 sec total, 2513.89 tokens/sec
Decode latency: 5.79 sec
Prefill latency: 0.73 sec
Bandwidth achieved: 11415.25 GB/s
FLOPS achieved: 57.08 TF/s

Prefill latency: 0.7322177169844508 sec
Decode latency: 5.782932627014816 sec
Time for inference 8: 6.52 sec total, 2514.44 tokens/sec
Decode latency: 5.78 sec
Prefill latency: 0.73 sec
Bandwidth achieved: 11417.76 GB/s
FLOPS achieved: 57.09 TF/s

Prefill latency: 0.7312354957684875 sec
Decode latency: 5.785632597282529 sec
Time for inference 9: 6.52 sec total, 2513.79 tokens/sec
Decode latency: 5.79 sec
Prefill latency: 0.73 sec
Bandwidth achieved: 11414.80 GB/s
FLOPS achieved: 57.07 TF/s

Prefill latency: 0.7327006030827761 sec
Decode latency: 5.782017296180129 sec
Time for inference 10: 6.52 sec total, 2514.53 tokens/sec
Decode latency: 5.78 sec
Prefill latency: 0.73 sec
Bandwidth achieved: 11418.15 GB/s
FLOPS achieved: 57.09 TF/s

==========
Batch Size: 64
Prompt Length: 1024
Generated tokens: 256
Average decode latency: 5.7855 sec
Average prefill latency: 0.7308 sec
Average tokens/sec: 2514.02
Memory used: 30.87 GB
Done. we are killing the process
