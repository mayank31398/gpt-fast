W0928 20:31:42.264000 22871823386432 torch/distributed/run.py:779] 
W0928 20:31:42.264000 22871823386432 torch/distributed/run.py:779] *****************************************
W0928 20:31:42.264000 22871823386432 torch/distributed/run.py:779] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W0928 20:31:42.264000 22871823386432 torch/distributed/run.py:779] *****************************************
flash_kv_decode is set to True
Using device=cuda
Loading model ...
GPTEnsemble(
  (tok_embeddings): Embedding(128256, 8192)
  (layers): ModuleList(
    (0-79): 80 x EnsembleTransformerBlock(
      semi_compiled = False
      (attention): Attention(
        (wqkv): Linear(in_features=8192, out_features=5120, bias=False)
        (wo): Linear(in_features=4096, out_features=8192, bias=False)
      )
      (feed_forward): FeedForward(
        (w1): Linear(in_features=8192, out_features=28672, bias=False)
        (w2): Linear(in_features=14336, out_features=8192, bias=False)
      )
      (ffn_norm): RMSNorm()
      (attention_norm): RMSNorm()
    )
  )
  (norm): RMSNorm()
  (output): Linear(in_features=8192, out_features=128256, bias=False)
)
Time to load model: 1.04 seconds
Prefill latency: 0.2706004159990698 sec
Decode latency: 10.163079923950136 sec
Compilation time: 10.44 seconds
Compilation time: 10.43 seconds
Prefill latency: 0.2509373869979754 sec
Decode latency: 10.158412666991353 sec
Prefill latency: 0.2504803210031241 sec
Decode latency: 10.158023227006197 sec
Prefill latency: 0.2513822019682266 sec
Decode latency: 10.161303478002083 sec
Prefill latency: 0.2503164660301991 sec
Decode latency: 10.161076393036637 sec
Prefill latency: 0.25075228401692584 sec
Decode latency: 10.15986634598812 sec
Time for inference 1: 10.41 sec total, 24.59 tokens/sec
Decode latency: 10.16 sec
Prefill latency: 0.25 sec
Bandwidth achieved: 1734.78 GB/s
FLOPS achieved: 8.67 TF/s

Prefill latency: 0.2503646690165624 sec
Decode latency: 10.161451302003115 sec
Time for inference 2: 10.41 sec total, 24.58 tokens/sec
Decode latency: 10.16 sec
Prefill latency: 0.25 sec
Bandwidth achieved: 1734.59 GB/s
FLOPS achieved: 8.67 TF/s

Prefill latency: 0.25131596700521186 sec
Decode latency: 10.159922461025417 sec
Time for inference 3: 10.41 sec total, 24.59 tokens/sec
Decode latency: 10.16 sec
Prefill latency: 0.25 sec
Bandwidth achieved: 1734.70 GB/s
FLOPS achieved: 8.67 TF/s

Prefill latency: 0.24981374898925424 sec
Decode latency: 10.160872929962352 sec
Time for inference 4: 10.41 sec total, 24.59 tokens/sec
Decode latency: 10.16 sec
Prefill latency: 0.25 sec
Bandwidth achieved: 1734.75 GB/s
FLOPS achieved: 8.67 TF/s

Prefill latency: 0.2510665920563042 sec
Decode latency: 10.160833243979141 sec
Time for inference 5: 10.41 sec total, 24.58 tokens/sec
Decode latency: 10.16 sec
Prefill latency: 0.25 sec
Bandwidth achieved: 1734.58 GB/s
FLOPS achieved: 8.67 TF/s

Prefill latency: 0.2504715829854831 sec
Decode latency: 10.16051920998143 sec
Time for inference 6: 10.41 sec total, 24.59 tokens/sec
Decode latency: 10.16 sec
Prefill latency: 0.25 sec
Bandwidth achieved: 1734.73 GB/s
FLOPS achieved: 8.67 TF/s

Prefill latency: 0.25075030204607174 sec
Decode latency: 10.161048301961273 sec
Time for inference 7: 10.41 sec total, 24.58 tokens/sec
Decode latency: 10.16 sec
Prefill latency: 0.25 sec
Bandwidth achieved: 1734.59 GB/s
FLOPS achieved: 8.67 TF/s

Prefill latency: 0.2499466220033355 sec
Decode latency: 10.160836521943565 sec
Time for inference 8: 10.41 sec total, 24.59 tokens/sec
Decode latency: 10.16 sec
Prefill latency: 0.25 sec
Bandwidth achieved: 1734.77 GB/s
FLOPS achieved: 8.67 TF/s

Prefill latency: 0.25127430498832837 sec
Decode latency: 10.161047684028745 sec
Time for inference 9: 10.41 sec total, 24.58 tokens/sec
Decode latency: 10.16 sec
Prefill latency: 0.25 sec
Bandwidth achieved: 1734.51 GB/s
FLOPS achieved: 8.67 TF/s

Prefill latency: 0.25008842698298395 sec
Decode latency: 10.16122126497794 sec
Time for inference 10: 10.41 sec total, 24.59 tokens/sec
Decode latency: 10.16 sec
Prefill latency: 0.25 sec
Bandwidth achieved: 1734.66 GB/s
FLOPS achieved: 8.67 TF/s

==========
Batch Size: 1
Prompt Length: 1024
Generated tokens: 256
Average decode latency: 10.1608 sec
Average prefill latency: 0.2506 sec
Average tokens/sec: 24.59
Memory used: 75.76 GB
Done. we are killing the process
