flash_kv_decode is set to True
Using device=cuda
Loading model ...
GPTParallel(
  (tok_embeddings): Embedding(49152, 2304)
  (layers): ModuleList(
    (0-39): 40 x ParallelTransformerBlock(
      semi_compiled = False
      (attention): FuseAttentionMLP(
        (wqkv1): Linear(in_features=2304, out_features=25344, bias=False)
        (wo): Linear(in_features=2304, out_features=2304, bias=False)
        (w2): Linear(in_features=9216, out_features=2304, bias=False)
      )
      (attention_norm): RMSNorm()
    )
  )
  (norm): RMSNorm()
  (output): Linear(in_features=2304, out_features=49152, bias=False)
)
Time to load model: 0.97 seconds
Prefill latency: 0.031393463956192136 sec
Decode latency: 2.4956311280839145 sec
Compilation time: 2.53 seconds
Prefill latency: 0.03108213806990534 sec
Decode latency: 2.4950620610034093 sec
Prefill latency: 0.030995472916401923 sec
Decode latency: 2.3708023000508547 sec
Prefill latency: 0.030995497945696115 sec
Decode latency: 2.4950499669648707 sec
Prefill latency: 0.03106781793758273 sec
Decode latency: 2.4928941669641063 sec
Prefill latency: 0.031025830074213445 sec
Decode latency: 2.4955272749066353 sec
Time for inference 1: 2.53 sec total, 101.30 tokens/sec
Decode latency: 2.50 sec
Prefill latency: 0.03 sec
Bandwidth achieved: 711.26 GB/s
FLOPS achieved: 3.56 TF/s

Prefill latency: 0.030997960944660008 sec
Decode latency: 2.420797456987202 sec
Time for inference 2: 2.45 sec total, 104.39 tokens/sec
Decode latency: 2.42 sec
Prefill latency: 0.03 sec
Bandwidth achieved: 732.94 GB/s
FLOPS achieved: 3.66 TF/s

Prefill latency: 0.03100040298886597 sec
Decode latency: 2.4946392429992557 sec
Time for inference 3: 2.53 sec total, 101.34 tokens/sec
Decode latency: 2.49 sec
Prefill latency: 0.03 sec
Bandwidth achieved: 711.52 GB/s
FLOPS achieved: 3.56 TF/s

Prefill latency: 0.030980882002040744 sec
Decode latency: 2.4937205290189013 sec
Time for inference 4: 2.53 sec total, 101.37 tokens/sec
Decode latency: 2.49 sec
Prefill latency: 0.03 sec
Bandwidth achieved: 711.79 GB/s
FLOPS achieved: 3.56 TF/s

Prefill latency: 0.031065120943821967 sec
Decode latency: 2.4945692600449547 sec
Time for inference 5: 2.53 sec total, 101.34 tokens/sec
Decode latency: 2.49 sec
Prefill latency: 0.03 sec
Bandwidth achieved: 711.53 GB/s
FLOPS achieved: 3.56 TF/s

Prefill latency: 0.030984855955466628 sec
Decode latency: 2.446631879080087 sec
Time for inference 6: 2.48 sec total, 103.30 tokens/sec
Decode latency: 2.45 sec
Prefill latency: 0.03 sec
Bandwidth achieved: 725.31 GB/s
FLOPS achieved: 3.63 TF/s

Prefill latency: 0.03103760303929448 sec
Decode latency: 2.3970436319941655 sec
Time for inference 7: 2.43 sec total, 105.40 tokens/sec
Decode latency: 2.40 sec
Prefill latency: 0.03 sec
Bandwidth achieved: 740.09 GB/s
FLOPS achieved: 3.70 TF/s

Prefill latency: 0.03106765600387007 sec
Decode latency: 2.374257234041579 sec
Time for inference 8: 2.41 sec total, 106.40 tokens/sec
Decode latency: 2.37 sec
Prefill latency: 0.03 sec
Bandwidth achieved: 747.09 GB/s
FLOPS achieved: 3.74 TF/s

Prefill latency: 0.0310543579980731 sec
Decode latency: 2.494340463075787 sec
Time for inference 9: 2.53 sec total, 101.34 tokens/sec
Decode latency: 2.49 sec
Prefill latency: 0.03 sec
Bandwidth achieved: 711.58 GB/s
FLOPS achieved: 3.56 TF/s

Prefill latency: 0.03100555296987295 sec
Decode latency: 2.49435628997162 sec
Time for inference 10: 2.53 sec total, 101.34 tokens/sec
Decode latency: 2.49 sec
Prefill latency: 0.03 sec
Bandwidth achieved: 711.59 GB/s
FLOPS achieved: 3.56 TF/s

==========
Batch Size: 1
Prompt Length: 1024
Generated tokens: 256
Average decode latency: 2.4606 sec
Average prefill latency: 0.0310 sec
Average tokens/sec: 102.75
Memory used: 8.54 GB
Done. we are killing the process
