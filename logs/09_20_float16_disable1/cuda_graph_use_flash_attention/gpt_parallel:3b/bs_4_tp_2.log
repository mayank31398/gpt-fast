W1001 03:52:04.575000 22399516059456 torch/distributed/run.py:779] 
W1001 03:52:04.575000 22399516059456 torch/distributed/run.py:779] *****************************************
W1001 03:52:04.575000 22399516059456 torch/distributed/run.py:779] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W1001 03:52:04.575000 22399516059456 torch/distributed/run.py:779] *****************************************
flash_kv_decode is set to True
Using device=cuda
Loading model ...
GPTParallel(
  (tok_embeddings): Embedding(49152, 2304)
  (layers): ModuleList(
    (0-39): 40 x ParallelTransformerBlock(
      semi_compiled = False
      (attention): FuseAttentionMLP(
        (wqkv1): Linear(in_features=2304, out_features=12672, bias=False)
        (wo): Linear(in_features=1152, out_features=2304, bias=False)
        (w2): Linear(in_features=4608, out_features=2304, bias=False)
      )
      (attention_norm): RMSNorm()
    )
  )
  (norm): RMSNorm()
  (output): Linear(in_features=2304, out_features=49152, bias=False)
)
Time to load model: 1.01 seconds
Prefill latency: 0.12884468701668084 sec
Decode latency: 2.5821513610426337 sec
Compilation time: 2.71 seconds
Compilation time: 2.70 seconds
Prefill latency: 0.1085971639258787 sec
Decode latency: 2.5802820790559053 sec
Prefill latency: 0.10875848704017699 sec
Decode latency: 2.581329280976206 sec
Prefill latency: 0.10937059193383902 sec
Decode latency: 2.5808849529130384 sec
Prefill latency: 0.10905798908788711 sec
Decode latency: 2.579316596966237 sec
Prefill latency: 0.10916279698722064 sec
Decode latency: 2.580696906079538 sec
Time for inference 1: 2.69 sec total, 380.53 tokens/sec
Decode latency: 2.58 sec
Prefill latency: 0.11 sec
Bandwidth achieved: 1379.08 GB/s
FLOPS achieved: 6.90 TF/s

Prefill latency: 0.10931404097937047 sec
Decode latency: 2.5813541839597747 sec
Time for inference 2: 2.69 sec total, 380.43 tokens/sec
Decode latency: 2.58 sec
Prefill latency: 0.11 sec
Bandwidth achieved: 1378.70 GB/s
FLOPS achieved: 6.89 TF/s

Prefill latency: 0.10915761906653643 sec
Decode latency: 2.5815212330780923 sec
Time for inference 3: 2.69 sec total, 380.44 tokens/sec
Decode latency: 2.58 sec
Prefill latency: 0.11 sec
Bandwidth achieved: 1378.72 GB/s
FLOPS achieved: 6.89 TF/s

Prefill latency: 0.10930191492661834 sec
Decode latency: 2.5806335820816457 sec
Time for inference 4: 2.69 sec total, 380.57 tokens/sec
Decode latency: 2.58 sec
Prefill latency: 0.11 sec
Bandwidth achieved: 1379.20 GB/s
FLOPS achieved: 6.90 TF/s

Prefill latency: 0.10916949599049985 sec
Decode latency: 2.5811982380691916 sec
Time for inference 5: 2.69 sec total, 380.51 tokens/sec
Decode latency: 2.58 sec
Prefill latency: 0.11 sec
Bandwidth achieved: 1379.00 GB/s
FLOPS achieved: 6.89 TF/s

Prefill latency: 0.10924690996762365 sec
Decode latency: 2.581667826976627 sec
Time for inference 6: 2.69 sec total, 380.43 tokens/sec
Decode latency: 2.58 sec
Prefill latency: 0.11 sec
Bandwidth achieved: 1378.71 GB/s
FLOPS achieved: 6.89 TF/s

Prefill latency: 0.10918062599375844 sec
Decode latency: 2.581701324088499 sec
Time for inference 7: 2.69 sec total, 380.44 tokens/sec
Decode latency: 2.58 sec
Prefill latency: 0.11 sec
Bandwidth achieved: 1378.73 GB/s
FLOPS achieved: 6.89 TF/s

Prefill latency: 0.10933131200727075 sec
Decode latency: 2.5804503919789568 sec
Time for inference 8: 2.69 sec total, 380.60 tokens/sec
Decode latency: 2.58 sec
Prefill latency: 0.11 sec
Bandwidth achieved: 1379.31 GB/s
FLOPS achieved: 6.90 TF/s

Prefill latency: 0.10923919605556875 sec
Decode latency: 2.5808521000435576 sec
Time for inference 9: 2.69 sec total, 380.55 tokens/sec
Decode latency: 2.58 sec
Prefill latency: 0.11 sec
Bandwidth achieved: 1379.13 GB/s
FLOPS achieved: 6.90 TF/s

Prefill latency: 0.10937463608570397 sec
Decode latency: 2.5822148949373513 sec
Time for inference 10: 2.69 sec total, 380.31 tokens/sec
Decode latency: 2.58 sec
Prefill latency: 0.11 sec
Bandwidth achieved: 1378.29 GB/s
FLOPS achieved: 6.89 TF/s

==========
Batch Size: 4
Prompt Length: 1024
Generated tokens: 256
Average decode latency: 2.5812 sec
Average prefill latency: 0.1092 sec
Average tokens/sec: 380.48
Memory used: 6.62 GB
Done. we are killing the process
