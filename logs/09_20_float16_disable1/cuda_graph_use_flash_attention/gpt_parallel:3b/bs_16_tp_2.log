W1001 03:58:28.745000 22425158477632 torch/distributed/run.py:779] 
W1001 03:58:28.745000 22425158477632 torch/distributed/run.py:779] *****************************************
W1001 03:58:28.745000 22425158477632 torch/distributed/run.py:779] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W1001 03:58:28.745000 22425158477632 torch/distributed/run.py:779] *****************************************
flash_kv_decode is set to True
Using device=cuda
Loading model ...
GPTParallel(
  (tok_embeddings): Embedding(49152, 2304)
  (layers): ModuleList(
    (0-39): 40 x ParallelTransformerBlock(
      semi_compiled = False
      (attention): FuseAttentionMLP(
        (wqkv1): Linear(in_features=2304, out_features=12672, bias=False)
        (wo): Linear(in_features=1152, out_features=2304, bias=False)
        (w2): Linear(in_features=4608, out_features=2304, bias=False)
      )
      (attention_norm): RMSNorm()
    )
  )
  (norm): RMSNorm()
  (output): Linear(in_features=2304, out_features=49152, bias=False)
)
Time to load model: 0.98 seconds
Prefill latency: 0.4358140949625522 sec
Decode latency: 3.4850952919805422 sec
Compilation time: 3.94 seconds
Compilation time: 3.92 seconds
Prefill latency: 0.4108105310006067 sec
Decode latency: 3.4818379239877686 sec
Prefill latency: 0.4112603859975934 sec
Decode latency: 3.4818310500122607 sec
Prefill latency: 0.41167589207179844 sec
Decode latency: 3.4773025929462165 sec
Prefill latency: 0.41023424395825714 sec
Decode latency: 3.477336679934524 sec
Prefill latency: 0.41127266304101795 sec
Decode latency: 3.4760259960312396 sec
Time for inference 1: 3.89 sec total, 1053.45 tokens/sec
Decode latency: 3.48 sec
Prefill latency: 0.41 sec
Bandwidth achieved: 3817.78 GB/s
FLOPS achieved: 19.09 TF/s

Prefill latency: 0.4108907670015469 sec
Decode latency: 3.4760661909822375 sec
Time for inference 2: 3.89 sec total, 1053.57 tokens/sec
Decode latency: 3.48 sec
Prefill latency: 0.41 sec
Bandwidth achieved: 3818.19 GB/s
FLOPS achieved: 19.09 TF/s

Prefill latency: 0.4102554830024019 sec
Decode latency: 3.476323537994176 sec
Time for inference 3: 3.89 sec total, 1053.69 tokens/sec
Decode latency: 3.48 sec
Prefill latency: 0.41 sec
Bandwidth achieved: 3818.64 GB/s
FLOPS achieved: 19.09 TF/s

Prefill latency: 0.41098925401456654 sec
Decode latency: 3.477591831004247 sec
Time for inference 4: 3.89 sec total, 1053.14 tokens/sec
Decode latency: 3.48 sec
Prefill latency: 0.41 sec
Bandwidth achieved: 3816.66 GB/s
FLOPS achieved: 19.08 TF/s

Prefill latency: 0.41044323798269033 sec
Decode latency: 3.4769594570389017 sec
Time for inference 5: 3.89 sec total, 1053.47 tokens/sec
Decode latency: 3.48 sec
Prefill latency: 0.41 sec
Bandwidth achieved: 3817.83 GB/s
FLOPS achieved: 19.09 TF/s

Prefill latency: 0.4109475240111351 sec
Decode latency: 3.4761154679581523 sec
Time for inference 6: 3.89 sec total, 1053.52 tokens/sec
Decode latency: 3.48 sec
Prefill latency: 0.41 sec
Bandwidth achieved: 3818.04 GB/s
FLOPS achieved: 19.09 TF/s

Prefill latency: 0.41067650995682925 sec
Decode latency: 3.4764454269316047 sec
Time for inference 7: 3.89 sec total, 1053.52 tokens/sec
Decode latency: 3.48 sec
Prefill latency: 0.41 sec
Bandwidth achieved: 3818.02 GB/s
FLOPS achieved: 19.09 TF/s

Prefill latency: 0.41083585389424115 sec
Decode latency: 3.478346375050023 sec
Time for inference 8: 3.89 sec total, 1052.91 tokens/sec
Decode latency: 3.48 sec
Prefill latency: 0.41 sec
Bandwidth achieved: 3815.83 GB/s
FLOPS achieved: 19.08 TF/s

Prefill latency: 0.4107784510124475 sec
Decode latency: 3.47596278693527 sec
Time for inference 9: 3.89 sec total, 1053.60 tokens/sec
Decode latency: 3.48 sec
Prefill latency: 0.41 sec
Bandwidth achieved: 3818.33 GB/s
FLOPS achieved: 19.09 TF/s

Prefill latency: 0.41159909300040454 sec
Decode latency: 3.475629938999191 sec
Time for inference 10: 3.89 sec total, 1053.50 tokens/sec
Decode latency: 3.48 sec
Prefill latency: 0.41 sec
Bandwidth achieved: 3817.96 GB/s
FLOPS achieved: 19.09 TF/s

==========
Batch Size: 16
Prompt Length: 1024
Generated tokens: 256
Average decode latency: 3.4765 sec
Average prefill latency: 0.4109 sec
Average tokens/sec: 1053.44
Memory used: 13.98 GB
Done. we are killing the process
