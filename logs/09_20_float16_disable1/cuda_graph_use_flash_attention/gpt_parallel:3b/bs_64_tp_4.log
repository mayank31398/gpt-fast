W1001 04:07:10.032000 23073866889024 torch/distributed/run.py:779] 
W1001 04:07:10.032000 23073866889024 torch/distributed/run.py:779] *****************************************
W1001 04:07:10.032000 23073866889024 torch/distributed/run.py:779] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W1001 04:07:10.032000 23073866889024 torch/distributed/run.py:779] *****************************************
flash_kv_decode is set to True
Using device=cuda
Loading model ...
GPTParallel(
  (tok_embeddings): Embedding(49152, 2304)
  (layers): ModuleList(
    (0-39): 40 x ParallelTransformerBlock(
      semi_compiled = False
      (attention): FuseAttentionMLP(
        (wqkv1): Linear(in_features=2304, out_features=6336, bias=False)
        (wo): Linear(in_features=576, out_features=2304, bias=False)
        (w2): Linear(in_features=2304, out_features=2304, bias=False)
      )
      (attention_norm): RMSNorm()
    )
  )
  (norm): RMSNorm()
  (output): Linear(in_features=2304, out_features=49152, bias=False)
)
Time to load model: 1.18 seconds
Prefill latency: 0.5074297270039096 sec
Decode latency: 5.062942962045781 sec
Compilation time: 5.56 seconds
Compilation time: 5.56 seconds
Compilation time: 5.57 seconds
Compilation time: 5.56 seconds
Prefill latency: 0.4916351019637659 sec
Decode latency: 5.060039421077818 sec
Prefill latency: 0.4920310489833355 sec
Decode latency: 5.061774722998962 sec
Prefill latency: 0.49205990007612854 sec
Decode latency: 5.061667593894526 sec
Prefill latency: 0.4918236288940534 sec
Decode latency: 5.063438937999308 sec
Prefill latency: 0.49292196705937386 sec
Decode latency: 5.061263228999451 sec
Time for inference 1: 5.56 sec total, 2949.34 tokens/sec
Decode latency: 5.06 sec
Prefill latency: 0.49 sec
Bandwidth achieved: 5678.58 GB/s
FLOPS achieved: 28.39 TF/s

Prefill latency: 0.49312981602270156 sec
Decode latency: 5.059879343025386 sec
Time for inference 2: 5.55 sec total, 2950.03 tokens/sec
Decode latency: 5.06 sec
Prefill latency: 0.49 sec
Bandwidth achieved: 5679.91 GB/s
FLOPS achieved: 28.40 TF/s

Prefill latency: 0.4933964309748262 sec
Decode latency: 5.061737448908389 sec
Time for inference 3: 5.56 sec total, 2948.98 tokens/sec
Decode latency: 5.06 sec
Prefill latency: 0.49 sec
Bandwidth achieved: 5677.90 GB/s
FLOPS achieved: 28.39 TF/s

Prefill latency: 0.49334536399692297 sec
Decode latency: 5.061394187039696 sec
Time for inference 4: 5.56 sec total, 2949.14 tokens/sec
Decode latency: 5.06 sec
Prefill latency: 0.49 sec
Bandwidth achieved: 5678.20 GB/s
FLOPS achieved: 28.39 TF/s

Prefill latency: 0.49359947501216084 sec
Decode latency: 5.060391698032618 sec
Time for inference 5: 5.55 sec total, 2949.56 tokens/sec
Decode latency: 5.06 sec
Prefill latency: 0.49 sec
Bandwidth achieved: 5679.00 GB/s
FLOPS achieved: 28.39 TF/s

Prefill latency: 0.49286198196932673 sec
Decode latency: 5.059339734027162 sec
Time for inference 6: 5.55 sec total, 2950.48 tokens/sec
Decode latency: 5.06 sec
Prefill latency: 0.49 sec
Bandwidth achieved: 5680.78 GB/s
FLOPS achieved: 28.40 TF/s

Prefill latency: 0.4928732729749754 sec
Decode latency: 5.062746157986112 sec
Time for inference 7: 5.56 sec total, 2948.62 tokens/sec
Decode latency: 5.06 sec
Prefill latency: 0.49 sec
Bandwidth achieved: 5677.19 GB/s
FLOPS achieved: 28.39 TF/s

Prefill latency: 0.4935109110083431 sec
Decode latency: 5.060372957028449 sec
Time for inference 8: 5.55 sec total, 2949.59 tokens/sec
Decode latency: 5.06 sec
Prefill latency: 0.49 sec
Bandwidth achieved: 5679.07 GB/s
FLOPS achieved: 28.40 TF/s

Prefill latency: 0.49366556806489825 sec
Decode latency: 5.0592577329371125 sec
Time for inference 9: 5.55 sec total, 2950.10 tokens/sec
Decode latency: 5.06 sec
Prefill latency: 0.49 sec
Bandwidth achieved: 5680.05 GB/s
FLOPS achieved: 28.40 TF/s

Prefill latency: 0.49299574200995266 sec
Decode latency: 5.059937911923043 sec
Time for inference 10: 5.55 sec total, 2950.11 tokens/sec
Decode latency: 5.06 sec
Prefill latency: 0.49 sec
Bandwidth achieved: 5680.06 GB/s
FLOPS achieved: 28.40 TF/s

==========
Batch Size: 64
Prompt Length: 1024
Generated tokens: 256
Average decode latency: 5.0606 sec
Average prefill latency: 0.4932 sec
Average tokens/sec: 2949.59
Memory used: 31.45 GB
Done. we are killing the process
