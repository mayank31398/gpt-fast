W1001 04:20:09.702000 22957197731648 torch/distributed/run.py:779] 
W1001 04:20:09.702000 22957197731648 torch/distributed/run.py:779] *****************************************
W1001 04:20:09.702000 22957197731648 torch/distributed/run.py:779] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W1001 04:20:09.702000 22957197731648 torch/distributed/run.py:779] *****************************************
flash_kv_decode is set to True
Using device=cuda
Loading model ...
GPTEnsemble(
  (tok_embeddings): Embedding(49152, 2304)
  (layers): ModuleList(
    (0-39): 40 x EnsembleTransformerBlock(
      semi_compiled = False
      (attention): Attention(
        (wqkv): Linear(in_features=2304, out_features=1728, bias=False)
        (wo): Linear(in_features=576, out_features=2304, bias=False)
      )
      (feed_forward): FeedForward(
        (w1): Linear(in_features=2304, out_features=4608, bias=False)
        (w2): Linear(in_features=2304, out_features=2304, bias=False)
      )
      (ffn_norm): RMSNorm()
      (attention_norm): RMSNorm()
    )
  )
  (norm): RMSNorm()
  (output): Linear(in_features=2304, out_features=49152, bias=False)
)
Time to load model: 1.05 seconds
Prefill latency: 0.13981063303072006 sec
Decode latency: 2.961119655985385 sec
Compilation time: 3.10 seconds
Compilation time: 3.10 seconds
Compilation time: 3.10 seconds
Compilation time: 3.09 seconds
Prefill latency: 0.13146150205284357 sec
Decode latency: 2.9592418720712885 sec
Prefill latency: 0.13151039206422865 sec
Decode latency: 2.958944650948979 sec
Prefill latency: 0.13125822599977255 sec
Decode latency: 2.9590636070352048 sec
Prefill latency: 0.13145858305506408 sec
Decode latency: 2.9581416790606454 sec
Prefill latency: 0.1314467650372535 sec
Decode latency: 2.959592091036029 sec
Time for inference 1: 3.09 sec total, 1324.80 tokens/sec
Decode latency: 2.96 sec
Prefill latency: 0.13 sec
Bandwidth achieved: 2550.98 GB/s
FLOPS achieved: 12.75 TF/s

Prefill latency: 0.1312498579500243 sec
Decode latency: 2.9599236639915034 sec
Time for inference 2: 3.09 sec total, 1324.74 tokens/sec
Decode latency: 2.96 sec
Prefill latency: 0.13 sec
Bandwidth achieved: 2550.86 GB/s
FLOPS achieved: 12.75 TF/s

Prefill latency: 0.1314131119288504 sec
Decode latency: 2.9606883568922058 sec
Time for inference 3: 3.09 sec total, 1324.35 tokens/sec
Decode latency: 2.96 sec
Prefill latency: 0.13 sec
Bandwidth achieved: 2550.10 GB/s
FLOPS achieved: 12.75 TF/s

Prefill latency: 0.13152264594100416 sec
Decode latency: 2.9579167020274326 sec
Time for inference 4: 3.09 sec total, 1325.43 tokens/sec
Decode latency: 2.96 sec
Prefill latency: 0.13 sec
Bandwidth achieved: 2552.19 GB/s
FLOPS achieved: 12.76 TF/s

Prefill latency: 0.1313319590408355 sec
Decode latency: 2.9602088120300323 sec
Time for inference 5: 3.09 sec total, 1324.56 tokens/sec
Decode latency: 2.96 sec
Prefill latency: 0.13 sec
Bandwidth achieved: 2550.52 GB/s
FLOPS achieved: 12.75 TF/s

Prefill latency: 0.1315006110817194 sec
Decode latency: 2.958820806001313 sec
Time for inference 6: 3.09 sec total, 1325.01 tokens/sec
Decode latency: 2.96 sec
Prefill latency: 0.13 sec
Bandwidth achieved: 2551.39 GB/s
FLOPS achieved: 12.76 TF/s

Prefill latency: 0.13147961103823036 sec
Decode latency: 2.959350691991858 sec
Time for inference 7: 3.09 sec total, 1324.83 tokens/sec
Decode latency: 2.96 sec
Prefill latency: 0.13 sec
Bandwidth achieved: 2551.05 GB/s
FLOPS achieved: 12.76 TF/s

Prefill latency: 0.13144943106453866 sec
Decode latency: 2.9604510199278593 sec
Time for inference 8: 3.09 sec total, 1324.42 tokens/sec
Decode latency: 2.96 sec
Prefill latency: 0.13 sec
Bandwidth achieved: 2550.24 GB/s
FLOPS achieved: 12.75 TF/s

Prefill latency: 0.13146414596121758 sec
Decode latency: 2.9582061369437724 sec
Time for inference 9: 3.09 sec total, 1325.39 tokens/sec
Decode latency: 2.96 sec
Prefill latency: 0.13 sec
Bandwidth achieved: 2552.11 GB/s
FLOPS achieved: 12.76 TF/s

Prefill latency: 0.13156012503895909 sec
Decode latency: 2.9585908559383824 sec
Time for inference 10: 3.09 sec total, 1325.21 tokens/sec
Decode latency: 2.96 sec
Prefill latency: 0.13 sec
Bandwidth achieved: 2551.76 GB/s
FLOPS achieved: 12.76 TF/s

==========
Batch Size: 16
Prompt Length: 1024
Generated tokens: 256
Average decode latency: 2.9594 sec
Average prefill latency: 0.1314 sec
Average tokens/sec: 1324.87
Memory used: 9.77 GB
Done. we are killing the process
