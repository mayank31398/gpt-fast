W1001 04:25:10.719000 22499613226816 torch/distributed/run.py:779] 
W1001 04:25:10.719000 22499613226816 torch/distributed/run.py:779] *****************************************
W1001 04:25:10.719000 22499613226816 torch/distributed/run.py:779] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W1001 04:25:10.719000 22499613226816 torch/distributed/run.py:779] *****************************************
flash_kv_decode is set to True
Using device=cuda
Loading model ...
GPTEnsemble(
  (tok_embeddings): Embedding(49152, 2304)
  (layers): ModuleList(
    (0-39): 40 x EnsembleTransformerBlock(
      semi_compiled = False
      (attention): Attention(
        (wqkv): Linear(in_features=2304, out_features=3456, bias=False)
        (wo): Linear(in_features=1152, out_features=2304, bias=False)
      )
      (feed_forward): FeedForward(
        (w1): Linear(in_features=2304, out_features=9216, bias=False)
        (w2): Linear(in_features=4608, out_features=2304, bias=False)
      )
      (ffn_norm): RMSNorm()
      (attention_norm): RMSNorm()
    )
  )
  (norm): RMSNorm()
  (output): Linear(in_features=2304, out_features=49152, bias=False)
)
Time to load model: 1.05 seconds
Prefill latency: 1.709877802990377 sec
Decode latency: 7.905420911964029 sec
Compilation time: 9.63 seconds
Compilation time: 9.62 seconds
Prefill latency: 1.632779173902236 sec
Decode latency: 7.906172181013972 sec
Prefill latency: 1.6357854210073128 sec
Decode latency: 7.909165338962339 sec
Prefill latency: 1.6365074509521946 sec
Decode latency: 7.901216209982522 sec
Prefill latency: 1.640476842992939 sec
Decode latency: 7.899979781941511 sec
Prefill latency: 1.6351830119965598 sec
Decode latency: 7.898951106937602 sec
Time for inference 1: 9.54 sec total, 1718.22 tokens/sec
Decode latency: 7.90 sec
Prefill latency: 1.64 sec
Bandwidth achieved: 6227.25 GB/s
FLOPS achieved: 31.14 TF/s

Prefill latency: 1.6408235830022022 sec
Decode latency: 7.903577235061675 sec
Time for inference 2: 9.55 sec total, 1716.40 tokens/sec
Decode latency: 7.90 sec
Prefill latency: 1.64 sec
Bandwidth achieved: 6220.68 GB/s
FLOPS achieved: 31.10 TF/s

Prefill latency: 1.6372592239640653 sec
Decode latency: 7.896944878040813 sec
Time for inference 3: 9.54 sec total, 1718.27 tokens/sec
Decode latency: 7.90 sec
Prefill latency: 1.64 sec
Bandwidth achieved: 6227.46 GB/s
FLOPS achieved: 31.14 TF/s

Prefill latency: 1.6396846900461242 sec
Decode latency: 7.897329977015033 sec
Time for inference 4: 9.54 sec total, 1717.78 tokens/sec
Decode latency: 7.90 sec
Prefill latency: 1.64 sec
Bandwidth achieved: 6225.69 GB/s
FLOPS achieved: 31.13 TF/s

Prefill latency: 1.6382847760105506 sec
Decode latency: 7.900029459968209 sec
Time for inference 5: 9.54 sec total, 1717.49 tokens/sec
Decode latency: 7.90 sec
Prefill latency: 1.64 sec
Bandwidth achieved: 6224.63 GB/s
FLOPS achieved: 31.12 TF/s

Prefill latency: 1.6394492899999022 sec
Decode latency: 7.9006423690589145 sec
Time for inference 6: 9.54 sec total, 1717.21 tokens/sec
Decode latency: 7.90 sec
Prefill latency: 1.64 sec
Bandwidth achieved: 6223.62 GB/s
FLOPS achieved: 31.12 TF/s

Prefill latency: 1.642594882985577 sec
Decode latency: 7.8904749191133305 sec
Time for inference 7: 9.53 sec total, 1718.49 tokens/sec
Decode latency: 7.89 sec
Prefill latency: 1.64 sec
Bandwidth achieved: 6228.24 GB/s
FLOPS achieved: 31.14 TF/s

Prefill latency: 1.6388934899587184 sec
Decode latency: 7.888878589030355 sec
Time for inference 8: 9.53 sec total, 1719.41 tokens/sec
Decode latency: 7.89 sec
Prefill latency: 1.64 sec
Bandwidth achieved: 6231.59 GB/s
FLOPS achieved: 31.16 TF/s

Prefill latency: 1.6346073129680008 sec
Decode latency: 7.88933185802307 sec
Time for inference 9: 9.52 sec total, 1720.12 tokens/sec
Decode latency: 7.89 sec
Prefill latency: 1.63 sec
Bandwidth achieved: 6234.15 GB/s
FLOPS achieved: 31.17 TF/s

Prefill latency: 1.6362409560242668 sec
Decode latency: 7.8936765170656145 sec
Time for inference 10: 9.53 sec total, 1719.05 tokens/sec
Decode latency: 7.89 sec
Prefill latency: 1.64 sec
Bandwidth achieved: 6230.27 GB/s
FLOPS achieved: 31.15 TF/s

==========
Batch Size: 64
Prompt Length: 1024
Generated tokens: 256
Average decode latency: 7.8960 sec
Average prefill latency: 1.6383 sec
Average tokens/sec: 1718.25
Memory used: 42.02 GB
Done. we are killing the process
