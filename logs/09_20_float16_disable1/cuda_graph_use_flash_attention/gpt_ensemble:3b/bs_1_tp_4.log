W1001 04:10:31.902000 23129535665984 torch/distributed/run.py:779] 
W1001 04:10:31.902000 23129535665984 torch/distributed/run.py:779] *****************************************
W1001 04:10:31.902000 23129535665984 torch/distributed/run.py:779] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W1001 04:10:31.902000 23129535665984 torch/distributed/run.py:779] *****************************************
flash_kv_decode is set to True
Using device=cuda
Loading model ...
GPTEnsemble(
  (tok_embeddings): Embedding(49152, 2304)
  (layers): ModuleList(
    (0-39): 40 x EnsembleTransformerBlock(
      semi_compiled = False
      (attention): Attention(
        (wqkv): Linear(in_features=2304, out_features=1728, bias=False)
        (wo): Linear(in_features=576, out_features=2304, bias=False)
      )
      (feed_forward): FeedForward(
        (w1): Linear(in_features=2304, out_features=4608, bias=False)
        (w2): Linear(in_features=2304, out_features=2304, bias=False)
      )
      (ffn_norm): RMSNorm()
      (attention_norm): RMSNorm()
    )
  )
  (norm): RMSNorm()
  (output): Linear(in_features=2304, out_features=49152, bias=False)
)
Time to load model: 1.07 seconds
Prefill latency: 0.017170918988995254 sec
Decode latency: 2.281861297087744 sec
Compilation time: 2.30 seconds
Compilation time: 2.30 seconds
Compilation time: 2.30 seconds
Compilation time: 2.30 seconds
Prefill latency: 0.016731363022699952 sec
Decode latency: 2.2788392569636926 sec
Prefill latency: 0.016736102988943458 sec
Decode latency: 2.280733395018615 sec
Prefill latency: 0.01665510900784284 sec
Decode latency: 2.279768695938401 sec
Prefill latency: 0.016600191011093557 sec
Decode latency: 2.2797239189967513 sec
Prefill latency: 0.016731741023249924 sec
Decode latency: 2.2788431689841673 sec
Time for inference 1: 2.30 sec total, 111.49 tokens/sec
Decode latency: 2.28 sec
Prefill latency: 0.02 sec
Bandwidth achieved: 214.68 GB/s
FLOPS achieved: 1.07 TF/s

Prefill latency: 0.016717438003979623 sec
Decode latency: 2.28032975201495 sec
Time for inference 2: 2.30 sec total, 111.41 tokens/sec
Decode latency: 2.28 sec
Prefill latency: 0.02 sec
Bandwidth achieved: 214.52 GB/s
FLOPS achieved: 1.07 TF/s

Prefill latency: 0.016727852984331548 sec
Decode latency: 2.279923001071438 sec
Time for inference 3: 2.30 sec total, 111.43 tokens/sec
Decode latency: 2.28 sec
Prefill latency: 0.02 sec
Bandwidth achieved: 214.56 GB/s
FLOPS achieved: 1.07 TF/s

Prefill latency: 0.016698436113074422 sec
Decode latency: 2.279493134934455 sec
Time for inference 4: 2.30 sec total, 111.45 tokens/sec
Decode latency: 2.28 sec
Prefill latency: 0.02 sec
Bandwidth achieved: 214.61 GB/s
FLOPS achieved: 1.07 TF/s

Prefill latency: 0.01665804802905768 sec
Decode latency: 2.2792614969657734 sec
Time for inference 5: 2.30 sec total, 111.47 tokens/sec
Decode latency: 2.28 sec
Prefill latency: 0.02 sec
Bandwidth achieved: 214.65 GB/s
FLOPS achieved: 1.07 TF/s

Prefill latency: 0.016744575928896666 sec
Decode latency: 2.2803001649444923 sec
Time for inference 6: 2.30 sec total, 111.41 tokens/sec
Decode latency: 2.28 sec
Prefill latency: 0.02 sec
Bandwidth achieved: 214.53 GB/s
FLOPS achieved: 1.07 TF/s

Prefill latency: 0.016665161936543882 sec
Decode latency: 2.2797615859890357 sec
Time for inference 7: 2.30 sec total, 111.45 tokens/sec
Decode latency: 2.28 sec
Prefill latency: 0.02 sec
Bandwidth achieved: 214.60 GB/s
FLOPS achieved: 1.07 TF/s

Prefill latency: 0.0166695510270074 sec
Decode latency: 2.2791874120011926 sec
Time for inference 8: 2.30 sec total, 111.47 tokens/sec
Decode latency: 2.28 sec
Prefill latency: 0.02 sec
Bandwidth achieved: 214.64 GB/s
FLOPS achieved: 1.07 TF/s

Prefill latency: 0.016727228998206556 sec
Decode latency: 2.279458240023814 sec
Time for inference 9: 2.30 sec total, 111.45 tokens/sec
Decode latency: 2.28 sec
Prefill latency: 0.02 sec
Bandwidth achieved: 214.61 GB/s
FLOPS achieved: 1.07 TF/s

Prefill latency: 0.016682062996551394 sec
Decode latency: 2.2795727000338957 sec
Time for inference 10: 2.30 sec total, 111.45 tokens/sec
Decode latency: 2.28 sec
Prefill latency: 0.02 sec
Bandwidth achieved: 214.61 GB/s
FLOPS achieved: 1.07 TF/s

==========
Batch Size: 1
Prompt Length: 1024
Generated tokens: 256
Average decode latency: 2.2796 sec
Average prefill latency: 0.0167 sec
Average tokens/sec: 111.45
Memory used: 2.82 GB
Done. we are killing the process
