W0928 18:54:48.973000 22429388224320 torch/distributed/run.py:779] 
W0928 18:54:48.973000 22429388224320 torch/distributed/run.py:779] *****************************************
W0928 18:54:48.973000 22429388224320 torch/distributed/run.py:779] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W0928 18:54:48.973000 22429388224320 torch/distributed/run.py:779] *****************************************
flash_kv_decode is set to True
Using device=cuda
Loading model ...
GPTDense(
  (tok_embeddings): Embedding(128256, 8192)
  (layers): ModuleList(
    (0-79): 80 x DenseTransformerBlock(
      semi_compiled = False
      (attention): Attention(
        (wqkv): Linear(in_features=8192, out_features=5120, bias=False)
        (wo): Linear(in_features=4096, out_features=8192, bias=False)
      )
      (feed_forward): FeedForward(
        (w1): Linear(in_features=8192, out_features=28672, bias=False)
        (w2): Linear(in_features=14336, out_features=8192, bias=False)
      )
      (ffn_norm): RMSNorm()
      (attention_norm): RMSNorm()
    )
  )
  (norm): RMSNorm()
  (output): Linear(in_features=8192, out_features=128256, bias=False)
)
Time to load model: 1.01 seconds
Prefill latency: 0.3677096330211498 sec
Decode latency: 10.570248283969704 sec
Compilation time: 10.94 seconds
Compilation time: 10.97 seconds
Prefill latency: 0.3430530020268634 sec
Decode latency: 10.564419193018693 sec
Prefill latency: 0.3425152510171756 sec
Decode latency: 10.56296472903341 sec
Prefill latency: 0.34282802598318085 sec
Decode latency: 10.563633771962486 sec
Prefill latency: 0.34282729600090533 sec
Decode latency: 10.563399153004866 sec
Prefill latency: 0.3426425799843855 sec
Decode latency: 10.562652441964019 sec
Time for inference 1: 10.91 sec total, 23.47 tokens/sec
Decode latency: 10.56 sec
Prefill latency: 0.34 sec
Bandwidth achieved: 1656.10 GB/s
FLOPS achieved: 8.28 TF/s

Prefill latency: 0.34246692596934736 sec
Decode latency: 10.563604941009544 sec
Time for inference 2: 10.91 sec total, 23.47 tokens/sec
Decode latency: 10.56 sec
Prefill latency: 0.34 sec
Bandwidth achieved: 1656.00 GB/s
FLOPS achieved: 8.28 TF/s

Prefill latency: 0.3422230139840394 sec
Decode latency: 10.563659576000646 sec
Time for inference 3: 10.91 sec total, 23.47 tokens/sec
Decode latency: 10.56 sec
Prefill latency: 0.34 sec
Bandwidth achieved: 1656.02 GB/s
FLOPS achieved: 8.28 TF/s

Prefill latency: 0.34237728297011927 sec
Decode latency: 10.564471415011212 sec
Time for inference 4: 10.91 sec total, 23.47 tokens/sec
Decode latency: 10.56 sec
Prefill latency: 0.34 sec
Bandwidth achieved: 1655.88 GB/s
FLOPS achieved: 8.28 TF/s

Prefill latency: 0.34273491700878367 sec
Decode latency: 10.56397601601202 sec
Time for inference 5: 10.91 sec total, 23.47 tokens/sec
Decode latency: 10.56 sec
Prefill latency: 0.34 sec
Bandwidth achieved: 1655.91 GB/s
FLOPS achieved: 8.28 TF/s

Prefill latency: 0.3425424169981852 sec
Decode latency: 10.565013770014048 sec
Time for inference 6: 10.91 sec total, 23.47 tokens/sec
Decode latency: 10.57 sec
Prefill latency: 0.34 sec
Bandwidth achieved: 1655.78 GB/s
FLOPS achieved: 8.28 TF/s

Prefill latency: 0.342277214047499 sec
Decode latency: 10.563981193001382 sec
Time for inference 7: 10.91 sec total, 23.47 tokens/sec
Decode latency: 10.56 sec
Prefill latency: 0.34 sec
Bandwidth achieved: 1655.98 GB/s
FLOPS achieved: 8.28 TF/s

Prefill latency: 0.34229711297666654 sec
Decode latency: 10.564794689009432 sec
Time for inference 8: 10.91 sec total, 23.47 tokens/sec
Decode latency: 10.56 sec
Prefill latency: 0.34 sec
Bandwidth achieved: 1655.83 GB/s
FLOPS achieved: 8.28 TF/s

Prefill latency: 0.342479765007738 sec
Decode latency: 10.564893289993051 sec
Time for inference 9: 10.91 sec total, 23.47 tokens/sec
Decode latency: 10.56 sec
Prefill latency: 0.34 sec
Bandwidth achieved: 1655.78 GB/s
FLOPS achieved: 8.28 TF/s

Prefill latency: 0.34258346498245373 sec
Decode latency: 10.564240980951581 sec
Time for inference 10: 10.91 sec total, 23.47 tokens/sec
Decode latency: 10.56 sec
Prefill latency: 0.34 sec
Bandwidth achieved: 1655.89 GB/s
FLOPS achieved: 8.28 TF/s

==========
Batch Size: 1
Prompt Length: 1024
Generated tokens: 256
Average decode latency: 10.5641 sec
Average prefill latency: 0.3425 sec
Average tokens/sec: 23.47
Memory used: 78.11 GB
Done. we are killing the process
