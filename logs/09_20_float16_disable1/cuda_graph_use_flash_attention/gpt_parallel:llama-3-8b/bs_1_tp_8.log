W0928 19:03:48.485000 22458797659968 torch/distributed/run.py:779] 
W0928 19:03:48.485000 22458797659968 torch/distributed/run.py:779] *****************************************
W0928 19:03:48.485000 22458797659968 torch/distributed/run.py:779] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W0928 19:03:48.485000 22458797659968 torch/distributed/run.py:779] *****************************************
flash_kv_decode is set to True
Using device=cuda
Loading model ...
GPTParallel(
  (tok_embeddings): Embedding(128256, 4096)
  (layers): ModuleList(
    (0-31): 32 x ParallelTransformerBlock(
      semi_compiled = False
      (attention): FuseAttentionMLP(
        (wqkv1): Linear(in_features=4096, out_features=4352, bias=False)
        (wo): Linear(in_features=512, out_features=4096, bias=False)
        (w2): Linear(in_features=1792, out_features=4096, bias=False)
      )
      (attention_norm): RMSNorm()
    )
  )
  (norm): RMSNorm()
  (output): Linear(in_features=4096, out_features=128256, bias=False)
)
Time to load model: 1.02 seconds
Prefill latency: 0.0958566078916192 sec
Decode latency: 1.8983017392456532 sec
Compilation time: 1.96 seconds
Compilation time: 2.02 seconds
Compilation time: 1.93 seconds
Compilation time: 2.00 seconds
Compilation time: 1.93 secondsCompilation time: 1.97 seconds

Compilation time: 1.95 seconds
Compilation time: 2.00 seconds
Prefill latency: 0.025379907339811325 sec
Decode latency: 1.8954051109030843 sec
Prefill latency: 0.025932377204298973 sec
Decode latency: 1.8969944939017296 sec
Prefill latency: 0.025680691935122013 sec
Decode latency: 1.8946641283109784 sec
Prefill latency: 0.025484484620392323 sec
Decode latency: 1.8940987745299935 sec
Prefill latency: 0.025504587218165398 sec
Decode latency: 1.8955604573711753 sec
Time for inference 1: 1.92 sec total, 133.21 tokens/sec
Decode latency: 1.90 sec
Prefill latency: 0.03 sec
Bandwidth achieved: 372.42 GB/s
FLOPS achieved: 1.86 TF/s

Prefill latency: 0.026600451208651066 sec
Decode latency: 1.8942761914804578 sec
Time for inference 2: 1.92 sec total, 133.21 tokens/sec
Decode latency: 1.89 sec
Prefill latency: 0.03 sec
Bandwidth achieved: 372.43 GB/s
FLOPS achieved: 1.86 TF/s

Prefill latency: 0.02530884277075529 sec
Decode latency: 1.89813840854913 sec
Time for inference 3: 1.92 sec total, 133.04 tokens/sec
Decode latency: 1.90 sec
Prefill latency: 0.03 sec
Bandwidth achieved: 371.96 GB/s
FLOPS achieved: 1.86 TF/s

Prefill latency: 0.025135863572359085 sec
Decode latency: 1.9025780903175473 sec
Time for inference 4: 1.93 sec total, 132.74 tokens/sec
Decode latency: 1.90 sec
Prefill latency: 0.03 sec
Bandwidth achieved: 371.11 GB/s
FLOPS achieved: 1.86 TF/s

Prefill latency: 0.025202413089573383 sec
Decode latency: 1.8932576077058911 sec
Time for inference 5: 1.92 sec total, 133.39 tokens/sec
Decode latency: 1.89 sec
Prefill latency: 0.03 sec
Bandwidth achieved: 372.92 GB/s
FLOPS achieved: 1.86 TF/s

Prefill latency: 0.02542377170175314 sec
Decode latency: 1.8996545942500234 sec
Time for inference 6: 1.93 sec total, 132.92 tokens/sec
Decode latency: 1.90 sec
Prefill latency: 0.03 sec
Bandwidth achieved: 371.62 GB/s
FLOPS achieved: 1.86 TF/s

Prefill latency: 0.02999129891395569 sec
Decode latency: 1.894868134520948 sec
Time for inference 7: 1.93 sec total, 132.94 tokens/sec
Decode latency: 1.89 sec
Prefill latency: 0.03 sec
Bandwidth achieved: 371.67 GB/s
FLOPS achieved: 1.86 TF/s

Prefill latency: 0.028894498944282532 sec
Decode latency: 1.8897995138540864 sec
Time for inference 8: 1.92 sec total, 133.36 tokens/sec
Decode latency: 1.89 sec
Prefill latency: 0.03 sec
Bandwidth achieved: 372.84 GB/s
FLOPS achieved: 1.86 TF/s

Prefill latency: 0.025308091193437576 sec
Decode latency: 1.8962156334891915 sec
Time for inference 9: 1.92 sec total, 133.17 tokens/sec
Decode latency: 1.90 sec
Prefill latency: 0.03 sec
Bandwidth achieved: 372.32 GB/s
FLOPS achieved: 1.86 TF/s

Prefill latency: 0.025208013132214546 sec
Decode latency: 1.8921403419226408 sec
Time for inference 10: 1.92 sec total, 133.46 tokens/sec
Decode latency: 1.89 sec
Prefill latency: 0.03 sec
Bandwidth achieved: 373.14 GB/s
FLOPS achieved: 1.87 TF/s

==========
Batch Size: 1
Prompt Length: 1024
Generated tokens: 256
Average decode latency: 1.8956 sec
Average prefill latency: 0.0263 sec
Average tokens/sec: 133.14
Memory used: 4.73 GB
Done. we are killing the process
