W0928 19:02:25.823000 23325969438528 torch/distributed/run.py:779] 
W0928 19:02:25.823000 23325969438528 torch/distributed/run.py:779] *****************************************
W0928 19:02:25.823000 23325969438528 torch/distributed/run.py:779] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W0928 19:02:25.823000 23325969438528 torch/distributed/run.py:779] *****************************************
flash_kv_decode is set to True
Using device=cuda
Loading model ...
GPTParallel(
  (tok_embeddings): Embedding(128256, 4096)
  (layers): ModuleList(
    (0-31): 32 x ParallelTransformerBlock(
      semi_compiled = False
      (attention): FuseAttentionMLP(
        (wqkv1): Linear(in_features=4096, out_features=17408, bias=False)
        (wo): Linear(in_features=2048, out_features=4096, bias=False)
        (w2): Linear(in_features=7168, out_features=4096, bias=False)
      )
      (attention_norm): RMSNorm()
    )
  )
  (norm): RMSNorm()
  (output): Linear(in_features=4096, out_features=128256, bias=False)
)
Time to load model: 0.76 seconds
Prefill latency: 0.04272706247866154 sec
Decode latency: 2.277462737634778 sec
Compilation time: 2.33 seconds
Compilation time: 2.32 seconds
Prefill latency: 0.04040328972041607 sec
Decode latency: 2.2757444381713867 sec
Prefill latency: 0.040355831384658813 sec
Decode latency: 2.2780712693929672 sec
Prefill latency: 0.04040656331926584 sec
Decode latency: 2.27762205991894 sec
Prefill latency: 0.04034124314785004 sec
Decode latency: 2.27699629496783 sec
Prefill latency: 0.040563504211604595 sec
Decode latency: 2.2768021263182163 sec
Time for inference 1: 2.32 sec total, 110.44 tokens/sec
Decode latency: 2.28 sec
Prefill latency: 0.04 sec
Bandwidth achieved: 886.83 GB/s
FLOPS achieved: 4.43 TF/s

Prefill latency: 0.04041303414851427 sec
Decode latency: 2.276507525704801 sec
Time for inference 2: 2.32 sec total, 110.46 tokens/sec
Decode latency: 2.28 sec
Prefill latency: 0.04 sec
Bandwidth achieved: 887.00 GB/s
FLOPS achieved: 4.44 TF/s

Prefill latency: 0.04045911971479654 sec
Decode latency: 2.2765669841319323 sec
Time for inference 3: 2.32 sec total, 110.45 tokens/sec
Decode latency: 2.28 sec
Prefill latency: 0.04 sec
Bandwidth achieved: 886.93 GB/s
FLOPS achieved: 4.43 TF/s

Prefill latency: 0.04049374535679817 sec
Decode latency: 2.276145875453949 sec
Time for inference 4: 2.32 sec total, 110.47 tokens/sec
Decode latency: 2.28 sec
Prefill latency: 0.04 sec
Bandwidth achieved: 887.09 GB/s
FLOPS achieved: 4.44 TF/s

Prefill latency: 0.040448674000799656 sec
Decode latency: 2.2763625429943204 sec
Time for inference 5: 2.32 sec total, 110.47 tokens/sec
Decode latency: 2.28 sec
Prefill latency: 0.04 sec
Bandwidth achieved: 887.09 GB/s
FLOPS achieved: 4.44 TF/s

Prefill latency: 0.04045567195862532 sec
Decode latency: 2.2767784437164664 sec
Time for inference 6: 2.32 sec total, 110.44 tokens/sec
Decode latency: 2.28 sec
Prefill latency: 0.04 sec
Bandwidth achieved: 886.86 GB/s
FLOPS achieved: 4.43 TF/s

Prefill latency: 0.04040174372494221 sec
Decode latency: 2.2770024007186294 sec
Time for inference 7: 2.32 sec total, 110.43 tokens/sec
Decode latency: 2.28 sec
Prefill latency: 0.04 sec
Bandwidth achieved: 886.82 GB/s
FLOPS achieved: 4.43 TF/s

Prefill latency: 0.04046428855508566 sec
Decode latency: 2.2776518454775214 sec
Time for inference 8: 2.32 sec total, 110.40 tokens/sec
Decode latency: 2.28 sec
Prefill latency: 0.04 sec
Bandwidth achieved: 886.55 GB/s
FLOPS achieved: 4.43 TF/s

Prefill latency: 0.04041276592761278 sec
Decode latency: 2.2770462157204747 sec
Time for inference 9: 2.32 sec total, 110.43 tokens/sec
Decode latency: 2.28 sec
Prefill latency: 0.04 sec
Bandwidth achieved: 886.77 GB/s
FLOPS achieved: 4.43 TF/s

Prefill latency: 0.04038120899349451 sec
Decode latency: 2.277125890366733 sec
Time for inference 10: 2.32 sec total, 110.43 tokens/sec
Decode latency: 2.28 sec
Prefill latency: 0.04 sec
Bandwidth achieved: 886.77 GB/s
FLOPS achieved: 4.43 TF/s

==========
Batch Size: 1
Prompt Length: 1024
Generated tokens: 256
Average decode latency: 2.2768 sec
Average prefill latency: 0.0404 sec
Average tokens/sec: 110.44
Memory used: 10.14 GB
Done. we are killing the process
