W0927 08:52:39.715000 22856029992768 torch/distributed/run.py:779] 
W0927 08:52:39.715000 22856029992768 torch/distributed/run.py:779] *****************************************
W0927 08:52:39.715000 22856029992768 torch/distributed/run.py:779] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W0927 08:52:39.715000 22856029992768 torch/distributed/run.py:779] *****************************************
flash_kv_decode is set to True
Using device=cuda
Loading model ...
GPTParallel(
  (tok_embeddings): Embedding(128256, 4096)
  (layers): ModuleList(
    (0-31): 32 x ParallelTransformerBlock(
      semi_compiled = False
      (attention): Attention(
        (wqkv): Linear(in_features=4096, out_features=3072, bias=False)
        (wo): Linear(in_features=2048, out_features=4096, bias=False)
      )
      (feed_forward): FeedForward(
        (w1): Linear(in_features=4096, out_features=14336, bias=False)
        (w2): Linear(in_features=7168, out_features=4096, bias=False)
      )
      (ffn_norm): RMSNorm()
      (attention_norm): RMSNorm()
    )
  )
  (norm): RMSNorm()
  (output): Linear(in_features=4096, out_features=128256, bias=False)
)
Time to load model: 1.08 seconds
Prefill latency: 0.05365190299926326 sec
Decode latency: 2.3248386629857123 sec
Compilation time: 2.38 seconds
Compilation time: 2.37 seconds
Prefill latency: 0.04121673997724429 sec
Decode latency: 2.3203448870335706 sec
Prefill latency: 0.04113450297154486 sec
Decode latency: 2.320571933989413 sec
Prefill latency: 0.04125764104537666 sec
Decode latency: 2.3208520500338636 sec
Prefill latency: 0.04113275301642716 sec
Decode latency: 2.320885975030251 sec
Prefill latency: 0.04135234601562843 sec
Decode latency: 2.320138812006917 sec
Time for inference 1: 2.36 sec total, 108.37 tokens/sec
Decode latency: 2.32 sec
Prefill latency: 0.04 sec
Bandwidth achieved: 870.29 GB/s
FLOPS achieved: 4.35 TF/s

Prefill latency: 0.04141034296480939 sec
Decode latency: 2.320788156008348 sec
Time for inference 2: 2.36 sec total, 108.34 tokens/sec
Decode latency: 2.32 sec
Prefill latency: 0.04 sec
Bandwidth achieved: 870.05 GB/s
FLOPS achieved: 4.35 TF/s

Prefill latency: 0.041407625016290694 sec
Decode latency: 2.3205911240074784 sec
Time for inference 3: 2.36 sec total, 108.35 tokens/sec
Decode latency: 2.32 sec
Prefill latency: 0.04 sec
Bandwidth achieved: 870.13 GB/s
FLOPS achieved: 4.35 TF/s

Prefill latency: 0.0412558619864285 sec
Decode latency: 2.3205452620168217 sec
Time for inference 4: 2.36 sec total, 108.36 tokens/sec
Decode latency: 2.32 sec
Prefill latency: 0.04 sec
Bandwidth achieved: 870.18 GB/s
FLOPS achieved: 4.35 TF/s

Prefill latency: 0.041470733005553484 sec
Decode latency: 2.3208061850164086 sec
Time for inference 5: 2.36 sec total, 108.34 tokens/sec
Decode latency: 2.32 sec
Prefill latency: 0.04 sec
Bandwidth achieved: 870.04 GB/s
FLOPS achieved: 4.35 TF/s

Prefill latency: 0.04137978202197701 sec
Decode latency: 2.3206234999815933 sec
Time for inference 6: 2.36 sec total, 108.35 tokens/sec
Decode latency: 2.32 sec
Prefill latency: 0.04 sec
Bandwidth achieved: 870.12 GB/s
FLOPS achieved: 4.35 TF/s

Prefill latency: 0.0412915589986369 sec
Decode latency: 2.3206501390086487 sec
Time for inference 7: 2.36 sec total, 108.36 tokens/sec
Decode latency: 2.32 sec
Prefill latency: 0.04 sec
Bandwidth achieved: 870.15 GB/s
FLOPS achieved: 4.35 TF/s

Prefill latency: 0.04128533398034051 sec
Decode latency: 2.3200739330495708 sec
Time for inference 8: 2.36 sec total, 108.38 tokens/sec
Decode latency: 2.32 sec
Prefill latency: 0.04 sec
Bandwidth achieved: 870.39 GB/s
FLOPS achieved: 4.35 TF/s

Prefill latency: 0.041298955969978124 sec
Decode latency: 2.3201454309746623 sec
Time for inference 9: 2.36 sec total, 108.38 tokens/sec
Decode latency: 2.32 sec
Prefill latency: 0.04 sec
Bandwidth achieved: 870.34 GB/s
FLOPS achieved: 4.35 TF/s

Prefill latency: 0.041219730977900326 sec
Decode latency: 2.3209555479697883 sec
Time for inference 10: 2.36 sec total, 108.34 tokens/sec
Decode latency: 2.32 sec
Prefill latency: 0.04 sec
Bandwidth achieved: 870.06 GB/s
FLOPS achieved: 4.35 TF/s

==========
Batch Size: 1
Prompt Length: 1024
Generated tokens: 256
Average decode latency: 2.3205 sec
Average prefill latency: 0.0413 sec
Average tokens/sec: 108.36
Memory used: 10.12 GB
[rank1]:[E927 08:54:21.502093350 ProcessGroupNCCL.cpp:1076] [PG 0 (default_pg) Rank 1] Future for ProcessGroup abort timed out after 60000 ms
[rank0]:[E927 08:54:21.502144666 ProcessGroupNCCL.cpp:1076] [PG 0 (default_pg) Rank 0] Future for ProcessGroup abort timed out after 60000 ms
