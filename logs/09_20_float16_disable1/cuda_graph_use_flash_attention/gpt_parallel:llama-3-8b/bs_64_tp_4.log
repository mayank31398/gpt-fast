W0928 19:25:27.877000 22478266279744 torch/distributed/run.py:779] 
W0928 19:25:27.877000 22478266279744 torch/distributed/run.py:779] *****************************************
W0928 19:25:27.877000 22478266279744 torch/distributed/run.py:779] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W0928 19:25:27.877000 22478266279744 torch/distributed/run.py:779] *****************************************
flash_kv_decode is set to True
Using device=cuda
Loading model ...
GPTParallel(
  (tok_embeddings): Embedding(128256, 4096)
  (layers): ModuleList(
    (0-31): 32 x ParallelTransformerBlock(
      semi_compiled = False
      (attention): FuseAttentionMLP(
        (wqkv1): Linear(in_features=4096, out_features=8704, bias=False)
        (wo): Linear(in_features=1024, out_features=4096, bias=False)
        (w2): Linear(in_features=3584, out_features=4096, bias=False)
      )
      (attention_norm): RMSNorm()
    )
  )
  (norm): RMSNorm()
  (output): Linear(in_features=4096, out_features=128256, bias=False)
)
Time to load model: 0.94 seconds
Prefill latency: 0.7907714042812586 sec
Decode latency: 6.044147726148367 sec
Compilation time: 6.82 seconds
Compilation time: 6.84 seconds
Compilation time: 6.82 secondsCompilation time: 6.84 seconds

Prefill latency: 0.7820788314566016 sec
Decode latency: 6.044818077236414 sec
Prefill latency: 0.7821112554520369 sec
Decode latency: 6.044213934801519 sec
Prefill latency: 0.781017055734992 sec
Decode latency: 6.045376223511994 sec
Prefill latency: 0.7849026126787066 sec
Decode latency: 6.042224292643368 sec
Prefill latency: 0.7843656288459897 sec
Decode latency: 6.042191194370389 sec
Time for inference 1: 6.83 sec total, 2399.77 tokens/sec
Decode latency: 6.04 sec
Prefill latency: 0.78 sec
Bandwidth achieved: 10896.40 GB/s
FLOPS achieved: 54.48 TF/s

Prefill latency: 0.7827767273411155 sec
Decode latency: 6.045472043566406 sec
Time for inference 2: 6.83 sec total, 2399.12 tokens/sec
Decode latency: 6.05 sec
Prefill latency: 0.78 sec
Bandwidth achieved: 10893.47 GB/s
FLOPS achieved: 54.47 TF/s

Prefill latency: 0.782892263494432 sec
Decode latency: 6.041193404234946 sec
Time for inference 3: 6.82 sec total, 2400.59 tokens/sec
Decode latency: 6.04 sec
Prefill latency: 0.78 sec
Bandwidth achieved: 10900.11 GB/s
FLOPS achieved: 54.50 TF/s

Prefill latency: 0.7845828123390675 sec
Decode latency: 6.041761347092688 sec
Time for inference 4: 6.83 sec total, 2399.84 tokens/sec
Decode latency: 6.04 sec
Prefill latency: 0.78 sec
Bandwidth achieved: 10896.74 GB/s
FLOPS achieved: 54.48 TF/s

Prefill latency: 0.784697731025517 sec
Decode latency: 6.0429316107183695 sec
Time for inference 5: 6.83 sec total, 2399.36 tokens/sec
Decode latency: 6.04 sec
Prefill latency: 0.78 sec
Bandwidth achieved: 10894.54 GB/s
FLOPS achieved: 54.47 TF/s

Prefill latency: 0.7859903387725353 sec
Decode latency: 6.041981405578554 sec
Time for inference 6: 6.83 sec total, 2399.21 tokens/sec
Decode latency: 6.04 sec
Prefill latency: 0.79 sec
Bandwidth achieved: 10893.85 GB/s
FLOPS achieved: 54.47 TF/s

Prefill latency: 0.7856871774420142 sec
Decode latency: 6.044479205273092 sec
Time for inference 7: 6.83 sec total, 2398.47 tokens/sec
Decode latency: 6.04 sec
Prefill latency: 0.79 sec
Bandwidth achieved: 10890.51 GB/s
FLOPS achieved: 54.45 TF/s

Prefill latency: 0.7851189048960805 sec
Decode latency: 6.043160269036889 sec
Time for inference 8: 6.83 sec total, 2399.16 tokens/sec
Decode latency: 6.04 sec
Prefill latency: 0.79 sec
Bandwidth achieved: 10893.61 GB/s
FLOPS achieved: 54.47 TF/s

Prefill latency: 0.7846363261342049 sec
Decode latency: 6.043803695589304 sec
Time for inference 9: 6.83 sec total, 2399.10 tokens/sec
Decode latency: 6.04 sec
Prefill latency: 0.78 sec
Bandwidth achieved: 10893.36 GB/s
FLOPS achieved: 54.47 TF/s

Prefill latency: 0.785346313379705 sec
Decode latency: 6.045136988162994 sec
Time for inference 10: 6.83 sec total, 2398.37 tokens/sec
Decode latency: 6.05 sec
Prefill latency: 0.79 sec
Bandwidth achieved: 10890.04 GB/s
FLOPS achieved: 54.45 TF/s

==========
Batch Size: 64
Prompt Length: 1024
Generated tokens: 256
Average decode latency: 6.0432 sec
Average prefill latency: 0.7846 sec
Average tokens/sec: 2399.30
Memory used: 48.14 GB
Done. we are killing the process
