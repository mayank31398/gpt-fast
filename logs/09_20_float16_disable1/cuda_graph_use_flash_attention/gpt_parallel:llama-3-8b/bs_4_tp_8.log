W0928 19:07:18.097000 23069695895360 torch/distributed/run.py:779] 
W0928 19:07:18.097000 23069695895360 torch/distributed/run.py:779] *****************************************
W0928 19:07:18.097000 23069695895360 torch/distributed/run.py:779] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W0928 19:07:18.097000 23069695895360 torch/distributed/run.py:779] *****************************************
flash_kv_decode is set to True
Using device=cuda
Loading model ...
GPTParallel(
  (tok_embeddings): Embedding(128256, 4096)
  (layers): ModuleList(
    (0-31): 32 x ParallelTransformerBlock(
      semi_compiled = False
      (attention): FuseAttentionMLP(
        (wqkv1): Linear(in_features=4096, out_features=4352, bias=False)
        (wo): Linear(in_features=512, out_features=4096, bias=False)
        (w2): Linear(in_features=1792, out_features=4096, bias=False)
      )
      (attention_norm): RMSNorm()
    )
  )
  (norm): RMSNorm()
  (output): Linear(in_features=4096, out_features=128256, bias=False)
)
Time to load model: 0.92 seconds
Prefill latency: 0.1285819709300995 sec
Decode latency: 2.2852601315826178 sec
Compilation time: 2.43 secondsCompilation time: 2.36 seconds

Compilation time: 2.39 seconds
Compilation time: 2.38 seconds
Compilation time: 2.37 secondsCompilation time: 2.36 seconds

Compilation time: 2.37 seconds
Compilation time: 2.42 seconds
Prefill latency: 0.07121480256319046 sec
Decode latency: 2.2836233796551824 sec
Prefill latency: 0.07667845208197832 sec
Decode latency: 2.2908357018604875 sec
Prefill latency: 0.06968761328607798 sec
Decode latency: 2.2907118145376444 sec
Prefill latency: 0.07173460349440575 sec
Decode latency: 2.2862410955131054 sec
Prefill latency: 0.06926599144935608 sec
Decode latency: 2.2926627965644 sec
Time for inference 1: 2.36 sec total, 433.36 tokens/sec
Decode latency: 2.29 sec
Prefill latency: 0.07 sec
Bandwidth achieved: 1211.59 GB/s
FLOPS achieved: 6.06 TF/s

Prefill latency: 0.07233276590704918 sec
Decode latency: 2.2894125459715724 sec
Time for inference 2: 2.36 sec total, 433.43 tokens/sec
Decode latency: 2.29 sec
Prefill latency: 0.07 sec
Bandwidth achieved: 1211.77 GB/s
FLOPS achieved: 6.06 TF/s

Prefill latency: 0.0695049287751317 sec
Decode latency: 2.2911073295399547 sec
Time for inference 3: 2.36 sec total, 433.61 tokens/sec
Decode latency: 2.29 sec
Prefill latency: 0.07 sec
Bandwidth achieved: 1212.28 GB/s
FLOPS achieved: 6.06 TF/s

Prefill latency: 0.0702293748036027 sec
Decode latency: 2.2859802758321166 sec
Time for inference 4: 2.36 sec total, 434.44 tokens/sec
Decode latency: 2.29 sec
Prefill latency: 0.07 sec
Bandwidth achieved: 1214.60 GB/s
FLOPS achieved: 6.07 TF/s

Prefill latency: 0.06967077031731606 sec
Decode latency: 2.2827147440984845 sec
Time for inference 5: 2.35 sec total, 435.15 tokens/sec
Decode latency: 2.28 sec
Prefill latency: 0.07 sec
Bandwidth achieved: 1216.57 GB/s
FLOPS achieved: 6.08 TF/s

Prefill latency: 0.06974941305816174 sec
Decode latency: 2.2833222169429064 sec
Time for inference 6: 2.35 sec total, 435.01 tokens/sec
Decode latency: 2.28 sec
Prefill latency: 0.07 sec
Bandwidth achieved: 1216.18 GB/s
FLOPS achieved: 6.08 TF/s

Prefill latency: 0.07083324063569307 sec
Decode latency: 2.297509246505797 sec
Time for inference 7: 2.37 sec total, 432.21 tokens/sec
Decode latency: 2.30 sec
Prefill latency: 0.07 sec
Bandwidth achieved: 1208.38 GB/s
FLOPS achieved: 6.04 TF/s

Prefill latency: 0.0695617152377963 sec
Decode latency: 2.2861312218010426 sec
Time for inference 8: 2.36 sec total, 434.54 tokens/sec
Decode latency: 2.29 sec
Prefill latency: 0.07 sec
Bandwidth achieved: 1214.89 GB/s
FLOPS achieved: 6.07 TF/s

Prefill latency: 0.06998011190444231 sec
Decode latency: 2.287034790031612 sec
Time for inference 9: 2.36 sec total, 434.31 tokens/sec
Decode latency: 2.29 sec
Prefill latency: 0.07 sec
Bandwidth achieved: 1214.23 GB/s
FLOPS achieved: 6.07 TF/s

Prefill latency: 0.06996921636164188 sec
Decode latency: 2.2890345845371485 sec
Time for inference 10: 2.36 sec total, 433.91 tokens/sec
Decode latency: 2.29 sec
Prefill latency: 0.07 sec
Bandwidth achieved: 1213.10 GB/s
FLOPS achieved: 6.07 TF/s

==========
Batch Size: 4
Prompt Length: 1024
Generated tokens: 256
Average decode latency: 2.2885 sec
Average prefill latency: 0.0701 sec
Average tokens/sec: 434.00
Memory used: 6.78 GB
Done. we are killing the process
