W0928 20:23:38.720000 23226630051648 torch/distributed/run.py:779] 
W0928 20:23:38.720000 23226630051648 torch/distributed/run.py:779] *****************************************
W0928 20:23:38.720000 23226630051648 torch/distributed/run.py:779] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W0928 20:23:38.720000 23226630051648 torch/distributed/run.py:779] *****************************************
flash_kv_decode is set to True
Using device=cuda
Loading model ...
GPTParallel(
  (tok_embeddings): Embedding(128256, 8192)
  (layers): ModuleList(
    (0-79): 80 x ParallelTransformerBlock(
      semi_compiled = False
      (attention): FuseAttentionMLP(
        (wqkv1): Linear(in_features=8192, out_features=16896, bias=False)
        (wo): Linear(in_features=2048, out_features=8192, bias=False)
        (w2): Linear(in_features=7168, out_features=8192, bias=False)
      )
      (attention_norm): RMSNorm()
    )
  )
  (norm): RMSNorm()
  (output): Linear(in_features=8192, out_features=128256, bias=False)
)
Time to load model: 1.19 seconds
Prefill latency: 1.4255136440042406 sec
Decode latency: 11.827836407988798 sec
Compilation time: 13.26 secondsCompilation time: 13.25 seconds

Compilation time: 13.25 seconds
Compilation time: 13.26 seconds
Prefill latency: 1.4236622019670904 sec
Decode latency: 11.823307984974235 sec
Prefill latency: 1.4279542459989898 sec
Decode latency: 11.817907518998254 sec
Prefill latency: 1.4243472469970584 sec
Decode latency: 11.820826537034009 sec
Prefill latency: 1.4274560949997976 sec
Decode latency: 11.820310594979674 sec
Prefill latency: 1.4264894259977154 sec
Decode latency: 11.817303881980479 sec
Time for inference 1: 13.24 sec total, 309.25 tokens/sec
Decode latency: 11.82 sec
Prefill latency: 1.43 sec
Bandwidth achieved: 11234.65 GB/s
FLOPS achieved: 56.17 TF/s

Prefill latency: 1.4290274549857713 sec
Decode latency: 11.81922211998608 sec
Time for inference 2: 13.25 sec total, 309.15 tokens/sec
Decode latency: 11.82 sec
Prefill latency: 1.43 sec
Bandwidth achieved: 11230.83 GB/s
FLOPS achieved: 56.15 TF/s

Prefill latency: 1.4229795020073652 sec
Decode latency: 11.819590447994415 sec
Time for inference 3: 13.24 sec total, 309.28 tokens/sec
Decode latency: 11.82 sec
Prefill latency: 1.42 sec
Bandwidth achieved: 11235.63 GB/s
FLOPS achieved: 56.18 TF/s

Prefill latency: 1.4307176980073564 sec
Decode latency: 11.819291541003622 sec
Time for inference 4: 13.25 sec total, 309.11 tokens/sec
Decode latency: 11.82 sec
Prefill latency: 1.43 sec
Bandwidth achieved: 11229.29 GB/s
FLOPS achieved: 56.15 TF/s

Prefill latency: 1.4235586170107126 sec
Decode latency: 11.815903740993235 sec
Time for inference 5: 13.24 sec total, 309.36 tokens/sec
Decode latency: 11.82 sec
Prefill latency: 1.42 sec
Bandwidth achieved: 11238.34 GB/s
FLOPS achieved: 56.19 TF/s

Prefill latency: 1.4238882379722781 sec
Decode latency: 11.815992833988275 sec
Time for inference 6: 13.24 sec total, 309.34 tokens/sec
Decode latency: 11.82 sec
Prefill latency: 1.42 sec
Bandwidth achieved: 11237.86 GB/s
FLOPS achieved: 56.19 TF/s

Prefill latency: 1.423399000952486 sec
Decode latency: 11.821845766040497 sec
Time for inference 7: 13.25 sec total, 309.22 tokens/sec
Decode latency: 11.82 sec
Prefill latency: 1.42 sec
Bandwidth achieved: 11233.40 GB/s
FLOPS achieved: 56.17 TF/s

Prefill latency: 1.424140127026476 sec
Decode latency: 11.823635127046145 sec
Time for inference 8: 13.25 sec total, 309.16 tokens/sec
Decode latency: 11.82 sec
Prefill latency: 1.42 sec
Bandwidth achieved: 11231.15 GB/s
FLOPS achieved: 56.16 TF/s

Prefill latency: 1.4278814409626648 sec
Decode latency: 11.818694292043801 sec
Time for inference 9: 13.25 sec total, 309.18 tokens/sec
Decode latency: 11.82 sec
Prefill latency: 1.43 sec
Bandwidth achieved: 11232.11 GB/s
FLOPS achieved: 56.16 TF/s

Prefill latency: 1.4238867840031162 sec
Decode latency: 11.816170350997709 sec
Time for inference 10: 13.24 sec total, 309.34 tokens/sec
Decode latency: 11.82 sec
Prefill latency: 1.42 sec
Bandwidth achieved: 11237.88 GB/s
FLOPS achieved: 56.19 TF/s

==========
Batch Size: 16
Prompt Length: 1024
Generated tokens: 256
Average decode latency: 11.8188 sec
Average prefill latency: 1.4256 sec
Average tokens/sec: 309.24
Memory used: 68.76 GB
Done. we are killing the process
