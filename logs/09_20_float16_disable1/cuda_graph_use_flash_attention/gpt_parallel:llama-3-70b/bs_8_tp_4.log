W0928 20:17:45.594000 23289199294272 torch/distributed/run.py:779] 
W0928 20:17:45.594000 23289199294272 torch/distributed/run.py:779] *****************************************
W0928 20:17:45.594000 23289199294272 torch/distributed/run.py:779] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W0928 20:17:45.594000 23289199294272 torch/distributed/run.py:779] *****************************************
flash_kv_decode is set to True
Using device=cuda
Loading model ...
GPTParallel(
  (tok_embeddings): Embedding(128256, 8192)
  (layers): ModuleList(
    (0-79): 80 x ParallelTransformerBlock(
      semi_compiled = False
      (attention): FuseAttentionMLP(
        (wqkv1): Linear(in_features=8192, out_features=16896, bias=False)
        (wo): Linear(in_features=2048, out_features=8192, bias=False)
        (w2): Linear(in_features=7168, out_features=8192, bias=False)
      )
      (attention_norm): RMSNorm()
    )
  )
  (norm): RMSNorm()
  (output): Linear(in_features=8192, out_features=128256, bias=False)
)
Time to load model: 1.05 seconds
Prefill latency: 0.7016637159977108 sec
Decode latency: 9.532566056994256 sec
Compilation time: 10.23 seconds
Compilation time: 10.24 seconds
Compilation time: 10.23 seconds
Compilation time: 10.23 seconds
Prefill latency: 0.6992680369876325 sec
Decode latency: 9.528887944004964 sec
Prefill latency: 0.7004247850272804 sec
Decode latency: 9.529260172042996 sec
Prefill latency: 0.6996399349882267 sec
Decode latency: 9.526168184005655 sec
Prefill latency: 0.7000080670113675 sec
Decode latency: 9.525591378973331 sec
Prefill latency: 0.6997112749959342 sec
Decode latency: 9.527049083029851 sec
Time for inference 1: 10.23 sec total, 200.24 tokens/sec
Decode latency: 9.53 sec
Prefill latency: 0.70 sec
Bandwidth achieved: 7274.39 GB/s
FLOPS achieved: 36.37 TF/s

Prefill latency: 0.6997999240411445 sec
Decode latency: 9.526146256015636 sec
Time for inference 2: 10.23 sec total, 200.26 tokens/sec
Decode latency: 9.53 sec
Prefill latency: 0.70 sec
Bandwidth achieved: 7274.96 GB/s
FLOPS achieved: 36.37 TF/s

Prefill latency: 0.6999151970376261 sec
Decode latency: 9.525723156984895 sec
Time for inference 3: 10.23 sec total, 200.26 tokens/sec
Decode latency: 9.53 sec
Prefill latency: 0.70 sec
Bandwidth achieved: 7275.18 GB/s
FLOPS achieved: 36.38 TF/s

Prefill latency: 0.6993450479931198 sec
Decode latency: 9.528583848034032 sec
Time for inference 4: 10.23 sec total, 200.22 tokens/sec
Decode latency: 9.53 sec
Prefill latency: 0.70 sec
Bandwidth achieved: 7273.59 GB/s
FLOPS achieved: 36.37 TF/s

Prefill latency: 0.7008187180035748 sec
Decode latency: 9.525765599973965 sec
Time for inference 5: 10.23 sec total, 200.25 tokens/sec
Decode latency: 9.53 sec
Prefill latency: 0.70 sec
Bandwidth achieved: 7274.59 GB/s
FLOPS achieved: 36.37 TF/s

Prefill latency: 0.7010548479738645 sec
Decode latency: 9.527190105989575 sec
Time for inference 6: 10.23 sec total, 200.21 tokens/sec
Decode latency: 9.53 sec
Prefill latency: 0.70 sec
Bandwidth achieved: 7273.29 GB/s
FLOPS achieved: 36.37 TF/s

Prefill latency: 0.6996188640478067 sec
Decode latency: 9.52575218200218 sec
Time for inference 7: 10.23 sec total, 200.27 tokens/sec
Decode latency: 9.53 sec
Prefill latency: 0.70 sec
Bandwidth achieved: 7275.41 GB/s
FLOPS achieved: 36.38 TF/s

Prefill latency: 0.7006704430095851 sec
Decode latency: 9.527940604020841 sec
Time for inference 8: 10.23 sec total, 200.21 tokens/sec
Decode latency: 9.53 sec
Prefill latency: 0.70 sec
Bandwidth achieved: 7273.16 GB/s
FLOPS achieved: 36.37 TF/s

Prefill latency: 0.6995415129931644 sec
Decode latency: 9.527423507999629 sec
Time for inference 9: 10.23 sec total, 200.24 tokens/sec
Decode latency: 9.53 sec
Prefill latency: 0.70 sec
Bandwidth achieved: 7274.29 GB/s
FLOPS achieved: 36.37 TF/s

Prefill latency: 0.7019998870091513 sec
Decode latency: 9.525614665995818 sec
Time for inference 10: 10.23 sec total, 200.23 tokens/sec
Decode latency: 9.53 sec
Prefill latency: 0.70 sec
Bandwidth achieved: 7273.82 GB/s
FLOPS achieved: 36.37 TF/s

==========
Batch Size: 8
Prompt Length: 1024
Generated tokens: 256
Average decode latency: 9.5267 sec
Average prefill latency: 0.7002 sec
Average tokens/sec: 200.24
Memory used: 53.67 GB
Done. we are killing the process
