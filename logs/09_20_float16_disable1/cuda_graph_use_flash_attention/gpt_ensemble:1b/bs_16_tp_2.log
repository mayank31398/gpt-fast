W0930 21:14:16.474000 22930424928064 torch/distributed/run.py:779] 
W0930 21:14:16.474000 22930424928064 torch/distributed/run.py:779] *****************************************
W0930 21:14:16.474000 22930424928064 torch/distributed/run.py:779] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W0930 21:14:16.474000 22930424928064 torch/distributed/run.py:779] *****************************************
flash_kv_decode is set to True
Using device=cuda
Loading model ...
GPTEnsemble(
  (tok_embeddings): Embedding(49152, 1536)
  (layers): ModuleList(
    (0-39): 40 x EnsembleTransformerBlock(
      semi_compiled = False
      (attention): Attention(
        (wqkv): Linear(in_features=1536, out_features=1280, bias=False)
        (wo): Linear(in_features=768, out_features=1536, bias=False)
      )
      (feed_forward): FeedForward(
        (w1): Linear(in_features=1536, out_features=4096, bias=False)
        (w2): Linear(in_features=2048, out_features=1536, bias=False)
      )
      (ffn_norm): RMSNorm()
      (attention_norm): RMSNorm()
    )
  )
  (norm): RMSNorm()
  (output): Linear(in_features=1536, out_features=49152, bias=False)
)
Time to load model: 1.15 seconds
Prefill latency: 0.25886658299714327 sec
Decode latency: 3.164618422044441 sec
Compilation time: 3.42 seconds
Compilation time: 3.42 seconds
Prefill latency: 0.23982755502220243 sec
Decode latency: 3.16328252106905 sec
Prefill latency: 0.2395876299124211 sec
Decode latency: 3.1643653959035873 sec
Prefill latency: 0.2404673470882699 sec
Decode latency: 3.1633184810634702 sec
Prefill latency: 0.23968632600735873 sec
Decode latency: 3.1628877749899402 sec
Prefill latency: 0.2402133559808135 sec
Decode latency: 3.1642327579902485 sec
Time for inference 1: 3.41 sec total, 1202.89 tokens/sec
Decode latency: 3.16 sec
Prefill latency: 0.24 sec
Bandwidth achieved: 1392.80 GB/s
FLOPS achieved: 6.96 TF/s

Prefill latency: 0.24019203893840313 sec
Decode latency: 3.162485979963094 sec
Time for inference 2: 3.40 sec total, 1203.41 tokens/sec
Decode latency: 3.16 sec
Prefill latency: 0.24 sec
Bandwidth achieved: 1393.41 GB/s
FLOPS achieved: 6.97 TF/s

Prefill latency: 0.2397859380580485 sec
Decode latency: 3.1621366640320048 sec
Time for inference 3: 3.40 sec total, 1203.68 tokens/sec
Decode latency: 3.16 sec
Prefill latency: 0.24 sec
Bandwidth achieved: 1393.71 GB/s
FLOPS achieved: 6.97 TF/s

Prefill latency: 0.2407989091007039 sec
Decode latency: 3.162388675962575 sec
Time for inference 4: 3.40 sec total, 1203.28 tokens/sec
Decode latency: 3.16 sec
Prefill latency: 0.24 sec
Bandwidth achieved: 1393.26 GB/s
FLOPS achieved: 6.97 TF/s

Prefill latency: 0.23854859999846667 sec
Decode latency: 3.1614927500486374 sec
Time for inference 5: 3.40 sec total, 1204.42 tokens/sec
Decode latency: 3.16 sec
Prefill latency: 0.24 sec
Bandwidth achieved: 1394.57 GB/s
FLOPS achieved: 6.97 TF/s

Prefill latency: 0.239981611026451 sec
Decode latency: 3.1640317959245294 sec
Time for inference 6: 3.40 sec total, 1202.97 tokens/sec
Decode latency: 3.16 sec
Prefill latency: 0.24 sec
Bandwidth achieved: 1392.90 GB/s
FLOPS achieved: 6.96 TF/s

Prefill latency: 0.23898632801137865 sec
Decode latency: 3.1619488719152287 sec
Time for inference 7: 3.40 sec total, 1204.10 tokens/sec
Decode latency: 3.16 sec
Prefill latency: 0.24 sec
Bandwidth achieved: 1394.20 GB/s
FLOPS achieved: 6.97 TF/s

Prefill latency: 0.24009645800106227 sec
Decode latency: 3.1617290009744465 sec
Time for inference 8: 3.40 sec total, 1203.77 tokens/sec
Decode latency: 3.16 sec
Prefill latency: 0.24 sec
Bandwidth achieved: 1393.82 GB/s
FLOPS achieved: 6.97 TF/s

Prefill latency: 0.23970742791425437 sec
Decode latency: 3.162293038913049 sec
Time for inference 9: 3.40 sec total, 1203.74 tokens/sec
Decode latency: 3.16 sec
Prefill latency: 0.24 sec
Bandwidth achieved: 1393.79 GB/s
FLOPS achieved: 6.97 TF/s

Prefill latency: 0.23955879302229732 sec
Decode latency: 3.1625519460067153 sec
Time for inference 10: 3.40 sec total, 1203.73 tokens/sec
Decode latency: 3.16 sec
Prefill latency: 0.24 sec
Bandwidth achieved: 1393.77 GB/s
FLOPS achieved: 6.97 TF/s

==========
Batch Size: 16
Prompt Length: 1024
Generated tokens: 256
Average decode latency: 3.1625 sec
Average prefill latency: 0.2398 sec
Average tokens/sec: 1203.60
Memory used: 7.20 GB
Done. we are killing the process
