W1001 04:07:21.781000 22646399424320 torch/distributed/run.py:779] 
W1001 04:07:21.781000 22646399424320 torch/distributed/run.py:779] *****************************************
W1001 04:07:21.781000 22646399424320 torch/distributed/run.py:779] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W1001 04:07:21.781000 22646399424320 torch/distributed/run.py:779] *****************************************
flash_kv_decode is set to True
Using device=cuda
Loading model ...
GPTEnsemble(
  (tok_embeddings): Embedding(49152, 1536)
  (layers): ModuleList(
    (0-39): 40 x EnsembleTransformerBlock(
      semi_compiled = False
      (attention): Attention(
        (wqkv): Linear(in_features=1536, out_features=2304, bias=False)
        (wo): Linear(in_features=768, out_features=1536, bias=False)
      )
      (feed_forward): FeedForward(
        (w1): Linear(in_features=1536, out_features=4096, bias=False)
        (w2): Linear(in_features=2048, out_features=1536, bias=False)
      )
      (ffn_norm): RMSNorm()
      (attention_norm): RMSNorm()
    )
  )
  (norm): RMSNorm()
  (output): Linear(in_features=1536, out_features=49152, bias=False)
)
Time to load model: 0.91 seconds
Prefill latency: 0.012018920038826764 sec
Decode latency: 1.7515132569242269 sec
Compilation time: 1.76 seconds
Prefill latency: 0.01203032792545855 sec
Compilation time: 1.85 seconds
Decode latency: 1.8284378910902888 sec
Prefill latency: 0.011995436972938478 sec
Decode latency: 1.7165523539297283 sec
Prefill latency: 0.012018727022223175 sec
Decode latency: 1.693476281943731 sec
Prefill latency: 0.012011951999738812 sec
Decode latency: 1.7714343230472878 sec
Prefill latency: 0.012001767987385392 sec
Decode latency: 1.8293520770967007 sec
Time for inference 1: 1.84 sec total, 138.98 tokens/sec
Decode latency: 1.83 sec
Prefill latency: 0.01 sec
Bandwidth achieved: 178.41 GB/s
FLOPS achieved: 0.89 TF/s

Prefill latency: 0.012007697951048613 sec
Decode latency: 1.8288614409975708 sec
Time for inference 2: 1.84 sec total, 139.02 tokens/sec
Decode latency: 1.83 sec
Prefill latency: 0.01 sec
Bandwidth achieved: 178.46 GB/s
FLOPS achieved: 0.89 TF/s

Prefill latency: 0.012026887037791312 sec
Decode latency: 1.8278273639734834 sec
Time for inference 3: 1.84 sec total, 139.10 tokens/sec
Decode latency: 1.83 sec
Prefill latency: 0.01 sec
Bandwidth achieved: 178.56 GB/s
FLOPS achieved: 0.89 TF/s

Prefill latency: 0.012031857040710747 sec
Decode latency: 1.7102327559841797 sec
Time for inference 4: 1.72 sec total, 148.59 tokens/sec
Decode latency: 1.71 sec
Prefill latency: 0.01 sec
Bandwidth achieved: 190.75 GB/s
FLOPS achieved: 0.95 TF/s

Prefill latency: 0.012004429008811712 sec
Decode latency: 1.8294982659863308 sec
Time for inference 5: 1.84 sec total, 138.97 tokens/sec
Decode latency: 1.83 sec
Prefill latency: 0.01 sec
Bandwidth achieved: 178.40 GB/s
FLOPS achieved: 0.89 TF/s

Prefill latency: 0.012025727075524628 sec
Decode latency: 1.7919850129401311 sec
Time for inference 6: 1.80 sec total, 141.85 tokens/sec
Decode latency: 1.79 sec
Prefill latency: 0.01 sec
Bandwidth achieved: 182.09 GB/s
FLOPS achieved: 0.91 TF/s

Prefill latency: 0.012030341080389917 sec
Decode latency: 1.8284795440267771 sec
Time for inference 7: 1.84 sec total, 139.03 tokens/sec
Decode latency: 1.83 sec
Prefill latency: 0.01 sec
Bandwidth achieved: 178.48 GB/s
FLOPS achieved: 0.89 TF/s

Prefill latency: 0.012022620998322964 sec
Decode latency: 1.7459283680655062 sec
Time for inference 8: 1.76 sec total, 145.56 tokens/sec
Decode latency: 1.75 sec
Prefill latency: 0.01 sec
Bandwidth achieved: 186.86 GB/s
FLOPS achieved: 0.93 TF/s

Prefill latency: 0.012036553001962602 sec
Decode latency: 1.7739586300449446 sec
Time for inference 9: 1.79 sec total, 143.29 tokens/sec
Decode latency: 1.77 sec
Prefill latency: 0.01 sec
Bandwidth achieved: 183.94 GB/s
FLOPS achieved: 0.92 TF/s

Prefill latency: 0.012012940947897732 sec
Decode latency: 1.828305933973752 sec
Time for inference 10: 1.84 sec total, 139.06 tokens/sec
Decode latency: 1.83 sec
Prefill latency: 0.01 sec
Bandwidth achieved: 178.51 GB/s
FLOPS achieved: 0.89 TF/s

==========
Batch Size: 1
Prompt Length: 1024
Generated tokens: 256
Average decode latency: 1.7994 sec
Average prefill latency: 0.0120 sec
Average tokens/sec: 141.35
Memory used: 1.92 GB
Done. we are killing the process
