W0930 21:11:20.427000 22739724695360 torch/distributed/run.py:779] 
W0930 21:11:20.427000 22739724695360 torch/distributed/run.py:779] *****************************************
W0930 21:11:20.427000 22739724695360 torch/distributed/run.py:779] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W0930 21:11:20.427000 22739724695360 torch/distributed/run.py:779] *****************************************
flash_kv_decode is set to True
Using device=cuda
Loading model ...
GPTEnsemble(
  (tok_embeddings): Embedding(49152, 1536)
  (layers): ModuleList(
    (0-39): 40 x EnsembleTransformerBlock(
      semi_compiled = False
      (attention): Attention(
        (wqkv): Linear(in_features=1536, out_features=640, bias=False)
        (wo): Linear(in_features=384, out_features=1536, bias=False)
      )
      (feed_forward): FeedForward(
        (w1): Linear(in_features=1536, out_features=2048, bias=False)
        (w2): Linear(in_features=1024, out_features=1536, bias=False)
      )
      (ffn_norm): RMSNorm()
      (attention_norm): RMSNorm()
    )
  )
  (norm): RMSNorm()
  (output): Linear(in_features=1536, out_features=49152, bias=False)
)
Time to load model: 1.01 seconds
Prefill latency: 0.03925163298845291 sec
Decode latency: 2.430026608053595 sec
Compilation time: 2.49 seconds
Compilation time: 2.53 seconds
Compilation time: 2.51 seconds
Compilation time: 2.47 seconds
Prefill latency: 0.03870340099092573 sec
Decode latency: 2.428636892931536 sec
Prefill latency: 0.0388838549843058 sec
Decode latency: 2.4286479000002146 sec
Prefill latency: 0.038754255045205355 sec
Decode latency: 2.4258132880786434 sec
Prefill latency: 0.03879390493966639 sec
Decode latency: 2.4248596919933334 sec
Prefill latency: 0.03874953603371978 sec
Decode latency: 2.425360150053166 sec
Time for inference 1: 2.46 sec total, 830.90 tokens/sec
Decode latency: 2.43 sec
Prefill latency: 0.04 sec
Bandwidth achieved: 543.87 GB/s
FLOPS achieved: 2.72 TF/s

Prefill latency: 0.03893676900770515 sec
Decode latency: 2.426274564000778 sec
Time for inference 2: 2.47 sec total, 830.52 tokens/sec
Decode latency: 2.43 sec
Prefill latency: 0.04 sec
Bandwidth achieved: 543.63 GB/s
FLOPS achieved: 2.72 TF/s

Prefill latency: 0.038751421961933374 sec
Decode latency: 2.426731530111283 sec
Time for inference 3: 2.47 sec total, 830.27 tokens/sec
Decode latency: 2.43 sec
Prefill latency: 0.04 sec
Bandwidth achieved: 543.46 GB/s
FLOPS achieved: 2.72 TF/s

Prefill latency: 0.03872704692184925 sec
Decode latency: 2.424406604957767 sec
Time for inference 4: 2.46 sec total, 831.12 tokens/sec
Decode latency: 2.42 sec
Prefill latency: 0.04 sec
Bandwidth achieved: 544.02 GB/s
FLOPS achieved: 2.72 TF/s

Prefill latency: 0.03877084795385599 sec
Decode latency: 2.42638982005883 sec
Time for inference 5: 2.47 sec total, 830.44 tokens/sec
Decode latency: 2.43 sec
Prefill latency: 0.04 sec
Bandwidth achieved: 543.57 GB/s
FLOPS achieved: 2.72 TF/s

Prefill latency: 0.038717659073881805 sec
Decode latency: 2.4272930059814826 sec
Time for inference 6: 2.47 sec total, 830.18 tokens/sec
Decode latency: 2.43 sec
Prefill latency: 0.04 sec
Bandwidth achieved: 543.40 GB/s
FLOPS achieved: 2.72 TF/s

Prefill latency: 0.03879829205106944 sec
Decode latency: 2.42982458404731 sec
Time for inference 7: 2.47 sec total, 829.37 tokens/sec
Decode latency: 2.43 sec
Prefill latency: 0.04 sec
Bandwidth achieved: 542.87 GB/s
FLOPS achieved: 2.71 TF/s

Prefill latency: 0.03885897796135396 sec
Decode latency: 2.4264768220018595 sec
Time for inference 8: 2.47 sec total, 830.42 tokens/sec
Decode latency: 2.43 sec
Prefill latency: 0.04 sec
Bandwidth achieved: 543.56 GB/s
FLOPS achieved: 2.72 TF/s

Prefill latency: 0.03875166492071003 sec
Decode latency: 2.423763853032142 sec
Time for inference 9: 2.46 sec total, 831.38 tokens/sec
Decode latency: 2.42 sec
Prefill latency: 0.04 sec
Bandwidth achieved: 544.19 GB/s
FLOPS achieved: 2.72 TF/s

Prefill latency: 0.03879458294250071 sec
Decode latency: 2.4251794209703803 sec
Time for inference 10: 2.46 sec total, 830.88 tokens/sec
Decode latency: 2.43 sec
Prefill latency: 0.04 sec
Bandwidth achieved: 543.86 GB/s
FLOPS achieved: 2.72 TF/s

==========
Batch Size: 8
Prompt Length: 1024
Generated tokens: 256
Average decode latency: 2.4262 sec
Average prefill latency: 0.0388 sec
Average tokens/sec: 830.55
Memory used: 3.45 GB
Done. we are killing the process
