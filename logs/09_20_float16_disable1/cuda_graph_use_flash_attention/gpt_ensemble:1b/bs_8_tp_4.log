W1001 04:13:45.122000 22789260584768 torch/distributed/run.py:779] 
W1001 04:13:45.122000 22789260584768 torch/distributed/run.py:779] *****************************************
W1001 04:13:45.122000 22789260584768 torch/distributed/run.py:779] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W1001 04:13:45.122000 22789260584768 torch/distributed/run.py:779] *****************************************
flash_kv_decode is set to True
Using device=cuda
Loading model ...
GPTEnsemble(
  (tok_embeddings): Embedding(49152, 1536)
  (layers): ModuleList(
    (0-39): 40 x EnsembleTransformerBlock(
      semi_compiled = False
      (attention): Attention(
        (wqkv): Linear(in_features=1536, out_features=1152, bias=False)
        (wo): Linear(in_features=384, out_features=1536, bias=False)
      )
      (feed_forward): FeedForward(
        (w1): Linear(in_features=1536, out_features=2048, bias=False)
        (w2): Linear(in_features=1024, out_features=1536, bias=False)
      )
      (ffn_norm): RMSNorm()
      (attention_norm): RMSNorm()
    )
  )
  (norm): RMSNorm()
  (output): Linear(in_features=1536, out_features=49152, bias=False)
)
Time to load model: 0.96 seconds
Prefill latency: 0.03433190705254674 sec
Decode latency: 2.0261913429712877 sec
Compilation time: 2.06 seconds
Compilation time: 2.06 seconds
Compilation time: 2.07 seconds
Compilation time: 2.10 seconds
Prefill latency: 0.0340345409931615 sec
Decode latency: 2.022358941962011 sec
Prefill latency: 0.03400009300094098 sec
Decode latency: 1.9765885199885815 sec
Prefill latency: 0.03401490696705878 sec
Decode latency: 2.0221346450271085 sec
Prefill latency: 0.03405140701215714 sec
Decode latency: 2.0223244690569118 sec
Prefill latency: 0.03402659494895488 sec
Decode latency: 2.0219027099665254 sec
Time for inference 1: 2.06 sec total, 995.84 tokens/sec
Decode latency: 2.02 sec
Prefill latency: 0.03 sec
Bandwidth achieved: 714.49 GB/s
FLOPS achieved: 3.57 TF/s

Prefill latency: 0.03400646091904491 sec
Decode latency: 2.022280486067757 sec
Time for inference 2: 2.06 sec total, 995.68 tokens/sec
Decode latency: 2.02 sec
Prefill latency: 0.03 sec
Bandwidth achieved: 714.38 GB/s
FLOPS achieved: 3.57 TF/s

Prefill latency: 0.03402189305052161 sec
Decode latency: 2.0224429150111973 sec
Time for inference 3: 2.06 sec total, 995.60 tokens/sec
Decode latency: 2.02 sec
Prefill latency: 0.03 sec
Bandwidth achieved: 714.32 GB/s
FLOPS achieved: 3.57 TF/s

Prefill latency: 0.03397908003535122 sec
Decode latency: 2.0225242599844933 sec
Time for inference 4: 2.06 sec total, 995.58 tokens/sec
Decode latency: 2.02 sec
Prefill latency: 0.03 sec
Bandwidth achieved: 714.30 GB/s
FLOPS achieved: 3.57 TF/s

Prefill latency: 0.03399953700136393 sec
Decode latency: 2.02237933606375 sec
Time for inference 5: 2.06 sec total, 995.64 tokens/sec
Decode latency: 2.02 sec
Prefill latency: 0.03 sec
Bandwidth achieved: 714.34 GB/s
FLOPS achieved: 3.57 TF/s

Prefill latency: 0.03400429000612348 sec
Decode latency: 2.0222890899749473 sec
Time for inference 6: 2.06 sec total, 995.68 tokens/sec
Decode latency: 2.02 sec
Prefill latency: 0.03 sec
Bandwidth achieved: 714.37 GB/s
FLOPS achieved: 3.57 TF/s

Prefill latency: 0.03400412597693503 sec
Decode latency: 2.0219762939959764 sec
Time for inference 7: 2.06 sec total, 995.83 tokens/sec
Decode latency: 2.02 sec
Prefill latency: 0.03 sec
Bandwidth achieved: 714.48 GB/s
FLOPS achieved: 3.57 TF/s

Prefill latency: 0.03399080503731966 sec
Decode latency: 2.0219582109712064 sec
Time for inference 8: 2.06 sec total, 995.82 tokens/sec
Decode latency: 2.02 sec
Prefill latency: 0.03 sec
Bandwidth achieved: 714.48 GB/s
FLOPS achieved: 3.57 TF/s

Prefill latency: 0.034016610006801784 sec
Decode latency: 2.0219935149652883 sec
Time for inference 9: 2.06 sec total, 995.79 tokens/sec
Decode latency: 2.02 sec
Prefill latency: 0.03 sec
Bandwidth achieved: 714.45 GB/s
FLOPS achieved: 3.57 TF/s

Prefill latency: 0.03399401402566582 sec
Decode latency: 2.022156100952998 sec
Time for inference 10: 2.06 sec total, 995.74 tokens/sec
Decode latency: 2.02 sec
Prefill latency: 0.03 sec
Bandwidth achieved: 714.42 GB/s
FLOPS achieved: 3.57 TF/s

==========
Batch Size: 8
Prompt Length: 1024
Generated tokens: 256
Average decode latency: 2.0222 sec
Average prefill latency: 0.0340 sec
Average tokens/sec: 995.72
Memory used: 2.88 GB
Done. we are killing the process
