W0930 20:44:16.451000 22450732537664 torch/distributed/run.py:779] 
W0930 20:44:16.451000 22450732537664 torch/distributed/run.py:779] *****************************************
W0930 20:44:16.451000 22450732537664 torch/distributed/run.py:779] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W0930 20:44:16.451000 22450732537664 torch/distributed/run.py:779] *****************************************
flash_kv_decode is set to True
Using device=cuda
Loading model ...
GPTParallel(
  (tok_embeddings): Embedding(49152, 1536)
  (layers): ModuleList(
    (0-39): 40 x ParallelTransformerBlock(
      semi_compiled = False
      (attention): FuseAttentionMLP(
        (wqkv1): Linear(in_features=1536, out_features=1344, bias=False)
        (wo): Linear(in_features=192, out_features=1536, bias=False)
        (w2): Linear(in_features=512, out_features=1536, bias=False)
      )
      (attention_norm): RMSNorm()
    )
  )
  (norm): RMSNorm()
  (output): Linear(in_features=1536, out_features=49152, bias=False)
)
Time to load model: 1.08 seconds
Prefill latency: 0.014517907984554768 sec
Decode latency: 2.057987396954559 sec
Compilation time: 2.08 seconds
Compilation time: 2.09 seconds
Compilation time: 2.09 seconds
Compilation time: 2.09 seconds
Compilation time: 2.07 seconds
Compilation time: 2.07 seconds
Compilation time: 2.09 seconds
Compilation time: 2.09 seconds
Prefill latency: 0.013936421950347722 sec
Decode latency: 2.0524821910075843 sec
Prefill latency: 0.013723714975640178 sec
Decode latency: 2.0619915470015258 sec
Prefill latency: 0.014813542016781867 sec
Decode latency: 2.049311063019559 sec
Prefill latency: 0.013503519003279507 sec
Decode latency: 2.0499880569987 sec
Prefill latency: 0.013659641961567104 sec
Decode latency: 2.0324043210130185 sec
Time for inference 1: 2.05 sec total, 125.07 tokens/sec
Decode latency: 2.03 sec
Prefill latency: 0.01 sec
Bandwidth achieved: 50.38 GB/s
FLOPS achieved: 0.25 TF/s

Prefill latency: 0.013831821968778968 sec
Decode latency: 2.0424167870078236 sec
Time for inference 2: 2.06 sec total, 124.45 tokens/sec
Decode latency: 2.04 sec
Prefill latency: 0.01 sec
Bandwidth achieved: 50.13 GB/s
FLOPS achieved: 0.25 TF/s

Prefill latency: 0.02163094491697848 sec
Decode latency: 2.043575056013651 sec
Time for inference 3: 2.07 sec total, 123.91 tokens/sec
Decode latency: 2.04 sec
Prefill latency: 0.02 sec
Bandwidth achieved: 49.91 GB/s
FLOPS achieved: 0.25 TF/s

Prefill latency: 0.013924205908551812 sec
Decode latency: 2.051430590916425 sec
Time for inference 4: 2.07 sec total, 123.90 tokens/sec
Decode latency: 2.05 sec
Prefill latency: 0.01 sec
Bandwidth achieved: 49.90 GB/s
FLOPS achieved: 0.25 TF/s

Prefill latency: 0.013768814038485289 sec
Decode latency: 2.064065619953908 sec
Time for inference 5: 2.08 sec total, 123.15 tokens/sec
Decode latency: 2.06 sec
Prefill latency: 0.01 sec
Bandwidth achieved: 49.60 GB/s
FLOPS achieved: 0.25 TF/s

Prefill latency: 0.017400295939296484 sec
Decode latency: 2.063292382983491 sec
Time for inference 6: 2.08 sec total, 122.99 tokens/sec
Decode latency: 2.06 sec
Prefill latency: 0.02 sec
Bandwidth achieved: 49.54 GB/s
FLOPS achieved: 0.25 TF/s

Prefill latency: 0.016262076911516488 sec
Decode latency: 2.050960781984031 sec
Time for inference 7: 2.07 sec total, 123.78 tokens/sec
Decode latency: 2.05 sec
Prefill latency: 0.02 sec
Bandwidth achieved: 49.86 GB/s
FLOPS achieved: 0.25 TF/s

Prefill latency: 0.013479760033078492 sec
Decode latency: 2.0395723950350657 sec
Time for inference 8: 2.05 sec total, 124.64 tokens/sec
Decode latency: 2.04 sec
Prefill latency: 0.01 sec
Bandwidth achieved: 50.20 GB/s
FLOPS achieved: 0.25 TF/s

Prefill latency: 0.013687845901586115 sec
Decode latency: 2.0590870230225846 sec
Time for inference 9: 2.07 sec total, 123.46 tokens/sec
Decode latency: 2.06 sec
Prefill latency: 0.01 sec
Bandwidth achieved: 49.73 GB/s
FLOPS achieved: 0.25 TF/s

Prefill latency: 0.016051399055868387 sec
Decode latency: 2.05897183297202 sec
Time for inference 10: 2.08 sec total, 123.32 tokens/sec
Decode latency: 2.06 sec
Prefill latency: 0.02 sec
Bandwidth achieved: 49.67 GB/s
FLOPS achieved: 0.25 TF/s

==========
Batch Size: 1
Prompt Length: 1024
Generated tokens: 256
Average decode latency: 2.0506 sec
Average prefill latency: 0.0154 sec
Average tokens/sec: 123.87
Memory used: 0.97 GB
Done. we are killing the process
