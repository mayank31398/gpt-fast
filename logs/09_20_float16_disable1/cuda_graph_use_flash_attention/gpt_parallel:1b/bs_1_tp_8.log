W1001 03:48:37.916000 23010350118720 torch/distributed/run.py:779] 
W1001 03:48:37.916000 23010350118720 torch/distributed/run.py:779] *****************************************
W1001 03:48:37.916000 23010350118720 torch/distributed/run.py:779] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W1001 03:48:37.916000 23010350118720 torch/distributed/run.py:779] *****************************************
flash_kv_decode is set to True
Using device=cuda
Loading model ...
GPTParallel(
  (tok_embeddings): Embedding(49152, 1536)
  (layers): ModuleList(
    (0-39): 40 x ParallelTransformerBlock(
      semi_compiled = False
      (attention): FuseAttentionMLP(
        (wqkv1): Linear(in_features=1536, out_features=1600, bias=False)
        (wo): Linear(in_features=192, out_features=1536, bias=False)
        (w2): Linear(in_features=512, out_features=1536, bias=False)
      )
      (attention_norm): RMSNorm()
    )
  )
  (norm): RMSNorm()
  (output): Linear(in_features=1536, out_features=49152, bias=False)
)
Time to load model: 1.15 seconds
Prefill latency: 0.03354428696911782 sec
Decode latency: 2.07188576401677 sec
Compilation time: 2.09 seconds
Compilation time: 2.10 seconds
Compilation time: 2.11 seconds
Compilation time: 2.11 seconds
Compilation time: 2.14 seconds
Compilation time: 2.10 seconds
Compilation time: 2.10 seconds
Compilation time: 2.12 seconds
Prefill latency: 0.016812394955195487 sec
Decode latency: 2.0749859330244362 sec
Prefill latency: 0.016228710999712348 sec
Decode latency: 2.069962497917004 sec
Prefill latency: 0.01673263101838529 sec
Decode latency: 2.0722608369542286 sec
Prefill latency: 0.013896152027882636 sec
Decode latency: 2.0713914619991556 sec
Prefill latency: 0.014233545982278883 sec
Decode latency: 2.0653551480500028 sec
Time for inference 1: 2.08 sec total, 123.05 tokens/sec
Decode latency: 2.07 sec
Prefill latency: 0.01 sec
Bandwidth achieved: 53.43 GB/s
FLOPS achieved: 0.27 TF/s

Prefill latency: 0.01657740806695074 sec
Decode latency: 2.0721630809130147 sec
Time for inference 2: 2.09 sec total, 122.52 tokens/sec
Decode latency: 2.07 sec
Prefill latency: 0.02 sec
Bandwidth achieved: 53.20 GB/s
FLOPS achieved: 0.27 TF/s

Prefill latency: 0.014314106083475053 sec
Decode latency: 2.0519363989587873 sec
Time for inference 3: 2.07 sec total, 123.85 tokens/sec
Decode latency: 2.05 sec
Prefill latency: 0.01 sec
Bandwidth achieved: 53.78 GB/s
FLOPS achieved: 0.27 TF/s

Prefill latency: 0.016265640035271645 sec
Decode latency: 2.0623450169805437 sec
Time for inference 4: 2.08 sec total, 123.11 tokens/sec
Decode latency: 2.06 sec
Prefill latency: 0.02 sec
Bandwidth achieved: 53.46 GB/s
FLOPS achieved: 0.27 TF/s

Prefill latency: 0.013215946964919567 sec
Decode latency: 2.0564943850040436 sec
Time for inference 5: 2.07 sec total, 123.63 tokens/sec
Decode latency: 2.06 sec
Prefill latency: 0.01 sec
Bandwidth achieved: 53.69 GB/s
FLOPS achieved: 0.27 TF/s

Prefill latency: 0.013962881988845766 sec
Decode latency: 2.055105577921495 sec
Time for inference 6: 2.07 sec total, 123.69 tokens/sec
Decode latency: 2.06 sec
Prefill latency: 0.01 sec
Bandwidth achieved: 53.71 GB/s
FLOPS achieved: 0.27 TF/s

Prefill latency: 0.01358333695679903 sec
Decode latency: 2.0713429759489372 sec
Time for inference 7: 2.09 sec total, 122.73 tokens/sec
Decode latency: 2.07 sec
Prefill latency: 0.01 sec
Bandwidth achieved: 53.30 GB/s
FLOPS achieved: 0.27 TF/s

Prefill latency: 0.014283733093179762 sec
Decode latency: 2.0598650900647044 sec
Time for inference 8: 2.08 sec total, 123.37 tokens/sec
Decode latency: 2.06 sec
Prefill latency: 0.01 sec
Bandwidth achieved: 53.57 GB/s
FLOPS achieved: 0.27 TF/s

Prefill latency: 0.013543423032388091 sec
Decode latency: 2.0469158890191466 sec
Time for inference 9: 2.06 sec total, 124.19 tokens/sec
Decode latency: 2.05 sec
Prefill latency: 0.01 sec
Bandwidth achieved: 53.93 GB/s
FLOPS achieved: 0.27 TF/s

Prefill latency: 0.021973310969769955 sec
Decode latency: 2.068878958001733 sec
Time for inference 10: 2.09 sec total, 122.39 tokens/sec
Decode latency: 2.07 sec
Prefill latency: 0.02 sec
Bandwidth achieved: 53.15 GB/s
FLOPS achieved: 0.27 TF/s

==========
Batch Size: 1
Prompt Length: 1024
Generated tokens: 256
Average decode latency: 2.0610 sec
Average prefill latency: 0.0152 sec
Average tokens/sec: 123.26
Memory used: 1.04 GB
Done. we are killing the process
