flash_kv_decode is set to True
Using device=cuda
Loading model ...
GPTParallel(
  (tok_embeddings): Embedding(49152, 1536)
  (layers): ModuleList(
    (0-39): 40 x ParallelTransformerBlock(
      semi_compiled = False
      (attention): FuseAttentionMLP(
        (wqkv1): Linear(in_features=1536, out_features=12800, bias=False)
        (wo): Linear(in_features=1536, out_features=1536, bias=False)
        (w2): Linear(in_features=4096, out_features=1536, bias=False)
      )
      (attention_norm): RMSNorm()
    )
  )
  (norm): RMSNorm()
  (output): Linear(in_features=1536, out_features=49152, bias=False)
)
Time to load model: 0.92 seconds
Prefill latency: 0.20659315900411457 sec
Decode latency: 3.3044156279647723 sec
Compilation time: 3.51 seconds
Prefill latency: 0.2059540479676798 sec
Decode latency: 3.302213644958101 sec
Prefill latency: 0.2060416720341891 sec
Decode latency: 3.3020242740167305 sec
Prefill latency: 0.2061414560303092 sec
Decode latency: 3.3021667770808563 sec
Prefill latency: 0.20612772298045456 sec
Decode latency: 3.3033323669806123 sec
Prefill latency: 0.2060833580326289 sec
Decode latency: 3.3026082910364494 sec
Time for inference 1: 3.51 sec total, 1167.10 tokens/sec
Decode latency: 3.30 sec
Prefill latency: 0.21 sec
Bandwidth achieved: 2819.77 GB/s
FLOPS achieved: 14.10 TF/s

Prefill latency: 0.20605236000847071 sec
Decode latency: 3.2579722279915586 sec
Time for inference 2: 3.46 sec total, 1182.16 tokens/sec
Decode latency: 3.26 sec
Prefill latency: 0.21 sec
Bandwidth achieved: 2856.14 GB/s
FLOPS achieved: 14.28 TF/s

Prefill latency: 0.20612871600314975 sec
Decode latency: 3.302601826027967 sec
Time for inference 3: 3.51 sec total, 1167.10 tokens/sec
Decode latency: 3.30 sec
Prefill latency: 0.21 sec
Bandwidth achieved: 2819.77 GB/s
FLOPS achieved: 14.10 TF/s

Prefill latency: 0.20613713399507105 sec
Decode latency: 3.30247924500145 sec
Time for inference 4: 3.51 sec total, 1167.15 tokens/sec
Decode latency: 3.30 sec
Prefill latency: 0.21 sec
Bandwidth achieved: 2819.90 GB/s
FLOPS achieved: 14.10 TF/s

Prefill latency: 0.20611634303350002 sec
Decode latency: 3.2071947639342397 sec
Time for inference 5: 3.41 sec total, 1199.73 tokens/sec
Decode latency: 3.21 sec
Prefill latency: 0.21 sec
Bandwidth achieved: 2898.61 GB/s
FLOPS achieved: 14.49 TF/s

Prefill latency: 0.20614596200175583 sec
Decode latency: 3.281876493943855 sec
Time for inference 6: 3.49 sec total, 1174.07 tokens/sec
Decode latency: 3.28 sec
Prefill latency: 0.21 sec
Bandwidth achieved: 2836.62 GB/s
FLOPS achieved: 14.18 TF/s

Prefill latency: 0.20606194995343685 sec
Decode latency: 3.208657282986678 sec
Time for inference 7: 3.42 sec total, 1199.27 tokens/sec
Decode latency: 3.21 sec
Prefill latency: 0.21 sec
Bandwidth achieved: 2897.48 GB/s
FLOPS achieved: 14.49 TF/s

Prefill latency: 0.20610461803153157 sec
Decode latency: 3.255117270979099 sec
Time for inference 8: 3.46 sec total, 1183.17 tokens/sec
Decode latency: 3.26 sec
Prefill latency: 0.21 sec
Bandwidth achieved: 2858.60 GB/s
FLOPS achieved: 14.29 TF/s

Prefill latency: 0.20615026401355863 sec
Decode latency: 3.3028351170942187 sec
Time for inference 9: 3.51 sec total, 1167.00 tokens/sec
Decode latency: 3.30 sec
Prefill latency: 0.21 sec
Bandwidth achieved: 2819.53 GB/s
FLOPS achieved: 14.10 TF/s

Prefill latency: 0.20615999400615692 sec
Decode latency: 3.302502105012536 sec
Time for inference 10: 3.51 sec total, 1167.12 tokens/sec
Decode latency: 3.30 sec
Prefill latency: 0.21 sec
Bandwidth achieved: 2819.82 GB/s
FLOPS achieved: 14.10 TF/s

==========
Batch Size: 16
Prompt Length: 1024
Generated tokens: 256
Average decode latency: 3.2724 sec
Average prefill latency: 0.2061 sec
Average tokens/sec: 1177.39
Memory used: 13.08 GB
Done. we are killing the process
