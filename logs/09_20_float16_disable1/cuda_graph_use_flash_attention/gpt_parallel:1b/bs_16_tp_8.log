W1001 03:58:45.747000 23256675256128 torch/distributed/run.py:779] 
W1001 03:58:45.747000 23256675256128 torch/distributed/run.py:779] *****************************************
W1001 03:58:45.747000 23256675256128 torch/distributed/run.py:779] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W1001 03:58:45.747000 23256675256128 torch/distributed/run.py:779] *****************************************
flash_kv_decode is set to True
Using device=cuda
Loading model ...
GPTParallel(
  (tok_embeddings): Embedding(49152, 1536)
  (layers): ModuleList(
    (0-39): 40 x ParallelTransformerBlock(
      semi_compiled = False
      (attention): FuseAttentionMLP(
        (wqkv1): Linear(in_features=1536, out_features=1600, bias=False)
        (wo): Linear(in_features=192, out_features=1536, bias=False)
        (w2): Linear(in_features=512, out_features=1536, bias=False)
      )
      (attention_norm): RMSNorm()
    )
  )
  (norm): RMSNorm()
  (output): Linear(in_features=1536, out_features=49152, bias=False)
)
Time to load model: 1.18 seconds
Prefill latency: 0.07402681896928698 sec
Decode latency: 2.8220126719679683 sec
Compilation time: 2.91 seconds
Compilation time: 2.90 seconds
Compilation time: 2.91 seconds
Compilation time: 2.88 seconds
Compilation time: 2.91 seconds
Compilation time: 2.88 seconds
Compilation time: 2.91 seconds
Compilation time: 2.90 seconds
Prefill latency: 0.05473399301990867 sec
Decode latency: 2.8277925169095397 sec
Prefill latency: 0.054633673978969455 sec
Decode latency: 2.812149322940968 sec
Prefill latency: 0.0550762889906764 sec
Decode latency: 2.827869285014458 sec
Prefill latency: 0.05774333898443729 sec
Decode latency: 2.823285974911414 sec
Prefill latency: 0.055048872949555516 sec
Decode latency: 2.8224022689973935 sec
Time for inference 1: 2.88 sec total, 1422.95 tokens/sec
Decode latency: 2.82 sec
Prefill latency: 0.06 sec
Bandwidth achieved: 617.90 GB/s
FLOPS achieved: 3.09 TF/s

Prefill latency: 0.05491637601517141 sec
Decode latency: 2.8270589290186763 sec
Time for inference 2: 2.88 sec total, 1420.78 tokens/sec
Decode latency: 2.83 sec
Prefill latency: 0.05 sec
Bandwidth achieved: 616.96 GB/s
FLOPS achieved: 3.08 TF/s

Prefill latency: 0.0550927110016346 sec
Decode latency: 2.824381403042935 sec
Time for inference 3: 2.88 sec total, 1422.05 tokens/sec
Decode latency: 2.82 sec
Prefill latency: 0.06 sec
Bandwidth achieved: 617.51 GB/s
FLOPS achieved: 3.09 TF/s

Prefill latency: 0.054904289077967405 sec
Decode latency: 2.820446870988235 sec
Time for inference 4: 2.88 sec total, 1424.15 tokens/sec
Decode latency: 2.82 sec
Prefill latency: 0.05 sec
Bandwidth achieved: 618.42 GB/s
FLOPS achieved: 3.09 TF/s

Prefill latency: 0.05527651309967041 sec
Decode latency: 2.828335205093026 sec
Time for inference 5: 2.88 sec total, 1420.02 tokens/sec
Decode latency: 2.83 sec
Prefill latency: 0.06 sec
Bandwidth achieved: 616.63 GB/s
FLOPS achieved: 3.08 TF/s

Prefill latency: 0.05549277504906058 sec
Decode latency: 2.8162026300560683 sec
Time for inference 6: 2.87 sec total, 1425.88 tokens/sec
Decode latency: 2.82 sec
Prefill latency: 0.06 sec
Bandwidth achieved: 619.17 GB/s
FLOPS achieved: 3.10 TF/s

Prefill latency: 0.055098016979172826 sec
Decode latency: 2.8265813440084457 sec
Time for inference 7: 2.88 sec total, 1420.99 tokens/sec
Decode latency: 2.83 sec
Prefill latency: 0.06 sec
Bandwidth achieved: 617.05 GB/s
FLOPS achieved: 3.09 TF/s

Prefill latency: 0.055836573941633105 sec
Decode latency: 2.827342810924165 sec
Time for inference 8: 2.88 sec total, 1420.27 tokens/sec
Decode latency: 2.83 sec
Prefill latency: 0.06 sec
Bandwidth achieved: 616.73 GB/s
FLOPS achieved: 3.08 TF/s

Prefill latency: 0.05512984190136194 sec
Decode latency: 2.8320148959755898 sec
Time for inference 9: 2.89 sec total, 1418.24 tokens/sec
Decode latency: 2.83 sec
Prefill latency: 0.06 sec
Bandwidth achieved: 615.85 GB/s
FLOPS achieved: 3.08 TF/s

Prefill latency: 0.05488074407912791 sec
Decode latency: 2.817613512976095 sec
Time for inference 10: 2.87 sec total, 1425.48 tokens/sec
Decode latency: 2.82 sec
Prefill latency: 0.05 sec
Bandwidth achieved: 619.00 GB/s
FLOPS achieved: 3.09 TF/s

==========
Batch Size: 16
Prompt Length: 1024
Generated tokens: 256
Average decode latency: 2.8242 sec
Average prefill latency: 0.0552 sec
Average tokens/sec: 1422.08
Memory used: 5.54 GB
Done. we are killing the process
