W0930 20:54:43.916000 22843865716544 torch/distributed/run.py:779] 
W0930 20:54:43.916000 22843865716544 torch/distributed/run.py:779] *****************************************
W0930 20:54:43.916000 22843865716544 torch/distributed/run.py:779] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W0930 20:54:43.916000 22843865716544 torch/distributed/run.py:779] *****************************************
flash_kv_decode is set to True
Using device=cuda
Loading model ...
GPTParallel(
  (tok_embeddings): Embedding(49152, 1536)
  (layers): ModuleList(
    (0-39): 40 x ParallelTransformerBlock(
      semi_compiled = False
      (attention): FuseAttentionMLP(
        (wqkv1): Linear(in_features=1536, out_features=1344, bias=False)
        (wo): Linear(in_features=192, out_features=1536, bias=False)
        (w2): Linear(in_features=512, out_features=1536, bias=False)
      )
      (attention_norm): RMSNorm()
    )
  )
  (norm): RMSNorm()
  (output): Linear(in_features=1536, out_features=49152, bias=False)
)
Time to load model: 1.10 seconds
Prefill latency: 0.08137719810474664 sec
Decode latency: 2.845243633026257 sec
Compilation time: 2.93 seconds
Compilation time: 2.90 seconds
Compilation time: 2.93 seconds
Compilation time: 2.90 seconds
Compilation time: 2.90 seconds
Compilation time: 2.95 secondsCompilation time: 2.93 seconds

Compilation time: 2.93 seconds
Prefill latency: 0.05147289496380836 sec
Decode latency: 2.842585538048297 sec
Prefill latency: 0.05172167799901217 sec
Decode latency: 2.839689656975679 sec
Prefill latency: 0.051394100999459624 sec
Decode latency: 2.843837436987087 sec
Prefill latency: 0.05134857597295195 sec
Decode latency: 2.842894940986298 sec
Prefill latency: 0.05156279297079891 sec
Decode latency: 2.83965323807206 sec
Time for inference 1: 2.89 sec total, 1416.31 tokens/sec
Decode latency: 2.84 sec
Prefill latency: 0.05 sec
Bandwidth achieved: 570.46 GB/s
FLOPS achieved: 2.85 TF/s

Prefill latency: 0.05481154506560415 sec
Decode latency: 2.8404482529731467 sec
Time for inference 2: 2.90 sec total, 1414.21 tokens/sec
Decode latency: 2.84 sec
Prefill latency: 0.05 sec
Bandwidth achieved: 569.62 GB/s
FLOPS achieved: 2.85 TF/s

Prefill latency: 0.05236073804553598 sec
Decode latency: 2.850745012052357 sec
Time for inference 3: 2.90 sec total, 1410.44 tokens/sec
Decode latency: 2.85 sec
Prefill latency: 0.05 sec
Bandwidth achieved: 568.10 GB/s
FLOPS achieved: 2.84 TF/s

Prefill latency: 0.05146096204407513 sec
Decode latency: 2.846037862007506 sec
Time for inference 4: 2.90 sec total, 1413.09 tokens/sec
Decode latency: 2.85 sec
Prefill latency: 0.05 sec
Bandwidth achieved: 569.16 GB/s
FLOPS achieved: 2.85 TF/s

Prefill latency: 0.05152573704253882 sec
Decode latency: 2.8362979169469327 sec
Time for inference 5: 2.89 sec total, 1417.89 tokens/sec
Decode latency: 2.84 sec
Prefill latency: 0.05 sec
Bandwidth achieved: 571.10 GB/s
FLOPS achieved: 2.86 TF/s

Prefill latency: 0.051776721025817096 sec
Decode latency: 2.8514329589670524 sec
Time for inference 6: 2.90 sec total, 1410.32 tokens/sec
Decode latency: 2.85 sec
Prefill latency: 0.05 sec
Bandwidth achieved: 568.05 GB/s
FLOPS achieved: 2.84 TF/s

Prefill latency: 0.05165505292825401 sec
Decode latency: 2.842977758962661 sec
Time for inference 7: 2.90 sec total, 1414.51 tokens/sec
Decode latency: 2.84 sec
Prefill latency: 0.05 sec
Bandwidth achieved: 569.73 GB/s
FLOPS achieved: 2.85 TF/s

Prefill latency: 0.05145851196721196 sec
Decode latency: 2.8470830230508 sec
Time for inference 8: 2.90 sec total, 1412.68 tokens/sec
Decode latency: 2.85 sec
Prefill latency: 0.05 sec
Bandwidth achieved: 569.00 GB/s
FLOPS achieved: 2.84 TF/s

Prefill latency: 0.05191209900658578 sec
Decode latency: 2.83945086307358 sec
Time for inference 9: 2.89 sec total, 1416.23 tokens/sec
Decode latency: 2.84 sec
Prefill latency: 0.05 sec
Bandwidth achieved: 570.43 GB/s
FLOPS achieved: 2.85 TF/s

Prefill latency: 0.054495891905389726 sec
Decode latency: 2.8472818840527907 sec
Time for inference 10: 2.90 sec total, 1411.04 tokens/sec
Decode latency: 2.85 sec
Prefill latency: 0.05 sec
Bandwidth achieved: 568.34 GB/s
FLOPS achieved: 2.84 TF/s

==========
Batch Size: 16
Prompt Length: 1024
Generated tokens: 256
Average decode latency: 2.8441 sec
Average prefill latency: 0.0523 sec
Average tokens/sec: 1413.67
Memory used: 4.86 GB
Done. we are killing the process
