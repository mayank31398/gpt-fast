flash_kv_decode is set to True
Using device=cuda
Loading model ...
GPTParallel(
  (tok_embeddings): Embedding(49152, 1536)
  (layers): ModuleList(
    (0-39): 40 x ParallelTransformerBlock(
      semi_compiled = False
      (attention): FuseAttentionMLP(
        (wqkv1): Linear(in_features=1536, out_features=10752, bias=False)
        (wo): Linear(in_features=1536, out_features=1536, bias=False)
        (w2): Linear(in_features=4096, out_features=1536, bias=False)
      )
      (attention_norm): RMSNorm()
    )
  )
  (norm): RMSNorm()
  (output): Linear(in_features=1536, out_features=49152, bias=False)
)
Time to load model: 0.99 seconds
Prefill latency: 0.015610657981596887 sec
Decode latency: 1.872297572903335 sec
Compilation time: 1.89 seconds
Prefill latency: 0.015248122974298894 sec
Decode latency: 1.9513970710104331 sec
Prefill latency: 0.015257982071489096 sec
Decode latency: 1.951256660046056 sec
Prefill latency: 0.015237376093864441 sec
Decode latency: 1.9514527650317177 sec
Prefill latency: 0.015205373987555504 sec
Decode latency: 1.9371667720843107 sec
Prefill latency: 0.015227764029987156 sec
Decode latency: 1.9515129560604692 sec
Time for inference 1: 1.97 sec total, 130.13 tokens/sec
Decode latency: 1.95 sec
Prefill latency: 0.02 sec
Bandwidth achieved: 281.64 GB/s
FLOPS achieved: 1.41 TF/s

Prefill latency: 0.01527992996852845 sec
Decode latency: 1.951417998992838 sec
Time for inference 2: 1.97 sec total, 130.13 tokens/sec
Decode latency: 1.95 sec
Prefill latency: 0.02 sec
Bandwidth achieved: 281.65 GB/s
FLOPS achieved: 1.41 TF/s

Prefill latency: 0.01524927606806159 sec
Decode latency: 1.951438844902441 sec
Time for inference 3: 1.97 sec total, 130.13 tokens/sec
Decode latency: 1.95 sec
Prefill latency: 0.02 sec
Bandwidth achieved: 281.65 GB/s
FLOPS achieved: 1.41 TF/s

Prefill latency: 0.01524886698462069 sec
Decode latency: 1.9065246609970927 sec
Time for inference 4: 1.92 sec total, 133.17 tokens/sec
Decode latency: 1.91 sec
Prefill latency: 0.02 sec
Bandwidth achieved: 288.23 GB/s
FLOPS achieved: 1.44 TF/s

Prefill latency: 0.015235677012242377 sec
Decode latency: 1.9514779790770262 sec
Time for inference 5: 1.97 sec total, 130.13 tokens/sec
Decode latency: 1.95 sec
Prefill latency: 0.02 sec
Bandwidth achieved: 281.65 GB/s
FLOPS achieved: 1.41 TF/s

Prefill latency: 0.015259137959219515 sec
Decode latency: 1.9511428660480306 sec
Time for inference 6: 1.97 sec total, 130.14 tokens/sec
Decode latency: 1.95 sec
Prefill latency: 0.02 sec
Bandwidth achieved: 281.66 GB/s
FLOPS achieved: 1.41 TF/s

Prefill latency: 0.015266085974872112 sec
Decode latency: 1.951483232085593 sec
Time for inference 7: 1.97 sec total, 130.12 tokens/sec
Decode latency: 1.95 sec
Prefill latency: 0.02 sec
Bandwidth achieved: 281.62 GB/s
FLOPS achieved: 1.41 TF/s

Prefill latency: 0.01525712397415191 sec
Decode latency: 1.9513401159783825 sec
Time for inference 8: 1.97 sec total, 130.13 tokens/sec
Decode latency: 1.95 sec
Prefill latency: 0.02 sec
Bandwidth achieved: 281.65 GB/s
FLOPS achieved: 1.41 TF/s

Prefill latency: 0.015255058067850769 sec
Decode latency: 1.9513222019886598 sec
Time for inference 9: 1.97 sec total, 130.13 tokens/sec
Decode latency: 1.95 sec
Prefill latency: 0.02 sec
Bandwidth achieved: 281.66 GB/s
FLOPS achieved: 1.41 TF/s

Prefill latency: 0.015230929013341665 sec
Decode latency: 1.9511270370567217 sec
Time for inference 10: 1.97 sec total, 130.15 tokens/sec
Decode latency: 1.95 sec
Prefill latency: 0.02 sec
Bandwidth achieved: 281.69 GB/s
FLOPS achieved: 1.41 TF/s

==========
Batch Size: 1
Prompt Length: 1024
Generated tokens: 256
Average decode latency: 1.9469 sec
Average prefill latency: 0.0153 sec
Average tokens/sec: 130.43
Memory used: 2.95 GB
Done. we are killing the process
