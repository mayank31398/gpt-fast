flash_kv_decode is set to True
Using device=cuda
Loading model ...
GPTParallel(
  (tok_embeddings): Embedding(49152, 1536)
  (layers): ModuleList(
    (0-39): 40 x ParallelTransformerBlock(
      semi_compiled = False
      (attention): FuseAttentionMLP(
        (wqkv1): Linear(in_features=1536, out_features=12800, bias=False)
        (wo): Linear(in_features=1536, out_features=1536, bias=False)
        (w2): Linear(in_features=4096, out_features=1536, bias=False)
      )
      (attention_norm): RMSNorm()
    )
  )
  (norm): RMSNorm()
  (output): Linear(in_features=1536, out_features=49152, bias=False)
)
Time to load model: 0.92 seconds
Prefill latency: 0.054359280969947577 sec
Decode latency: 2.3122129790717736 sec
Compilation time: 2.37 seconds
Prefill latency: 0.05402118095662445 sec
Decode latency: 2.370451391907409 sec
Prefill latency: 0.05405615398194641 sec
Decode latency: 2.370730211958289 sec
Prefill latency: 0.05408667400479317 sec
Decode latency: 2.3705036609899253 sec
Prefill latency: 0.05408593395259231 sec
Decode latency: 2.370177568984218 sec
Prefill latency: 0.05404373595956713 sec
Decode latency: 2.3711503139929846 sec
Time for inference 1: 2.43 sec total, 422.08 tokens/sec
Decode latency: 2.37 sec
Prefill latency: 0.05 sec
Bandwidth achieved: 1019.76 GB/s
FLOPS achieved: 5.10 TF/s

Prefill latency: 0.05407229997217655 sec
Decode latency: 2.36957043397706 sec
Time for inference 2: 2.42 sec total, 422.36 tokens/sec
Decode latency: 2.37 sec
Prefill latency: 0.05 sec
Bandwidth achieved: 1020.45 GB/s
FLOPS achieved: 5.10 TF/s

Prefill latency: 0.05406018497887999 sec
Decode latency: 2.366705760010518 sec
Time for inference 3: 2.42 sec total, 422.88 tokens/sec
Decode latency: 2.37 sec
Prefill latency: 0.05 sec
Bandwidth achieved: 1021.70 GB/s
FLOPS achieved: 5.11 TF/s

Prefill latency: 0.05391512205824256 sec
Decode latency: 2.3649977130116895 sec
Time for inference 4: 2.42 sec total, 423.21 tokens/sec
Decode latency: 2.36 sec
Prefill latency: 0.05 sec
Bandwidth achieved: 1022.49 GB/s
FLOPS achieved: 5.11 TF/s

Prefill latency: 0.054011994041502476 sec
Decode latency: 2.307078654062934 sec
Time for inference 5: 2.36 sec total, 433.57 tokens/sec
Decode latency: 2.31 sec
Prefill latency: 0.05 sec
Bandwidth achieved: 1047.53 GB/s
FLOPS achieved: 5.24 TF/s

Prefill latency: 0.05392867897171527 sec
Decode latency: 2.36596162407659 sec
Time for inference 6: 2.42 sec total, 423.04 tokens/sec
Decode latency: 2.37 sec
Prefill latency: 0.05 sec
Bandwidth achieved: 1022.09 GB/s
FLOPS achieved: 5.11 TF/s

Prefill latency: 0.05390364199411124 sec
Decode latency: 2.3653911099536344 sec
Time for inference 7: 2.42 sec total, 423.15 tokens/sec
Decode latency: 2.37 sec
Prefill latency: 0.05 sec
Bandwidth achieved: 1022.34 GB/s
FLOPS achieved: 5.11 TF/s

Prefill latency: 0.05397420993540436 sec
Decode latency: 2.2971222539199516 sec
Time for inference 8: 2.35 sec total, 435.42 tokens/sec
Decode latency: 2.30 sec
Prefill latency: 0.05 sec
Bandwidth achieved: 1051.99 GB/s
FLOPS achieved: 5.26 TF/s

Prefill latency: 0.053947148961015046 sec
Decode latency: 2.3664180210325867 sec
Time for inference 9: 2.42 sec total, 422.96 tokens/sec
Decode latency: 2.37 sec
Prefill latency: 0.05 sec
Bandwidth achieved: 1021.89 GB/s
FLOPS achieved: 5.11 TF/s

Prefill latency: 0.053899482009001076 sec
Decode latency: 2.366523882956244 sec
Time for inference 10: 2.42 sec total, 422.96 tokens/sec
Decode latency: 2.37 sec
Prefill latency: 0.05 sec
Bandwidth achieved: 1021.88 GB/s
FLOPS achieved: 5.11 TF/s

==========
Batch Size: 4
Prompt Length: 1024
Generated tokens: 256
Average decode latency: 2.3541 sec
Average prefill latency: 0.0540 sec
Average tokens/sec: 425.16
Memory used: 5.46 GB
Done. we are killing the process
