W1001 03:56:55.472000 22859458885440 torch/distributed/run.py:779] 
W1001 03:56:55.472000 22859458885440 torch/distributed/run.py:779] *****************************************
W1001 03:56:55.472000 22859458885440 torch/distributed/run.py:779] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W1001 03:56:55.472000 22859458885440 torch/distributed/run.py:779] *****************************************
flash_kv_decode is set to True
Using device=cuda
Loading model ...
GPTParallel(
  (tok_embeddings): Embedding(49152, 1536)
  (layers): ModuleList(
    (0-39): 40 x ParallelTransformerBlock(
      semi_compiled = False
      (attention): FuseAttentionMLP(
        (wqkv1): Linear(in_features=1536, out_features=6400, bias=False)
        (wo): Linear(in_features=768, out_features=1536, bias=False)
        (w2): Linear(in_features=2048, out_features=1536, bias=False)
      )
      (attention_norm): RMSNorm()
    )
  )
  (norm): RMSNorm()
  (output): Linear(in_features=1536, out_features=49152, bias=False)
)
Time to load model: 0.94 seconds
Prefill latency: 0.2676306840730831 sec
Decode latency: 2.8519442710094154 sec
Compilation time: 3.15 seconds
Compilation time: 3.12 seconds
Prefill latency: 0.2517923819832504 sec
Decode latency: 2.8491658490383998 sec
Prefill latency: 0.25186054897494614 sec
Decode latency: 2.8491744910134003 sec
Prefill latency: 0.2521508929785341 sec
Decode latency: 2.850186006980948 sec
Prefill latency: 0.25160806509666145 sec
Decode latency: 2.8487869480159134 sec
Prefill latency: 0.25260220596101135 sec
Decode latency: 2.8507938090479 sec
Time for inference 1: 3.10 sec total, 1319.48 tokens/sec
Decode latency: 2.85 sec
Prefill latency: 0.25 sec
Bandwidth achieved: 1693.67 GB/s
FLOPS achieved: 8.47 TF/s

Prefill latency: 0.2516598179936409 sec
Decode latency: 2.8508629109710455 sec
Time for inference 2: 3.10 sec total, 1319.82 tokens/sec
Decode latency: 2.85 sec
Prefill latency: 0.25 sec
Bandwidth achieved: 1694.10 GB/s
FLOPS achieved: 8.47 TF/s

Prefill latency: 0.25259269995149225 sec
Decode latency: 2.8495372419711202 sec
Time for inference 3: 3.10 sec total, 1320.03 tokens/sec
Decode latency: 2.85 sec
Prefill latency: 0.25 sec
Bandwidth achieved: 1694.37 GB/s
FLOPS achieved: 8.47 TF/s

Prefill latency: 0.2516731909709051 sec
Decode latency: 2.8505581739591435 sec
Time for inference 4: 3.10 sec total, 1320.00 tokens/sec
Decode latency: 2.85 sec
Prefill latency: 0.25 sec
Bandwidth achieved: 1694.33 GB/s
FLOPS achieved: 8.47 TF/s

Prefill latency: 0.252430040971376 sec
Decode latency: 2.8507974130334333 sec
Time for inference 5: 3.10 sec total, 1319.59 tokens/sec
Decode latency: 2.85 sec
Prefill latency: 0.25 sec
Bandwidth achieved: 1693.80 GB/s
FLOPS achieved: 8.47 TF/s

Prefill latency: 0.25170478597283363 sec
Decode latency: 2.8495630100369453 sec
Time for inference 6: 3.10 sec total, 1320.43 tokens/sec
Decode latency: 2.85 sec
Prefill latency: 0.25 sec
Bandwidth achieved: 1694.88 GB/s
FLOPS achieved: 8.47 TF/s

Prefill latency: 0.25209177006036043 sec
Decode latency: 2.8521279039559886 sec
Time for inference 7: 3.10 sec total, 1319.18 tokens/sec
Decode latency: 2.85 sec
Prefill latency: 0.25 sec
Bandwidth achieved: 1693.28 GB/s
FLOPS achieved: 8.47 TF/s

Prefill latency: 0.25202157197054476 sec
Decode latency: 2.8460818510502577 sec
Time for inference 8: 3.10 sec total, 1321.77 tokens/sec
Decode latency: 2.85 sec
Prefill latency: 0.25 sec
Bandwidth achieved: 1696.61 GB/s
FLOPS achieved: 8.48 TF/s

Prefill latency: 0.25183424400165677 sec
Decode latency: 2.8473954260116443 sec
Time for inference 9: 3.10 sec total, 1321.33 tokens/sec
Decode latency: 2.85 sec
Prefill latency: 0.25 sec
Bandwidth achieved: 1696.03 GB/s
FLOPS achieved: 8.48 TF/s

Prefill latency: 0.252158552990295 sec
Decode latency: 2.847990044974722 sec
Time for inference 10: 3.10 sec total, 1320.82 tokens/sec
Decode latency: 2.85 sec
Prefill latency: 0.25 sec
Bandwidth achieved: 1695.39 GB/s
FLOPS achieved: 8.48 TF/s

==========
Batch Size: 16
Prompt Length: 1024
Generated tokens: 256
Average decode latency: 2.8496 sec
Average prefill latency: 0.2521 sec
Average tokens/sec: 1320.25
Memory used: 9.15 GB
Done. we are killing the process
