W0930 20:49:55.932000 22908634007360 torch/distributed/run.py:779] 
W0930 20:49:55.932000 22908634007360 torch/distributed/run.py:779] *****************************************
W0930 20:49:55.932000 22908634007360 torch/distributed/run.py:779] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W0930 20:49:55.932000 22908634007360 torch/distributed/run.py:779] *****************************************
flash_kv_decode is set to True
Using device=cuda
Loading model ...
GPTParallel(
  (tok_embeddings): Embedding(49152, 1536)
  (layers): ModuleList(
    (0-39): 40 x ParallelTransformerBlock(
      semi_compiled = False
      (attention): FuseAttentionMLP(
        (wqkv1): Linear(in_features=1536, out_features=2688, bias=False)
        (wo): Linear(in_features=384, out_features=1536, bias=False)
        (w2): Linear(in_features=1024, out_features=1536, bias=False)
      )
      (attention_norm): RMSNorm()
    )
  )
  (norm): RMSNorm()
  (output): Linear(in_features=1536, out_features=49152, bias=False)
)
Time to load model: 1.03 seconds
Prefill latency: 0.04494310694281012 sec
Decode latency: 2.3152853740612045 sec
Compilation time: 2.40 seconds
Compilation time: 2.40 seconds
Compilation time: 2.35 seconds
Compilation time: 2.36 seconds
Prefill latency: 0.037143690045922995 sec
Decode latency: 2.313628313015215 sec
Prefill latency: 0.037198628997430205 sec
Decode latency: 2.3156030509853736 sec
Prefill latency: 0.03729649796150625 sec
Decode latency: 2.3144601550884545 sec
Prefill latency: 0.03732014598790556 sec
Decode latency: 2.316975818015635 sec
Prefill latency: 0.037337447982281446 sec
Decode latency: 2.3190593539038673 sec
Time for inference 1: 2.36 sec total, 868.76 tokens/sec
Decode latency: 2.32 sec
Prefill latency: 0.04 sec
Bandwidth achieved: 568.55 GB/s
FLOPS achieved: 2.84 TF/s

Prefill latency: 0.037157522048801184 sec
Decode latency: 2.3149280439829454 sec
Time for inference 2: 2.35 sec total, 870.38 tokens/sec
Decode latency: 2.31 sec
Prefill latency: 0.04 sec
Bandwidth achieved: 569.61 GB/s
FLOPS achieved: 2.85 TF/s

Prefill latency: 0.03714830207172781 sec
Decode latency: 2.314509649993852 sec
Time for inference 3: 2.35 sec total, 870.58 tokens/sec
Decode latency: 2.31 sec
Prefill latency: 0.04 sec
Bandwidth achieved: 569.74 GB/s
FLOPS achieved: 2.85 TF/s

Prefill latency: 0.03728655900340527 sec
Decode latency: 2.3121575540862978 sec
Time for inference 4: 2.35 sec total, 871.41 tokens/sec
Decode latency: 2.31 sec
Prefill latency: 0.04 sec
Bandwidth achieved: 570.28 GB/s
FLOPS achieved: 2.85 TF/s

Prefill latency: 0.03715435601770878 sec
Decode latency: 2.3110150930006057 sec
Time for inference 5: 2.35 sec total, 871.87 tokens/sec
Decode latency: 2.31 sec
Prefill latency: 0.04 sec
Bandwidth achieved: 570.59 GB/s
FLOPS achieved: 2.85 TF/s

Prefill latency: 0.03718806791584939 sec
Decode latency: 2.3128829119959846 sec
Time for inference 6: 2.35 sec total, 871.20 tokens/sec
Decode latency: 2.31 sec
Prefill latency: 0.04 sec
Bandwidth achieved: 570.14 GB/s
FLOPS achieved: 2.85 TF/s

Prefill latency: 0.03737610497046262 sec
Decode latency: 2.3121545820031315 sec
Time for inference 7: 2.35 sec total, 871.39 tokens/sec
Decode latency: 2.31 sec
Prefill latency: 0.04 sec
Bandwidth achieved: 570.27 GB/s
FLOPS achieved: 2.85 TF/s

Prefill latency: 0.03715358697809279 sec
Decode latency: 2.3128685920964926 sec
Time for inference 8: 2.35 sec total, 871.14 tokens/sec
Decode latency: 2.31 sec
Prefill latency: 0.04 sec
Bandwidth achieved: 570.11 GB/s
FLOPS achieved: 2.85 TF/s

Prefill latency: 0.037212225957773626 sec
Decode latency: 2.3114276719279587 sec
Time for inference 9: 2.35 sec total, 871.62 tokens/sec
Decode latency: 2.31 sec
Prefill latency: 0.04 sec
Bandwidth achieved: 570.42 GB/s
FLOPS achieved: 2.85 TF/s

Prefill latency: 0.03713330894242972 sec
Decode latency: 2.3105069290613756 sec
Time for inference 10: 2.35 sec total, 872.03 tokens/sec
Decode latency: 2.31 sec
Prefill latency: 0.04 sec
Bandwidth achieved: 570.69 GB/s
FLOPS achieved: 2.85 TF/s

==========
Batch Size: 8
Prompt Length: 1024
Generated tokens: 256
Average decode latency: 2.3132 sec
Average prefill latency: 0.0372 sec
Average tokens/sec: 871.04
Memory used: 3.20 GB
Done. we are killing the process
