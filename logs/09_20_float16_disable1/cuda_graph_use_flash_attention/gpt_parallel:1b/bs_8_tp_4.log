W1001 03:54:10.609000 23173792499520 torch/distributed/run.py:779] 
W1001 03:54:10.609000 23173792499520 torch/distributed/run.py:779] *****************************************
W1001 03:54:10.609000 23173792499520 torch/distributed/run.py:779] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W1001 03:54:10.609000 23173792499520 torch/distributed/run.py:779] *****************************************
flash_kv_decode is set to True
Using device=cuda
Loading model ...
GPTParallel(
  (tok_embeddings): Embedding(49152, 1536)
  (layers): ModuleList(
    (0-39): 40 x ParallelTransformerBlock(
      semi_compiled = False
      (attention): FuseAttentionMLP(
        (wqkv1): Linear(in_features=1536, out_features=3200, bias=False)
        (wo): Linear(in_features=384, out_features=1536, bias=False)
        (w2): Linear(in_features=1024, out_features=1536, bias=False)
      )
      (attention_norm): RMSNorm()
    )
  )
  (norm): RMSNorm()
  (output): Linear(in_features=1536, out_features=49152, bias=False)
)
Time to load model: 1.10 seconds
Prefill latency: 0.06199862400535494 sec
Decode latency: 2.3013000449864194 sec
Compilation time: 2.36 seconds
Compilation time: 2.34 seconds
Compilation time: 2.36 seconds
Compilation time: 2.37 seconds
Prefill latency: 0.039472674019634724 sec
Decode latency: 2.3004500690149143 sec
Prefill latency: 0.03956210403703153 sec
Decode latency: 2.3012047869851813 sec
Prefill latency: 0.03957698296289891 sec
Decode latency: 2.3013683930039406 sec
Prefill latency: 0.03956246399320662 sec
Decode latency: 2.3018787449691445 sec
Prefill latency: 0.03938911098521203 sec
Decode latency: 2.3004033990437165 sec
Time for inference 1: 2.34 sec total, 874.98 tokens/sec
Decode latency: 2.30 sec
Prefill latency: 0.04 sec
Bandwidth achieved: 627.67 GB/s
FLOPS achieved: 3.14 TF/s

Prefill latency: 0.03956284304149449 sec
Decode latency: 2.301438527996652 sec
Time for inference 2: 2.34 sec total, 874.56 tokens/sec
Decode latency: 2.30 sec
Prefill latency: 0.04 sec
Bandwidth achieved: 627.37 GB/s
FLOPS achieved: 3.14 TF/s

Prefill latency: 0.03953203896526247 sec
Decode latency: 2.3019917180063203 sec
Time for inference 3: 2.34 sec total, 874.28 tokens/sec
Decode latency: 2.30 sec
Prefill latency: 0.04 sec
Bandwidth achieved: 627.17 GB/s
FLOPS achieved: 3.14 TF/s

Prefill latency: 0.03945553593803197 sec
Decode latency: 2.301175507949665 sec
Time for inference 4: 2.34 sec total, 874.71 tokens/sec
Decode latency: 2.30 sec
Prefill latency: 0.04 sec
Bandwidth achieved: 627.47 GB/s
FLOPS achieved: 3.14 TF/s

Prefill latency: 0.03964830201584846 sec
Decode latency: 2.3018279740354046 sec
Time for inference 5: 2.34 sec total, 874.36 tokens/sec
Decode latency: 2.30 sec
Prefill latency: 0.04 sec
Bandwidth achieved: 627.22 GB/s
FLOPS achieved: 3.14 TF/s

Prefill latency: 0.039526069071143866 sec
Decode latency: 2.300911713973619 sec
Time for inference 6: 2.34 sec total, 874.77 tokens/sec
Decode latency: 2.30 sec
Prefill latency: 0.04 sec
Bandwidth achieved: 627.52 GB/s
FLOPS achieved: 3.14 TF/s

Prefill latency: 0.039476052043028176 sec
Decode latency: 2.302121954970062 sec
Time for inference 7: 2.34 sec total, 874.24 tokens/sec
Decode latency: 2.30 sec
Prefill latency: 0.04 sec
Bandwidth achieved: 627.14 GB/s
FLOPS achieved: 3.14 TF/s

Prefill latency: 0.03951974702067673 sec
Decode latency: 2.3010174819501117 sec
Time for inference 8: 2.34 sec total, 874.68 tokens/sec
Decode latency: 2.30 sec
Prefill latency: 0.04 sec
Bandwidth achieved: 627.45 GB/s
FLOPS achieved: 3.14 TF/s

Prefill latency: 0.03952161502093077 sec
Decode latency: 2.2982561649987474 sec
Time for inference 9: 2.34 sec total, 875.74 tokens/sec
Decode latency: 2.30 sec
Prefill latency: 0.04 sec
Bandwidth achieved: 628.21 GB/s
FLOPS achieved: 3.14 TF/s

Prefill latency: 0.03954809403512627 sec
Decode latency: 2.298857726971619 sec
Time for inference 10: 2.34 sec total, 875.51 tokens/sec
Decode latency: 2.30 sec
Prefill latency: 0.04 sec
Bandwidth achieved: 628.05 GB/s
FLOPS achieved: 3.14 TF/s

==========
Batch Size: 8
Prompt Length: 1024
Generated tokens: 256
Average decode latency: 2.3008 sec
Average prefill latency: 0.0395 sec
Average tokens/sec: 874.78
Memory used: 3.90 GB
Done. we are killing the process
