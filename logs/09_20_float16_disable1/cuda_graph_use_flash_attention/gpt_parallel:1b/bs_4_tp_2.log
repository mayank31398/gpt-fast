W1001 03:50:12.703000 23438135072576 torch/distributed/run.py:779] 
W1001 03:50:12.703000 23438135072576 torch/distributed/run.py:779] *****************************************
W1001 03:50:12.703000 23438135072576 torch/distributed/run.py:779] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W1001 03:50:12.703000 23438135072576 torch/distributed/run.py:779] *****************************************
flash_kv_decode is set to True
Using device=cuda
Loading model ...
GPTParallel(
  (tok_embeddings): Embedding(49152, 1536)
  (layers): ModuleList(
    (0-39): 40 x ParallelTransformerBlock(
      semi_compiled = False
      (attention): FuseAttentionMLP(
        (wqkv1): Linear(in_features=1536, out_features=6400, bias=False)
        (wo): Linear(in_features=768, out_features=1536, bias=False)
        (w2): Linear(in_features=2048, out_features=1536, bias=False)
      )
      (attention_norm): RMSNorm()
    )
  )
  (norm): RMSNorm()
  (output): Linear(in_features=1536, out_features=49152, bias=False)
)
Time to load model: 0.87 seconds
Prefill latency: 0.07255044498015195 sec
Decode latency: 2.228858234011568 sec
Compilation time: 2.30 seconds
Compilation time: 2.30 seconds
Prefill latency: 0.06709166395012289 sec
Decode latency: 2.228606609045528 sec
Prefill latency: 0.06725579593330622 sec
Decode latency: 2.2308280690340325 sec
Prefill latency: 0.06724284496158361 sec
Decode latency: 2.229589155060239 sec
Prefill latency: 0.06715746002737433 sec
Decode latency: 2.2291954190004617 sec
Prefill latency: 0.06741950404830277 sec
Decode latency: 2.2255264499690384 sec
Time for inference 1: 2.29 sec total, 446.45 tokens/sec
Decode latency: 2.23 sec
Prefill latency: 0.07 sec
Bandwidth achieved: 573.05 GB/s
FLOPS achieved: 2.87 TF/s

Prefill latency: 0.06717304105404764 sec
Decode latency: 2.2251774000469595 sec
Time for inference 2: 2.29 sec total, 446.58 tokens/sec
Decode latency: 2.23 sec
Prefill latency: 0.07 sec
Bandwidth achieved: 573.23 GB/s
FLOPS achieved: 2.87 TF/s

Prefill latency: 0.06732626399025321 sec
Decode latency: 2.224909516982734 sec
Time for inference 3: 2.29 sec total, 446.60 tokens/sec
Decode latency: 2.22 sec
Prefill latency: 0.07 sec
Bandwidth achieved: 573.25 GB/s
FLOPS achieved: 2.87 TF/s

Prefill latency: 0.06709265406243503 sec
Decode latency: 2.22596091509331 sec
Time for inference 4: 2.29 sec total, 446.44 tokens/sec
Decode latency: 2.23 sec
Prefill latency: 0.07 sec
Bandwidth achieved: 573.04 GB/s
FLOPS achieved: 2.87 TF/s

Prefill latency: 0.06723563210107386 sec
Decode latency: 2.226103496970609 sec
Time for inference 5: 2.29 sec total, 446.36 tokens/sec
Decode latency: 2.23 sec
Prefill latency: 0.07 sec
Bandwidth achieved: 572.94 GB/s
FLOPS achieved: 2.86 TF/s

Prefill latency: 0.06724437209777534 sec
Decode latency: 2.2258345030713826 sec
Time for inference 6: 2.29 sec total, 446.43 tokens/sec
Decode latency: 2.23 sec
Prefill latency: 0.07 sec
Bandwidth achieved: 573.04 GB/s
FLOPS achieved: 2.87 TF/s

Prefill latency: 0.06697375106159598 sec
Decode latency: 2.2254115730756894 sec
Time for inference 7: 2.29 sec total, 446.56 tokens/sec
Decode latency: 2.23 sec
Prefill latency: 0.07 sec
Bandwidth achieved: 573.20 GB/s
FLOPS achieved: 2.87 TF/s

Prefill latency: 0.06747806305065751 sec
Decode latency: 2.225836045923643 sec
Time for inference 8: 2.29 sec total, 446.36 tokens/sec
Decode latency: 2.23 sec
Prefill latency: 0.07 sec
Bandwidth achieved: 572.94 GB/s
FLOPS achieved: 2.86 TF/s

Prefill latency: 0.06720502197276801 sec
Decode latency: 2.2262274379609153 sec
Time for inference 9: 2.29 sec total, 446.34 tokens/sec
Decode latency: 2.23 sec
Prefill latency: 0.07 sec
Bandwidth achieved: 572.91 GB/s
FLOPS achieved: 2.86 TF/s

Prefill latency: 0.06717127410229295 sec
Decode latency: 2.2258789690677077 sec
Time for inference 10: 2.29 sec total, 446.42 tokens/sec
Decode latency: 2.23 sec
Prefill latency: 0.07 sec
Bandwidth achieved: 573.01 GB/s
FLOPS achieved: 2.87 TF/s

==========
Batch Size: 4
Prompt Length: 1024
Generated tokens: 256
Average decode latency: 2.2257 sec
Average prefill latency: 0.0672 sec
Average tokens/sec: 446.45
Memory used: 3.71 GB
Done. we are killing the process
