W1001 03:50:56.209000 22370474469184 torch/distributed/run.py:779] 
W1001 03:50:56.209000 22370474469184 torch/distributed/run.py:779] *****************************************
W1001 03:50:56.209000 22370474469184 torch/distributed/run.py:779] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W1001 03:50:56.209000 22370474469184 torch/distributed/run.py:779] *****************************************
flash_kv_decode is set to True
Using device=cuda
Loading model ...
GPTParallel(
  (tok_embeddings): Embedding(49152, 1536)
  (layers): ModuleList(
    (0-39): 40 x ParallelTransformerBlock(
      semi_compiled = False
      (attention): FuseAttentionMLP(
        (wqkv1): Linear(in_features=1536, out_features=3200, bias=False)
        (wo): Linear(in_features=384, out_features=1536, bias=False)
        (w2): Linear(in_features=1024, out_features=1536, bias=False)
      )
      (attention_norm): RMSNorm()
    )
  )
  (norm): RMSNorm()
  (output): Linear(in_features=1536, out_features=49152, bias=False)
)
Time to load model: 1.16 seconds
Prefill latency: 0.023026574053801596 sec
Decode latency: 2.146265415009111 sec
Compilation time: 2.19 seconds
Compilation time: 2.26 seconds
Compilation time: 2.18 seconds
Compilation time: 2.17 seconds
Prefill latency: 0.022796937031671405 sec
Decode latency: 2.1424725789111108 sec
Prefill latency: 0.022878870950080454 sec
Decode latency: 2.1454593060771003 sec
Prefill latency: 0.0227938269963488 sec
Decode latency: 2.143187995068729 sec
Prefill latency: 0.022700797067955136 sec
Decode latency: 2.14287418697495 sec
Prefill latency: 0.022776852012611926 sec
Decode latency: 2.1439630850218236 sec
Time for inference 1: 2.17 sec total, 472.40 tokens/sec
Decode latency: 2.14 sec
Prefill latency: 0.02 sec
Bandwidth achieved: 338.88 GB/s
FLOPS achieved: 1.69 TF/s

Prefill latency: 0.022763481945730746 sec
Decode latency: 2.1486988799879327 sec
Time for inference 2: 2.17 sec total, 471.32 tokens/sec
Decode latency: 2.15 sec
Prefill latency: 0.02 sec
Bandwidth achieved: 338.11 GB/s
FLOPS achieved: 1.69 TF/s

Prefill latency: 0.022745662019588053 sec
Decode latency: 2.1491958210244775 sec
Time for inference 3: 2.17 sec total, 471.28 tokens/sec
Decode latency: 2.15 sec
Prefill latency: 0.02 sec
Bandwidth achieved: 338.07 GB/s
FLOPS achieved: 1.69 TF/s

Prefill latency: 0.022859825985506177 sec
Decode latency: 2.1489599919877946 sec
Time for inference 4: 2.17 sec total, 471.33 tokens/sec
Decode latency: 2.15 sec
Prefill latency: 0.02 sec
Bandwidth achieved: 338.11 GB/s
FLOPS achieved: 1.69 TF/s

Prefill latency: 0.022850277950055897 sec
Decode latency: 2.1472796270390972 sec
Time for inference 5: 2.17 sec total, 471.70 tokens/sec
Decode latency: 2.15 sec
Prefill latency: 0.02 sec
Bandwidth achieved: 338.38 GB/s
FLOPS achieved: 1.69 TF/s

Prefill latency: 0.02281736209988594 sec
Decode latency: 2.149073862005025 sec
Time for inference 6: 2.17 sec total, 471.33 tokens/sec
Decode latency: 2.15 sec
Prefill latency: 0.02 sec
Bandwidth achieved: 338.11 GB/s
FLOPS achieved: 1.69 TF/s

Prefill latency: 0.02281838608905673 sec
Decode latency: 2.149022121098824 sec
Time for inference 7: 2.17 sec total, 471.31 tokens/sec
Decode latency: 2.15 sec
Prefill latency: 0.02 sec
Bandwidth achieved: 338.10 GB/s
FLOPS achieved: 1.69 TF/s

Prefill latency: 0.02279991703107953 sec
Decode latency: 2.1478907980490476 sec
Time for inference 8: 2.17 sec total, 471.55 tokens/sec
Decode latency: 2.15 sec
Prefill latency: 0.02 sec
Bandwidth achieved: 338.27 GB/s
FLOPS achieved: 1.69 TF/s

Prefill latency: 0.02270609699189663 sec
Decode latency: 2.1475149400066584 sec
Time for inference 9: 2.17 sec total, 471.65 tokens/sec
Decode latency: 2.15 sec
Prefill latency: 0.02 sec
Bandwidth achieved: 338.34 GB/s
FLOPS achieved: 1.69 TF/s

Prefill latency: 0.022777482983656228 sec
Decode latency: 2.1458672180306166 sec
Time for inference 10: 2.17 sec total, 472.00 tokens/sec
Decode latency: 2.15 sec
Prefill latency: 0.02 sec
Bandwidth achieved: 338.59 GB/s
FLOPS achieved: 1.69 TF/s

==========
Batch Size: 4
Prompt Length: 1024
Generated tokens: 256
Average decode latency: 2.1477 sec
Average prefill latency: 0.0228 sec
Average tokens/sec: 471.59
Memory used: 2.38 GB
Done. we are killing the process
