W0930 20:47:20.526000 22651516409664 torch/distributed/run.py:779] 
W0930 20:47:20.526000 22651516409664 torch/distributed/run.py:779] *****************************************
W0930 20:47:20.526000 22651516409664 torch/distributed/run.py:779] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W0930 20:47:20.526000 22651516409664 torch/distributed/run.py:779] *****************************************
flash_kv_decode is set to True
Using device=cuda
Loading model ...
GPTParallel(
  (tok_embeddings): Embedding(49152, 1536)
  (layers): ModuleList(
    (0-39): 40 x ParallelTransformerBlock(
      semi_compiled = False
      (attention): FuseAttentionMLP(
        (wqkv1): Linear(in_features=1536, out_features=1344, bias=False)
        (wo): Linear(in_features=192, out_features=1536, bias=False)
        (w2): Linear(in_features=512, out_features=1536, bias=False)
      )
      (attention_norm): RMSNorm()
    )
  )
  (norm): RMSNorm()
  (output): Linear(in_features=1536, out_features=49152, bias=False)
)
Time to load model: 1.14 seconds
Prefill latency: 0.03815973398741335 sec
Decode latency: 2.195951561909169 sec
Compilation time: 2.25 seconds
Compilation time: 2.25 seconds
Compilation time: 2.23 seconds
Compilation time: 2.22 seconds
Compilation time: 2.24 seconds
Compilation time: 2.24 seconds
Compilation time: 2.24 seconds
Compilation time: 2.26 seconds
Prefill latency: 0.020857512950897217 sec
Decode latency: 2.199534852989018 sec
Prefill latency: 0.022518925019539893 sec
Decode latency: 2.192348020034842 sec
Prefill latency: 0.02054247190244496 sec
Decode latency: 2.1948805410647765 sec
Prefill latency: 0.020568728912621737 sec
Decode latency: 2.198664981056936 sec
Prefill latency: 0.020510739996097982 sec
Decode latency: 2.1989813790423796 sec
Time for inference 1: 2.22 sec total, 461.12 tokens/sec
Decode latency: 2.20 sec
Prefill latency: 0.02 sec
Bandwidth achieved: 185.73 GB/s
FLOPS achieved: 0.93 TF/s

Prefill latency: 0.020564284990541637 sec
Decode latency: 2.1904528229497373 sec
Time for inference 2: 2.21 sec total, 462.92 tokens/sec
Decode latency: 2.19 sec
Prefill latency: 0.02 sec
Bandwidth achieved: 186.45 GB/s
FLOPS achieved: 0.93 TF/s

Prefill latency: 0.020683874958194792 sec
Decode latency: 2.185062634991482 sec
Time for inference 3: 2.21 sec total, 464.09 tokens/sec
Decode latency: 2.19 sec
Prefill latency: 0.02 sec
Bandwidth achieved: 186.93 GB/s
FLOPS achieved: 0.93 TF/s

Prefill latency: 0.020516777061857283 sec
Decode latency: 2.190717510995455 sec
Time for inference 4: 2.21 sec total, 462.90 tokens/sec
Decode latency: 2.19 sec
Prefill latency: 0.02 sec
Bandwidth achieved: 186.45 GB/s
FLOPS achieved: 0.93 TF/s

Prefill latency: 0.02062999503687024 sec
Decode latency: 2.1908847199520096 sec
Time for inference 5: 2.21 sec total, 462.81 tokens/sec
Decode latency: 2.19 sec
Prefill latency: 0.02 sec
Bandwidth achieved: 186.41 GB/s
FLOPS achieved: 0.93 TF/s

Prefill latency: 0.02054200100246817 sec
Decode latency: 2.1805086289532483 sec
Time for inference 6: 2.20 sec total, 465.03 tokens/sec
Decode latency: 2.18 sec
Prefill latency: 0.02 sec
Bandwidth achieved: 187.30 GB/s
FLOPS achieved: 0.94 TF/s

Prefill latency: 0.020629873033612967 sec
Decode latency: 2.2048264120239764 sec
Time for inference 7: 2.23 sec total, 459.95 tokens/sec
Decode latency: 2.20 sec
Prefill latency: 0.02 sec
Bandwidth achieved: 185.26 GB/s
FLOPS achieved: 0.93 TF/s

Prefill latency: 0.020749454968608916 sec
Decode latency: 2.185551912058145 sec
Time for inference 8: 2.21 sec total, 463.92 tokens/sec
Decode latency: 2.19 sec
Prefill latency: 0.02 sec
Bandwidth achieved: 186.86 GB/s
FLOPS achieved: 0.93 TF/s

Prefill latency: 0.022350031067617238 sec
Decode latency: 2.196419875952415 sec
Time for inference 9: 2.22 sec total, 461.34 tokens/sec
Decode latency: 2.20 sec
Prefill latency: 0.02 sec
Bandwidth achieved: 185.82 GB/s
FLOPS achieved: 0.93 TF/s

Prefill latency: 0.020576476003043354 sec
Decode latency: 2.195155235938728 sec
Time for inference 10: 2.22 sec total, 461.97 tokens/sec
Decode latency: 2.20 sec
Prefill latency: 0.02 sec
Bandwidth achieved: 186.07 GB/s
FLOPS achieved: 0.93 TF/s

==========
Batch Size: 4
Prompt Length: 1024
Generated tokens: 256
Average decode latency: 2.1919 sec
Average prefill latency: 0.0208 sec
Average tokens/sec: 462.61
Memory used: 1.77 GB
Done. we are killing the process
