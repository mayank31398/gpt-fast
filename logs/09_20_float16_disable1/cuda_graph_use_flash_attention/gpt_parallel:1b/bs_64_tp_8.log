W1001 04:05:23.901000 23168088704832 torch/distributed/run.py:779] 
W1001 04:05:23.901000 23168088704832 torch/distributed/run.py:779] *****************************************
W1001 04:05:23.901000 23168088704832 torch/distributed/run.py:779] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W1001 04:05:23.901000 23168088704832 torch/distributed/run.py:779] *****************************************
flash_kv_decode is set to True
Using device=cuda
Loading model ...
GPTParallel(
  (tok_embeddings): Embedding(49152, 1536)
  (layers): ModuleList(
    (0-39): 40 x ParallelTransformerBlock(
      semi_compiled = False
      (attention): FuseAttentionMLP(
        (wqkv1): Linear(in_features=1536, out_features=1600, bias=False)
        (wo): Linear(in_features=192, out_features=1536, bias=False)
        (w2): Linear(in_features=512, out_features=1536, bias=False)
      )
      (attention_norm): RMSNorm()
    )
  )
  (norm): RMSNorm()
  (output): Linear(in_features=1536, out_features=49152, bias=False)
)
Time to load model: 1.20 seconds
Prefill latency: 0.21574281598441303 sec
Decode latency: 3.4030357589945197 sec
Compilation time: 3.61 seconds
Compilation time: 3.60 secondsCompilation time: 3.60 seconds

Compilation time: 3.62 seconds
Compilation time: 3.60 seconds
Compilation time: 3.60 seconds
Compilation time: 3.60 seconds
Compilation time: 3.60 seconds
Prefill latency: 0.18967871193308383 sec
Decode latency: 3.3956085400423035 sec
Prefill latency: 0.1894099760102108 sec
Decode latency: 3.444350289995782 sec
Prefill latency: 0.1907661829609424 sec
Decode latency: 3.3987119200173765 sec
Prefill latency: 0.19120698305778205 sec
Decode latency: 3.403543747961521 sec
Prefill latency: 0.18975183193106204 sec
Decode latency: 3.411530292010866 sec
Time for inference 1: 3.60 sec total, 4548.26 tokens/sec
Decode latency: 3.41 sec
Prefill latency: 0.19 sec
Bandwidth achieved: 1975.02 GB/s
FLOPS achieved: 9.88 TF/s

Prefill latency: 0.18990359804593027 sec
Decode latency: 3.4158492470160127 sec
Time for inference 2: 3.61 sec total, 4542.71 tokens/sec
Decode latency: 3.42 sec
Prefill latency: 0.19 sec
Bandwidth achieved: 1972.61 GB/s
FLOPS achieved: 9.86 TF/s

Prefill latency: 0.18995934806298465 sec
Decode latency: 3.406408449052833 sec
Time for inference 3: 3.60 sec total, 4554.53 tokens/sec
Decode latency: 3.41 sec
Prefill latency: 0.19 sec
Bandwidth achieved: 1977.74 GB/s
FLOPS achieved: 9.89 TF/s

Prefill latency: 0.1901776830200106 sec
Decode latency: 3.413194015971385 sec
Time for inference 4: 3.60 sec total, 4545.64 tokens/sec
Decode latency: 3.41 sec
Prefill latency: 0.19 sec
Bandwidth achieved: 1973.88 GB/s
FLOPS achieved: 9.87 TF/s

Prefill latency: 0.19115924392826855 sec
Decode latency: 3.410662360023707 sec
Time for inference 5: 3.60 sec total, 4547.42 tokens/sec
Decode latency: 3.41 sec
Prefill latency: 0.19 sec
Bandwidth achieved: 1974.66 GB/s
FLOPS achieved: 9.87 TF/s

Prefill latency: 0.189480522996746 sec
Decode latency: 3.42443919100333 sec
Time for inference 6: 3.61 sec total, 4532.27 tokens/sec
Decode latency: 3.42 sec
Prefill latency: 0.19 sec
Bandwidth achieved: 1968.08 GB/s
FLOPS achieved: 9.84 TF/s

Prefill latency: 0.18944870692212135 sec
Decode latency: 3.405786465969868 sec
Time for inference 7: 3.60 sec total, 4555.79 tokens/sec
Decode latency: 3.41 sec
Prefill latency: 0.19 sec
Bandwidth achieved: 1978.29 GB/s
FLOPS achieved: 9.89 TF/s

Prefill latency: 0.19054314505774528 sec
Decode latency: 3.4264009959297255 sec
Time for inference 8: 3.62 sec total, 4528.78 tokens/sec
Decode latency: 3.43 sec
Prefill latency: 0.19 sec
Bandwidth achieved: 1966.56 GB/s
FLOPS achieved: 9.83 TF/s

Prefill latency: 0.19011440104804933 sec
Decode latency: 3.413478162023239 sec
Time for inference 9: 3.60 sec total, 4545.44 tokens/sec
Decode latency: 3.41 sec
Prefill latency: 0.19 sec
Bandwidth achieved: 1973.80 GB/s
FLOPS achieved: 9.87 TF/s

Prefill latency: 0.19136605598032475 sec
Decode latency: 3.4025111119262874 sec
Time for inference 10: 3.59 sec total, 4557.75 tokens/sec
Decode latency: 3.40 sec
Prefill latency: 0.19 sec
Bandwidth achieved: 1979.14 GB/s
FLOPS achieved: 9.90 TF/s

==========
Batch Size: 64
Prompt Length: 1024
Generated tokens: 256
Average decode latency: 3.4130 sec
Average prefill latency: 0.1902 sec
Average tokens/sec: 4545.86
Memory used: 22.32 GB
Done. we are killing the process
