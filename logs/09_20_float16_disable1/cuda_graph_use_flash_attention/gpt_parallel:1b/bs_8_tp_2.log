W0930 20:49:05.924000 22489370236736 torch/distributed/run.py:779] 
W0930 20:49:05.924000 22489370236736 torch/distributed/run.py:779] *****************************************
W0930 20:49:05.924000 22489370236736 torch/distributed/run.py:779] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W0930 20:49:05.924000 22489370236736 torch/distributed/run.py:779] *****************************************
flash_kv_decode is set to True
Using device=cuda
Loading model ...
GPTParallel(
  (tok_embeddings): Embedding(49152, 1536)
  (layers): ModuleList(
    (0-39): 40 x ParallelTransformerBlock(
      semi_compiled = False
      (attention): FuseAttentionMLP(
        (wqkv1): Linear(in_features=1536, out_features=5376, bias=False)
        (wo): Linear(in_features=768, out_features=1536, bias=False)
        (w2): Linear(in_features=2048, out_features=1536, bias=False)
      )
      (attention_norm): RMSNorm()
    )
  )
  (norm): RMSNorm()
  (output): Linear(in_features=1536, out_features=49152, bias=False)
)
Time to load model: 0.87 seconds
Prefill latency: 0.14053973904810846 sec
Decode latency: 2.581087739090435 sec
Compilation time: 2.72 seconds
Compilation time: 2.71 seconds
Prefill latency: 0.11934041092172265 sec
Decode latency: 2.58132140210364 sec
Prefill latency: 0.11946572305168957 sec
Decode latency: 2.580264702090062 sec
Prefill latency: 0.11912498401943594 sec
Decode latency: 2.576573711936362 sec
Prefill latency: 0.11971419595647603 sec
Decode latency: 2.578373358002864 sec
Prefill latency: 0.11931069300044328 sec
Decode latency: 2.5781904089963064 sec
Time for inference 1: 2.70 sec total, 759.01 tokens/sec
Decode latency: 2.58 sec
Prefill latency: 0.12 sec
Bandwidth achieved: 878.75 GB/s
FLOPS achieved: 4.39 TF/s

Prefill latency: 0.11910865700338036 sec
Decode latency: 2.5808425170835108 sec
Time for inference 2: 2.70 sec total, 758.31 tokens/sec
Decode latency: 2.58 sec
Prefill latency: 0.12 sec
Bandwidth achieved: 877.94 GB/s
FLOPS achieved: 4.39 TF/s

Prefill latency: 0.11961904296185821 sec
Decode latency: 2.5808756860205904 sec
Time for inference 3: 2.70 sec total, 758.16 tokens/sec
Decode latency: 2.58 sec
Prefill latency: 0.12 sec
Bandwidth achieved: 877.76 GB/s
FLOPS achieved: 4.39 TF/s

Prefill latency: 0.11979641695506871 sec
Decode latency: 2.580931347911246 sec
Time for inference 4: 2.70 sec total, 758.13 tokens/sec
Decode latency: 2.58 sec
Prefill latency: 0.12 sec
Bandwidth achieved: 877.73 GB/s
FLOPS achieved: 4.39 TF/s

Prefill latency: 0.11937741993460804 sec
Decode latency: 2.5775862120790407 sec
Time for inference 5: 2.70 sec total, 759.17 tokens/sec
Decode latency: 2.58 sec
Prefill latency: 0.12 sec
Bandwidth achieved: 878.93 GB/s
FLOPS achieved: 4.39 TF/s

Prefill latency: 0.11964086897205561 sec
Decode latency: 2.580776149057783 sec
Time for inference 6: 2.70 sec total, 758.19 tokens/sec
Decode latency: 2.58 sec
Prefill latency: 0.12 sec
Bandwidth achieved: 877.80 GB/s
FLOPS achieved: 4.39 TF/s

Prefill latency: 0.11939318000804633 sec
Decode latency: 2.580313932034187 sec
Time for inference 7: 2.70 sec total, 758.40 tokens/sec
Decode latency: 2.58 sec
Prefill latency: 0.12 sec
Bandwidth achieved: 878.04 GB/s
FLOPS achieved: 4.39 TF/s

Prefill latency: 0.11932858498767018 sec
Decode latency: 2.5791051160776988 sec
Time for inference 8: 2.70 sec total, 758.69 tokens/sec
Decode latency: 2.58 sec
Prefill latency: 0.12 sec
Bandwidth achieved: 878.37 GB/s
FLOPS achieved: 4.39 TF/s

Prefill latency: 0.11935312498826534 sec
Decode latency: 2.5766020140144974 sec
Time for inference 9: 2.70 sec total, 759.41 tokens/sec
Decode latency: 2.58 sec
Prefill latency: 0.12 sec
Bandwidth achieved: 879.21 GB/s
FLOPS achieved: 4.40 TF/s

Prefill latency: 0.11949074093718082 sec
Decode latency: 2.576527905999683 sec
Time for inference 10: 2.70 sec total, 759.36 tokens/sec
Decode latency: 2.58 sec
Prefill latency: 0.12 sec
Bandwidth achieved: 879.15 GB/s
FLOPS achieved: 4.40 TF/s

==========
Batch Size: 8
Prompt Length: 1024
Generated tokens: 256
Average decode latency: 2.5792 sec
Average prefill latency: 0.1194 sec
Average tokens/sec: 758.68
Memory used: 4.54 GB
Done. we are killing the process
