W1001 03:53:22.330000 23048940767040 torch/distributed/run.py:779] 
W1001 03:53:22.330000 23048940767040 torch/distributed/run.py:779] *****************************************
W1001 03:53:22.330000 23048940767040 torch/distributed/run.py:779] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W1001 03:53:22.330000 23048940767040 torch/distributed/run.py:779] *****************************************
flash_kv_decode is set to True
Using device=cuda
Loading model ...
GPTParallel(
  (tok_embeddings): Embedding(49152, 1536)
  (layers): ModuleList(
    (0-39): 40 x ParallelTransformerBlock(
      semi_compiled = False
      (attention): FuseAttentionMLP(
        (wqkv1): Linear(in_features=1536, out_features=6400, bias=False)
        (wo): Linear(in_features=768, out_features=1536, bias=False)
        (w2): Linear(in_features=2048, out_features=1536, bias=False)
      )
      (attention_norm): RMSNorm()
    )
  )
  (norm): RMSNorm()
  (output): Linear(in_features=1536, out_features=49152, bias=False)
)
Time to load model: 0.88 seconds
Prefill latency: 0.14242756890598685 sec
Decode latency: 2.463245049933903 sec
Compilation time: 2.60 seconds
Compilation time: 2.61 seconds
Prefill latency: 0.12720313493628055 sec
Decode latency: 2.461362779024057 sec
Prefill latency: 0.1275097100296989 sec
Decode latency: 2.4628691589459777 sec
Prefill latency: 0.1273685779888183 sec
Decode latency: 2.461899535963312 sec
Prefill latency: 0.12750965799205005 sec
Decode latency: 2.462361754034646 sec
Prefill latency: 0.1273563529830426 sec
Decode latency: 2.460681998054497 sec
Time for inference 1: 2.59 sec total, 791.08 tokens/sec
Decode latency: 2.46 sec
Prefill latency: 0.13 sec
Bandwidth achieved: 1015.42 GB/s
FLOPS achieved: 5.08 TF/s

Prefill latency: 0.12749061500653625 sec
Decode latency: 2.4632323660189286 sec
Time for inference 2: 2.59 sec total, 790.28 tokens/sec
Decode latency: 2.46 sec
Prefill latency: 0.13 sec
Bandwidth achieved: 1014.40 GB/s
FLOPS achieved: 5.07 TF/s

Prefill latency: 0.12766942498274148 sec
Decode latency: 2.46329128195066 sec
Time for inference 3: 2.59 sec total, 790.14 tokens/sec
Decode latency: 2.46 sec
Prefill latency: 0.13 sec
Bandwidth achieved: 1014.20 GB/s
FLOPS achieved: 5.07 TF/s

Prefill latency: 0.12794992397539318 sec
Decode latency: 2.4616136939730495 sec
Time for inference 4: 2.59 sec total, 790.58 tokens/sec
Decode latency: 2.46 sec
Prefill latency: 0.13 sec
Bandwidth achieved: 1014.78 GB/s
FLOPS achieved: 5.07 TF/s

Prefill latency: 0.1273908909643069 sec
Decode latency: 2.4617629640270025 sec
Time for inference 5: 2.59 sec total, 790.69 tokens/sec
Decode latency: 2.46 sec
Prefill latency: 0.13 sec
Bandwidth achieved: 1014.91 GB/s
FLOPS achieved: 5.07 TF/s

Prefill latency: 0.12792561494279653 sec
Decode latency: 2.462658958043903 sec
Time for inference 6: 2.59 sec total, 790.30 tokens/sec
Decode latency: 2.46 sec
Prefill latency: 0.13 sec
Bandwidth achieved: 1014.42 GB/s
FLOPS achieved: 5.07 TF/s

Prefill latency: 0.1272736070677638 sec
Decode latency: 2.461798014002852 sec
Time for inference 7: 2.59 sec total, 790.76 tokens/sec
Decode latency: 2.46 sec
Prefill latency: 0.13 sec
Bandwidth achieved: 1015.01 GB/s
FLOPS achieved: 5.08 TF/s

Prefill latency: 0.12752939900383353 sec
Decode latency: 2.46215180400759 sec
Time for inference 8: 2.59 sec total, 790.60 tokens/sec
Decode latency: 2.46 sec
Prefill latency: 0.13 sec
Bandwidth achieved: 1014.80 GB/s
FLOPS achieved: 5.07 TF/s

Prefill latency: 0.12739749101456255 sec
Decode latency: 2.46203135792166 sec
Time for inference 9: 2.59 sec total, 790.68 tokens/sec
Decode latency: 2.46 sec
Prefill latency: 0.13 sec
Bandwidth achieved: 1014.91 GB/s
FLOPS achieved: 5.07 TF/s

Prefill latency: 0.12748851696960628 sec
Decode latency: 2.4631918679224327 sec
Time for inference 10: 2.59 sec total, 790.25 tokens/sec
Decode latency: 2.46 sec
Prefill latency: 0.13 sec
Bandwidth achieved: 1014.35 GB/s
FLOPS achieved: 5.07 TF/s

==========
Batch Size: 8
Prompt Length: 1024
Generated tokens: 256
Average decode latency: 2.4622 sec
Average prefill latency: 0.1275 sec
Average tokens/sec: 790.54
Memory used: 5.67 GB
Done. we are killing the process
