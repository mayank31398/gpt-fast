W1001 03:07:29.313000 23133184558912 torch/distributed/run.py:779] 
W1001 03:07:29.313000 23133184558912 torch/distributed/run.py:779] *****************************************
W1001 03:07:29.313000 23133184558912 torch/distributed/run.py:779] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W1001 03:07:29.313000 23133184558912 torch/distributed/run.py:779] *****************************************
flash_kv_decode is set to True
Using device=cuda
Loading model ...
GPTDense(
  (tok_embeddings): Embedding(49152, 1536)
  (layers): ModuleList(
    (0-39): 40 x DenseTransformerBlock(
      semi_compiled = False
      (attention): Attention(
        (wqkv): Linear(in_features=1536, out_features=1152, bias=False)
        (wo): Linear(in_features=384, out_features=1536, bias=False)
      )
      (feed_forward): FeedForward(
        (w1): Linear(in_features=1536, out_features=2048, bias=False)
        (w2): Linear(in_features=1024, out_features=1536, bias=False)
      )
      (ffn_norm): RMSNorm()
      (attention_norm): RMSNorm()
    )
  )
  (norm): RMSNorm()
  (output): Linear(in_features=1536, out_features=49152, bias=False)
)
Time to load model: 0.99 seconds
Prefill latency: 0.027455365052446723 sec
Decode latency: 2.539583696052432 sec
Compilation time: 2.59 seconds
Compilation time: 2.59 seconds
Compilation time: 2.57 seconds
Compilation time: 2.59 seconds
Prefill latency: 0.027204515994526446 sec
Decode latency: 2.535430099000223 sec
Prefill latency: 0.02718010009266436 sec
Decode latency: 2.53246237791609 sec
Prefill latency: 0.02715331199578941 sec
Decode latency: 2.5373559480067343 sec
Prefill latency: 0.02710959396790713 sec
Decode latency: 2.5363206829642877 sec
Prefill latency: 0.027105182991363108 sec
Decode latency: 2.5343009430216625 sec
Time for inference 1: 2.56 sec total, 399.62 tokens/sec
Decode latency: 2.53 sec
Prefill latency: 0.03 sec
Bandwidth achieved: 286.72 GB/s
FLOPS achieved: 1.43 TF/s

Prefill latency: 0.02714315301273018 sec
Decode latency: 2.5362088090041652 sec
Time for inference 2: 2.56 sec total, 399.34 tokens/sec
Decode latency: 2.54 sec
Prefill latency: 0.03 sec
Bandwidth achieved: 286.52 GB/s
FLOPS achieved: 1.43 TF/s

Prefill latency: 0.027094783959910274 sec
Decode latency: 2.5339800699148327 sec
Time for inference 3: 2.56 sec total, 399.71 tokens/sec
Decode latency: 2.53 sec
Prefill latency: 0.03 sec
Bandwidth achieved: 286.78 GB/s
FLOPS achieved: 1.43 TF/s

Prefill latency: 0.027145568979904056 sec
Decode latency: 2.5345587560441345 sec
Time for inference 4: 2.56 sec total, 399.62 tokens/sec
Decode latency: 2.53 sec
Prefill latency: 0.03 sec
Bandwidth achieved: 286.72 GB/s
FLOPS achieved: 1.43 TF/s

Prefill latency: 0.027231361949816346 sec
Decode latency: 2.537204040098004 sec
Time for inference 5: 2.57 sec total, 399.19 tokens/sec
Decode latency: 2.54 sec
Prefill latency: 0.03 sec
Bandwidth achieved: 286.41 GB/s
FLOPS achieved: 1.43 TF/s

Prefill latency: 0.02720945794135332 sec
Decode latency: 2.5357355889864266 sec
Time for inference 6: 2.56 sec total, 399.42 tokens/sec
Decode latency: 2.54 sec
Prefill latency: 0.03 sec
Bandwidth achieved: 286.58 GB/s
FLOPS achieved: 1.43 TF/s

Prefill latency: 0.02713288099039346 sec
Decode latency: 2.536000813008286 sec
Time for inference 7: 2.56 sec total, 399.39 tokens/sec
Decode latency: 2.54 sec
Prefill latency: 0.03 sec
Bandwidth achieved: 286.56 GB/s
FLOPS achieved: 1.43 TF/s

Prefill latency: 0.027155796997249126 sec
Decode latency: 2.536404607933946 sec
Time for inference 8: 2.56 sec total, 399.33 tokens/sec
Decode latency: 2.54 sec
Prefill latency: 0.03 sec
Bandwidth achieved: 286.51 GB/s
FLOPS achieved: 1.43 TF/s

Prefill latency: 0.027175200055353343 sec
Decode latency: 2.5383633780293167 sec
Time for inference 9: 2.57 sec total, 399.03 tokens/sec
Decode latency: 2.54 sec
Prefill latency: 0.03 sec
Bandwidth achieved: 286.29 GB/s
FLOPS achieved: 1.43 TF/s

Prefill latency: 0.027236563968472183 sec
Decode latency: 2.5404575490392745 sec
Time for inference 10: 2.57 sec total, 398.69 tokens/sec
Decode latency: 2.54 sec
Prefill latency: 0.03 sec
Bandwidth achieved: 286.05 GB/s
FLOPS achieved: 1.43 TF/s

==========
Batch Size: 4
Prompt Length: 1024
Generated tokens: 256
Average decode latency: 2.5363 sec
Average prefill latency: 0.0272 sec
Average tokens/sec: 399.34
Memory used: 3.01 GB
Done. we are killing the process
