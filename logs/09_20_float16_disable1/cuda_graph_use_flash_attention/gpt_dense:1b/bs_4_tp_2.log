W0930 20:20:40.353000 22427332704064 torch/distributed/run.py:779] 
W0930 20:20:40.353000 22427332704064 torch/distributed/run.py:779] *****************************************
W0930 20:20:40.353000 22427332704064 torch/distributed/run.py:779] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W0930 20:20:40.353000 22427332704064 torch/distributed/run.py:779] *****************************************
flash_kv_decode is set to True
Using device=cuda
Loading model ...
GPTDense(
  (tok_embeddings): Embedding(49152, 1536)
  (layers): ModuleList(
    (0-39): 40 x DenseTransformerBlock(
      semi_compiled = False
      (attention): Attention(
        (wqkv): Linear(in_features=1536, out_features=1280, bias=False)
        (wo): Linear(in_features=768, out_features=1536, bias=False)
      )
      (feed_forward): FeedForward(
        (w1): Linear(in_features=1536, out_features=4096, bias=False)
        (w2): Linear(in_features=2048, out_features=1536, bias=False)
      )
      (ffn_norm): RMSNorm()
      (attention_norm): RMSNorm()
    )
  )
  (norm): RMSNorm()
  (output): Linear(in_features=1536, out_features=49152, bias=False)
)
Time to load model: 0.97 seconds
Prefill latency: 0.11045942304190248 sec
Decode latency: 2.555189628037624 sec
Compilation time: 2.67 seconds
Compilation time: 2.67 seconds
Prefill latency: 0.10180024697910994 sec
Decode latency: 2.5559975830838084 sec
Prefill latency: 0.10150743497069925 sec
Decode latency: 2.555032868986018 sec
Prefill latency: 0.10211925499606878 sec
Decode latency: 2.5554052690276876 sec
Prefill latency: 0.10119989805389196 sec
Decode latency: 2.554505206993781 sec
Prefill latency: 0.10184319608379155 sec
Decode latency: 2.556177213904448 sec
Time for inference 1: 2.66 sec total, 385.14 tokens/sec
Decode latency: 2.56 sec
Prefill latency: 0.10 sec
Bandwidth achieved: 445.95 GB/s
FLOPS achieved: 2.23 TF/s

Prefill latency: 0.10085760802030563 sec
Decode latency: 2.5539640550268814 sec
Time for inference 2: 2.66 sec total, 385.62 tokens/sec
Decode latency: 2.55 sec
Prefill latency: 0.10 sec
Bandwidth achieved: 446.50 GB/s
FLOPS achieved: 2.23 TF/s

Prefill latency: 0.10222621995490044 sec
Decode latency: 2.55359355697874 sec
Time for inference 3: 2.66 sec total, 385.45 tokens/sec
Decode latency: 2.55 sec
Prefill latency: 0.10 sec
Bandwidth achieved: 446.31 GB/s
FLOPS achieved: 2.23 TF/s

Prefill latency: 0.10157816193532199 sec
Decode latency: 2.5554010630585253 sec
Time for inference 4: 2.66 sec total, 385.29 tokens/sec
Decode latency: 2.56 sec
Prefill latency: 0.10 sec
Bandwidth achieved: 446.11 GB/s
FLOPS achieved: 2.23 TF/s

Prefill latency: 0.1022051409818232 sec
Decode latency: 2.5569917139364406 sec
Time for inference 5: 2.66 sec total, 384.98 tokens/sec
Decode latency: 2.56 sec
Prefill latency: 0.10 sec
Bandwidth achieved: 445.76 GB/s
FLOPS achieved: 2.23 TF/s

Prefill latency: 0.10097821895033121 sec
Decode latency: 2.5550516189541668 sec
Time for inference 6: 2.66 sec total, 385.43 tokens/sec
Decode latency: 2.56 sec
Prefill latency: 0.10 sec
Bandwidth achieved: 446.28 GB/s
FLOPS achieved: 2.23 TF/s

Prefill latency: 0.10181918006855994 sec
Decode latency: 2.5561736810486764 sec
Time for inference 7: 2.66 sec total, 385.11 tokens/sec
Decode latency: 2.56 sec
Prefill latency: 0.10 sec
Bandwidth achieved: 445.91 GB/s
FLOPS achieved: 2.23 TF/s

Prefill latency: 0.10092156904283911 sec
Decode latency: 2.5553412589943036 sec
Time for inference 8: 2.66 sec total, 385.36 tokens/sec
Decode latency: 2.56 sec
Prefill latency: 0.10 sec
Bandwidth achieved: 446.20 GB/s
FLOPS achieved: 2.23 TF/s

Prefill latency: 0.10222083795815706 sec
Decode latency: 2.5551424119621515 sec
Time for inference 9: 2.66 sec total, 385.22 tokens/sec
Decode latency: 2.56 sec
Prefill latency: 0.10 sec
Bandwidth achieved: 446.04 GB/s
FLOPS achieved: 2.23 TF/s

Prefill latency: 0.10132968297693878 sec
Decode latency: 2.5547702240291983 sec
Time for inference 10: 2.66 sec total, 385.42 tokens/sec
Decode latency: 2.55 sec
Prefill latency: 0.10 sec
Bandwidth achieved: 446.26 GB/s
FLOPS achieved: 2.23 TF/s

==========
Batch Size: 4
Prompt Length: 1024
Generated tokens: 256
Average decode latency: 2.5553 sec
Average prefill latency: 0.1016 sec
Average tokens/sec: 385.30
Memory used: 3.59 GB
Done. we are killing the process
