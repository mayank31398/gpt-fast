W1001 03:14:12.770000 22478430836544 torch/distributed/run.py:779] 
W1001 03:14:12.770000 22478430836544 torch/distributed/run.py:779] *****************************************
W1001 03:14:12.770000 22478430836544 torch/distributed/run.py:779] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W1001 03:14:12.770000 22478430836544 torch/distributed/run.py:779] *****************************************
flash_kv_decode is set to True
Using device=cuda
Loading model ...
GPTDense(
  (tok_embeddings): Embedding(49152, 1536)
  (layers): ModuleList(
    (0-39): 40 x DenseTransformerBlock(
      semi_compiled = False
      (attention): Attention(
        (wqkv): Linear(in_features=1536, out_features=2304, bias=False)
        (wo): Linear(in_features=768, out_features=1536, bias=False)
      )
      (feed_forward): FeedForward(
        (w1): Linear(in_features=1536, out_features=4096, bias=False)
        (w2): Linear(in_features=2048, out_features=1536, bias=False)
      )
      (ffn_norm): RMSNorm()
      (attention_norm): RMSNorm()
    )
  )
  (norm): RMSNorm()
  (output): Linear(in_features=1536, out_features=49152, bias=False)
)
Time to load model: 1.05 seconds
Prefill latency: 0.4320000320440158 sec
Decode latency: 3.1962809779215604 sec
Compilation time: 3.66 seconds
Compilation time: 3.63 seconds
Prefill latency: 0.3973340369993821 sec
Decode latency: 3.193857402075082 sec
Prefill latency: 0.39605624903924763 sec
Decode latency: 3.1946483820211142 sec
Prefill latency: 0.39991683093830943 sec
Decode latency: 3.193762773065828 sec
Prefill latency: 0.39653760800138116 sec
Decode latency: 3.1956525649875402 sec
Prefill latency: 0.3999801289755851 sec
Decode latency: 3.197465813951567 sec
Time for inference 1: 3.60 sec total, 1138.29 tokens/sec
Decode latency: 3.20 sec
Prefill latency: 0.40 sec
Bandwidth achieved: 1461.22 GB/s
FLOPS achieved: 7.31 TF/s

Prefill latency: 0.3955698519712314 sec
Decode latency: 3.194433309021406 sec
Time for inference 2: 3.59 sec total, 1140.66 tokens/sec
Decode latency: 3.19 sec
Prefill latency: 0.40 sec
Bandwidth achieved: 1464.27 GB/s
FLOPS achieved: 7.32 TF/s

Prefill latency: 0.3987610179465264 sec
Decode latency: 3.1945191990816966 sec
Time for inference 3: 3.59 sec total, 1139.62 tokens/sec
Decode latency: 3.19 sec
Prefill latency: 0.40 sec
Bandwidth achieved: 1462.93 GB/s
FLOPS achieved: 7.31 TF/s

Prefill latency: 0.39725508994888514 sec
Decode latency: 3.194674881058745 sec
Time for inference 4: 3.59 sec total, 1140.04 tokens/sec
Decode latency: 3.19 sec
Prefill latency: 0.40 sec
Bandwidth achieved: 1463.47 GB/s
FLOPS achieved: 7.32 TF/s

Prefill latency: 0.39953651698306203 sec
Decode latency: 3.1958385709440336 sec
Time for inference 5: 3.60 sec total, 1138.96 tokens/sec
Decode latency: 3.20 sec
Prefill latency: 0.40 sec
Bandwidth achieved: 1462.08 GB/s
FLOPS achieved: 7.31 TF/s

Prefill latency: 0.39553977898322046 sec
Decode latency: 3.194878341979347 sec
Time for inference 6: 3.59 sec total, 1140.53 tokens/sec
Decode latency: 3.19 sec
Prefill latency: 0.40 sec
Bandwidth achieved: 1464.11 GB/s
FLOPS achieved: 7.32 TF/s

Prefill latency: 0.3978918839711696 sec
Decode latency: 3.192934672930278 sec
Time for inference 7: 3.59 sec total, 1140.43 tokens/sec
Decode latency: 3.19 sec
Prefill latency: 0.40 sec
Bandwidth achieved: 1463.98 GB/s
FLOPS achieved: 7.32 TF/s

Prefill latency: 0.3960544440196827 sec
Decode latency: 3.194457724923268 sec
Time for inference 8: 3.59 sec total, 1140.54 tokens/sec
Decode latency: 3.19 sec
Prefill latency: 0.40 sec
Bandwidth achieved: 1464.12 GB/s
FLOPS achieved: 7.32 TF/s

Prefill latency: 0.3992091619875282 sec
Decode latency: 3.193613594979979 sec
Time for inference 9: 3.59 sec total, 1139.79 tokens/sec
Decode latency: 3.19 sec
Prefill latency: 0.40 sec
Bandwidth achieved: 1463.16 GB/s
FLOPS achieved: 7.32 TF/s

Prefill latency: 0.39634882705286145 sec
Decode latency: 3.1943164720432833 sec
Time for inference 10: 3.59 sec total, 1140.47 tokens/sec
Decode latency: 3.19 sec
Prefill latency: 0.40 sec
Bandwidth achieved: 1464.03 GB/s
FLOPS achieved: 7.32 TF/s

==========
Batch Size: 16
Prompt Length: 1024
Generated tokens: 256
Average decode latency: 3.1947 sec
Average prefill latency: 0.3976 sec
Average tokens/sec: 1139.93
Memory used: 11.60 GB
Done. we are killing the process
