W0928 18:31:14.994000 22457693042496 torch/distributed/run.py:779] 
W0928 18:31:14.994000 22457693042496 torch/distributed/run.py:779] *****************************************
W0928 18:31:14.994000 22457693042496 torch/distributed/run.py:779] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W0928 18:31:14.994000 22457693042496 torch/distributed/run.py:779] *****************************************
flash_kv_decode is set to True
Using device=cuda
Loading model ...
GPTLadder(
  (tok_embeddings): Embedding(128256, 8192)
  (layers): ModuleList(
    (0-79): 80 x LadderTransformerBlock(
      semi_compiled = False
      (attention): Attention(
        (wqkv): Linear(in_features=8192, out_features=5120, bias=False)
        (wo): Linear(in_features=4096, out_features=8192, bias=False)
      )
      (feed_forward): FeedForward(
        (w1): Linear(in_features=8192, out_features=28672, bias=False)
        (w2): Linear(in_features=14336, out_features=8192, bias=False)
      )
      (ffn_norm): RMSNorm()
      (attention_norm): RMSNorm()
    )
  )
  (norm): RMSNorm()
  (output): Linear(in_features=8192, out_features=128256, bias=False)
)
Time to load model: 0.32 seconds
Prefill latency: 0.24084474798291922 sec
Decode latency: 9.875234593986534 sec
Compilation time: 10.12 seconds
Compilation time: 10.11 seconds
Prefill latency: 0.23218545003328472 sec
Decode latency: 9.867489859985653 sec
Prefill latency: 0.23185029096202925 sec
Decode latency: 9.869065720005892 sec
Prefill latency: 0.23112532001687214 sec
Decode latency: 9.868028536031488 sec
Prefill latency: 0.2326051369891502 sec
Decode latency: 9.865670799976215 sec
Prefill latency: 0.23158797097858042 sec
Decode latency: 9.865848599001765 sec
Time for inference 1: 10.10 sec total, 25.35 tokens/sec
Decode latency: 9.87 sec
Prefill latency: 0.23 sec
Bandwidth achieved: 1788.58 GB/s
FLOPS achieved: 8.94 TF/s

Prefill latency: 0.23212022398365662 sec
Decode latency: 9.868397822021507 sec
Time for inference 2: 10.10 sec total, 25.34 tokens/sec
Decode latency: 9.87 sec
Prefill latency: 0.23 sec
Bandwidth achieved: 1788.03 GB/s
FLOPS achieved: 8.94 TF/s

Prefill latency: 0.23239270399790257 sec
Decode latency: 9.865162411006168 sec
Time for inference 3: 10.10 sec total, 25.35 tokens/sec
Decode latency: 9.87 sec
Prefill latency: 0.23 sec
Bandwidth achieved: 1788.57 GB/s
FLOPS achieved: 8.94 TF/s

Prefill latency: 0.232391607016325 sec
Decode latency: 9.86559603101341 sec
Time for inference 4: 10.10 sec total, 25.35 tokens/sec
Decode latency: 9.87 sec
Prefill latency: 0.23 sec
Bandwidth achieved: 1788.47 GB/s
FLOPS achieved: 8.94 TF/s

Prefill latency: 0.23207223101053387 sec
Decode latency: 9.864592286001425 sec
Time for inference 5: 10.10 sec total, 25.35 tokens/sec
Decode latency: 9.86 sec
Prefill latency: 0.23 sec
Bandwidth achieved: 1788.72 GB/s
FLOPS achieved: 8.94 TF/s

Prefill latency: 0.2327949749887921 sec
Decode latency: 9.8654373390018 sec
Time for inference 6: 10.10 sec total, 25.35 tokens/sec
Decode latency: 9.87 sec
Prefill latency: 0.23 sec
Bandwidth achieved: 1788.45 GB/s
FLOPS achieved: 8.94 TF/s

Prefill latency: 0.23007475695339963 sec
Decode latency: 9.864299366017804 sec
Time for inference 7: 10.10 sec total, 25.36 tokens/sec
Decode latency: 9.86 sec
Prefill latency: 0.23 sec
Bandwidth achieved: 1789.13 GB/s
FLOPS achieved: 8.95 TF/s

Prefill latency: 0.2313345930306241 sec
Decode latency: 9.864701209997293 sec
Time for inference 8: 10.10 sec total, 25.35 tokens/sec
Decode latency: 9.86 sec
Prefill latency: 0.23 sec
Bandwidth achieved: 1788.81 GB/s
FLOPS achieved: 8.94 TF/s

Prefill latency: 0.23089143104152754 sec
Decode latency: 9.864403348998167 sec
Time for inference 9: 10.10 sec total, 25.36 tokens/sec
Decode latency: 9.86 sec
Prefill latency: 0.23 sec
Bandwidth achieved: 1788.98 GB/s
FLOPS achieved: 8.94 TF/s

Prefill latency: 0.23160837998148054 sec
Decode latency: 9.864146294014063 sec
Time for inference 10: 10.10 sec total, 25.35 tokens/sec
Decode latency: 9.86 sec
Prefill latency: 0.23 sec
Bandwidth achieved: 1788.89 GB/s
FLOPS achieved: 8.94 TF/s

==========
Batch Size: 1
Prompt Length: 1024
Generated tokens: 256
Average decode latency: 9.8653 sec
Average prefill latency: 0.2317 sec
Average tokens/sec: 25.35
Memory used: 78.07 GB
Done. we are killing the process
