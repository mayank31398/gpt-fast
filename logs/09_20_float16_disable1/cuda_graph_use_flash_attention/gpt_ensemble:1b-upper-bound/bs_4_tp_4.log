W1001 03:30:03.261000 22839262218048 torch/distributed/run.py:779] 
W1001 03:30:03.261000 22839262218048 torch/distributed/run.py:779] *****************************************
W1001 03:30:03.261000 22839262218048 torch/distributed/run.py:779] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W1001 03:30:03.261000 22839262218048 torch/distributed/run.py:779] *****************************************
flash_kv_decode is set to True
Using device=cuda
Loading model ...
GPTEnsemble(
  (tok_embeddings): Embedding(49152, 1536)
  (layers): ModuleList(
    (0-39): 40 x EnsembleTransformerBlock(
      semi_compiled = False
      (attention): Attention(
        (wqkv): Linear(in_features=1536, out_features=1152, bias=False)
        (wo): Linear(in_features=384, out_features=1536, bias=False)
      )
      (feed_forward): FeedForward(
        (w1): Linear(in_features=1536, out_features=2048, bias=False)
        (w2): Linear(in_features=1024, out_features=1536, bias=False)
      )
      (ffn_norm): RMSNorm()
      (attention_norm): RMSNorm()
    )
  )
  (norm): RMSNorm()
  (output): Linear(in_features=1536, out_features=49152, bias=False)
)
Time to load model: 4.98 seconds
Prefill latency: 0.03509313799440861 sec
Decode latency: 2.2346805561101064 sec
Compilation time: 2.26 seconds
Compilation time: 2.26 seconds
Compilation time: 2.26 seconds
Compilation time: 2.27 seconds
Prefill latency: 0.023531447048299015 sec
Decode latency: 2.230972299934365 sec
Prefill latency: 0.023646943038329482 sec
Decode latency: 2.232199619989842 sec
Prefill latency: 0.023570113931782544 sec
Decode latency: 2.2326074320590124 sec
Prefill latency: 0.023570492980070412 sec
Decode latency: 2.229699476971291 sec
Prefill latency: 0.023528111982159317 sec
Decode latency: 2.2310789570910856 sec
Time for inference 1: 2.26 sec total, 454.04 tokens/sec
Decode latency: 2.23 sec
Prefill latency: 0.02 sec
Bandwidth achieved: 325.76 GB/s
FLOPS achieved: 1.63 TF/s

Prefill latency: 0.023620479041710496 sec
Decode latency: 2.232462821993977 sec
Time for inference 2: 2.26 sec total, 453.75 tokens/sec
Decode latency: 2.23 sec
Prefill latency: 0.02 sec
Bandwidth achieved: 325.56 GB/s
FLOPS achieved: 1.63 TF/s

Prefill latency: 0.023597197025083005 sec
Decode latency: 2.231948222965002 sec
Time for inference 3: 2.26 sec total, 453.87 tokens/sec
Decode latency: 2.23 sec
Prefill latency: 0.02 sec
Bandwidth achieved: 325.64 GB/s
FLOPS achieved: 1.63 TF/s

Prefill latency: 0.023648804053664207 sec
Decode latency: 2.231455061933957 sec
Time for inference 4: 2.26 sec total, 453.89 tokens/sec
Decode latency: 2.23 sec
Prefill latency: 0.02 sec
Bandwidth achieved: 325.65 GB/s
FLOPS achieved: 1.63 TF/s

Prefill latency: 0.02354572305921465 sec
Decode latency: 2.2312895349459723 sec
Time for inference 5: 2.26 sec total, 453.94 tokens/sec
Decode latency: 2.23 sec
Prefill latency: 0.02 sec
Bandwidth achieved: 325.69 GB/s
FLOPS achieved: 1.63 TF/s

Prefill latency: 0.02351643203292042 sec
Decode latency: 2.2317021519411355 sec
Time for inference 6: 2.26 sec total, 453.90 tokens/sec
Decode latency: 2.23 sec
Prefill latency: 0.02 sec
Bandwidth achieved: 325.66 GB/s
FLOPS achieved: 1.63 TF/s

Prefill latency: 0.02355421206448227 sec
Decode latency: 2.231238915002905 sec
Time for inference 7: 2.26 sec total, 453.96 tokens/sec
Decode latency: 2.23 sec
Prefill latency: 0.02 sec
Bandwidth achieved: 325.70 GB/s
FLOPS achieved: 1.63 TF/s

Prefill latency: 0.023517270921729505 sec
Decode latency: 2.2313032110687345 sec
Time for inference 8: 2.26 sec total, 453.99 tokens/sec
Decode latency: 2.23 sec
Prefill latency: 0.02 sec
Bandwidth achieved: 325.73 GB/s
FLOPS achieved: 1.63 TF/s

Prefill latency: 0.023572353995405138 sec
Decode latency: 2.229996540932916 sec
Time for inference 9: 2.25 sec total, 454.25 tokens/sec
Decode latency: 2.23 sec
Prefill latency: 0.02 sec
Bandwidth achieved: 325.91 GB/s
FLOPS achieved: 1.63 TF/s

Prefill latency: 0.023557791952043772 sec
Decode latency: 2.231277475017123 sec
Time for inference 10: 2.26 sec total, 454.00 tokens/sec
Decode latency: 2.23 sec
Prefill latency: 0.02 sec
Bandwidth achieved: 325.73 GB/s
FLOPS achieved: 1.63 TF/s

==========
Batch Size: 4
Prompt Length: 1024
Generated tokens: 256
Average decode latency: 2.2314 sec
Average prefill latency: 0.0236 sec
Average tokens/sec: 453.96
Memory used: 2.49 GB
Done. we are killing the process
