W1001 03:26:01.732000 23394856183616 torch/distributed/run.py:779] 
W1001 03:26:01.732000 23394856183616 torch/distributed/run.py:779] *****************************************
W1001 03:26:01.732000 23394856183616 torch/distributed/run.py:779] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W1001 03:26:01.732000 23394856183616 torch/distributed/run.py:779] *****************************************
flash_kv_decode is set to True
Using device=cuda
Loading model ...
GPTEnsemble(
  (tok_embeddings): Embedding(49152, 1536)
  (layers): ModuleList(
    (0-39): 40 x EnsembleTransformerBlock(
      semi_compiled = False
      (attention): Attention(
        (wqkv): Linear(in_features=1536, out_features=2304, bias=False)
        (wo): Linear(in_features=768, out_features=1536, bias=False)
      )
      (feed_forward): FeedForward(
        (w1): Linear(in_features=1536, out_features=4096, bias=False)
        (w2): Linear(in_features=2048, out_features=1536, bias=False)
      )
      (ffn_norm): RMSNorm()
      (attention_norm): RMSNorm()
    )
  )
  (norm): RMSNorm()
  (output): Linear(in_features=1536, out_features=49152, bias=False)
)
Time to load model: 1.02 seconds
Prefill latency: 0.05090550100430846 sec
Decode latency: 2.0270885539939627 sec
Compilation time: 2.05 seconds
Compilation time: 2.08 seconds
Prefill latency: 0.02239131706301123 sec
Decode latency: 2.023883620975539 sec
Prefill latency: 0.022394899977371097 sec
Decode latency: 2.0247938950778916 sec
Prefill latency: 0.022185860900208354 sec
Decode latency: 2.023049720097333 sec
Prefill latency: 0.022307010018266737 sec
Decode latency: 2.023298360989429 sec
Prefill latency: 0.022322862991131842 sec
Decode latency: 2.0242542249616235 sec
Time for inference 1: 2.05 sec total, 125.03 tokens/sec
Decode latency: 2.02 sec
Prefill latency: 0.02 sec
Bandwidth achieved: 160.50 GB/s
FLOPS achieved: 0.80 TF/s

Prefill latency: 0.022411128040403128 sec
Decode latency: 2.023978010052815 sec
Time for inference 2: 2.05 sec total, 125.05 tokens/sec
Decode latency: 2.02 sec
Prefill latency: 0.02 sec
Bandwidth achieved: 160.53 GB/s
FLOPS achieved: 0.80 TF/s

Prefill latency: 0.022236380027607083 sec
Decode latency: 2.024060453986749 sec
Time for inference 3: 2.05 sec total, 125.05 tokens/sec
Decode latency: 2.02 sec
Prefill latency: 0.02 sec
Bandwidth achieved: 160.52 GB/s
FLOPS achieved: 0.80 TF/s

Prefill latency: 0.022217235062271357 sec
Decode latency: 2.026719306013547 sec
Time for inference 4: 2.05 sec total, 124.89 tokens/sec
Decode latency: 2.03 sec
Prefill latency: 0.02 sec
Bandwidth achieved: 160.32 GB/s
FLOPS achieved: 0.80 TF/s

Prefill latency: 0.02231447002850473 sec
Decode latency: 2.0231572120683268 sec
Time for inference 5: 2.05 sec total, 125.11 tokens/sec
Decode latency: 2.02 sec
Prefill latency: 0.02 sec
Bandwidth achieved: 160.60 GB/s
FLOPS achieved: 0.80 TF/s

Prefill latency: 0.02225310099311173 sec
Decode latency: 2.0196201290236786 sec
Time for inference 6: 2.04 sec total, 125.33 tokens/sec
Decode latency: 2.02 sec
Prefill latency: 0.02 sec
Bandwidth achieved: 160.89 GB/s
FLOPS achieved: 0.80 TF/s

Prefill latency: 0.02231109596323222 sec
Decode latency: 2.0233589009149 sec
Time for inference 7: 2.05 sec total, 125.10 tokens/sec
Decode latency: 2.02 sec
Prefill latency: 0.02 sec
Bandwidth achieved: 160.59 GB/s
FLOPS achieved: 0.80 TF/s

Prefill latency: 0.022138326079584658 sec
Decode latency: 2.0177960239816457 sec
Time for inference 8: 2.04 sec total, 125.45 tokens/sec
Decode latency: 2.02 sec
Prefill latency: 0.02 sec
Bandwidth achieved: 161.04 GB/s
FLOPS achieved: 0.81 TF/s

Prefill latency: 0.02228130295407027 sec
Decode latency: 2.0252532170852646 sec
Time for inference 9: 2.05 sec total, 124.99 tokens/sec
Decode latency: 2.03 sec
Prefill latency: 0.02 sec
Bandwidth achieved: 160.45 GB/s
FLOPS achieved: 0.80 TF/s

Prefill latency: 0.022498658974654973 sec
Decode latency: 2.0234890120336786 sec
Time for inference 10: 2.05 sec total, 125.08 tokens/sec
Decode latency: 2.02 sec
Prefill latency: 0.02 sec
Bandwidth achieved: 160.57 GB/s
FLOPS achieved: 0.80 TF/s

==========
Batch Size: 1
Prompt Length: 1024
Generated tokens: 256
Average decode latency: 2.0232 sec
Average prefill latency: 0.0223 sec
Average tokens/sec: 125.11
Memory used: 2.05 GB
Done. we are killing the process
