[2024-09-13 07:53:31,457] torch.distributed.run: [WARNING] 
[2024-09-13 07:53:31,457] torch.distributed.run: [WARNING] *****************************************
[2024-09-13 07:53:31,457] torch.distributed.run: [WARNING] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
[2024-09-13 07:53:31,457] torch.distributed.run: [WARNING] *****************************************
our tp world size is 4
our tp world size is 4
our tp world size is 4
our tp world size is 4
our tp world size is 4
our tp world size is 4
our tp world size is 4
our tp world size is 4
our tp world size is 4
our tp world size is 4
our tp world size is 4
our tp world size is 4
our tp world size is 4
our tp world size is 4
our tp world size is 4
our tp world size is 4
Using device=cuda
our tp world size is our tp world size is our tp world size is Loading model ...
4
4
4
our tp world size is our tp world size isour tp world size isour tp world size is4
 4 4 4our tp world size is 


our tp world size is4
our tp world size is our tp world size is  4our tp world size is 4
4

4
our tp world size isour tp world size is our tp world size is our tp world size is  44
4
4

our tp world size is our tp world size is our tp world size is our tp world size is 44
4
4

our tp world size is our tp world size isour tp world size is our tp world size is 4
 44
4our tp world size is 
our tp world size is 
4
our tp world size is 4
our tp world size is our tp world size is 4
our tp world size is44
our tp world size is  4
our tp world size is 4

our tp world size is 4
our tp world size is our tp world size is4
our tp world size is 4 4our tp world size is 4

our tp world size is
4our tp world size is  4our tp world size is 
our tp world size is4

4
 our tp world size is our tp world size is our tp world size is 4
4
44our tp world size is our tp world size is 

4
4
our tp world size is our tp world size is our tp world size is our tp world size is 4
4
4
4our tp world size is our tp world size is 
our tp world size is 4
4
our tp world size is 4
our tp world size is our tp world size is 4
our tp world size is4
4
our tp world size is  4our tp world size is our tp world size is 4

our tp world size is4
4 4our tp world size is 
we finish operating the TP!

our tp world size is4
our tp world size is  4our tp world size is 4

our tp world size is4
our tp world size is  4our tp world size is4

our tp world size is our tp world size is  44
4

our tp world size is our tp world size isour tp world size is 4
 4
our tp world size is 4
our tp world size is 4
our tp world size is 4
our tp world size is 4
our tp world size is 4
our tp world size is4our tp world size is  4
4
our tp world size is 
our tp world size is 4
our tp world size is 4our tp world size is 4

our tp world size is4
our tp world size is  4our tp world size is 4

our tp world size is4
our tp world size is 4our tp world size is  4
our tp world size is4

our tp world size is our tp world size is  44
4

our tp world size is our tp world size is our tp world size is 4
44
our tp world size is 
our tp world size is4
our tp world size is  our tp world size is44
 
our tp world size isour tp world size is 4 44

our tp world size is
our tp world size is 4our tp world size is  
44our tp world size is

 our tp world size is our tp world size is4
4 4our tp world size is 

4
our tp world size is our tp world size isour tp world size is 4
 44

we finish operating the TP!Applying tensor parallel to model ...

we finish operating the TP!
we finish operating the TP!
GPTResidual(
  (tok_embeddings): Embedding(128256, 4096)
  (layers): ModuleList(
    (0-31): 32 x TurboTransformerBlock(
      (attention): Attention(
        (wqkv): Linear(in_features=4096, out_features=1536, bias=False)
        (wo): Linear(in_features=1024, out_features=4096, bias=False)
      )
      (feed_forward): FeedForward(
        (w1): Linear(in_features=4096, out_features=7168, bias=False)
        (w2): Linear(in_features=3584, out_features=4096, bias=False)
      )
      (ffn_norm): RMSNorm()
      (attention_norm): RMSNorm()
    )
  )
  (norm): RMSNorm()
  (output): Linear(in_features=4096, out_features=128256, bias=False)
)
models all reduce stream is None
Time to load model: 0.49 seconds
tokens we generated: 1024
Time for prefill: 57.39 sec
Time for inference -4: 127.20 sec total, 8.05 tokens/sec
Bandwidth achieved: 36.56 GB/s
FLOPS achieved: 0.07 TF/s

tokens we generated: 1024
Time for prefill: 0.51 sec
Time for inference -3: 3.57 sec total, 286.59 tokens/sec
Bandwidth achieved: 1301.35 GB/s
FLOPS achieved: 2.60 TF/s

tokens we generated: 1024
Time for prefill: 0.01 sec
Time for inference -2: 3.01 sec total, 340.37 tokens/sec
Bandwidth achieved: 1545.58 GB/s
FLOPS achieved: 3.09 TF/s

tokens we generated: 1024
Time for prefill: 0.01 sec
Time for inference -1: 3.01 sec total, 339.95 tokens/sec
Bandwidth achieved: 1543.68 GB/s
FLOPS achieved: 3.09 TF/s

Compilation time: 3.01 seconds
tokens we generated: 1024
Time for prefill: 0.01 sec
Time for inference 1: 3.01 sec total, 340.21 tokens/sec
Bandwidth achieved: 1544.85 GB/s
FLOPS achieved: 3.09 TF/s

tokens we generated: 1024
Time for prefill: 0.01 sec
Time for inference 2: 3.02 sec total, 339.48 tokens/sec
Bandwidth achieved: 1541.54 GB/s
FLOPS achieved: 3.08 TF/s

tokens we generated: 1024
Time for prefill: 0.01 sec
Time for inference 3: 3.02 sec total, 339.21 tokens/sec
Bandwidth achieved: 1540.30 GB/s
FLOPS achieved: 3.08 TF/s

tokens we generated: 1024
Time for prefill: 0.02 sec
Time for inference 4: 3.01 sec total, 340.58 tokens/sec
Bandwidth achieved: 1546.51 GB/s
FLOPS achieved: 3.09 TF/s

tokens we generated: 1024
Time for prefill: 0.01 sec
Time for inference 5: 3.00 sec total, 340.94 tokens/sec
Bandwidth achieved: 1548.14 GB/s
FLOPS achieved: 3.10 TF/s

tokens we generated: 1024
Time for prefill: 0.01 sec
Time for inference 6: 3.02 sec total, 339.28 tokens/sec
Bandwidth achieved: 1540.65 GB/s
FLOPS achieved: 3.08 TF/s

tokens we generated: 1024
Time for prefill: 0.01 sec
Time for inference 7: 2.99 sec total, 342.05 tokens/sec
Bandwidth achieved: 1553.19 GB/s
FLOPS achieved: 3.11 TF/s

tokens we generated: 1024
Time for prefill: 0.01 sec
Time for inference 8: 2.99 sec total, 342.31 tokens/sec
Bandwidth achieved: 1554.38 GB/s
FLOPS achieved: 3.11 TF/s

tokens we generated: 1024
Time for prefill: 0.01 sec
Time for inference 9: 3.02 sec total, 339.60 tokens/sec
Bandwidth achieved: 1542.08 GB/s
FLOPS achieved: 3.08 TF/s

tokens we generated: 1024
Time for prefill: 0.01 sec
Time for inference 10: 3.00 sec total, 341.16 tokens/sec
Bandwidth achieved: 1549.15 GB/s
FLOPS achieved: 3.10 TF/s

tokens we generated: 1024
Time for prefill: 0.01 sec
Time for inference 11: 2.99 sec total, 342.40 tokens/sec
Bandwidth achieved: 1554.81 GB/s
FLOPS achieved: 3.11 TF/s

tokens we generated: 1024
Time for prefill: 0.01 sec
Time for inference 12: 2.99 sec total, 342.64 tokens/sec
Bandwidth achieved: 1555.87 GB/s
FLOPS achieved: 3.11 TF/s

tokens we generated: 1024
Time for prefill: 0.01 sec
Time for inference 13: 2.99 sec total, 342.69 tokens/sec
Bandwidth achieved: 1556.10 GB/s
FLOPS achieved: 3.11 TF/s

tokens we generated: 1024
Time for prefill: 0.01 sec
Time for inference 14: 2.99 sec total, 342.34 tokens/sec
Bandwidth achieved: 1554.53 GB/s
FLOPS achieved: 3.11 TF/s

tokens we generated: 1024
Time for prefill: 0.01 sec
Time for inference 15: 3.00 sec total, 341.73 tokens/sec
Bandwidth achieved: 1551.73 GB/s
FLOPS achieved: 3.10 TF/s

STAGE:2024-09-13 07:56:40 4120429:4120429 ActivityProfilerController.cpp:314] Completed Stage: Warm Up
STAGE:2024-09-13 07:56:40 4120429:4120429 ActivityProfilerController.cpp:320] Completed Stage: Collection
STAGE:2024-09-13 07:56:40 4120429:4120429 ActivityProfilerController.cpp:324] Completed Stage: Post Processing
tokens we generated: 1024
Time for prefill: 0.01 sec
Time for inference 16: 3.07 sec total, 333.94 tokens/sec
Bandwidth achieved: 1516.39 GB/s
FLOPS achieved: 3.03 TF/s

==========
Batch Size: 1
Prompt Length: 1024
Generated tokens: 1024
Average prefill latency: 0.04 sec
Average tokens/sec: 337.76
Memory used: 6.53 GB
