[2024-09-13 07:49:14,608] torch.distributed.run: [WARNING] 
[2024-09-13 07:49:14,608] torch.distributed.run: [WARNING] *****************************************
[2024-09-13 07:49:14,608] torch.distributed.run: [WARNING] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
[2024-09-13 07:49:14,608] torch.distributed.run: [WARNING] *****************************************
our tp world size is 2
our tp world size is 2
our tp world size is 2
our tp world size is 2
our tp world size is 2
Using device=cudaour tp world size is 
Loading model ...2

our tp world size is 2
our tp world size is our tp world size is 2
2
our tp world size is our tp world size is 2
2
our tp world size is our tp world size is 2
2
our tp world size is our tp world size is 2
2
our tp world size is our tp world size is 2
2
our tp world size is our tp world size is 2
2
our tp world size is our tp world size is 2
2
our tp world size is our tp world size is 2
2
our tp world size is our tp world size is 2
2
our tp world size is our tp world size is 2
2
our tp world size is our tp world size is 2
2
our tp world size is our tp world size is 2
2
our tp world size is our tp world size is 2
2
our tp world size is our tp world size is 2
2our tp world size is 
2
our tp world size is our tp world size is2 2

our tp world size is our tp world size is 2
2
our tp world size is our tp world size is 2
2
our tp world size is our tp world size is 2
2
our tp world size is our tp world size is 2
2
our tp world size is our tp world size is2
 2our tp world size is 
our tp world size is2
 2our tp world size is 
2
our tp world size is our tp world size is 2
2
our tp world size isour tp world size is  22

our tp world size is our tp world size is 2
2
our tp world size is 2we finish operating the TP!

our tp world size is 2
our tp world size is 2
our tp world size is 2
our tp world size is 2
our tp world size is 2
our tp world size is 2
Applying tensor parallel to model ...
we finish operating the TP!
GPTResidual(
  (tok_embeddings): Embedding(128256, 4096)
  (layers): ModuleList(
    (0-31): 32 x TurboTransformerBlock(
      (attention): Attention(
        (wqkv): Linear(in_features=4096, out_features=3072, bias=False)
        (wo): Linear(in_features=2048, out_features=4096, bias=False)
      )
      (feed_forward): FeedForward(
        (w1): Linear(in_features=4096, out_features=14336, bias=False)
        (w2): Linear(in_features=7168, out_features=4096, bias=False)
      )
      (ffn_norm): RMSNorm()
      (attention_norm): RMSNorm()
    )
  )
  (norm): RMSNorm()
  (output): Linear(in_features=4096, out_features=128256, bias=False)
)
models all reduce stream is None
Time to load model: 0.39 seconds
tokens we generated: 1024
Time for prefill: 56.98 sec
Time for inference -4: 134.07 sec total, 7.64 tokens/sec
Bandwidth achieved: 61.34 GB/s
FLOPS achieved: 0.12 TF/s

tokens we generated: 1024
Time for prefill: 0.49 sec
Time for inference -3: 4.66 sec total, 219.78 tokens/sec
Bandwidth achieved: 1764.92 GB/s
FLOPS achieved: 3.53 TF/s

tokens we generated: 1024
Time for prefill: 0.02 sec
Time for inference -2: 4.12 sec total, 248.45 tokens/sec
Bandwidth achieved: 1995.21 GB/s
FLOPS achieved: 3.99 TF/s

tokens we generated: 1024
Time for prefill: 0.02 sec
Time for inference -1: 4.12 sec total, 248.63 tokens/sec
Bandwidth achieved: 1996.59 GB/s
FLOPS achieved: 3.99 TF/s

Compilation time: 4.12 seconds
tokens we generated: 1024
Time for prefill: 0.02 sec
Time for inference 1: 4.12 sec total, 248.84 tokens/sec
Bandwidth achieved: 1998.30 GB/s
FLOPS achieved: 4.00 TF/s

tokens we generated: 1024
Time for prefill: 0.02 sec
Time for inference 2: 4.13 sec total, 248.22 tokens/sec
Bandwidth achieved: 1993.34 GB/s
FLOPS achieved: 3.99 TF/s

tokens we generated: 1024
Time for prefill: 0.02 sec
Time for inference 3: 4.12 sec total, 248.55 tokens/sec
Bandwidth achieved: 1995.97 GB/s
FLOPS achieved: 3.99 TF/s

tokens we generated: 1024
Time for prefill: 0.02 sec
Time for inference 4: 4.12 sec total, 248.33 tokens/sec
Bandwidth achieved: 1994.21 GB/s
FLOPS achieved: 3.99 TF/s

tokens we generated: 1024
Time for prefill: 0.02 sec
Time for inference 5: 4.12 sec total, 248.76 tokens/sec
Bandwidth achieved: 1997.65 GB/s
FLOPS achieved: 4.00 TF/s

tokens we generated: 1024
Time for prefill: 0.02 sec
Time for inference 6: 4.12 sec total, 248.84 tokens/sec
Bandwidth achieved: 1998.30 GB/s
FLOPS achieved: 4.00 TF/s

tokens we generated: 1024
Time for prefill: 0.02 sec
Time for inference 7: 4.12 sec total, 248.67 tokens/sec
Bandwidth achieved: 1996.93 GB/s
FLOPS achieved: 3.99 TF/s

tokens we generated: 1024
Time for prefill: 0.02 sec
Time for inference 8: 4.10 sec total, 249.81 tokens/sec
Bandwidth achieved: 2006.12 GB/s
FLOPS achieved: 4.01 TF/s

tokens we generated: 1024
Time for prefill: 0.02 sec
Time for inference 9: 4.10 sec total, 249.91 tokens/sec
Bandwidth achieved: 2006.92 GB/s
FLOPS achieved: 4.01 TF/s

tokens we generated: 1024
Time for prefill: 0.02 sec
Time for inference 10: 4.09 sec total, 250.08 tokens/sec
Bandwidth achieved: 2008.28 GB/s
FLOPS achieved: 4.02 TF/s

tokens we generated: 1024
Time for prefill: 0.02 sec
Time for inference 11: 4.11 sec total, 249.32 tokens/sec
Bandwidth achieved: 2002.15 GB/s
FLOPS achieved: 4.00 TF/s

tokens we generated: 1024
Time for prefill: 0.02 sec
Time for inference 12: 4.10 sec total, 250.00 tokens/sec
Bandwidth achieved: 2007.60 GB/s
FLOPS achieved: 4.02 TF/s

tokens we generated: 1024
Time for prefill: 0.02 sec
Time for inference 13: 4.10 sec total, 249.97 tokens/sec
Bandwidth achieved: 2007.36 GB/s
FLOPS achieved: 4.01 TF/s

tokens we generated: 1024
Time for prefill: 0.02 sec
Time for inference 14: 4.09 sec total, 250.12 tokens/sec
Bandwidth achieved: 2008.60 GB/s
FLOPS achieved: 4.02 TF/s

tokens we generated: 1024
Time for prefill: 0.02 sec
Time for inference 15: 4.10 sec total, 249.85 tokens/sec
Bandwidth achieved: 2006.44 GB/s
FLOPS achieved: 4.01 TF/s

STAGE:2024-09-13 07:52:50 4114811:4114811 ActivityProfilerController.cpp:314] Completed Stage: Warm Up
STAGE:2024-09-13 07:52:50 4114811:4114811 ActivityProfilerController.cpp:320] Completed Stage: Collection
STAGE:2024-09-13 07:52:50 4114811:4114811 ActivityProfilerController.cpp:324] Completed Stage: Post Processing
tokens we generated: 1024
Time for prefill: 0.02 sec
Time for inference 16: 4.20 sec total, 244.05 tokens/sec
Bandwidth achieved: 1959.81 GB/s
FLOPS achieved: 3.92 TF/s

==========
Batch Size: 1
Prompt Length: 1024
Generated tokens: 1024
Average prefill latency: 0.05 sec
Average tokens/sec: 247.38
Memory used: 10.68 GB
