W1001 20:22:00.732000 22749954148160 torch/distributed/run.py:779] 
W1001 20:22:00.732000 22749954148160 torch/distributed/run.py:779] *****************************************
W1001 20:22:00.732000 22749954148160 torch/distributed/run.py:779] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W1001 20:22:00.732000 22749954148160 torch/distributed/run.py:779] *****************************************
flash_kv_decode is set to True
Using device=cuda
Loading model ...
GPTLadder(
  (tok_embeddings): Embedding(128256, 4096)
  (layers): ModuleList(
    (0-31): 32 x LadderTransformerBlock(
      semi_compiled = False
      (attention): Attention(
        (wqkv): Linear(in_features=4096, out_features=768, bias=False)
        (wo): Linear(in_features=512, out_features=4096, bias=False)
      )
      (feed_forward): FeedForward(
        (w1): Linear(in_features=4096, out_features=3584, bias=False)
        (w2): Linear(in_features=1792, out_features=4096, bias=False)
      )
      (ffn_norm): RMSNorm()
      (attention_norm): RMSNorm()
    )
  )
  (norm): RMSNorm()
  (output): Linear(in_features=4096, out_features=128256, bias=False)
)
Time to load model: 0.19 seconds
[rank1]:[W1001 20:22:13.336716285 CUDAGraph.cpp:150] Warning: Waiting for pending NCCL work to finish before starting graph capture. (function operator())
[rank5]:[W1001 20:22:13.337565231 CUDAGraph.cpp:150] Warning: Waiting for pending NCCL work to finish before starting graph capture. (function operator())
[rank2]:[W1001 20:22:13.838198944 CUDAGraph.cpp:150] Warning: Waiting for pending NCCL work to finish before starting graph capture. (function operator())
[rank7]:[W1001 20:22:13.852590416 CUDAGraph.cpp:150] Warning: Waiting for pending NCCL work to finish before starting graph capture. (function operator())
Prefill latency: 0.07196457008831203 sec
Decode latency: 0.17823375994339585 sec
Compilation time: 0.23 seconds
Compilation time: 0.23 seconds
Compilation time: 0.22 seconds
Compilation time: 0.25 seconds
Compilation time: 0.25 seconds
Compilation time: 0.25 seconds
Compilation time: 0.22 seconds
Compilation time: 0.25 seconds
Prefill latency: 0.03731884900480509 sec
Decode latency: 0.18429777899291366 sec
Prefill latency: 0.037513007991947234 sec
Decode latency: 0.18104917905293405 sec
Prefill latency: 0.03963202808517963 sec
Decode latency: 0.17905558599159122 sec
Prefill latency: 0.03753198706544936 sec
Decode latency: 0.1808952490100637 sec
Prefill latency: 0.03772630007006228 sec
Decode latency: 0.18547007895540446 sec
Time for inference 1: 0.22 sec total, 572.22 tokens/sec
Decode latency: 0.19 sec
Prefill latency: 0.04 sec
Bandwidth achieved: 1599.94 GB/s
FLOPS achieved: 52.80 TF/s

Prefill latency: 0.03809712396468967 sec
Decode latency: 0.18045261804945767 sec
Time for inference 2: 0.22 sec total, 584.16 tokens/sec
Decode latency: 0.18 sec
Prefill latency: 0.04 sec
Bandwidth achieved: 1633.33 GB/s
FLOPS achieved: 53.90 TF/s

Prefill latency: 0.038264772039838135 sec
Decode latency: 0.17693103500641882 sec
Time for inference 3: 0.22 sec total, 593.20 tokens/sec
Decode latency: 0.18 sec
Prefill latency: 0.04 sec
Bandwidth achieved: 1658.61 GB/s
FLOPS achieved: 54.73 TF/s

Prefill latency: 0.03753750491887331 sec
Decode latency: 0.17932174005545676 sec
Time for inference 4: 0.22 sec total, 587.64 tokens/sec
Decode latency: 0.18 sec
Prefill latency: 0.04 sec
Bandwidth achieved: 1643.06 GB/s
FLOPS achieved: 54.22 TF/s

Prefill latency: 0.04043274896685034 sec
Decode latency: 0.18280003708787262 sec
Time for inference 5: 0.22 sec total, 571.91 tokens/sec
Decode latency: 0.18 sec
Prefill latency: 0.04 sec
Bandwidth achieved: 1599.07 GB/s
FLOPS achieved: 52.77 TF/s

Prefill latency: 0.04446596198249608 sec
Decode latency: 0.17868760507553816 sec
Time for inference 6: 0.22 sec total, 571.83 tokens/sec
Decode latency: 0.18 sec
Prefill latency: 0.04 sec
Bandwidth achieved: 1598.87 GB/s
FLOPS achieved: 52.76 TF/s

Prefill latency: 0.03904871898703277 sec
Decode latency: 0.18216504296287894 sec
Time for inference 7: 0.22 sec total, 576.71 tokens/sec
Decode latency: 0.18 sec
Prefill latency: 0.04 sec
Bandwidth achieved: 1612.50 GB/s
FLOPS achieved: 53.21 TF/s

Prefill latency: 0.03729017497971654 sec
Decode latency: 0.1830889399861917 sec
Time for inference 8: 0.22 sec total, 579.09 tokens/sec
Decode latency: 0.18 sec
Prefill latency: 0.04 sec
Bandwidth achieved: 1619.17 GB/s
FLOPS achieved: 53.43 TF/s

Prefill latency: 0.04074013396166265 sec
Decode latency: 0.17956678895279765 sec
Time for inference 9: 0.22 sec total, 579.26 tokens/sec
Decode latency: 0.18 sec
Prefill latency: 0.04 sec
Bandwidth achieved: 1619.64 GB/s
FLOPS achieved: 53.45 TF/s

Prefill latency: 0.04045565496198833 sec
Decode latency: 0.18091336206998676 sec
Time for inference 10: 0.22 sec total, 576.64 tokens/sec
Decode latency: 0.18 sec
Prefill latency: 0.04 sec
Bandwidth achieved: 1612.32 GB/s
FLOPS achieved: 53.21 TF/s

==========
Batch Size: 4
Prompt Length: 1024
Generated tokens: 32
Average decode latency: 0.1809 sec
Average prefill latency: 0.0394 sec
Average tokens/sec: 579.27
Memory used: 7.42 GB
Done. we are killing the process
