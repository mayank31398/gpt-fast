W1001 20:19:38.671000 22431635834688 torch/distributed/run.py:779] 
W1001 20:19:38.671000 22431635834688 torch/distributed/run.py:779] *****************************************
W1001 20:19:38.671000 22431635834688 torch/distributed/run.py:779] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W1001 20:19:38.671000 22431635834688 torch/distributed/run.py:779] *****************************************
flash_kv_decode is set to True
Using device=cuda
Loading model ...
GPTDense(
  (tok_embeddings): Embedding(49152, 1536)
  (layers): ModuleList(
    (0-39): 40 x DenseTransformerBlock(
      semi_compiled = False
      (attention): Attention(
        (wqkv): Linear(in_features=1536, out_features=1152, bias=False)
        (wo): Linear(in_features=384, out_features=1536, bias=False)
      )
      (feed_forward): FeedForward(
        (w1): Linear(in_features=1536, out_features=2048, bias=False)
        (w2): Linear(in_features=1024, out_features=1536, bias=False)
      )
      (ffn_norm): RMSNorm()
      (attention_norm): RMSNorm()
    )
  )
  (norm): RMSNorm()
  (output): Linear(in_features=1536, out_features=49152, bias=False)
)
Time to load model: 0.92 seconds
Prefill latency: 0.1443280769744888 sec
Decode latency: 3.749633954023011 sec
Compilation time: 3.90 seconds
Compilation time: 3.90 seconds
Compilation time: 3.90 seconds
Compilation time: 3.90 seconds
Prefill latency: 0.14543124788906425 sec
Decode latency: 3.779841870069504 sec
Prefill latency: 0.14404479507356882 sec
Decode latency: 3.767392155015841 sec
Prefill latency: 0.1430862690322101 sec
Decode latency: 3.735368932946585 sec
Prefill latency: 0.14307125401683152 sec
Decode latency: 3.6796888469252735 sec
Prefill latency: 0.14172410091850907 sec
Decode latency: 3.6548364809714258 sec
Time for inference 1: 3.80 sec total, 1077.18 tokens/sec
Decode latency: 3.65 sec
Prefill latency: 0.14 sec
Bandwidth achieved: 772.85 GB/s
FLOPS achieved: 3.86 TF/s

Prefill latency: 0.14268755703233182 sec
Decode latency: 3.675685668946244 sec
Time for inference 2: 3.82 sec total, 1071.29 tokens/sec
Decode latency: 3.68 sec
Prefill latency: 0.14 sec
Bandwidth achieved: 768.62 GB/s
FLOPS achieved: 3.84 TF/s

Prefill latency: 0.13998402294237167 sec
Decode latency: 3.69373427296523 sec
Time for inference 3: 3.84 sec total, 1066.41 tokens/sec
Decode latency: 3.69 sec
Prefill latency: 0.14 sec
Bandwidth achieved: 765.12 GB/s
FLOPS achieved: 3.83 TF/s

Prefill latency: 0.14040158002171665 sec
Decode latency: 3.706351976026781 sec
Time for inference 4: 3.85 sec total, 1063.35 tokens/sec
Decode latency: 3.71 sec
Prefill latency: 0.14 sec
Bandwidth achieved: 762.93 GB/s
FLOPS achieved: 3.81 TF/s

Prefill latency: 0.14498401794116944 sec
Decode latency: 3.7429829210741445 sec
Time for inference 5: 3.89 sec total, 1052.18 tokens/sec
Decode latency: 3.74 sec
Prefill latency: 0.14 sec
Bandwidth achieved: 754.91 GB/s
FLOPS achieved: 3.77 TF/s

Prefill latency: 0.14215348789002746 sec
Decode latency: 3.7506140739424154 sec
Time for inference 6: 3.90 sec total, 1050.31 tokens/sec
Decode latency: 3.75 sec
Prefill latency: 0.14 sec
Bandwidth achieved: 753.57 GB/s
FLOPS achieved: 3.77 TF/s

Prefill latency: 0.1443848490016535 sec
Decode latency: 3.782335484982468 sec
Time for inference 7: 3.93 sec total, 1041.97 tokens/sec
Decode latency: 3.78 sec
Prefill latency: 0.14 sec
Bandwidth achieved: 747.59 GB/s
FLOPS achieved: 3.74 TF/s

Prefill latency: 0.14434956095647067 sec
Decode latency: 3.784154374967329 sec
Time for inference 8: 3.94 sec total, 1040.85 tokens/sec
Decode latency: 3.78 sec
Prefill latency: 0.14 sec
Bandwidth achieved: 746.78 GB/s
FLOPS achieved: 3.73 TF/s

Prefill latency: 0.14378953096456826 sec
Decode latency: 3.724847397999838 sec
Time for inference 9: 3.88 sec total, 1056.84 tokens/sec
Decode latency: 3.72 sec
Prefill latency: 0.14 sec
Bandwidth achieved: 758.26 GB/s
FLOPS achieved: 3.79 TF/s

Prefill latency: 0.14151807001326233 sec
Decode latency: 3.7296781369950622 sec
Time for inference 10: 3.88 sec total, 1056.62 tokens/sec
Decode latency: 3.73 sec
Prefill latency: 0.14 sec
Bandwidth achieved: 758.10 GB/s
FLOPS achieved: 3.79 TF/s

==========
Batch Size: 16
Prompt Length: 1024
Generated tokens: 256
Average decode latency: 3.7245 sec
Average prefill latency: 0.1426 sec
Average tokens/sec: 1057.70
Memory used: 9.08 GB
Done. we are killing the process
