W1001 20:48:06.640000 23002260129600 torch/distributed/run.py:779] 
W1001 20:48:06.640000 23002260129600 torch/distributed/run.py:779] *****************************************
W1001 20:48:06.640000 23002260129600 torch/distributed/run.py:779] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W1001 20:48:06.640000 23002260129600 torch/distributed/run.py:779] *****************************************
flash_kv_decode is set to True
Using device=cuda
Loading model ...
GPTEnsemble(
  (tok_embeddings): Embedding(128256, 4096)
  (layers): ModuleList(
    (0-31): 32 x EnsembleTransformerBlock(
      semi_compiled = False
      (attention): Attention(
        (wqkv): Linear(in_features=4096, out_features=3072, bias=False)
        (wo): Linear(in_features=2048, out_features=4096, bias=False)
      )
      (feed_forward): FeedForward(
        (w1): Linear(in_features=4096, out_features=14336, bias=False)
        (w2): Linear(in_features=7168, out_features=4096, bias=False)
      )
      (ffn_norm): RMSNorm()
      (attention_norm): RMSNorm()
    )
  )
  (norm): RMSNorm()
  (output): Linear(in_features=4096, out_features=128256, bias=False)
)
Time to load model: 1.07 seconds
Prefill latency: 0.10923939303029329 sec
Decode latency: 0.21726775798015296 sec
Compilation time: 0.34 seconds
Compilation time: 0.33 seconds
Prefill latency: 0.10651894891634583 sec
Decode latency: 0.2175936559215188 sec
Prefill latency: 0.10647780005820096 sec
Decode latency: 0.21690549503546208 sec
Prefill latency: 0.10645428800489753 sec
Decode latency: 0.21700343198608607 sec
Prefill latency: 0.10667224891949445 sec
Decode latency: 0.2169488889630884 sec
Prefill latency: 0.10652948496863246 sec
Decode latency: 0.21703771501779556 sec
Time for inference 1: 0.32 sec total, 395.08 tokens/sec
Decode latency: 0.22 sec
Prefill latency: 0.11 sec
Bandwidth achieved: 3172.73 GB/s
FLOPS achieved: 104.70 TF/s

Prefill latency: 0.10682604101020843 sec
Decode latency: 0.21778752701357007 sec
Time for inference 2: 0.33 sec total, 393.84 tokens/sec
Decode latency: 0.22 sec
Prefill latency: 0.11 sec
Bandwidth achieved: 3162.74 GB/s
FLOPS achieved: 104.37 TF/s

Prefill latency: 0.10654698207508773 sec
Decode latency: 0.21707863209303468 sec
Time for inference 3: 0.32 sec total, 394.93 tokens/sec
Decode latency: 0.22 sec
Prefill latency: 0.11 sec
Bandwidth achieved: 3171.53 GB/s
FLOPS achieved: 104.66 TF/s

Prefill latency: 0.10650455497670919 sec
Decode latency: 0.21721811895258725 sec
Time for inference 4: 0.32 sec total, 394.83 tokens/sec
Decode latency: 0.22 sec
Prefill latency: 0.11 sec
Bandwidth achieved: 3170.69 GB/s
FLOPS achieved: 104.63 TF/s

Prefill latency: 0.10651254397816956 sec
Decode latency: 0.2170794529374689 sec
Time for inference 5: 0.32 sec total, 394.98 tokens/sec
Decode latency: 0.22 sec
Prefill latency: 0.11 sec
Bandwidth achieved: 3171.89 GB/s
FLOPS achieved: 104.67 TF/s

Prefill latency: 0.10669661103747785 sec
Decode latency: 0.2174231760436669 sec
Time for inference 6: 0.32 sec total, 394.41 tokens/sec
Decode latency: 0.22 sec
Prefill latency: 0.11 sec
Bandwidth achieved: 3167.31 GB/s
FLOPS achieved: 104.52 TF/s

Prefill latency: 0.10671442304737866 sec
Decode latency: 0.2169528619851917 sec
Time for inference 7: 0.32 sec total, 394.86 tokens/sec
Decode latency: 0.22 sec
Prefill latency: 0.11 sec
Bandwidth achieved: 3170.91 GB/s
FLOPS achieved: 104.64 TF/s

Prefill latency: 0.10669525701086968 sec
Decode latency: 0.21697566204238683 sec
Time for inference 8: 0.32 sec total, 394.86 tokens/sec
Decode latency: 0.22 sec
Prefill latency: 0.11 sec
Bandwidth achieved: 3170.91 GB/s
FLOPS achieved: 104.64 TF/s

Prefill latency: 0.10661946900654584 sec
Decode latency: 0.21712644305080175 sec
Time for inference 9: 0.32 sec total, 394.83 tokens/sec
Decode latency: 0.22 sec
Prefill latency: 0.11 sec
Bandwidth achieved: 3170.73 GB/s
FLOPS achieved: 104.63 TF/s

Prefill latency: 0.10656066297087818 sec
Decode latency: 0.21701117197517306 sec
Time for inference 10: 0.32 sec total, 395.00 tokens/sec
Decode latency: 0.22 sec
Prefill latency: 0.11 sec
Bandwidth achieved: 3172.02 GB/s
FLOPS achieved: 104.68 TF/s

==========
Batch Size: 4
Prompt Length: 1024
Generated tokens: 32
Average decode latency: 0.2172 sec
Average prefill latency: 0.1066 sec
Average tokens/sec: 394.76
Memory used: 11.93 GB
Done. we are killing the process
