W1001 20:36:57.220000 22777002198848 torch/distributed/run.py:779] 
W1001 20:36:57.220000 22777002198848 torch/distributed/run.py:779] *****************************************
W1001 20:36:57.220000 22777002198848 torch/distributed/run.py:779] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W1001 20:36:57.220000 22777002198848 torch/distributed/run.py:779] *****************************************
flash_kv_decode is set to True
Using device=cuda
Loading model ...
GPTParallel(
  (tok_embeddings): Embedding(128256, 4096)
  (layers): ModuleList(
    (0-31): 32 x ParallelTransformerBlock(
      semi_compiled = False
      (attention): FuseAttentionMLP(
        (wqkv1): Linear(in_features=4096, out_features=8704, bias=False)
        (wo): Linear(in_features=1024, out_features=4096, bias=False)
        (w2): Linear(in_features=3584, out_features=4096, bias=False)
      )
      (attention_norm): RMSNorm()
    )
  )
  (norm): RMSNorm()
  (output): Linear(in_features=4096, out_features=128256, bias=False)
)
Time to load model: 1.01 seconds
Prefill latency: 0.0408466289518401 sec
Decode latency: 0.16803306702058762 sec
Compilation time: 0.20 seconds
Compilation time: 0.21 secondsCompilation time: 0.19 seconds
Compilation time: 0.20 seconds

Prefill latency: 0.01636310399044305 sec
Decode latency: 0.16738511400762945 sec
Prefill latency: 0.01637419604230672 sec
Decode latency: 0.16668141598347574 sec
Prefill latency: 0.016290297964587808 sec
Decode latency: 0.16674324998166412 sec
Prefill latency: 0.016297376016154885 sec
Decode latency: 0.16702989698387682 sec
Prefill latency: 0.01629576797131449 sec
Decode latency: 0.16714256105478853 sec
Time for inference 1: 0.18 sec total, 174.08 tokens/sec
Decode latency: 0.17 sec
Prefill latency: 0.02 sec
Bandwidth achieved: 790.43 GB/s
FLOPS achieved: 26.08 TF/s

Prefill latency: 0.016327333985827863 sec
Decode latency: 0.1671633010264486 sec
Time for inference 2: 0.18 sec total, 173.99 tokens/sec
Decode latency: 0.17 sec
Prefill latency: 0.02 sec
Bandwidth achieved: 790.02 GB/s
FLOPS achieved: 26.07 TF/s

Prefill latency: 0.016547180013731122 sec
Decode latency: 0.1671767570078373 sec
Time for inference 3: 0.18 sec total, 173.77 tokens/sec
Decode latency: 0.17 sec
Prefill latency: 0.02 sec
Bandwidth achieved: 789.01 GB/s
FLOPS achieved: 26.04 TF/s

Prefill latency: 0.016326877055689692 sec
Decode latency: 0.16688551905099303 sec
Time for inference 4: 0.18 sec total, 174.21 tokens/sec
Decode latency: 0.17 sec
Prefill latency: 0.02 sec
Bandwidth achieved: 791.00 GB/s
FLOPS achieved: 26.10 TF/s

Prefill latency: 0.016277479007840157 sec
Decode latency: 0.16692960495129228 sec
Time for inference 5: 0.18 sec total, 174.20 tokens/sec
Decode latency: 0.17 sec
Prefill latency: 0.02 sec
Bandwidth achieved: 790.99 GB/s
FLOPS achieved: 26.10 TF/s

Prefill latency: 0.01627156895119697 sec
Decode latency: 0.16665699309669435 sec
Time for inference 6: 0.18 sec total, 174.50 tokens/sec
Decode latency: 0.17 sec
Prefill latency: 0.02 sec
Bandwidth achieved: 792.34 GB/s
FLOPS achieved: 26.15 TF/s

Prefill latency: 0.01628077996429056 sec
Decode latency: 0.16690121300052851 sec
Time for inference 7: 0.18 sec total, 174.25 tokens/sec
Decode latency: 0.17 sec
Prefill latency: 0.02 sec
Bandwidth achieved: 791.21 GB/s
FLOPS achieved: 26.11 TF/s

Prefill latency: 0.016327421995811164 sec
Decode latency: 0.16698566998820752 sec
Time for inference 8: 0.18 sec total, 174.19 tokens/sec
Decode latency: 0.17 sec
Prefill latency: 0.02 sec
Bandwidth achieved: 790.93 GB/s
FLOPS achieved: 26.10 TF/s

Prefill latency: 0.016296004061587155 sec
Decode latency: 0.1671904610702768 sec
Time for inference 9: 0.18 sec total, 174.00 tokens/sec
Decode latency: 0.17 sec
Prefill latency: 0.02 sec
Bandwidth achieved: 790.05 GB/s
FLOPS achieved: 26.07 TF/s

Prefill latency: 0.0163208240410313 sec
Decode latency: 0.16723724000621587 sec
Time for inference 10: 0.18 sec total, 173.94 tokens/sec
Decode latency: 0.17 sec
Prefill latency: 0.02 sec
Bandwidth achieved: 789.81 GB/s
FLOPS achieved: 26.06 TF/s

==========
Batch Size: 1
Prompt Length: 1024
Generated tokens: 32
Average decode latency: 0.1670 sec
Average prefill latency: 0.0163 sec
Average tokens/sec: 174.11
Memory used: 6.48 GB
Done. we are killing the process
