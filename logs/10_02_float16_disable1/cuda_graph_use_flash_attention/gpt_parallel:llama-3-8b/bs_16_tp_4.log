W1001 20:39:24.124000 22964367587136 torch/distributed/run.py:779] 
W1001 20:39:24.124000 22964367587136 torch/distributed/run.py:779] *****************************************
W1001 20:39:24.124000 22964367587136 torch/distributed/run.py:779] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W1001 20:39:24.124000 22964367587136 torch/distributed/run.py:779] *****************************************
flash_kv_decode is set to True
Using device=cuda
Loading model ...
GPTParallel(
  (tok_embeddings): Embedding(128256, 4096)
  (layers): ModuleList(
    (0-31): 32 x ParallelTransformerBlock(
      semi_compiled = False
      (attention): FuseAttentionMLP(
        (wqkv1): Linear(in_features=4096, out_features=8704, bias=False)
        (wo): Linear(in_features=1024, out_features=4096, bias=False)
        (w2): Linear(in_features=3584, out_features=4096, bias=False)
      )
      (attention_norm): RMSNorm()
    )
  )
  (norm): RMSNorm()
  (output): Linear(in_features=4096, out_features=128256, bias=False)
)
Time to load model: 1.05 seconds
Prefill latency: 0.17968172999098897 sec
Decode latency: 0.20626185601577163 sec
Compilation time: 0.39 seconds
Compilation time: 0.39 seconds
Compilation time: 0.39 seconds
Compilation time: 0.39 seconds
Prefill latency: 0.1784547029528767 sec
Decode latency: 0.20756379305385053 sec
Prefill latency: 0.17852151300758123 sec
Decode latency: 0.20673480501864105 sec
Prefill latency: 0.1792826410382986 sec
Decode latency: 0.20643278199713677 sec
Prefill latency: 0.17870222893543541 sec
Decode latency: 0.20661742403171957 sec
Prefill latency: 0.17934263206552714 sec
Decode latency: 0.20730175403878093 sec
Time for inference 1: 0.39 sec total, 1322.26 tokens/sec
Decode latency: 0.21 sec
Prefill latency: 0.18 sec
Bandwidth achieved: 6003.86 GB/s
FLOPS achieved: 198.13 TF/s

Prefill latency: 0.1786803479772061 sec
Decode latency: 0.20631702709943056 sec
Time for inference 2: 0.39 sec total, 1328.09 tokens/sec
Decode latency: 0.21 sec
Prefill latency: 0.18 sec
Bandwidth achieved: 6030.33 GB/s
FLOPS achieved: 199.00 TF/s

Prefill latency: 0.17933083605021238 sec
Decode latency: 0.20665761304553598 sec
Time for inference 3: 0.39 sec total, 1324.73 tokens/sec
Decode latency: 0.21 sec
Prefill latency: 0.18 sec
Bandwidth achieved: 6015.07 GB/s
FLOPS achieved: 198.50 TF/s

Prefill latency: 0.17861637601163238 sec
Decode latency: 0.20769097201991826 sec
Time for inference 4: 0.39 sec total, 1323.51 tokens/sec
Decode latency: 0.21 sec
Prefill latency: 0.18 sec
Bandwidth achieved: 6009.55 GB/s
FLOPS achieved: 198.32 TF/s

Prefill latency: 0.17873090994544327 sec
Decode latency: 0.20700583595316857 sec
Time for inference 5: 0.39 sec total, 1325.54 tokens/sec
Decode latency: 0.21 sec
Prefill latency: 0.18 sec
Bandwidth achieved: 6018.73 GB/s
FLOPS achieved: 198.62 TF/s

Prefill latency: 0.17914803500752896 sec
Decode latency: 0.20700530300382525 sec
Time for inference 6: 0.39 sec total, 1323.91 tokens/sec
Decode latency: 0.21 sec
Prefill latency: 0.18 sec
Bandwidth achieved: 6011.36 GB/s
FLOPS achieved: 198.37 TF/s

Prefill latency: 0.17972232808824629 sec
Decode latency: 0.2063632799545303 sec
Time for inference 7: 0.39 sec total, 1323.98 tokens/sec
Decode latency: 0.21 sec
Prefill latency: 0.18 sec
Bandwidth achieved: 6011.66 GB/s
FLOPS achieved: 198.38 TF/s

Prefill latency: 0.18017170089296997 sec
Decode latency: 0.20652340503875166 sec
Time for inference 8: 0.39 sec total, 1322.21 tokens/sec
Decode latency: 0.21 sec
Prefill latency: 0.18 sec
Bandwidth achieved: 6003.63 GB/s
FLOPS achieved: 198.12 TF/s

Prefill latency: 0.17924803006462753 sec
Decode latency: 0.20697215292602777 sec
Time for inference 9: 0.39 sec total, 1324.13 tokens/sec
Decode latency: 0.21 sec
Prefill latency: 0.18 sec
Bandwidth achieved: 6012.35 GB/s
FLOPS achieved: 198.41 TF/s

Prefill latency: 0.17925238993484527 sec
Decode latency: 0.2061495209345594 sec
Time for inference 10: 0.39 sec total, 1326.87 tokens/sec
Decode latency: 0.21 sec
Prefill latency: 0.18 sec
Bandwidth achieved: 6024.78 GB/s
FLOPS achieved: 198.82 TF/s

==========
Batch Size: 16
Prompt Length: 1024
Generated tokens: 32
Average decode latency: 0.2068 sec
Average prefill latency: 0.1792 sec
Average tokens/sec: 1324.52
Memory used: 18.53 GB
Done. we are killing the process
