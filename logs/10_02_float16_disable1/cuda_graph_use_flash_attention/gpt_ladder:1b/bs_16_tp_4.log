W1001 20:15:26.896000 22974340867904 torch/distributed/run.py:779] 
W1001 20:15:26.896000 22974340867904 torch/distributed/run.py:779] *****************************************
W1001 20:15:26.896000 22974340867904 torch/distributed/run.py:779] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W1001 20:15:26.896000 22974340867904 torch/distributed/run.py:779] *****************************************
flash_kv_decode is set to True
Using device=cuda
Loading model ...
GPTLadder(
  (tok_embeddings): Embedding(49152, 1536)
  (layers): ModuleList(
    (0-39): 40 x LadderTransformerBlock(
      semi_compiled = False
      (attention): Attention(
        (wqkv): Linear(in_features=1536, out_features=1152, bias=False)
        (wo): Linear(in_features=384, out_features=1536, bias=False)
      )
      (feed_forward): FeedForward(
        (w1): Linear(in_features=1536, out_features=2048, bias=False)
        (w2): Linear(in_features=1024, out_features=1536, bias=False)
      )
      (ffn_norm): RMSNorm()
      (attention_norm): RMSNorm()
    )
  )
  (norm): RMSNorm()
  (output): Linear(in_features=1536, out_features=49152, bias=False)
)
Time to load model: 0.14 seconds
Prefill latency: 0.1172935429494828 sec
Decode latency: 2.8279987779678777 sec
Compilation time: 2.95 seconds
Compilation time: 2.95 seconds
Compilation time: 2.95 seconds
Compilation time: 2.95 seconds
Prefill latency: 0.11249951703939587 sec
Decode latency: 2.800004752003588 sec
Prefill latency: 0.1173664319794625 sec
Decode latency: 2.8081263470230624 sec
Prefill latency: 0.1176671840948984 sec
Decode latency: 2.8259895329829305 sec
Prefill latency: 0.11585401999764144 sec
Decode latency: 2.832504009013064 sec
Prefill latency: 0.11299920594319701 sec
Decode latency: 2.837954099988565 sec
Time for inference 1: 2.95 sec total, 1386.37 tokens/sec
Decode latency: 2.84 sec
Prefill latency: 0.11 sec
Bandwidth achieved: 994.69 GB/s
FLOPS achieved: 4.97 TF/s

Prefill latency: 0.11837259703315794 sec
Decode latency: 2.8512594449566677 sec
Time for inference 2: 2.97 sec total, 1377.48 tokens/sec
Decode latency: 2.85 sec
Prefill latency: 0.12 sec
Bandwidth achieved: 988.30 GB/s
FLOPS achieved: 4.94 TF/s

Prefill latency: 0.11672011099290103 sec
Decode latency: 2.875851609976962 sec
Time for inference 3: 3.00 sec total, 1365.52 tokens/sec
Decode latency: 2.88 sec
Prefill latency: 0.12 sec
Bandwidth achieved: 979.72 GB/s
FLOPS achieved: 4.90 TF/s

Prefill latency: 0.11440115596633404 sec
Decode latency: 2.8800693289376795 sec
Time for inference 4: 3.00 sec total, 1365.47 tokens/sec
Decode latency: 2.88 sec
Prefill latency: 0.11 sec
Bandwidth achieved: 979.69 GB/s
FLOPS achieved: 4.90 TF/s

Prefill latency: 0.12002719705924392 sec
Decode latency: 2.892541442066431 sec
Time for inference 5: 3.02 sec total, 1357.58 tokens/sec
Decode latency: 2.89 sec
Prefill latency: 0.12 sec
Bandwidth achieved: 974.03 GB/s
FLOPS achieved: 4.87 TF/s

Prefill latency: 0.1178228649077937 sec
Decode latency: 2.9031703009968624 sec
Time for inference 6: 3.03 sec total, 1352.65 tokens/sec
Decode latency: 2.90 sec
Prefill latency: 0.12 sec
Bandwidth achieved: 970.49 GB/s
FLOPS achieved: 4.85 TF/s

Prefill latency: 0.11621666303835809 sec
Decode latency: 2.9114561280002818 sec
Time for inference 7: 3.03 sec total, 1350.57 tokens/sec
Decode latency: 2.91 sec
Prefill latency: 0.12 sec
Bandwidth achieved: 969.00 GB/s
FLOPS achieved: 4.84 TF/s

Prefill latency: 0.11888846301008016 sec
Decode latency: 2.8692036470165476 sec
Time for inference 8: 2.99 sec total, 1368.50 tokens/sec
Decode latency: 2.87 sec
Prefill latency: 0.12 sec
Bandwidth achieved: 981.86 GB/s
FLOPS achieved: 4.91 TF/s

Prefill latency: 0.11489450396038592 sec
Decode latency: 2.865911612054333 sec
Time for inference 9: 2.99 sec total, 1372.09 tokens/sec
Decode latency: 2.87 sec
Prefill latency: 0.11 sec
Bandwidth achieved: 984.44 GB/s
FLOPS achieved: 4.92 TF/s

Prefill latency: 0.11759679403621703 sec
Decode latency: 2.839973964029923 sec
Time for inference 10: 2.96 sec total, 1382.43 tokens/sec
Decode latency: 2.84 sec
Prefill latency: 0.12 sec
Bandwidth achieved: 991.86 GB/s
FLOPS achieved: 4.96 TF/s

==========
Batch Size: 16
Prompt Length: 1024
Generated tokens: 256
Average decode latency: 2.8727 sec
Average prefill latency: 0.1168 sec
Average tokens/sec: 1367.87
Memory used: 9.06 GB
Done. we are killing the process
