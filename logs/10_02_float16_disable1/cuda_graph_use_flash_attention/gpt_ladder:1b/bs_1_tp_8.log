W1001 20:14:35.635000 23302397773632 torch/distributed/run.py:779] 
W1001 20:14:35.635000 23302397773632 torch/distributed/run.py:779] *****************************************
W1001 20:14:35.635000 23302397773632 torch/distributed/run.py:779] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W1001 20:14:35.635000 23302397773632 torch/distributed/run.py:779] *****************************************
flash_kv_decode is set to True
Using device=cuda
Loading model ...
GPTLadder(
  (tok_embeddings): Embedding(49152, 1536)
  (layers): ModuleList(
    (0-39): 40 x LadderTransformerBlock(
      semi_compiled = False
      (attention): Attention(
        (wqkv): Linear(in_features=1536, out_features=576, bias=False)
        (wo): Linear(in_features=192, out_features=1536, bias=False)
      )
      (feed_forward): FeedForward(
        (w1): Linear(in_features=1536, out_features=1024, bias=False)
        (w2): Linear(in_features=512, out_features=1536, bias=False)
      )
      (ffn_norm): RMSNorm()
      (attention_norm): RMSNorm()
    )
  )
  (norm): RMSNorm()
  (output): Linear(in_features=1536, out_features=49152, bias=False)
)
Time to load model: 0.13 seconds
[rank5]:[W1001 20:14:47.021248268 CUDAGraph.cpp:150] Warning: Waiting for pending NCCL work to finish before starting graph capture. (function operator())
[rank4]:[W1001 20:14:47.021885433 CUDAGraph.cpp:150] Warning: Waiting for pending NCCL work to finish before starting graph capture. (function operator())
[rank3]:[W1001 20:14:47.045217187 CUDAGraph.cpp:150] Warning: Waiting for pending NCCL work to finish before starting graph capture. (function operator())
[rank6]:[W1001 20:14:47.046093773 CUDAGraph.cpp:150] Warning: Waiting for pending NCCL work to finish before starting graph capture. (function operator())
Prefill latency: 0.029156086035072803 sec
Decode latency: 2.4156915630446747 sec
Compilation time: 2.49 seconds
Compilation time: 2.46 seconds
Compilation time: 2.46 seconds
Compilation time: 2.51 seconds
Compilation time: 2.45 seconds
Compilation time: 2.45 secondsCompilation time: 2.48 seconds

Compilation time: 2.51 seconds
Prefill latency: 0.02727016806602478 sec
Decode latency: 2.426857296959497 sec
Prefill latency: 0.027603746973909438 sec
Decode latency: 2.3956915310118347 sec
Prefill latency: 0.021935252007097006 sec
Decode latency: 2.373264266992919 sec
Prefill latency: 0.02055367804132402 sec
Decode latency: 2.3790872109821066 sec
Prefill latency: 0.024810669012367725 sec
Decode latency: 2.3460581679828465 sec
Time for inference 1: 2.37 sec total, 107.81 tokens/sec
Decode latency: 2.35 sec
Prefill latency: 0.02 sec
Bandwidth achieved: 46.83 GB/s
FLOPS achieved: 0.23 TF/s

Prefill latency: 0.024036384071223438 sec
Decode latency: 2.3480891690123826 sec
Time for inference 2: 2.38 sec total, 107.75 tokens/sec
Decode latency: 2.35 sec
Prefill latency: 0.02 sec
Bandwidth achieved: 46.80 GB/s
FLOPS achieved: 0.23 TF/s

Prefill latency: 0.02229250397067517 sec
Decode latency: 2.34905771096237 sec
Time for inference 3: 2.38 sec total, 107.69 tokens/sec
Decode latency: 2.35 sec
Prefill latency: 0.02 sec
Bandwidth achieved: 46.77 GB/s
FLOPS achieved: 0.23 TF/s

Prefill latency: 0.029049837961792946 sec
Decode latency: 2.3417729209177196 sec
Time for inference 4: 2.38 sec total, 107.72 tokens/sec
Decode latency: 2.34 sec
Prefill latency: 0.03 sec
Bandwidth achieved: 46.79 GB/s
FLOPS achieved: 0.23 TF/s

Prefill latency: 0.018502895953133702 sec
Decode latency: 2.353223604033701 sec
Time for inference 5: 2.38 sec total, 107.76 tokens/sec
Decode latency: 2.35 sec
Prefill latency: 0.02 sec
Bandwidth achieved: 46.80 GB/s
FLOPS achieved: 0.23 TF/s

Prefill latency: 0.021875596954487264 sec
Decode latency: 2.3566165569936857 sec
Time for inference 6: 2.38 sec total, 107.36 tokens/sec
Decode latency: 2.36 sec
Prefill latency: 0.02 sec
Bandwidth achieved: 46.63 GB/s
FLOPS achieved: 0.23 TF/s

Prefill latency: 0.019273275043815374 sec
Decode latency: 2.3627725830301642 sec
Time for inference 7: 2.39 sec total, 107.17 tokens/sec
Decode latency: 2.36 sec
Prefill latency: 0.02 sec
Bandwidth achieved: 46.55 GB/s
FLOPS achieved: 0.23 TF/s

Prefill latency: 0.020538847078569233 sec
Decode latency: 2.3653381229378283 sec
Time for inference 8: 2.39 sec total, 107.15 tokens/sec
Decode latency: 2.37 sec
Prefill latency: 0.02 sec
Bandwidth achieved: 46.54 GB/s
FLOPS achieved: 0.23 TF/s

Prefill latency: 0.025335135986097157 sec
Decode latency: 2.3827020180178806 sec
Time for inference 9: 2.41 sec total, 106.17 tokens/sec
Decode latency: 2.38 sec
Prefill latency: 0.03 sec
Bandwidth achieved: 46.12 GB/s
FLOPS achieved: 0.23 TF/s

Prefill latency: 0.026967971003614366 sec
Decode latency: 2.380571777932346 sec
Time for inference 10: 2.41 sec total, 106.23 tokens/sec
Decode latency: 2.38 sec
Prefill latency: 0.03 sec
Bandwidth achieved: 46.14 GB/s
FLOPS achieved: 0.23 TF/s

==========
Batch Size: 1
Prompt Length: 1024
Generated tokens: 256
Average decode latency: 2.3586 sec
Average prefill latency: 0.0233 sec
Average tokens/sec: 107.28
Memory used: 1.17 GB
Done. we are killing the process
