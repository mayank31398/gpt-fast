W1001 20:13:55.753000 22619432146752 torch/distributed/run.py:779] 
W1001 20:13:55.753000 22619432146752 torch/distributed/run.py:779] *****************************************
W1001 20:13:55.753000 22619432146752 torch/distributed/run.py:779] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W1001 20:13:55.753000 22619432146752 torch/distributed/run.py:779] *****************************************
flash_kv_decode is set to True
Using device=cuda
Loading model ...
GPTLadder(
  (tok_embeddings): Embedding(49152, 1536)
  (layers): ModuleList(
    (0-39): 40 x LadderTransformerBlock(
      semi_compiled = False
      (attention): Attention(
        (wqkv): Linear(in_features=1536, out_features=1152, bias=False)
        (wo): Linear(in_features=384, out_features=1536, bias=False)
      )
      (feed_forward): FeedForward(
        (w1): Linear(in_features=1536, out_features=2048, bias=False)
        (w2): Linear(in_features=1024, out_features=1536, bias=False)
      )
      (ffn_norm): RMSNorm()
      (attention_norm): RMSNorm()
    )
  )
  (norm): RMSNorm()
  (output): Linear(in_features=1536, out_features=49152, bias=False)
)
Time to load model: 0.16 seconds
[rank1]:[W1001 20:14:02.750356594 CUDAGraph.cpp:150] Warning: Waiting for pending NCCL work to finish before starting graph capture. (function operator())
[rank3]:[W1001 20:14:02.759064306 CUDAGraph.cpp:150] Warning: Waiting for pending NCCL work to finish before starting graph capture. (function operator())
[rank0]:[W1001 20:14:02.780521516 CUDAGraph.cpp:150] Warning: Waiting for pending NCCL work to finish before starting graph capture. (function operator())
[rank2]:[W1001 20:14:02.197966491 CUDAGraph.cpp:150] Warning: Waiting for pending NCCL work to finish before starting graph capture. (function operator())
Prefill latency: 0.014259304036386311 sec
Decode latency: 2.0309937349520624 sec
Compilation time: 2.05 seconds
Compilation time: 2.05 seconds
Compilation time: 2.09 seconds
Compilation time: 2.08 seconds
Prefill latency: 0.02002256305422634 sec
Decode latency: 2.0293683849740773 sec
Prefill latency: 0.01927317795343697 sec
Decode latency: 2.033007796970196 sec
Prefill latency: 0.019367892062291503 sec
Decode latency: 2.0441697239875793 sec
Prefill latency: 0.019353854935616255 sec
Decode latency: 2.0457738570403308 sec
Prefill latency: 0.01731196208857 sec
Decode latency: 2.0546323760645464 sec
Time for inference 1: 2.08 sec total, 123.17 tokens/sec
Decode latency: 2.05 sec
Prefill latency: 0.02 sec
Bandwidth achieved: 88.37 GB/s
FLOPS achieved: 0.44 TF/s

Prefill latency: 0.019350868999026716 sec
Decode latency: 2.054122597910464 sec
Time for inference 2: 2.08 sec total, 123.19 tokens/sec
Decode latency: 2.05 sec
Prefill latency: 0.02 sec
Bandwidth achieved: 88.38 GB/s
FLOPS achieved: 0.44 TF/s

Prefill latency: 0.01954089303035289 sec
Decode latency: 2.039377846987918 sec
Time for inference 3: 2.06 sec total, 124.15 tokens/sec
Decode latency: 2.04 sec
Prefill latency: 0.02 sec
Bandwidth achieved: 89.08 GB/s
FLOPS achieved: 0.45 TF/s

Prefill latency: 0.019929461064748466 sec
Decode latency: 2.0286986000137404 sec
Time for inference 4: 2.05 sec total, 124.66 tokens/sec
Decode latency: 2.03 sec
Prefill latency: 0.02 sec
Bandwidth achieved: 89.44 GB/s
FLOPS achieved: 0.45 TF/s

Prefill latency: 0.015259016072377563 sec
Decode latency: 2.028417036985047 sec
Time for inference 5: 2.05 sec total, 124.85 tokens/sec
Decode latency: 2.03 sec
Prefill latency: 0.02 sec
Bandwidth achieved: 89.58 GB/s
FLOPS achieved: 0.45 TF/s

Prefill latency: 0.01933252508752048 sec
Decode latency: 2.0340839190175757 sec
Time for inference 6: 2.06 sec total, 124.55 tokens/sec
Decode latency: 2.03 sec
Prefill latency: 0.02 sec
Bandwidth achieved: 89.36 GB/s
FLOPS achieved: 0.45 TF/s

Prefill latency: 0.01979303394909948 sec
Decode latency: 1.9935732850572094 sec
Time for inference 7: 2.02 sec total, 126.93 tokens/sec
Decode latency: 1.99 sec
Prefill latency: 0.02 sec
Bandwidth achieved: 91.07 GB/s
FLOPS achieved: 0.46 TF/s

Prefill latency: 0.019841092987917364 sec
Decode latency: 1.9776143829803914 sec
Time for inference 8: 2.00 sec total, 127.84 tokens/sec
Decode latency: 1.98 sec
Prefill latency: 0.02 sec
Bandwidth achieved: 91.72 GB/s
FLOPS achieved: 0.46 TF/s

Prefill latency: 0.01708670996595174 sec
Decode latency: 1.996170355938375 sec
Time for inference 9: 2.02 sec total, 127.02 tokens/sec
Decode latency: 2.00 sec
Prefill latency: 0.02 sec
Bandwidth achieved: 91.13 GB/s
FLOPS achieved: 0.46 TF/s

Prefill latency: 0.019847603049129248 sec
Decode latency: 1.9903354940470308 sec
Time for inference 10: 2.02 sec total, 127.03 tokens/sec
Decode latency: 1.99 sec
Prefill latency: 0.02 sec
Bandwidth achieved: 91.14 GB/s
FLOPS achieved: 0.46 TF/s

==========
Batch Size: 1
Prompt Length: 1024
Generated tokens: 256
Average decode latency: 2.0197 sec
Average prefill latency: 0.0187 sec
Average tokens/sec: 125.34
Memory used: 1.50 GB
Done. we are killing the process
