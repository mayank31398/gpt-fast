W1124 21:21:39.008000 396958 site-packages/torch/distributed/run.py:793] 
W1124 21:21:39.008000 396958 site-packages/torch/distributed/run.py:793] *****************************************
W1124 21:21:39.008000 396958 site-packages/torch/distributed/run.py:793] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W1124 21:21:39.008000 396958 site-packages/torch/distributed/run.py:793] *****************************************
rank: 0, global_rank: 0, world_size: 2, global_world_size: 2
rank: 1, global_rank: 1, world_size: 2, global_world_size: 2
rank: 0, global_rank: 0, world_size: 2, global_world_size: 2
rank: 0, global_rank: 0, world_size: 2, global_world_size: 2
rank: 0, global_rank: 0, world_size: 2, global_world_size: 2
rank: 0, global_rank: 0, world_size: 2, global_world_size: 2
flash_kv_decode is set to True
rank: 0, global_rank: 0, world_size: 2, global_world_size: 2
our world size=2
Using device=cuda
Loading model ...
rank: 1, global_rank: 1, world_size: 2, global_world_size: 2
rank: 1, global_rank: 1, world_size: 2, global_world_size: 2
rank: 1, global_rank: 1, world_size: 2, global_world_size: 2
rank: 1, global_rank: 1, world_size: 2, global_world_size: 2
rank: 1, global_rank: 1, world_size: 2, global_world_size: 2
GPTEnsemble(
  (tok_embeddings): Embedding(128256, 4096)
  (layers): ModuleList(
    (0-31): 32 x EnsembleTransformerBlock(
      semi_compiled = False
      (attention): Attention(
        (wqkv): Linear(in_features=4096, out_features=3072, bias=False)
        (wo): Linear(in_features=2048, out_features=4096, bias=False)
      )
      (feed_forward): FeedForward(
        (w1): Linear(in_features=4096, out_features=14336, bias=False)
        (w2): Linear(in_features=7168, out_features=4096, bias=False)
      )
      (ffn_norm): RMSNorm()
      (attention_norm): RMSNorm()
    )
  )
  (norm): RMSNorm()
  (output): Linear(in_features=4096, out_features=128256, bias=False)
)
Time to load model: 0.94 seconds
CUDA_GRAPH are activate
Prefill latency: 2.3154162038117647 sec
Compilation time: 8.22 seconds
Decode latency: 5.95864187926054 sec
Compilation time: 8.28 seconds
Prefill latency: 2.318757003173232 sec
Decode latency: 5.958500457927585 sec
Prefill latency: 2.3163355886936188 sec
Decode latency: 5.957828924059868 sec
Prefill latency: 2.3203230910003185 sec
Decode latency: 5.958860935643315 sec
Prefill latency: 2.319706615060568 sec
Decode latency: 5.958661610260606 sec
Prefill latency: 2.3212348613888025 sec
Decode latency: 5.944498026743531 sec
Time for inference 1: 8.27 sec total, 7927.69 tokens/sec
Decode latency: 5.94 sec
Prefill latency: 2.32 sec
Bandwidth achieved: 63663.53 GB/s
FLOPS achieved: 190.99 TF/s

Prefill latency: 2.321696499362588 sec
Decode latency: 5.958711443468928 sec
Time for inference 2: 8.28 sec total, 7913.69 tokens/sec
Decode latency: 5.96 sec
Prefill latency: 2.32 sec
Bandwidth achieved: 63551.15 GB/s
FLOPS achieved: 190.65 TF/s

Prefill latency: 2.3261792678385973 sec
Decode latency: 5.956859804689884 sec
Time for inference 3: 8.28 sec total, 7910.94 tokens/sec
Decode latency: 5.96 sec
Prefill latency: 2.33 sec
Bandwidth achieved: 63529.05 GB/s
FLOPS achieved: 190.59 TF/s

Prefill latency: 2.325894819572568 sec
Decode latency: 5.954887600615621 sec
Time for inference 4: 8.28 sec total, 7913.32 tokens/sec
Decode latency: 5.95 sec
Prefill latency: 2.33 sec
Bandwidth achieved: 63548.15 GB/s
FLOPS achieved: 190.64 TF/s

Prefill latency: 2.3216033950448036 sec
Decode latency: 5.958539856597781 sec
Time for inference 5: 8.28 sec total, 7913.93 tokens/sec
Decode latency: 5.96 sec
Prefill latency: 2.32 sec
Bandwidth achieved: 63553.07 GB/s
FLOPS achieved: 190.66 TF/s

Prefill latency: 2.3223475720733404 sec
Decode latency: 5.958061700686812 sec
Time for inference 6: 8.28 sec total, 7913.51 tokens/sec
Decode latency: 5.96 sec
Prefill latency: 2.32 sec
Bandwidth achieved: 63549.69 GB/s
FLOPS achieved: 190.65 TF/s

Prefill latency: 2.321512158960104 sec
Decode latency: 5.957558572292328 sec
Time for inference 7: 8.28 sec total, 7914.92 tokens/sec
Decode latency: 5.96 sec
Prefill latency: 2.32 sec
Bandwidth achieved: 63560.96 GB/s
FLOPS achieved: 190.68 TF/s

Prefill latency: 2.322006432339549 sec
Decode latency: 5.8239026833325624 sec
Time for inference 8: 8.15 sec total, 8044.26 tokens/sec
Decode latency: 5.82 sec
Prefill latency: 2.32 sec
Bandwidth achieved: 64599.69 GB/s
FLOPS achieved: 193.80 TF/s

Prefill latency: 2.320805087685585 sec
Decode latency: 5.957920091226697 sec
Time for inference 9: 8.28 sec total, 7915.33 tokens/sec
Decode latency: 5.96 sec
Prefill latency: 2.32 sec
Bandwidth achieved: 63564.30 GB/s
FLOPS achieved: 190.69 TF/s

Prefill latency: 2.3275812435895205 sec
[rank1]:[W1124 21:23:58.195182173 ProcessGroupNCCL.cpp:4393] [PG ID 0 PG GUID 0 Rank 1]  using GPU 1 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.
Decode latency: 5.958582986146212 sec
Time for inference 10: 8.29 sec total, 7908.12 tokens/sec
Decode latency: 5.96 sec
Prefill latency: 2.33 sec
Bandwidth achieved: 63506.40 GB/s
FLOPS achieved: 190.52 TF/s

==========
Batch Size: 128
Prompt Length: 1024
Generated tokens: 512
Average decode latency: 5.9430 sec
Average prefill latency: 2.3231 sec
Average tokens/sec: 7927.57
Memory used: 70.67 GB
[rank0]:[W1124 21:23:59.645069326 ProcessGroupNCCL.cpp:4393] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.
Done. we are killing the process
[rank0]:[W1124 21:24:02.663763121 ProcessGroupNCCL.cpp:1374] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
