rank: 0, global_rank: 0, world_size: 1, global_world_size: 1
rank: 0, global_rank: 0, world_size: 1, global_world_size: 1
rank: 0, global_rank: 0, world_size: 1, global_world_size: 1
rank: 0, global_rank: 0, world_size: 1, global_world_size: 1
rank: 0, global_rank: 0, world_size: 1, global_world_size: 1
flash_kv_decode is set to True
rank: 0, global_rank: 0, world_size: 1, global_world_size: 1
our world size=1
Using device=cuda
Loading model ...
GPTLadder(
  (tok_embeddings): Embedding(128256, 4096)
  (layers): ModuleList(
    (0-31): 32 x LadderTransformerBlock(
      semi_compiled = False
      (attention): Attention(
        (wqkv): Linear(in_features=4096, out_features=6144, bias=False)
        (wo): Linear(in_features=4096, out_features=4096, bias=False)
      )
      (feed_forward): FeedForward(
        (w1): Linear(in_features=4096, out_features=28672, bias=False)
        (w2): Linear(in_features=14336, out_features=4096, bias=False)
      )
      (ffn_norm): RMSNorm()
      (attention_norm): RMSNorm()
    )
  )
  (norm): RMSNorm()
  (output): Linear(in_features=4096, out_features=128256, bias=False)
)
Time to load model: 0.21 seconds
CUDA_GRAPH are activate
[rank0]:[W1201 16:07:55.775391915 CUDAGraph.cpp:133] Warning: Waiting for pending NCCL work to finish before starting graph capture. (function operator())
Prefill latency: 0.5278684291988611 sec
Decode latency: 5.129656758159399 sec
Compilation time: 5.66 seconds
Prefill latency: 0.5292652160860598 sec
Decode latency: 5.172747524920851 sec
Prefill latency: 0.5320229437202215 sec
Decode latency: 5.203223489224911 sec
Prefill latency: 0.529204314108938 sec
Decode latency: 5.258567380253226 sec
Prefill latency: 0.5311333290301263 sec
Decode latency: 5.1070174355991185 sec
Prefill latency: 0.5301709109917283 sec
Decode latency: 5.249278270173818 sec
Time for inference 1: 5.78 sec total, 1417.14 tokens/sec
Decode latency: 5.25 sec
Prefill latency: 0.53 sec
Bandwidth achieved: 21271.09 GB/s
FLOPS achieved: 63.81 TF/s

Prefill latency: 0.5303071751259267 sec
Decode latency: 5.106355426833034 sec
Time for inference 2: 5.64 sec total, 1453.04 tokens/sec
Decode latency: 5.11 sec
Prefill latency: 0.53 sec
Bandwidth achieved: 21809.86 GB/s
FLOPS achieved: 65.43 TF/s

Prefill latency: 0.5313764531165361 sec
Decode latency: 5.219549966044724 sec
Time for inference 3: 5.75 sec total, 1424.15 tokens/sec
Decode latency: 5.22 sec
Prefill latency: 0.53 sec
Bandwidth achieved: 21376.25 GB/s
FLOPS achieved: 64.13 TF/s

Prefill latency: 0.5322095500305295 sec
Decode latency: 5.259080784860998 sec
Time for inference 4: 5.79 sec total, 1414.28 tokens/sec
Decode latency: 5.26 sec
Prefill latency: 0.53 sec
Bandwidth achieved: 21228.12 GB/s
FLOPS achieved: 63.68 TF/s

Prefill latency: 0.53066869918257 sec
Decode latency: 5.249121704138815 sec
Time for inference 5: 5.78 sec total, 1417.10 tokens/sec
Decode latency: 5.25 sec
Prefill latency: 0.53 sec
Bandwidth achieved: 21270.52 GB/s
FLOPS achieved: 63.81 TF/s

Prefill latency: 0.5333111910149455 sec
Decode latency: 5.254749078769237 sec
Time for inference 6: 5.79 sec total, 1415.03 tokens/sec
Decode latency: 5.25 sec
Prefill latency: 0.53 sec
Bandwidth achieved: 21239.38 GB/s
FLOPS achieved: 63.72 TF/s

Prefill latency: 0.5314820888452232 sec
Decode latency: 5.203240635339171 sec
Time for inference 7: 5.74 sec total, 1428.19 tokens/sec
Decode latency: 5.20 sec
Prefill latency: 0.53 sec
Bandwidth achieved: 21436.92 GB/s
FLOPS achieved: 64.31 TF/s

Prefill latency: 0.5302117061801255 sec
Decode latency: 5.094250848982483 sec
Time for inference 8: 5.63 sec total, 1456.16 tokens/sec
Decode latency: 5.09 sec
Prefill latency: 0.53 sec
Bandwidth achieved: 21856.67 GB/s
FLOPS achieved: 65.57 TF/s

Prefill latency: 0.5311421910300851 sec
Decode latency: 5.106129657011479 sec
Time for inference 9: 5.64 sec total, 1452.91 tokens/sec
Decode latency: 5.11 sec
Prefill latency: 0.53 sec
Bandwidth achieved: 21807.90 GB/s
FLOPS achieved: 65.42 TF/s

Prefill latency: 0.5300129102542996 sec
Decode latency: 5.147292497102171 sec
Time for inference 10: 5.68 sec total, 1442.66 tokens/sec
Decode latency: 5.15 sec
Prefill latency: 0.53 sec
Bandwidth achieved: 21654.04 GB/s
FLOPS achieved: 64.96 TF/s

==========
Batch Size: 16
Prompt Length: 1024
Generated tokens: 512
Average decode latency: 5.1889 sec
Average prefill latency: 0.5311 sec
Average tokens/sec: 1432.06
Memory used: 35.95 GB
Done. we are killing the process
[rank0]:[W1201 16:09:21.748201897 ProcessGroupNCCL.cpp:1374] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
