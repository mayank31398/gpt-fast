W1124 21:43:48.036000 418568 site-packages/torch/distributed/run.py:793] 
W1124 21:43:48.036000 418568 site-packages/torch/distributed/run.py:793] *****************************************
W1124 21:43:48.036000 418568 site-packages/torch/distributed/run.py:793] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W1124 21:43:48.036000 418568 site-packages/torch/distributed/run.py:793] *****************************************
rank: 1, global_rank: 1, world_size: 2, global_world_size: 2
rank: 0, global_rank: 0, world_size: 2, global_world_size: 2
rank: 0, global_rank: 0, world_size: 2, global_world_size: 2
rank: 0, global_rank: 0, world_size: 2, global_world_size: 2
rank: 0, global_rank: 0, world_size: 2, global_world_size: 2
rank: 0, global_rank: 0, world_size: 2, global_world_size: 2
flash_kv_decode is set to True
rank: 0, global_rank: 0, world_size: 2, global_world_size: 2
our world size=2
Using device=cuda
Loading model ...
rank: 1, global_rank: 1, world_size: 2, global_world_size: 2
rank: 1, global_rank: 1, world_size: 2, global_world_size: 2
rank: 1, global_rank: 1, world_size: 2, global_world_size: 2
rank: 1, global_rank: 1, world_size: 2, global_world_size: 2
rank: 1, global_rank: 1, world_size: 2, global_world_size: 2
GPTEnsemble(
  (tok_embeddings): Embedding(128256, 4096)
  (layers): ModuleList(
    (0-31): 32 x EnsembleTransformerBlock(
      semi_compiled = False
      (attention): Attention(
        (wqkv): Linear(in_features=4096, out_features=3072, bias=False)
        (wo): Linear(in_features=2048, out_features=4096, bias=False)
      )
      (feed_forward): FeedForward(
        (w1): Linear(in_features=4096, out_features=14336, bias=False)
        (w2): Linear(in_features=7168, out_features=4096, bias=False)
      )
      (ffn_norm): RMSNorm()
      (attention_norm): RMSNorm()
    )
  )
  (norm): RMSNorm()
  (output): Linear(in_features=4096, out_features=128256, bias=False)
)
Time to load model: 1.07 seconds
CUDA_GRAPH are activate
Prefill latency: 2.3148978240787983 sec
Compilation time: 8.13 seconds
Decode latency: 5.959184855222702 sec
Compilation time: 8.28 seconds
Prefill latency: 2.3259457387030125 sec
Decode latency: 5.958470648154616 sec
Prefill latency: 2.3240509256720543 sec
Decode latency: 5.958591913804412 sec
Prefill latency: 2.323534006252885 sec
Decode latency: 5.958595938980579 sec
Prefill latency: 2.317210868000984 sec
Decode latency: 5.9587233196944 sec
Prefill latency: 2.3206806294620037 sec
Decode latency: 5.958452807739377 sec
Time for inference 1: 8.28 sec total, 7914.79 tokens/sec
Decode latency: 5.96 sec
Prefill latency: 2.32 sec
Bandwidth achieved: 63559.97 GB/s
FLOPS achieved: 190.68 TF/s

Prefill latency: 2.323817463591695 sec
Decode latency: 5.928014075383544 sec
Time for inference 2: 8.25 sec total, 7940.95 tokens/sec
Decode latency: 5.93 sec
Prefill latency: 2.32 sec
Bandwidth achieved: 63769.98 GB/s
FLOPS achieved: 191.31 TF/s

Prefill latency: 2.3239088244736195 sec
Decode latency: 5.958590675145388 sec
Time for inference 3: 8.28 sec total, 7911.62 tokens/sec
Decode latency: 5.96 sec
Prefill latency: 2.32 sec
Bandwidth achieved: 63534.50 GB/s
FLOPS achieved: 190.60 TF/s

Prefill latency: 2.319464933127165 sec
Decode latency: 5.959091942757368 sec
Time for inference 4: 8.28 sec total, 7915.45 tokens/sec
Decode latency: 5.96 sec
Prefill latency: 2.32 sec
Bandwidth achieved: 63565.26 GB/s
FLOPS achieved: 190.70 TF/s

Prefill latency: 2.3267094921320677 sec
Decode latency: 5.959280524402857 sec
Time for inference 5: 8.29 sec total, 7908.32 tokens/sec
Decode latency: 5.96 sec
Prefill latency: 2.33 sec
Bandwidth achieved: 63507.97 GB/s
FLOPS achieved: 190.52 TF/s

Prefill latency: 2.321200232952833 sec
Decode latency: 5.9585685431957245 sec
Time for inference 6: 8.28 sec total, 7914.15 tokens/sec
Decode latency: 5.96 sec
Prefill latency: 2.32 sec
Bandwidth achieved: 63554.80 GB/s
FLOPS achieved: 190.66 TF/s

Prefill latency: 2.3187547400593758 sec
Decode latency: 5.958050211891532 sec
Time for inference 7: 8.28 sec total, 7916.94 tokens/sec
Decode latency: 5.96 sec
Prefill latency: 2.32 sec
Bandwidth achieved: 63577.17 GB/s
FLOPS achieved: 190.73 TF/s

Prefill latency: 2.3202557247132063 sec
Decode latency: 5.9589721746742725 sec
Time for inference 8: 8.28 sec total, 7914.69 tokens/sec
Decode latency: 5.96 sec
Prefill latency: 2.32 sec
Bandwidth achieved: 63559.15 GB/s
FLOPS achieved: 190.68 TF/s

Prefill latency: 2.3232660181820393 sec
Decode latency: 5.958257349207997 sec
Time for inference 9: 8.28 sec total, 7912.43 tokens/sec
Decode latency: 5.96 sec
Prefill latency: 2.32 sec
Bandwidth achieved: 63541.00 GB/s
FLOPS achieved: 190.62 TF/s

Prefill latency: 2.323609882965684 sec
[rank1]:[W1124 21:46:08.039499045 ProcessGroupNCCL.cpp:4393] [PG ID 0 PG GUID 0 Rank 1]  using GPU 1 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.
Decode latency: 5.958563160151243 sec
Time for inference 10: 8.28 sec total, 7911.90 tokens/sec
Decode latency: 5.96 sec
Prefill latency: 2.32 sec
Bandwidth achieved: 63536.71 GB/s
FLOPS achieved: 190.61 TF/s

==========
Batch Size: 128
Prompt Length: 1024
Generated tokens: 512
Average decode latency: 5.9556 sec
Average prefill latency: 2.3222 sec
Average tokens/sec: 7916.12
Memory used: 70.67 GB
[rank0]:[W1124 21:46:10.851906616 ProcessGroupNCCL.cpp:4393] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.
Done. we are killing the process
[rank0]:[W1124 21:46:12.284089927 ProcessGroupNCCL.cpp:1374] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
