W1203 12:41:36.313000 1856795 site-packages/torch/distributed/run.py:793] 
W1203 12:41:36.313000 1856795 site-packages/torch/distributed/run.py:793] *****************************************
W1203 12:41:36.313000 1856795 site-packages/torch/distributed/run.py:793] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W1203 12:41:36.313000 1856795 site-packages/torch/distributed/run.py:793] *****************************************
DeviceMesh('cuda', [[0, 1]], mesh_dim_names=('pp', 'tp'))
Using device=cuda
Loading model ...
DeviceMesh('cuda', [[0, 1]], mesh_dim_names=('pp', 'tp'))
GPTDense(
  (tok_embeddings): Embedding(128256, 4096)
  (layers): ModuleList(
    (0-31): 32 x DenseTransformerBlock(
      semi_compiled = False
      (attention): Attention(
        (wqkv): Linear(in_features=4096, out_features=3072, bias=False)
        (wo): Linear(in_features=2048, out_features=4096, bias=False)
      )
      (feed_forward): FeedForward(
        (w1): Linear(in_features=4096, out_features=14336, bias=False)
        (w2): Linear(in_features=7168, out_features=4096, bias=False)
      )
      (ffn_norm): RMSNorm()
      (attention_norm): RMSNorm()
    )
  )
  (norm): RMSNorm()
  (output): Linear(in_features=4096, out_features=128256, bias=False)
)
Time to load model: 1.20 seconds
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
Compiling prefill with dynamic=False
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py:222: UserWarning: TensorFloat32 tensor cores for float32 matrix multiplication available but not enabled. Consider setting `torch.set_float32_matmul_precision('high')` for better performance.
  warnings.warn(
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/site-packages/torch/_inductor/compile_fx.py:222: UserWarning: TensorFloat32 tensor cores for float32 matrix multiplication available but not enabled. Consider setting `torch.set_float32_matmul_precision('high')` for better performance.
  warnings.warn(
Prefill latency: 40.30659936903976 sec
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
Decode latency: 56.334773582057096 sec
Compilation time: 96.72 seconds
Compilation time: 96.64 seconds
Prefill latency: 0.06871465092990547 sec
Decode latency: 2.4891380390617996 sec
Prefill latency: 0.06771318102255464 sec
Decode latency: 2.4891246779588982 sec
Prefill latency: 0.0680076559074223 sec
Decode latency: 2.4885129580507055 sec
Prefill latency: 0.0674155690940097 sec
Decode latency: 2.489433276001364 sec
Prefill latency: 0.06743400997947901 sec
Decode latency: 2.490395141998306 sec
Time for inference 1: 2.56 sec total, 200.00 tokens/sec
Decode latency: 2.49 sec
Prefill latency: 0.07 sec
Bandwidth achieved: 1606.10 GB/s
FLOPS achieved: 4.82 TF/s

Prefill latency: 0.06778747099451721 sec
Decode latency: 2.489262072951533 sec
Time for inference 2: 2.56 sec total, 200.08 tokens/sec
Decode latency: 2.49 sec
Prefill latency: 0.07 sec
Bandwidth achieved: 1606.75 GB/s
FLOPS achieved: 4.82 TF/s

Prefill latency: 0.06795691000297666 sec
Decode latency: 2.4882757330778986 sec
Time for inference 3: 2.56 sec total, 200.14 tokens/sec
Decode latency: 2.49 sec
Prefill latency: 0.07 sec
Bandwidth achieved: 1607.21 GB/s
FLOPS achieved: 4.82 TF/s

Prefill latency: 0.06758797098882496 sec
Decode latency: 2.489342035027221 sec
Time for inference 4: 2.56 sec total, 200.09 tokens/sec
Decode latency: 2.49 sec
Prefill latency: 0.07 sec
Bandwidth achieved: 1606.86 GB/s
FLOPS achieved: 4.82 TF/s

Prefill latency: 0.06757531897164881 sec
Decode latency: 2.488890881999396 sec
Time for inference 5: 2.56 sec total, 200.13 tokens/sec
Decode latency: 2.49 sec
Prefill latency: 0.07 sec
Bandwidth achieved: 1607.13 GB/s
FLOPS achieved: 4.82 TF/s

Prefill latency: 0.0677512539550662 sec
Decode latency: 2.4898728360421956 sec
Time for inference 6: 2.56 sec total, 200.04 tokens/sec
Decode latency: 2.49 sec
Prefill latency: 0.07 sec
Bandwidth achieved: 1606.44 GB/s
FLOPS achieved: 4.82 TF/s

Prefill latency: 0.06773012294434011 sec
Decode latency: 2.488588275038637 sec
Time for inference 7: 2.56 sec total, 200.15 tokens/sec
Decode latency: 2.49 sec
Prefill latency: 0.07 sec
Bandwidth achieved: 1607.28 GB/s
FLOPS achieved: 4.82 TF/s

Prefill latency: 0.06798267795238644 sec
Decode latency: 2.488753800978884 sec
Time for inference 8: 2.56 sec total, 200.12 tokens/sec
Decode latency: 2.49 sec
Prefill latency: 0.07 sec
Bandwidth achieved: 1607.04 GB/s
FLOPS achieved: 4.82 TF/s

Prefill latency: 0.06744177092332393 sec
Decode latency: 2.4886278649792075 sec
Time for inference 9: 2.56 sec total, 200.17 tokens/sec
Decode latency: 2.49 sec
Prefill latency: 0.07 sec
Bandwidth achieved: 1607.47 GB/s
FLOPS achieved: 4.82 TF/s

Prefill latency: 0.06744881393387914 sec
Decode latency: 2.4884242030093446 sec
Time for inference 10: 2.56 sec total, 200.17 tokens/sec
Decode latency: 2.49 sec
Prefill latency: 0.07 sec
Bandwidth achieved: 1607.47 GB/s
FLOPS achieved: 4.82 TF/s

==========
Batch Size: 1
Prompt Length: 1024
Generated tokens: 512
Average decode latency: 2.4890 sec
Average prefill latency: 0.0677 sec
Average tokens/sec: 200.11
Memory used: 10.14 GB
Done. we are killing the process
[rank1]:[W1203 12:43:55.079310792 ProcessGroupNCCL.cpp:1374] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
[rank0]:[W1203 12:43:55.411432925 ProcessGroupNCCL.cpp:1374] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
