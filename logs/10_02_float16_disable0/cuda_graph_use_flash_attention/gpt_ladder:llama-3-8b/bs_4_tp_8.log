W1001 18:56:47.597000 22934532478784 torch/distributed/run.py:779] 
W1001 18:56:47.597000 22934532478784 torch/distributed/run.py:779] *****************************************
W1001 18:56:47.597000 22934532478784 torch/distributed/run.py:779] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W1001 18:56:47.597000 22934532478784 torch/distributed/run.py:779] *****************************************
flash_kv_decode is set to True
Using device=cuda
Loading model ...
GPTLadder(
  (tok_embeddings): Embedding(128256, 4096)
  (layers): ModuleList(
    (0-31): 32 x LadderTransformerBlock(
      semi_compiled = False
      (attention): Attention(
        (wqkv): Linear(in_features=4096, out_features=768, bias=False)
        (wo): Linear(in_features=512, out_features=4096, bias=False)
      )
      (feed_forward): FeedForward(
        (w1): Linear(in_features=4096, out_features=3584, bias=False)
        (w2): Linear(in_features=1792, out_features=4096, bias=False)
      )
      (ffn_norm): RMSNorm()
      (attention_norm): RMSNorm()
    )
  )
  (norm): RMSNorm()
  (output): Linear(in_features=4096, out_features=128256, bias=False)
)
Time to load model: 0.16 seconds
[rank2]:[W1001 18:56:59.125133539 CUDAGraph.cpp:150] Warning: Waiting for pending NCCL work to finish before starting graph capture. (function operator())
[rank7]:[W1001 18:57:00.688276718 CUDAGraph.cpp:150] Warning: Waiting for pending NCCL work to finish before starting graph capture. (function operator())
Prefill latency: 0.05167689803056419 sec
Decode latency: 1.2162277350435033 sec
Compilation time: 1.31 seconds
Compilation time: 1.25 seconds
Compilation time: 1.26 seconds
Compilation time: 1.27 seconds
Compilation time: 1.26 seconds
Compilation time: 1.26 seconds
Compilation time: 1.26 seconds
Compilation time: 1.27 seconds
Prefill latency: 0.03619877703022212 sec
Decode latency: 1.215334355016239 sec
Prefill latency: 0.03610134299378842 sec
Decode latency: 1.2153193569974974 sec
Prefill latency: 0.036106665967963636 sec
Decode latency: 1.2147761509986594 sec
Prefill latency: 0.03602402692195028 sec
Decode latency: 1.2155156870139763 sec
Prefill latency: 0.036061836988665164 sec
Decode latency: 1.2162182989995927 sec
Time for inference 1: 1.25 sec total, 817.30 tokens/sec
Decode latency: 1.22 sec
Prefill latency: 0.04 sec
Bandwidth achieved: 2285.21 GB/s
FLOPS achieved: 11.43 TF/s

Prefill latency: 0.036164490040391684 sec
Decode latency: 1.2151546459645033 sec
Time for inference 2: 1.25 sec total, 817.97 tokens/sec
Decode latency: 1.22 sec
Prefill latency: 0.04 sec
Bandwidth achieved: 2287.09 GB/s
FLOPS achieved: 11.44 TF/s

Prefill latency: 0.03608475299552083 sec
Decode latency: 1.2147149629890919 sec
Time for inference 3: 1.25 sec total, 818.23 tokens/sec
Decode latency: 1.21 sec
Prefill latency: 0.04 sec
Bandwidth achieved: 2287.81 GB/s
FLOPS achieved: 11.44 TF/s

Prefill latency: 0.036060851998627186 sec
Decode latency: 1.2148709970060736 sec
Time for inference 4: 1.25 sec total, 818.15 tokens/sec
Decode latency: 1.21 sec
Prefill latency: 0.04 sec
Bandwidth achieved: 2287.57 GB/s
FLOPS achieved: 11.44 TF/s

Prefill latency: 0.0362045030342415 sec
Decode latency: 1.2145996950566769 sec
Time for inference 5: 1.25 sec total, 818.25 tokens/sec
Decode latency: 1.21 sec
Prefill latency: 0.04 sec
Bandwidth achieved: 2287.84 GB/s
FLOPS achieved: 11.44 TF/s

Prefill latency: 0.03608441003598273 sec
Decode latency: 1.2152727799257264 sec
Time for inference 6: 1.25 sec total, 817.91 tokens/sec
Decode latency: 1.22 sec
Prefill latency: 0.04 sec
Bandwidth achieved: 2286.89 GB/s
FLOPS achieved: 11.43 TF/s

Prefill latency: 0.03612290997989476 sec
Decode latency: 1.2148287870222703 sec
Time for inference 7: 1.25 sec total, 818.11 tokens/sec
Decode latency: 1.21 sec
Prefill latency: 0.04 sec
Bandwidth achieved: 2287.47 GB/s
FLOPS achieved: 11.44 TF/s

Prefill latency: 0.036105199018493295 sec
Decode latency: 1.2155782890040427 sec
Time for inference 8: 1.25 sec total, 817.51 tokens/sec
Decode latency: 1.22 sec
Prefill latency: 0.04 sec
Bandwidth achieved: 2285.79 GB/s
FLOPS achieved: 11.43 TF/s

Prefill latency: 0.03602182795293629 sec
Decode latency: 1.215118472930044 sec
Time for inference 9: 1.25 sec total, 818.00 tokens/sec
Decode latency: 1.22 sec
Prefill latency: 0.04 sec
Bandwidth achieved: 2287.17 GB/s
FLOPS achieved: 11.44 TF/s

Prefill latency: 0.03606981399934739 sec
Decode latency: 1.2145917280577123 sec
Time for inference 10: 1.25 sec total, 818.20 tokens/sec
Decode latency: 1.21 sec
Prefill latency: 0.04 sec
Bandwidth achieved: 2287.71 GB/s
FLOPS achieved: 11.44 TF/s

==========
Batch Size: 4
Prompt Length: 1024
Generated tokens: 256
Average decode latency: 1.2151 sec
Average prefill latency: 0.0361 sec
Average tokens/sec: 817.96
Memory used: 7.44 GB
Done. we are killing the process
