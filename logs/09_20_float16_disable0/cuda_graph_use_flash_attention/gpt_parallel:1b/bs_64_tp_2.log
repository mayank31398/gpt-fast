W1001 02:20:32.567000 22373692036928 torch/distributed/run.py:779] 
W1001 02:20:32.567000 22373692036928 torch/distributed/run.py:779] *****************************************
W1001 02:20:32.567000 22373692036928 torch/distributed/run.py:779] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W1001 02:20:32.567000 22373692036928 torch/distributed/run.py:779] *****************************************
flash_kv_decode is set to True
Using device=cuda
Loading model ...
GPTParallel(
  (tok_embeddings): Embedding(49152, 1536)
  (layers): ModuleList(
    (0-39): 40 x ParallelTransformerBlock(
      semi_compiled = False
      (attention): FuseAttentionMLP(
        (wqkv1): Linear(in_features=1536, out_features=6400, bias=False)
        (wo): Linear(in_features=768, out_features=1536, bias=False)
        (w2): Linear(in_features=2048, out_features=1536, bias=False)
      )
      (attention_norm): RMSNorm()
    )
  )
  (norm): RMSNorm()
  (output): Linear(in_features=1536, out_features=49152, bias=False)
)
Time to load model: 1.09 seconds
Prefill latency: 0.45354678202420473 sec
Decode latency: 5.226304980926216 sec
Compilation time: 5.68 seconds
Compilation time: 5.68 seconds
Prefill latency: 0.45277160208206624 sec
Decode latency: 5.219933200045489 sec
Prefill latency: 0.4523130980087444 sec
Decode latency: 5.219868339947425 sec
Prefill latency: 0.45241335197351873 sec
Decode latency: 5.220771759049967 sec
Prefill latency: 0.45245553099084646 sec
Decode latency: 5.2183832849841565 sec
Prefill latency: 0.45262433600146323 sec
Decode latency: 5.2192601970164105 sec
Time for inference 1: 5.67 sec total, 2888.24 tokens/sec
Decode latency: 5.22 sec
Prefill latency: 0.45 sec
Bandwidth achieved: 3707.29 GB/s
FLOPS achieved: 18.54 TF/s

Prefill latency: 0.45321869500912726 sec
Decode latency: 5.225812703021802 sec
Time for inference 2: 5.68 sec total, 2884.47 tokens/sec
Decode latency: 5.23 sec
Prefill latency: 0.45 sec
Bandwidth achieved: 3702.45 GB/s
FLOPS achieved: 18.51 TF/s

Prefill latency: 0.4536780910566449 sec
Decode latency: 5.2260590919759125 sec
Time for inference 3: 5.68 sec total, 2884.19 tokens/sec
Decode latency: 5.23 sec
Prefill latency: 0.45 sec
Bandwidth achieved: 3702.09 GB/s
FLOPS achieved: 18.51 TF/s

Prefill latency: 0.45365970698185265 sec
Decode latency: 5.225631157984026 sec
Time for inference 4: 5.68 sec total, 2884.42 tokens/sec
Decode latency: 5.23 sec
Prefill latency: 0.45 sec
Bandwidth achieved: 3702.39 GB/s
FLOPS achieved: 18.51 TF/s

Prefill latency: 0.4538686559535563 sec
Decode latency: 5.224517788970843 sec
Time for inference 5: 5.68 sec total, 2884.90 tokens/sec
Decode latency: 5.22 sec
Prefill latency: 0.45 sec
Bandwidth achieved: 3703.01 GB/s
FLOPS achieved: 18.52 TF/s

Prefill latency: 0.4536975100636482 sec
Decode latency: 5.224612294929102 sec
Time for inference 6: 5.68 sec total, 2885.00 tokens/sec
Decode latency: 5.22 sec
Prefill latency: 0.45 sec
Bandwidth achieved: 3703.13 GB/s
FLOPS achieved: 18.52 TF/s

Prefill latency: 0.45375294401310384 sec
Decode latency: 5.2264902400784194 sec
Time for inference 7: 5.68 sec total, 2883.91 tokens/sec
Decode latency: 5.23 sec
Prefill latency: 0.45 sec
Bandwidth achieved: 3701.74 GB/s
FLOPS achieved: 18.51 TF/s

Prefill latency: 0.45399708102922887 sec
Decode latency: 5.224739497993141 sec
Time for inference 8: 5.68 sec total, 2884.69 tokens/sec
Decode latency: 5.22 sec
Prefill latency: 0.45 sec
Bandwidth achieved: 3702.74 GB/s
FLOPS achieved: 18.51 TF/s

Prefill latency: 0.45386572601273656 sec
Decode latency: 5.225746055948548 sec
Time for inference 9: 5.68 sec total, 2884.25 tokens/sec
Decode latency: 5.23 sec
Prefill latency: 0.45 sec
Bandwidth achieved: 3702.17 GB/s
FLOPS achieved: 18.51 TF/s

Prefill latency: 0.4539498249068856 sec
Decode latency: 5.225545998895541 sec
Time for inference 10: 5.68 sec total, 2884.32 tokens/sec
Decode latency: 5.23 sec
Prefill latency: 0.45 sec
Bandwidth achieved: 3702.27 GB/s
FLOPS achieved: 18.51 TF/s

==========
Batch Size: 64
Prompt Length: 1024
Generated tokens: 256
Average decode latency: 5.2248 sec
Average prefill latency: 0.4536 sec
Average tokens/sec: 2884.84
Memory used: 31.67 GB
Done. we are killing the process
