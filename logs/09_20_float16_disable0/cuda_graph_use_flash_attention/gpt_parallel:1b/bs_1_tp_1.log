flash_kv_decode is set to True
Using device=cuda
Loading model ...
GPTParallel(
  (tok_embeddings): Embedding(49152, 1536)
  (layers): ModuleList(
    (0-39): 40 x ParallelTransformerBlock(
      semi_compiled = False
      (attention): FuseAttentionMLP(
        (wqkv1): Linear(in_features=1536, out_features=10752, bias=False)
        (wo): Linear(in_features=1536, out_features=1536, bias=False)
        (w2): Linear(in_features=4096, out_features=1536, bias=False)
      )
      (attention_norm): RMSNorm()
    )
  )
  (norm): RMSNorm()
  (output): Linear(in_features=1536, out_features=49152, bias=False)
)
Time to load model: 1.08 seconds
Prefill latency: 0.015614943928085268 sec
Decode latency: 1.9524629469960928 sec
Compilation time: 1.97 seconds
Prefill latency: 0.015262780943885446 sec
Decode latency: 1.949587612063624 sec
Prefill latency: 0.01529122598003596 sec
Decode latency: 1.9506462330464274 sec
Prefill latency: 0.015288467984646559 sec
Decode latency: 1.950790744042024 sec
Prefill latency: 0.015255397069267929 sec
Decode latency: 1.9502367139793932 sec
Prefill latency: 0.015260223997756839 sec
Decode latency: 1.950842120917514 sec
Time for inference 1: 1.97 sec total, 130.16 tokens/sec
Decode latency: 1.95 sec
Prefill latency: 0.02 sec
Bandwidth achieved: 281.72 GB/s
FLOPS achieved: 1.41 TF/s

Prefill latency: 0.0152420710073784 sec
Decode latency: 1.9503716339822859 sec
Time for inference 2: 1.97 sec total, 130.20 tokens/sec
Decode latency: 1.95 sec
Prefill latency: 0.02 sec
Bandwidth achieved: 281.80 GB/s
FLOPS achieved: 1.41 TF/s

Prefill latency: 0.015260754968039691 sec
Decode latency: 1.950368450023234 sec
Time for inference 3: 1.97 sec total, 130.20 tokens/sec
Decode latency: 1.95 sec
Prefill latency: 0.02 sec
Bandwidth achieved: 281.79 GB/s
FLOPS achieved: 1.41 TF/s

Prefill latency: 0.015306126908399165 sec
Decode latency: 1.9500822110567242 sec
Time for inference 4: 1.97 sec total, 130.21 tokens/sec
Decode latency: 1.95 sec
Prefill latency: 0.02 sec
Bandwidth achieved: 281.83 GB/s
FLOPS achieved: 1.41 TF/s

Prefill latency: 0.015283444081433117 sec
Decode latency: 1.949915878009051 sec
Time for inference 5: 1.97 sec total, 130.22 tokens/sec
Decode latency: 1.95 sec
Prefill latency: 0.02 sec
Bandwidth achieved: 281.86 GB/s
FLOPS achieved: 1.41 TF/s

Prefill latency: 0.015259703970514238 sec
Decode latency: 1.950268579996191 sec
Time for inference 6: 1.97 sec total, 130.20 tokens/sec
Decode latency: 1.95 sec
Prefill latency: 0.02 sec
Bandwidth achieved: 281.81 GB/s
FLOPS achieved: 1.41 TF/s

Prefill latency: 0.015250801108777523 sec
Decode latency: 1.9510414489777759 sec
Time for inference 7: 1.97 sec total, 130.15 tokens/sec
Decode latency: 1.95 sec
Prefill latency: 0.02 sec
Bandwidth achieved: 281.70 GB/s
FLOPS achieved: 1.41 TF/s

Prefill latency: 0.015252751996740699 sec
Decode latency: 1.9507872770773247 sec
Time for inference 8: 1.97 sec total, 130.17 tokens/sec
Decode latency: 1.95 sec
Prefill latency: 0.02 sec
Bandwidth achieved: 281.73 GB/s
FLOPS achieved: 1.41 TF/s

Prefill latency: 0.015256198006682098 sec
Decode latency: 1.9508269609650597 sec
Time for inference 9: 1.97 sec total, 130.17 tokens/sec
Decode latency: 1.95 sec
Prefill latency: 0.02 sec
Bandwidth achieved: 281.73 GB/s
FLOPS achieved: 1.41 TF/s

Prefill latency: 0.01526101992931217 sec
Decode latency: 1.9506164310732856 sec
Time for inference 10: 1.97 sec total, 130.18 tokens/sec
Decode latency: 1.95 sec
Prefill latency: 0.02 sec
Bandwidth achieved: 281.76 GB/s
FLOPS achieved: 1.41 TF/s

==========
Batch Size: 1
Prompt Length: 1024
Generated tokens: 256
Average decode latency: 1.9505 sec
Average prefill latency: 0.0153 sec
Average tokens/sec: 130.19
Memory used: 2.95 GB
Done. we are killing the process
