W1001 02:17:08.252000 23204786464576 torch/distributed/run.py:779] 
W1001 02:17:08.252000 23204786464576 torch/distributed/run.py:779] *****************************************
W1001 02:17:08.252000 23204786464576 torch/distributed/run.py:779] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W1001 02:17:08.252000 23204786464576 torch/distributed/run.py:779] *****************************************
flash_kv_decode is set to True
Using device=cuda
Loading model ...
GPTParallel(
  (tok_embeddings): Embedding(49152, 1536)
  (layers): ModuleList(
    (0-39): 40 x ParallelTransformerBlock(
      semi_compiled = False
      (attention): FuseAttentionMLP(
        (wqkv1): Linear(in_features=1536, out_features=1600, bias=False)
        (wo): Linear(in_features=192, out_features=1536, bias=False)
        (w2): Linear(in_features=512, out_features=1536, bias=False)
      )
      (attention_norm): RMSNorm()
    )
  )
  (norm): RMSNorm()
  (output): Linear(in_features=1536, out_features=49152, bias=False)
)
Time to load model: 1.09 seconds
Prefill latency: 0.11004344199318439 sec
Decode latency: 2.2426218300824985 sec
Compilation time: 2.35 secondsCompilation time: 2.33 seconds
Compilation time: 2.34 seconds

Compilation time: 2.31 seconds
Compilation time: 2.30 seconds
Compilation time: 2.29 seconds
Compilation time: 2.32 seconds
Compilation time: 2.35 seconds
Prefill latency: 0.049652175046503544 sec
Decode latency: 2.241443085949868 sec
Prefill latency: 0.04976272792555392 sec
Decode latency: 2.2395041269483045 sec
Prefill latency: 0.049667311017401516 sec
Decode latency: 2.2392229579854757 sec
Prefill latency: 0.049883329891599715 sec
Decode latency: 2.238687006989494 sec
Prefill latency: 0.04968044499401003 sec
Decode latency: 2.238777724094689 sec
Time for inference 1: 2.29 sec total, 1789.17 tokens/sec
Decode latency: 2.24 sec
Prefill latency: 0.05 sec
Bandwidth achieved: 776.92 GB/s
FLOPS achieved: 3.88 TF/s

Prefill latency: 0.04966240900103003 sec
Decode latency: 2.238963067997247 sec
Time for inference 2: 2.29 sec total, 1788.90 tokens/sec
Decode latency: 2.24 sec
Prefill latency: 0.05 sec
Bandwidth achieved: 776.81 GB/s
FLOPS achieved: 3.88 TF/s

Prefill latency: 0.04971785796806216 sec
Decode latency: 2.239876567036845 sec
Time for inference 3: 2.29 sec total, 1788.24 tokens/sec
Decode latency: 2.24 sec
Prefill latency: 0.05 sec
Bandwidth achieved: 776.52 GB/s
FLOPS achieved: 3.88 TF/s

Prefill latency: 0.04971376899629831 sec
Decode latency: 2.2388640790013596 sec
Time for inference 4: 2.29 sec total, 1789.21 tokens/sec
Decode latency: 2.24 sec
Prefill latency: 0.05 sec
Bandwidth achieved: 776.94 GB/s
FLOPS achieved: 3.88 TF/s

Prefill latency: 0.04973927407991141 sec
Decode latency: 2.237860776949674 sec
Time for inference 5: 2.29 sec total, 1789.94 tokens/sec
Decode latency: 2.24 sec
Prefill latency: 0.05 sec
Bandwidth achieved: 777.26 GB/s
FLOPS achieved: 3.89 TF/s

Prefill latency: 0.04974692896939814 sec
Decode latency: 2.2392209050012752 sec
Time for inference 6: 2.29 sec total, 1788.49 tokens/sec
Decode latency: 2.24 sec
Prefill latency: 0.05 sec
Bandwidth achieved: 776.63 GB/s
FLOPS achieved: 3.88 TF/s

Prefill latency: 0.04965715005528182 sec
Decode latency: 2.239573883009143 sec
Time for inference 7: 2.29 sec total, 1788.43 tokens/sec
Decode latency: 2.24 sec
Prefill latency: 0.05 sec
Bandwidth achieved: 776.60 GB/s
FLOPS achieved: 3.88 TF/s

Prefill latency: 0.04972457094117999 sec
Decode latency: 2.2383028679760173 sec
Time for inference 8: 2.29 sec total, 1789.57 tokens/sec
Decode latency: 2.24 sec
Prefill latency: 0.05 sec
Bandwidth achieved: 777.10 GB/s
FLOPS achieved: 3.89 TF/s

Prefill latency: 0.04962386004626751 sec
Decode latency: 2.2384894490242004 sec
Time for inference 9: 2.29 sec total, 1789.52 tokens/sec
Decode latency: 2.24 sec
Prefill latency: 0.05 sec
Bandwidth achieved: 777.07 GB/s
FLOPS achieved: 3.89 TF/s

Prefill latency: 0.049614903051406145 sec
Decode latency: 2.2388049290748313 sec
Time for inference 10: 2.29 sec total, 1789.24 tokens/sec
Decode latency: 2.24 sec
Prefill latency: 0.05 sec
Bandwidth achieved: 776.95 GB/s
FLOPS achieved: 3.88 TF/s

==========
Batch Size: 16
Prompt Length: 1024
Generated tokens: 256
Average decode latency: 2.2389 sec
Average prefill latency: 0.0497 sec
Average tokens/sec: 1789.07
Memory used: 5.54 GB
Done. we are killing the process
