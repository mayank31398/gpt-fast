W0930 19:25:26.632000 22668561778496 torch/distributed/run.py:779] 
W0930 19:25:26.632000 22668561778496 torch/distributed/run.py:779] *****************************************
W0930 19:25:26.632000 22668561778496 torch/distributed/run.py:779] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W0930 19:25:26.632000 22668561778496 torch/distributed/run.py:779] *****************************************
flash_kv_decode is set to True
Using device=cuda
Loading model ...
GPTParallel(
  (tok_embeddings): Embedding(49152, 1536)
  (layers): ModuleList(
    (0-39): 40 x ParallelTransformerBlock(
      semi_compiled = False
      (attention): FuseAttentionMLP(
        (wqkv1): Linear(in_features=1536, out_features=1344, bias=False)
        (wo): Linear(in_features=192, out_features=1536, bias=False)
        (w2): Linear(in_features=512, out_features=1536, bias=False)
      )
      (attention_norm): RMSNorm()
    )
  )
  (norm): RMSNorm()
  (output): Linear(in_features=1536, out_features=49152, bias=False)
)
Time to load model: 1.10 seconds
Prefill latency: 0.046673911972902715 sec
Decode latency: 2.244730380945839 sec
Compilation time: 2.34 seconds
Compilation time: 2.37 secondsCompilation time: 2.30 seconds

Compilation time: 2.31 secondsCompilation time: 2.29 secondsCompilation time: 2.30 seconds


Compilation time: 2.33 seconds
Compilation time: 2.33 seconds
Prefill latency: 0.04647926497273147 sec
Decode latency: 2.2421275089727715 sec
Prefill latency: 0.04637591901700944 sec
Decode latency: 2.242902878904715 sec
Prefill latency: 0.04653567704372108 sec
Decode latency: 2.2425609440542758 sec
Prefill latency: 0.046575101907365024 sec
Decode latency: 2.241820008959621 sec
Prefill latency: 0.04635313607286662 sec
Decode latency: 2.241938816034235 sec
Time for inference 1: 2.29 sec total, 1789.25 tokens/sec
Decode latency: 2.24 sec
Prefill latency: 0.05 sec
Bandwidth achieved: 720.67 GB/s
FLOPS achieved: 3.60 TF/s

Prefill latency: 0.04653630999382585 sec
Decode latency: 2.2420536749996245 sec
Time for inference 2: 2.29 sec total, 1789.09 tokens/sec
Decode latency: 2.24 sec
Prefill latency: 0.05 sec
Bandwidth achieved: 720.61 GB/s
FLOPS achieved: 3.60 TF/s

Prefill latency: 0.046412583091296256 sec
Decode latency: 2.2420809160685167 sec
Time for inference 3: 2.29 sec total, 1789.19 tokens/sec
Decode latency: 2.24 sec
Prefill latency: 0.05 sec
Bandwidth achieved: 720.65 GB/s
FLOPS achieved: 3.60 TF/s

Prefill latency: 0.0463514719158411 sec
Decode latency: 2.2420012089423835 sec
Time for inference 4: 2.29 sec total, 1789.29 tokens/sec
Decode latency: 2.24 sec
Prefill latency: 0.05 sec
Bandwidth achieved: 720.69 GB/s
FLOPS achieved: 3.60 TF/s

Prefill latency: 0.04638234805315733 sec
Decode latency: 2.241404840024188 sec
Time for inference 5: 2.29 sec total, 1789.59 tokens/sec
Decode latency: 2.24 sec
Prefill latency: 0.05 sec
Bandwidth achieved: 720.81 GB/s
FLOPS achieved: 3.60 TF/s

Prefill latency: 0.04642360389698297 sec
Decode latency: 2.2415129120927304 sec
Time for inference 6: 2.29 sec total, 1789.65 tokens/sec
Decode latency: 2.24 sec
Prefill latency: 0.05 sec
Bandwidth achieved: 720.83 GB/s
FLOPS achieved: 3.60 TF/s

Prefill latency: 0.0463476279983297 sec
Decode latency: 2.241144408006221 sec
Time for inference 7: 2.29 sec total, 1790.06 tokens/sec
Decode latency: 2.24 sec
Prefill latency: 0.05 sec
Bandwidth achieved: 721.00 GB/s
FLOPS achieved: 3.60 TF/s

Prefill latency: 0.04634292307309806 sec
Decode latency: 2.2410961909918115 sec
Time for inference 8: 2.29 sec total, 1789.91 tokens/sec
Decode latency: 2.24 sec
Prefill latency: 0.05 sec
Bandwidth achieved: 720.94 GB/s
FLOPS achieved: 3.60 TF/s

Prefill latency: 0.04629879002459347 sec
Decode latency: 2.2407916360534728 sec
Time for inference 9: 2.29 sec total, 1790.22 tokens/sec
Decode latency: 2.24 sec
Prefill latency: 0.05 sec
Bandwidth achieved: 721.06 GB/s
FLOPS achieved: 3.61 TF/s

Prefill latency: 0.04635504400357604 sec
Decode latency: 2.2412277000257745 sec
Time for inference 10: 2.29 sec total, 1789.90 tokens/sec
Decode latency: 2.24 sec
Prefill latency: 0.05 sec
Bandwidth achieved: 720.93 GB/s
FLOPS achieved: 3.60 TF/s

==========
Batch Size: 16
Prompt Length: 1024
Generated tokens: 256
Average decode latency: 2.2415 sec
Average prefill latency: 0.0464 sec
Average tokens/sec: 1789.61
Memory used: 4.86 GB
Done. we are killing the process
