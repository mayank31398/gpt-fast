W0930 19:20:11.136000 22450483722048 torch/distributed/run.py:779] 
W0930 19:20:11.136000 22450483722048 torch/distributed/run.py:779] *****************************************
W0930 19:20:11.136000 22450483722048 torch/distributed/run.py:779] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W0930 19:20:11.136000 22450483722048 torch/distributed/run.py:779] *****************************************
flash_kv_decode is set to True
Using device=cuda
Loading model ...
GPTParallel(
  (tok_embeddings): Embedding(49152, 1536)
  (layers): ModuleList(
    (0-39): 40 x ParallelTransformerBlock(
      semi_compiled = False
      (attention): FuseAttentionMLP(
        (wqkv1): Linear(in_features=1536, out_features=5376, bias=False)
        (wo): Linear(in_features=768, out_features=1536, bias=False)
        (w2): Linear(in_features=2048, out_features=1536, bias=False)
      )
      (attention_norm): RMSNorm()
    )
  )
  (norm): RMSNorm()
  (output): Linear(in_features=1536, out_features=49152, bias=False)
)
Time to load model: 0.86 seconds
Prefill latency: 0.05435424705501646 sec
Decode latency: 2.4994107780512422 sec
Compilation time: 2.56 seconds
Compilation time: 2.55 seconds
Prefill latency: 0.05388854001648724 sec
Decode latency: 2.4994755600346252 sec
Prefill latency: 0.05391777795739472 sec
Decode latency: 2.49944946996402 sec
Prefill latency: 0.05394052492920309 sec
Decode latency: 2.4985636569326743 sec
Prefill latency: 0.05393488297704607 sec
Decode latency: 2.498483996023424 sec
Prefill latency: 0.053967472980730236 sec
Decode latency: 2.498847708920948 sec
Time for inference 1: 2.55 sec total, 801.96 tokens/sec
Decode latency: 2.50 sec
Prefill latency: 0.05 sec
Bandwidth achieved: 928.47 GB/s
FLOPS achieved: 4.64 TF/s

Prefill latency: 0.05391075892839581 sec
Decode latency: 2.4984313070308417 sec
Time for inference 2: 2.55 sec total, 802.20 tokens/sec
Decode latency: 2.50 sec
Prefill latency: 0.05 sec
Bandwidth achieved: 928.75 GB/s
FLOPS achieved: 4.64 TF/s

Prefill latency: 0.05400634102988988 sec
Decode latency: 2.498161872033961 sec
Time for inference 3: 2.55 sec total, 802.22 tokens/sec
Decode latency: 2.50 sec
Prefill latency: 0.05 sec
Bandwidth achieved: 928.78 GB/s
FLOPS achieved: 4.64 TF/s

Prefill latency: 0.0540084270760417 sec
Decode latency: 2.4989624250447378 sec
Time for inference 4: 2.55 sec total, 802.01 tokens/sec
Decode latency: 2.50 sec
Prefill latency: 0.05 sec
Bandwidth achieved: 928.53 GB/s
FLOPS achieved: 4.64 TF/s

Prefill latency: 0.05421360593754798 sec
Decode latency: 2.5012693690368906 sec
Time for inference 5: 2.56 sec total, 801.19 tokens/sec
Decode latency: 2.50 sec
Prefill latency: 0.05 sec
Bandwidth achieved: 927.58 GB/s
FLOPS achieved: 4.64 TF/s

Prefill latency: 0.05394427198916674 sec
Decode latency: 2.501466533052735 sec
Time for inference 6: 2.56 sec total, 801.20 tokens/sec
Decode latency: 2.50 sec
Prefill latency: 0.05 sec
Bandwidth achieved: 927.60 GB/s
FLOPS achieved: 4.64 TF/s

Prefill latency: 0.05402373289689422 sec
Decode latency: 2.501137741957791 sec
Time for inference 7: 2.56 sec total, 801.18 tokens/sec
Decode latency: 2.50 sec
Prefill latency: 0.05 sec
Bandwidth achieved: 927.57 GB/s
FLOPS achieved: 4.64 TF/s

Prefill latency: 0.05406526604201645 sec
Decode latency: 2.500662154983729 sec
Time for inference 8: 2.56 sec total, 801.38 tokens/sec
Decode latency: 2.50 sec
Prefill latency: 0.05 sec
Bandwidth achieved: 927.80 GB/s
FLOPS achieved: 4.64 TF/s

Prefill latency: 0.053965447936207056 sec
Decode latency: 2.498162891017273 sec
Time for inference 9: 2.55 sec total, 802.24 tokens/sec
Decode latency: 2.50 sec
Prefill latency: 0.05 sec
Bandwidth achieved: 928.80 GB/s
FLOPS achieved: 4.64 TF/s

Prefill latency: 0.05396830302197486 sec
Decode latency: 2.4989518710644916 sec
Time for inference 10: 2.55 sec total, 801.99 tokens/sec
Decode latency: 2.50 sec
Prefill latency: 0.05 sec
Bandwidth achieved: 928.51 GB/s
FLOPS achieved: 4.64 TF/s

==========
Batch Size: 8
Prompt Length: 1024
Generated tokens: 256
Average decode latency: 2.4996 sec
Average prefill latency: 0.0540 sec
Average tokens/sec: 801.76
Memory used: 4.35 GB
Done. we are killing the process
