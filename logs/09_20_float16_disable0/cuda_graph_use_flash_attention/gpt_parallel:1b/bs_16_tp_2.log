W1001 02:15:27.142000 22396716029760 torch/distributed/run.py:779] 
W1001 02:15:27.142000 22396716029760 torch/distributed/run.py:779] *****************************************
W1001 02:15:27.142000 22396716029760 torch/distributed/run.py:779] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W1001 02:15:27.142000 22396716029760 torch/distributed/run.py:779] *****************************************
flash_kv_decode is set to True
Using device=cuda
Loading model ...
GPTParallel(
  (tok_embeddings): Embedding(49152, 1536)
  (layers): ModuleList(
    (0-39): 40 x ParallelTransformerBlock(
      semi_compiled = False
      (attention): FuseAttentionMLP(
        (wqkv1): Linear(in_features=1536, out_features=6400, bias=False)
        (wo): Linear(in_features=768, out_features=1536, bias=False)
        (w2): Linear(in_features=2048, out_features=1536, bias=False)
      )
      (attention_norm): RMSNorm()
    )
  )
  (norm): RMSNorm()
  (output): Linear(in_features=1536, out_features=49152, bias=False)
)
Time to load model: 0.93 seconds
[rank0]:[W1001 02:15:34.312372798 CUDAGraph.cpp:150] Warning: Waiting for pending NCCL work to finish before starting graph capture. (function operator())
Prefill latency: 0.11920035898219794 sec
Decode latency: 2.716580998036079 secCompilation time: 2.86 seconds

Compilation time: 2.84 seconds
Prefill latency: 0.11873508698772639 sec
Decode latency: 2.7155973160406575 sec
Prefill latency: 0.11873870401177555 sec
Decode latency: 2.714981367927976 sec
Prefill latency: 0.11892630404327065 sec
Decode latency: 2.7138649290427566 sec
Prefill latency: 0.11881844000890851 sec
Decode latency: 2.7143326540244743 sec
Prefill latency: 0.1187901459634304 sec
Decode latency: 2.7146844778908417 sec
Time for inference 1: 2.83 sec total, 1445.19 tokens/sec
Decode latency: 2.71 sec
Prefill latency: 0.12 sec
Bandwidth achieved: 1855.02 GB/s
FLOPS achieved: 9.28 TF/s

Prefill latency: 0.11889787099789828 sec
Decode latency: 2.715827362961136 sec
Time for inference 2: 2.84 sec total, 1444.57 tokens/sec
Decode latency: 2.72 sec
Prefill latency: 0.12 sec
Bandwidth achieved: 1854.22 GB/s
FLOPS achieved: 9.27 TF/s

Prefill latency: 0.1188272830331698 sec
Decode latency: 2.7150225820951164 sec
Time for inference 3: 2.83 sec total, 1444.93 tokens/sec
Decode latency: 2.72 sec
Prefill latency: 0.12 sec
Bandwidth achieved: 1854.69 GB/s
FLOPS achieved: 9.27 TF/s

Prefill latency: 0.11883319797925651 sec
Decode latency: 2.7139049019897357 sec
Time for inference 4: 2.83 sec total, 1445.55 tokens/sec
Decode latency: 2.71 sec
Prefill latency: 0.12 sec
Bandwidth achieved: 1855.49 GB/s
FLOPS achieved: 9.28 TF/s

Prefill latency: 0.11889559496194124 sec
Decode latency: 2.714169601094909 sec
Time for inference 5: 2.83 sec total, 1445.38 tokens/sec
Decode latency: 2.71 sec
Prefill latency: 0.12 sec
Bandwidth achieved: 1855.26 GB/s
FLOPS achieved: 9.28 TF/s

Prefill latency: 0.11888729000929743 sec
Decode latency: 2.7144459919072688 sec
Time for inference 6: 2.83 sec total, 1445.21 tokens/sec
Decode latency: 2.71 sec
Prefill latency: 0.12 sec
Bandwidth achieved: 1855.05 GB/s
FLOPS achieved: 9.28 TF/s

Prefill latency: 0.11879780795425177 sec
Decode latency: 2.7136251259362325 sec
Time for inference 7: 2.83 sec total, 1445.68 tokens/sec
Decode latency: 2.71 sec
Prefill latency: 0.12 sec
Bandwidth achieved: 1855.65 GB/s
FLOPS achieved: 9.28 TF/s

Prefill latency: 0.1188320181099698 sec
Decode latency: 2.7138132780091837 sec
Time for inference 8: 2.83 sec total, 1445.54 tokens/sec
Decode latency: 2.71 sec
Prefill latency: 0.12 sec
Bandwidth achieved: 1855.48 GB/s
FLOPS achieved: 9.28 TF/s

Prefill latency: 0.1188316480256617 sec
Decode latency: 2.7144054180243984 sec
Time for inference 9: 2.83 sec total, 1445.34 tokens/sec
Decode latency: 2.71 sec
Prefill latency: 0.12 sec
Bandwidth achieved: 1855.21 GB/s
FLOPS achieved: 9.28 TF/s

Prefill latency: 0.11890925897751004 sec
Decode latency: 2.7139743650332093 sec
Time for inference 10: 2.83 sec total, 1445.48 tokens/sec
Decode latency: 2.71 sec
Prefill latency: 0.12 sec
Bandwidth achieved: 1855.39 GB/s
FLOPS achieved: 9.28 TF/s

==========
Batch Size: 16
Prompt Length: 1024
Generated tokens: 256
Average decode latency: 2.7144 sec
Average prefill latency: 0.1189 sec
Average tokens/sec: 1445.29
Memory used: 9.55 GB
Done. we are killing the process
