W1001 02:09:02.128000 22864581150528 torch/distributed/run.py:779] 
W1001 02:09:02.128000 22864581150528 torch/distributed/run.py:779] *****************************************
W1001 02:09:02.128000 22864581150528 torch/distributed/run.py:779] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W1001 02:09:02.128000 22864581150528 torch/distributed/run.py:779] *****************************************
flash_kv_decode is set to True
Using device=cuda
Loading model ...
GPTParallel(
  (tok_embeddings): Embedding(49152, 1536)
  (layers): ModuleList(
    (0-39): 40 x ParallelTransformerBlock(
      semi_compiled = False
      (attention): FuseAttentionMLP(
        (wqkv1): Linear(in_features=1536, out_features=6400, bias=False)
        (wo): Linear(in_features=768, out_features=1536, bias=False)
        (w2): Linear(in_features=2048, out_features=1536, bias=False)
      )
      (attention_norm): RMSNorm()
    )
  )
  (norm): RMSNorm()
  (output): Linear(in_features=1536, out_features=49152, bias=False)
)
Time to load model: 1.00 seconds
Prefill latency: 0.04394966294057667 sec
Decode latency: 2.1720119150122628 sec
Compilation time: 2.22 seconds
Compilation time: 2.21 seconds
Prefill latency: 0.03383651399053633 sec
Decode latency: 2.171684752916917 sec
Prefill latency: 0.03363678196910769 sec
Decode latency: 2.172283363994211 sec
Prefill latency: 0.033649594988673925 sec
Decode latency: 2.171748102060519 sec
Prefill latency: 0.03359724604524672 sec
Decode latency: 2.17168099002447 sec
Prefill latency: 0.03373249096330255 sec
Decode latency: 2.1712460070848465 sec
Time for inference 1: 2.21 sec total, 464.20 tokens/sec
Decode latency: 2.17 sec
Prefill latency: 0.03 sec
Bandwidth achieved: 595.84 GB/s
FLOPS achieved: 2.98 TF/s

Prefill latency: 0.03370714408811182 sec
Decode latency: 2.1725982539355755 sec
Time for inference 2: 2.21 sec total, 463.91 tokens/sec
Decode latency: 2.17 sec
Prefill latency: 0.03 sec
Bandwidth achieved: 595.47 GB/s
FLOPS achieved: 2.98 TF/s

Prefill latency: 0.033693019999191165 sec
Decode latency: 2.171759119955823 sec
Time for inference 3: 2.21 sec total, 464.15 tokens/sec
Decode latency: 2.17 sec
Prefill latency: 0.03 sec
Bandwidth achieved: 595.78 GB/s
FLOPS achieved: 2.98 TF/s

Prefill latency: 0.03371674392838031 sec
Decode latency: 2.1724985990440473 sec
Time for inference 4: 2.21 sec total, 463.99 tokens/sec
Decode latency: 2.17 sec
Prefill latency: 0.03 sec
Bandwidth achieved: 595.57 GB/s
FLOPS achieved: 2.98 TF/s

Prefill latency: 0.03364413289818913 sec
Decode latency: 2.171533911023289 sec
Time for inference 5: 2.21 sec total, 464.22 tokens/sec
Decode latency: 2.17 sec
Prefill latency: 0.03 sec
Bandwidth achieved: 595.87 GB/s
FLOPS achieved: 2.98 TF/s

Prefill latency: 0.03361663606483489 sec
Decode latency: 2.1730928509496152 sec
Time for inference 6: 2.21 sec total, 463.90 tokens/sec
Decode latency: 2.17 sec
Prefill latency: 0.03 sec
Bandwidth achieved: 595.46 GB/s
FLOPS achieved: 2.98 TF/s

Prefill latency: 0.03377963101956993 sec
Decode latency: 2.17135489708744 sec
Time for inference 7: 2.21 sec total, 464.20 tokens/sec
Decode latency: 2.17 sec
Prefill latency: 0.03 sec
Bandwidth achieved: 595.84 GB/s
FLOPS achieved: 2.98 TF/s

Prefill latency: 0.03359473496675491 sec
Decode latency: 2.1721865959698334 sec
Time for inference 8: 2.21 sec total, 464.10 tokens/sec
Decode latency: 2.17 sec
Prefill latency: 0.03 sec
Bandwidth achieved: 595.71 GB/s
FLOPS achieved: 2.98 TF/s

Prefill latency: 0.03374497301410884 sec
Decode latency: 2.1715982609894127 sec
Time for inference 9: 2.21 sec total, 464.19 tokens/sec
Decode latency: 2.17 sec
Prefill latency: 0.03 sec
Bandwidth achieved: 595.82 GB/s
FLOPS achieved: 2.98 TF/s

Prefill latency: 0.033597961999475956 sec
Decode latency: 2.1722883109468967 sec
Time for inference 10: 2.21 sec total, 464.02 tokens/sec
Decode latency: 2.17 sec
Prefill latency: 0.03 sec
Bandwidth achieved: 595.61 GB/s
FLOPS achieved: 2.98 TF/s

==========
Batch Size: 4
Prompt Length: 1024
Generated tokens: 256
Average decode latency: 2.1720 sec
Average prefill latency: 0.0337 sec
Average tokens/sec: 464.09
Memory used: 3.71 GB
Done. we are killing the process
