flash_kv_decode is set to True
Using device=cuda
Loading model ...
GPTParallel(
  (tok_embeddings): Embedding(49152, 1536)
  (layers): ModuleList(
    (0-39): 40 x ParallelTransformerBlock(
      semi_compiled = False
      (attention): FuseAttentionMLP(
        (wqkv1): Linear(in_features=1536, out_features=12800, bias=False)
        (wo): Linear(in_features=1536, out_features=1536, bias=False)
        (w2): Linear(in_features=4096, out_features=1536, bias=False)
      )
      (attention_norm): RMSNorm()
    )
  )
  (norm): RMSNorm()
  (output): Linear(in_features=1536, out_features=49152, bias=False)
)
Time to load model: 0.92 seconds
Prefill latency: 0.054397995001636446 sec
Decode latency: 2.2738619660958648 sec
Compilation time: 2.33 seconds
Prefill latency: 0.054044341086409986 sec
Decode latency: 2.2639681259170175 sec
Prefill latency: 0.05408899602480233 sec
Decode latency: 2.370782811078243 sec
Prefill latency: 0.05405553197488189 sec
Decode latency: 2.369519354077056 sec
Prefill latency: 0.054060098016634583 sec
Decode latency: 2.3048230869462714 sec
Prefill latency: 0.05403137695975602 sec
Decode latency: 2.3664589669788256 sec
Time for inference 1: 2.42 sec total, 422.94 tokens/sec
Decode latency: 2.37 sec
Prefill latency: 0.05 sec
Bandwidth achieved: 1021.85 GB/s
FLOPS achieved: 5.11 TF/s

Prefill latency: 0.053993363049812615 sec
Decode latency: 2.3658610889688134 sec
Time for inference 2: 2.42 sec total, 423.04 tokens/sec
Decode latency: 2.37 sec
Prefill latency: 0.05 sec
Bandwidth achieved: 1022.09 GB/s
FLOPS achieved: 5.11 TF/s

Prefill latency: 0.05397144099697471 sec
Decode latency: 2.313937857048586 sec
Time for inference 3: 2.37 sec total, 432.32 tokens/sec
Decode latency: 2.31 sec
Prefill latency: 0.05 sec
Bandwidth achieved: 1044.51 GB/s
FLOPS achieved: 5.22 TF/s

Prefill latency: 0.05402293091174215 sec
Decode latency: 2.3655492829857394 sec
Time for inference 4: 2.42 sec total, 423.10 tokens/sec
Decode latency: 2.37 sec
Prefill latency: 0.05 sec
Bandwidth achieved: 1022.23 GB/s
FLOPS achieved: 5.11 TF/s

Prefill latency: 0.05393899301998317 sec
Decode latency: 2.2978562059579417 sec
Time for inference 5: 2.35 sec total, 435.25 tokens/sec
Decode latency: 2.30 sec
Prefill latency: 0.05 sec
Bandwidth achieved: 1051.59 GB/s
FLOPS achieved: 5.26 TF/s

Prefill latency: 0.05402694002259523 sec
Decode latency: 2.3659828420495614 sec
Time for inference 6: 2.42 sec total, 422.98 tokens/sec
Decode latency: 2.37 sec
Prefill latency: 0.05 sec
Bandwidth achieved: 1021.95 GB/s
FLOPS achieved: 5.11 TF/s

Prefill latency: 0.05394707701634616 sec
Decode latency: 2.3664352151099592 sec
Time for inference 7: 2.42 sec total, 422.93 tokens/sec
Decode latency: 2.37 sec
Prefill latency: 0.05 sec
Bandwidth achieved: 1021.82 GB/s
FLOPS achieved: 5.11 TF/s

Prefill latency: 0.05403044098056853 sec
Decode latency: 2.364814085070975 sec
Time for inference 8: 2.42 sec total, 423.21 tokens/sec
Decode latency: 2.36 sec
Prefill latency: 0.05 sec
Bandwidth achieved: 1022.48 GB/s
FLOPS achieved: 5.11 TF/s

Prefill latency: 0.05394474102649838 sec
Decode latency: 2.3663924790453166 sec
Time for inference 9: 2.42 sec total, 422.96 tokens/sec
Decode latency: 2.37 sec
Prefill latency: 0.05 sec
Bandwidth achieved: 1021.88 GB/s
FLOPS achieved: 5.11 TF/s

Prefill latency: 0.05405166104901582 sec
Decode latency: 2.299853981938213 sec
Time for inference 10: 2.35 sec total, 434.90 tokens/sec
Decode latency: 2.30 sec
Prefill latency: 0.05 sec
Bandwidth achieved: 1050.73 GB/s
FLOPS achieved: 5.25 TF/s

==========
Batch Size: 4
Prompt Length: 1024
Generated tokens: 256
Average decode latency: 2.3473 sec
Average prefill latency: 0.0540 sec
Average tokens/sec: 426.36
Memory used: 5.46 GB
Done. we are killing the process
