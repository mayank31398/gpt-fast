W0930 19:21:43.862000 22422837897024 torch/distributed/run.py:779] 
W0930 19:21:43.862000 22422837897024 torch/distributed/run.py:779] *****************************************
W0930 19:21:43.862000 22422837897024 torch/distributed/run.py:779] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W0930 19:21:43.862000 22422837897024 torch/distributed/run.py:779] *****************************************
flash_kv_decode is set to True
Using device=cuda
Loading model ...
GPTParallel(
  (tok_embeddings): Embedding(49152, 1536)
  (layers): ModuleList(
    (0-39): 40 x ParallelTransformerBlock(
      semi_compiled = False
      (attention): FuseAttentionMLP(
        (wqkv1): Linear(in_features=1536, out_features=1344, bias=False)
        (wo): Linear(in_features=192, out_features=1536, bias=False)
        (w2): Linear(in_features=512, out_features=1536, bias=False)
      )
      (attention_norm): RMSNorm()
    )
  )
  (norm): RMSNorm()
  (output): Linear(in_features=1536, out_features=49152, bias=False)
)
Time to load model: 1.19 seconds
Prefill latency: 0.07891288795508444 sec
Decode latency: 2.0496689459541813 sec
Compilation time: 2.11 seconds
Compilation time: 2.14 secondsCompilation time: 2.12 secondsCompilation time: 2.09 seconds


Compilation time: 2.08 seconds
Compilation time: 2.10 seconds
Compilation time: 2.10 seconds
Compilation time: 2.13 seconds
Prefill latency: 0.02661710395477712 sec
Decode latency: 2.048032440012321 sec
Prefill latency: 0.02664524398278445 sec
Decode latency: 2.0485060159116983 sec
Prefill latency: 0.02669864206109196 sec
Decode latency: 2.0480824559926987 sec
Prefill latency: 0.026601791963912547 sec
Decode latency: 2.0481602089712396 sec
Prefill latency: 0.026626806939020753 sec
Decode latency: 2.0480266289087012 sec
Time for inference 1: 2.08 sec total, 986.80 tokens/sec
Decode latency: 2.05 sec
Prefill latency: 0.03 sec
Bandwidth achieved: 397.46 GB/s
FLOPS achieved: 1.99 TF/s

Prefill latency: 0.026875141076743603 sec
Decode latency: 2.048038888955489 sec
Time for inference 2: 2.08 sec total, 986.66 tokens/sec
Decode latency: 2.05 sec
Prefill latency: 0.03 sec
Bandwidth achieved: 397.41 GB/s
FLOPS achieved: 1.99 TF/s

Prefill latency: 0.02666969399433583 sec
Decode latency: 2.0474008929450065 sec
Time for inference 3: 2.07 sec total, 987.00 tokens/sec
Decode latency: 2.05 sec
Prefill latency: 0.03 sec
Bandwidth achieved: 397.54 GB/s
FLOPS achieved: 1.99 TF/s

Prefill latency: 0.02659918402787298 sec
Decode latency: 2.0470888239797205 sec
Time for inference 4: 2.07 sec total, 987.20 tokens/sec
Decode latency: 2.05 sec
Prefill latency: 0.03 sec
Bandwidth achieved: 397.62 GB/s
FLOPS achieved: 1.99 TF/s

Prefill latency: 0.026844893000088632 sec
Decode latency: 2.0469844120088965 sec
Time for inference 5: 2.07 sec total, 987.06 tokens/sec
Decode latency: 2.05 sec
Prefill latency: 0.03 sec
Bandwidth achieved: 397.57 GB/s
FLOPS achieved: 1.99 TF/s

Prefill latency: 0.026646981947124004 sec
Decode latency: 2.0483018369413912 sec
Time for inference 6: 2.08 sec total, 986.54 tokens/sec
Decode latency: 2.05 sec
Prefill latency: 0.03 sec
Bandwidth achieved: 397.36 GB/s
FLOPS achieved: 1.99 TF/s

Prefill latency: 0.026686389930546284 sec
Decode latency: 2.047321732970886 sec
Time for inference 7: 2.08 sec total, 986.99 tokens/sec
Decode latency: 2.05 sec
Prefill latency: 0.03 sec
Bandwidth achieved: 397.54 GB/s
FLOPS achieved: 1.99 TF/s

Prefill latency: 0.02660489093977958 sec
Decode latency: 2.0470644619781524 sec
Time for inference 8: 2.07 sec total, 987.14 tokens/sec
Decode latency: 2.05 sec
Prefill latency: 0.03 sec
Bandwidth achieved: 397.60 GB/s
FLOPS achieved: 1.99 TF/s

Prefill latency: 0.026694444939494133 sec
Decode latency: 2.047301805927418 sec
Time for inference 9: 2.07 sec total, 987.09 tokens/sec
Decode latency: 2.05 sec
Prefill latency: 0.03 sec
Bandwidth achieved: 397.58 GB/s
FLOPS achieved: 1.99 TF/s

Prefill latency: 0.026742017013020813 sec
Decode latency: 2.0475271890172735 sec
Time for inference 10: 2.08 sec total, 986.88 tokens/sec
Decode latency: 2.05 sec
Prefill latency: 0.03 sec
Bandwidth achieved: 397.50 GB/s
FLOPS achieved: 1.99 TF/s

==========
Batch Size: 8
Prompt Length: 1024
Generated tokens: 256
Average decode latency: 2.0475 sec
Average prefill latency: 0.0267 sec
Average tokens/sec: 986.93
Memory used: 2.80 GB
Done. we are killing the process
