W1001 02:10:27.128000 22574429890368 torch/distributed/run.py:779] 
W1001 02:10:27.128000 22574429890368 torch/distributed/run.py:779] *****************************************
W1001 02:10:27.128000 22574429890368 torch/distributed/run.py:779] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W1001 02:10:27.128000 22574429890368 torch/distributed/run.py:779] *****************************************
flash_kv_decode is set to True
Using device=cuda
Loading model ...
GPTParallel(
  (tok_embeddings): Embedding(49152, 1536)
  (layers): ModuleList(
    (0-39): 40 x ParallelTransformerBlock(
      semi_compiled = False
      (attention): FuseAttentionMLP(
        (wqkv1): Linear(in_features=1536, out_features=1600, bias=False)
        (wo): Linear(in_features=192, out_features=1536, bias=False)
        (w2): Linear(in_features=512, out_features=1536, bias=False)
      )
      (attention_norm): RMSNorm()
    )
  )
  (norm): RMSNorm()
  (output): Linear(in_features=1536, out_features=49152, bias=False)
)
Time to load model: 1.11 seconds
Prefill latency: 0.047759211040101945 sec
Decode latency: 1.968855734099634 sec
Compilation time: 2.01 seconds
Compilation time: 2.02 seconds
Compilation time: 1.99 secondsCompilation time: 2.01 seconds

Compilation time: 2.01 secondsCompilation time: 2.02 seconds

Compilation time: 2.04 seconds
Compilation time: 2.04 seconds
Prefill latency: 0.018483357969671488 sec
Decode latency: 1.968503447016701 sec
Prefill latency: 0.018459202954545617 sec
Decode latency: 1.9685844329651445 sec
Prefill latency: 0.018471877090632915 sec
Decode latency: 1.9686659359140322 sec
Prefill latency: 0.018477421952411532 sec
Decode latency: 1.9674113220535219 sec
Prefill latency: 0.018524001934565604 sec
Decode latency: 1.9672514779958874 sec
Time for inference 1: 1.99 sec total, 515.43 tokens/sec
Decode latency: 1.97 sec
Prefill latency: 0.02 sec
Bandwidth achieved: 223.82 GB/s
FLOPS achieved: 1.12 TF/s

Prefill latency: 0.018464754102751613 sec
Decode latency: 1.9675615460146219 sec
Time for inference 2: 1.99 sec total, 515.41 tokens/sec
Decode latency: 1.97 sec
Prefill latency: 0.02 sec
Bandwidth achieved: 223.81 GB/s
FLOPS achieved: 1.12 TF/s

Prefill latency: 0.01846455701161176 sec
Decode latency: 1.9675251509761438 sec
Time for inference 3: 1.99 sec total, 515.35 tokens/sec
Decode latency: 1.97 sec
Prefill latency: 0.02 sec
Bandwidth achieved: 223.79 GB/s
FLOPS achieved: 1.12 TF/s

Prefill latency: 0.018464691936969757 sec
Decode latency: 1.9673890270059928 sec
Time for inference 4: 1.99 sec total, 515.42 tokens/sec
Decode latency: 1.97 sec
Prefill latency: 0.02 sec
Bandwidth achieved: 223.81 GB/s
FLOPS achieved: 1.12 TF/s

Prefill latency: 0.01871808699797839 sec
Decode latency: 1.9681407919852063 sec
Time for inference 5: 1.99 sec total, 515.16 tokens/sec
Decode latency: 1.97 sec
Prefill latency: 0.02 sec
Bandwidth achieved: 223.70 GB/s
FLOPS achieved: 1.12 TF/s

Prefill latency: 0.01844759506639093 sec
Decode latency: 1.968001040047966 sec
Time for inference 6: 1.99 sec total, 515.30 tokens/sec
Decode latency: 1.97 sec
Prefill latency: 0.02 sec
Bandwidth achieved: 223.76 GB/s
FLOPS achieved: 1.12 TF/s

Prefill latency: 0.018516442039981484 sec
Decode latency: 1.9672943929908797 sec
Time for inference 7: 1.99 sec total, 515.43 tokens/sec
Decode latency: 1.97 sec
Prefill latency: 0.02 sec
Bandwidth achieved: 223.82 GB/s
FLOPS achieved: 1.12 TF/s

Prefill latency: 0.01844159292522818 sec
Decode latency: 1.967351443017833 sec
Time for inference 8: 1.99 sec total, 515.48 tokens/sec
Decode latency: 1.97 sec
Prefill latency: 0.02 sec
Bandwidth achieved: 223.84 GB/s
FLOPS achieved: 1.12 TF/s

Prefill latency: 0.018684072070755064 sec
Decode latency: 1.9681289520813152 sec
Time for inference 9: 1.99 sec total, 515.19 tokens/sec
Decode latency: 1.97 sec
Prefill latency: 0.02 sec
Bandwidth achieved: 223.72 GB/s
FLOPS achieved: 1.12 TF/s

Prefill latency: 0.018450899980962276 sec
Decode latency: 1.9678504699841142 sec
Time for inference 10: 1.99 sec total, 515.27 tokens/sec
Decode latency: 1.97 sec
Prefill latency: 0.02 sec
Bandwidth achieved: 223.75 GB/s
FLOPS achieved: 1.12 TF/s

==========
Batch Size: 4
Prompt Length: 1024
Generated tokens: 256
Average decode latency: 1.9676 sec
Average prefill latency: 0.0185 sec
Average tokens/sec: 515.34
Memory used: 1.92 GB
Done. we are killing the process
