W0930 19:18:30.830000 22637164599104 torch/distributed/run.py:779] 
W0930 19:18:30.830000 22637164599104 torch/distributed/run.py:779] *****************************************
W0930 19:18:30.830000 22637164599104 torch/distributed/run.py:779] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W0930 19:18:30.830000 22637164599104 torch/distributed/run.py:779] *****************************************
flash_kv_decode is set to True
Using device=cuda
Loading model ...
GPTParallel(
  (tok_embeddings): Embedding(49152, 1536)
  (layers): ModuleList(
    (0-39): 40 x ParallelTransformerBlock(
      semi_compiled = False
      (attention): FuseAttentionMLP(
        (wqkv1): Linear(in_features=1536, out_features=1344, bias=False)
        (wo): Linear(in_features=192, out_features=1536, bias=False)
        (w2): Linear(in_features=512, out_features=1536, bias=False)
      )
      (attention_norm): RMSNorm()
    )
  )
  (norm): RMSNorm()
  (output): Linear(in_features=1536, out_features=49152, bias=False)
)
Time to load model: 1.19 seconds
Prefill latency: 0.02772440400440246 sec
Decode latency: 1.9209210680564865 sec
Compilation time: 1.94 seconds
Compilation time: 1.95 seconds
Compilation time: 1.95 seconds
Compilation time: 1.95 seconds
Compilation time: 1.98 seconds
Compilation time: 1.98 secondsCompilation time: 1.95 seconds

Compilation time: 1.94 seconds
Prefill latency: 0.018098662956617773 sec
Decode latency: 1.9201665349537507 sec
Prefill latency: 0.01797436596825719 sec
Decode latency: 1.9205137650715187 sec
Prefill latency: 0.018006014986895025 sec
Decode latency: 1.9196572040673345 sec
Prefill latency: 0.017968152998946607 sec
Decode latency: 1.9198287340113893 sec
Prefill latency: 0.018192113027907908 sec
Decode latency: 1.9199741769116372 sec
Time for inference 1: 1.94 sec total, 528.15 tokens/sec
Decode latency: 1.92 sec
Prefill latency: 0.02 sec
Bandwidth achieved: 212.73 GB/s
FLOPS achieved: 1.06 TF/s

Prefill latency: 0.01798553508706391 sec
Decode latency: 1.9200178378960118 sec
Time for inference 2: 1.94 sec total, 528.15 tokens/sec
Decode latency: 1.92 sec
Prefill latency: 0.02 sec
Bandwidth achieved: 212.73 GB/s
FLOPS achieved: 1.06 TF/s

Prefill latency: 0.01804146496579051 sec
Decode latency: 1.9211703980108723 sec
Time for inference 3: 1.94 sec total, 527.82 tokens/sec
Decode latency: 1.92 sec
Prefill latency: 0.02 sec
Bandwidth achieved: 212.60 GB/s
FLOPS achieved: 1.06 TF/s

Prefill latency: 0.01805897697340697 sec
Decode latency: 1.9208688620710745 sec
Time for inference 4: 1.94 sec total, 527.95 tokens/sec
Decode latency: 1.92 sec
Prefill latency: 0.02 sec
Bandwidth achieved: 212.65 GB/s
FLOPS achieved: 1.06 TF/s

Prefill latency: 0.018001705058850348 sec
Decode latency: 1.9209922270383686 sec
Time for inference 5: 1.94 sec total, 527.92 tokens/sec
Decode latency: 1.92 sec
Prefill latency: 0.02 sec
Bandwidth achieved: 212.64 GB/s
FLOPS achieved: 1.06 TF/s

Prefill latency: 0.01799004292115569 sec
Decode latency: 1.9211163820000365 sec
Time for inference 6: 1.94 sec total, 527.90 tokens/sec
Decode latency: 1.92 sec
Prefill latency: 0.02 sec
Bandwidth achieved: 212.63 GB/s
FLOPS achieved: 1.06 TF/s

Prefill latency: 0.01797269599046558 sec
Decode latency: 1.920157408923842 sec
Time for inference 7: 1.94 sec total, 528.15 tokens/sec
Decode latency: 1.92 sec
Prefill latency: 0.02 sec
Bandwidth achieved: 212.73 GB/s
FLOPS achieved: 1.06 TF/s

Prefill latency: 0.01838319399394095 sec
Decode latency: 1.920197380008176 sec
Time for inference 8: 1.94 sec total, 528.02 tokens/sec
Decode latency: 1.92 sec
Prefill latency: 0.02 sec
Bandwidth achieved: 212.67 GB/s
FLOPS achieved: 1.06 TF/s

Prefill latency: 0.0182430490385741 sec
Decode latency: 1.920491426018998 sec
Time for inference 9: 1.94 sec total, 527.97 tokens/sec
Decode latency: 1.92 sec
Prefill latency: 0.02 sec
Bandwidth achieved: 212.66 GB/s
FLOPS achieved: 1.06 TF/s

Prefill latency: 0.01801249699201435 sec
Decode latency: 1.920191177050583 sec
Time for inference 10: 1.94 sec total, 528.12 tokens/sec
Decode latency: 1.92 sec
Prefill latency: 0.02 sec
Bandwidth achieved: 212.72 GB/s
FLOPS achieved: 1.06 TF/s

==========
Batch Size: 4
Prompt Length: 1024
Generated tokens: 256
Average decode latency: 1.9205 sec
Average prefill latency: 0.0181 sec
Average tokens/sec: 528.01
Memory used: 1.77 GB
Done. we are killing the process
