flash_kv_decode is set to True
Using device=cuda
Loading model ...
GPTParallel(
  (tok_embeddings): Embedding(49152, 1536)
  (layers): ModuleList(
    (0-39): 40 x ParallelTransformerBlock(
      semi_compiled = False
      (attention): FuseAttentionMLP(
        (wqkv1): Linear(in_features=1536, out_features=12800, bias=False)
        (wo): Linear(in_features=1536, out_features=1536, bias=False)
        (w2): Linear(in_features=4096, out_features=1536, bias=False)
      )
      (attention_norm): RMSNorm()
    )
  )
  (norm): RMSNorm()
  (output): Linear(in_features=1536, out_features=49152, bias=False)
)
Time to load model: 0.93 seconds
Prefill latency: 0.20648915192577988 sec
Decode latency: 3.302699887077324 sec
Compilation time: 3.51 seconds
Prefill latency: 0.20598683098796755 sec
Decode latency: 3.301901187049225 sec
Prefill latency: 0.20613755995873362 sec
Decode latency: 3.301158646005206 sec
Prefill latency: 0.2060228909831494 sec
Decode latency: 3.3020666090305895 sec
Prefill latency: 0.206045092898421 sec
Decode latency: 3.3017454750370234 sec
Prefill latency: 0.20605089410673827 sec
Decode latency: 3.3020002249395475 sec
Time for inference 1: 3.51 sec total, 1167.33 tokens/sec
Decode latency: 3.30 sec
Prefill latency: 0.21 sec
Bandwidth achieved: 2820.31 GB/s
FLOPS achieved: 14.10 TF/s

Prefill latency: 0.20617662905715406 sec
Decode latency: 3.30177963397 sec
Time for inference 2: 3.51 sec total, 1167.34 tokens/sec
Decode latency: 3.30 sec
Prefill latency: 0.21 sec
Bandwidth achieved: 2820.34 GB/s
FLOPS achieved: 14.10 TF/s

Prefill latency: 0.20605031307786703 sec
Decode latency: 3.3022609528852627 sec
Time for inference 3: 3.51 sec total, 1167.24 tokens/sec
Decode latency: 3.30 sec
Prefill latency: 0.21 sec
Bandwidth achieved: 2820.11 GB/s
FLOPS achieved: 14.10 TF/s

Prefill latency: 0.20608255302067846 sec
Decode latency: 3.3017779699293897 sec
Time for inference 4: 3.51 sec total, 1167.40 tokens/sec
Decode latency: 3.30 sec
Prefill latency: 0.21 sec
Bandwidth achieved: 2820.50 GB/s
FLOPS achieved: 14.10 TF/s

Prefill latency: 0.20599727099761367 sec
Decode latency: 3.294466120074503 sec
Time for inference 5: 3.50 sec total, 1169.86 tokens/sec
Decode latency: 3.29 sec
Prefill latency: 0.21 sec
Bandwidth achieved: 2826.43 GB/s
FLOPS achieved: 14.13 TF/s

Prefill latency: 0.20612265600357205 sec
Decode latency: 3.3017426809528843 sec
Time for inference 6: 3.51 sec total, 1167.41 tokens/sec
Decode latency: 3.30 sec
Prefill latency: 0.21 sec
Bandwidth achieved: 2820.51 GB/s
FLOPS achieved: 14.10 TF/s

Prefill latency: 0.20611553802154958 sec
Decode latency: 3.30315062799491 sec
Time for inference 7: 3.51 sec total, 1166.95 tokens/sec
Decode latency: 3.30 sec
Prefill latency: 0.21 sec
Bandwidth achieved: 2819.41 GB/s
FLOPS achieved: 14.10 TF/s

Prefill latency: 0.20618695206940174 sec
Decode latency: 3.30169572297018 sec
Time for inference 8: 3.51 sec total, 1167.36 tokens/sec
Decode latency: 3.30 sec
Prefill latency: 0.21 sec
Bandwidth achieved: 2820.39 GB/s
FLOPS achieved: 14.10 TF/s

Prefill latency: 0.20610994391608983 sec
Decode latency: 3.3036282990360633 sec
Time for inference 9: 3.51 sec total, 1166.75 tokens/sec
Decode latency: 3.30 sec
Prefill latency: 0.21 sec
Bandwidth achieved: 2818.92 GB/s
FLOPS achieved: 14.09 TF/s

Prefill latency: 0.20624111604411155 sec
Decode latency: 3.3017319729551673 sec
Time for inference 10: 3.51 sec total, 1167.33 tokens/sec
Decode latency: 3.30 sec
Prefill latency: 0.21 sec
Bandwidth achieved: 2820.33 GB/s
FLOPS achieved: 14.10 TF/s

==========
Batch Size: 16
Prompt Length: 1024
Generated tokens: 256
Average decode latency: 3.3014 sec
Average prefill latency: 0.2061 sec
Average tokens/sec: 1167.50
Memory used: 13.08 GB
Done. we are killing the process
