flash_kv_decode is set to True
Using device=cuda
Loading model ...
GPTParallel(
  (tok_embeddings): Embedding(49152, 1536)
  (layers): ModuleList(
    (0-39): 40 x ParallelTransformerBlock(
      semi_compiled = False
      (attention): FuseAttentionMLP(
        (wqkv1): Linear(in_features=1536, out_features=12800, bias=False)
        (wo): Linear(in_features=1536, out_features=1536, bias=False)
        (w2): Linear(in_features=4096, out_features=1536, bias=False)
      )
      (attention_norm): RMSNorm()
    )
  )
  (norm): RMSNorm()
  (output): Linear(in_features=1536, out_features=49152, bias=False)
)
Time to load model: 0.93 seconds
Prefill latency: 0.10641301004216075 sec
Decode latency: 2.69042374601122 sec
Compilation time: 2.80 seconds
Prefill latency: 0.10602695296984166 sec
Decode latency: 2.6979734709020704 sec
Prefill latency: 0.1062362560769543 sec
Decode latency: 2.6142897029640153 sec
Prefill latency: 0.10608673200476915 sec
Decode latency: 2.6919836559100077 sec
Prefill latency: 0.10615064797457308 sec
Decode latency: 2.586571119958535 sec
Prefill latency: 0.10617578809615225 sec
Decode latency: 2.6235961091006175 sec
Time for inference 1: 2.73 sec total, 749.96 tokens/sec
Decode latency: 2.62 sec
Prefill latency: 0.11 sec
Bandwidth achieved: 1811.94 GB/s
FLOPS achieved: 9.06 TF/s

Prefill latency: 0.10604974708985537 sec
Decode latency: 2.6451281750341877 sec
Time for inference 2: 2.75 sec total, 744.16 tokens/sec
Decode latency: 2.65 sec
Prefill latency: 0.11 sec
Bandwidth achieved: 1797.91 GB/s
FLOPS achieved: 8.99 TF/s

Prefill latency: 0.10608402302023023 sec
Decode latency: 2.578654872952029 sec
Time for inference 3: 2.69 sec total, 762.61 tokens/sec
Decode latency: 2.58 sec
Prefill latency: 0.11 sec
Bandwidth achieved: 1842.49 GB/s
FLOPS achieved: 9.21 TF/s

Prefill latency: 0.10570178204216063 sec
Decode latency: 2.5714118650648743 sec
Time for inference 4: 2.68 sec total, 764.78 tokens/sec
Decode latency: 2.57 sec
Prefill latency: 0.11 sec
Bandwidth achieved: 1847.75 GB/s
FLOPS achieved: 9.24 TF/s

Prefill latency: 0.1057203410891816 sec
Decode latency: 2.691451219958253 sec
Time for inference 5: 2.80 sec total, 731.94 tokens/sec
Decode latency: 2.69 sec
Prefill latency: 0.11 sec
Bandwidth achieved: 1768.39 GB/s
FLOPS achieved: 8.84 TF/s

Prefill latency: 0.10572975699324161 sec
Decode latency: 2.6913825240917504 sec
Time for inference 6: 2.80 sec total, 731.96 tokens/sec
Decode latency: 2.69 sec
Prefill latency: 0.11 sec
Bandwidth achieved: 1768.46 GB/s
FLOPS achieved: 8.84 TF/s

Prefill latency: 0.10572338697966188 sec
Decode latency: 2.5684637799859047 sec
Time for inference 7: 2.68 sec total, 765.60 tokens/sec
Decode latency: 2.57 sec
Prefill latency: 0.11 sec
Bandwidth achieved: 1849.72 GB/s
FLOPS achieved: 9.25 TF/s

Prefill latency: 0.1057274320628494 sec
Decode latency: 2.664340140996501 sec
Time for inference 8: 2.77 sec total, 739.12 tokens/sec
Decode latency: 2.66 sec
Prefill latency: 0.11 sec
Bandwidth achieved: 1785.75 GB/s
FLOPS achieved: 8.93 TF/s

Prefill latency: 0.10574656294193119 sec
Decode latency: 2.691356169991195 sec
Time for inference 9: 2.80 sec total, 731.99 tokens/sec
Decode latency: 2.69 sec
Prefill latency: 0.11 sec
Bandwidth achieved: 1768.51 GB/s
FLOPS achieved: 8.84 TF/s

Prefill latency: 0.10583295696415007 sec
Decode latency: 2.6456628299783915 sec
Time for inference 10: 2.75 sec total, 744.13 tokens/sec
Decode latency: 2.65 sec
Prefill latency: 0.11 sec
Bandwidth achieved: 1797.85 GB/s
FLOPS achieved: 8.99 TF/s

==========
Batch Size: 8
Prompt Length: 1024
Generated tokens: 256
Average decode latency: 2.6371 sec
Average prefill latency: 0.1058 sec
Average tokens/sec: 746.62
Memory used: 7.98 GB
Done. we are killing the process
