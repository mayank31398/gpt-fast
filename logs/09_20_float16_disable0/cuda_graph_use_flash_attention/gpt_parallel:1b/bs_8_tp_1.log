flash_kv_decode is set to True
Using device=cuda
Loading model ...
GPTParallel(
  (tok_embeddings): Embedding(49152, 1536)
  (layers): ModuleList(
    (0-39): 40 x ParallelTransformerBlock(
      semi_compiled = False
      (attention): FuseAttentionMLP(
        (wqkv1): Linear(in_features=1536, out_features=10752, bias=False)
        (wo): Linear(in_features=1536, out_features=1536, bias=False)
        (w2): Linear(in_features=4096, out_features=1536, bias=False)
      )
      (attention_norm): RMSNorm()
    )
  )
  (norm): RMSNorm()
  (output): Linear(in_features=1536, out_features=49152, bias=False)
)
Time to load model: 0.94 seconds
Prefill latency: 0.09121058799792081 sec
Decode latency: 2.9351234569912776 sec
Compilation time: 3.03 seconds
Prefill latency: 0.09089744801167399 sec
Decode latency: 2.925033002975397 sec
Prefill latency: 0.09054575301706791 sec
Decode latency: 2.924184554023668 sec
Prefill latency: 0.09060758992563933 sec
Decode latency: 2.7976058039348572 sec
Prefill latency: 0.09066479897592217 sec
Decode latency: 2.9250391649547964 sec
Prefill latency: 0.09067401895299554 sec
Decode latency: 2.9239203210454434 sec
Time for inference 1: 3.02 sec total, 679.20 tokens/sec
Decode latency: 2.92 sec
Prefill latency: 0.09 sec
Bandwidth achieved: 1470.06 GB/s
FLOPS achieved: 7.35 TF/s

Prefill latency: 0.09055629000067711 sec
Decode latency: 2.9232360979076475 sec
Time for inference 2: 3.01 sec total, 679.38 tokens/sec
Decode latency: 2.92 sec
Prefill latency: 0.09 sec
Bandwidth achieved: 1470.44 GB/s
FLOPS achieved: 7.35 TF/s

Prefill latency: 0.09054705698508769 sec
Decode latency: 2.827275056974031 sec
Time for inference 3: 2.92 sec total, 701.66 tokens/sec
Decode latency: 2.83 sec
Prefill latency: 0.09 sec
Bandwidth achieved: 1518.66 GB/s
FLOPS achieved: 7.59 TF/s

Prefill latency: 0.09053296502679586 sec
Decode latency: 2.924650266999379 sec
Time for inference 4: 3.02 sec total, 679.03 tokens/sec
Decode latency: 2.92 sec
Prefill latency: 0.09 sec
Bandwidth achieved: 1469.68 GB/s
FLOPS achieved: 7.35 TF/s

Prefill latency: 0.09062414907384664 sec
Decode latency: 2.8346811609808356 sec
Time for inference 5: 2.93 sec total, 699.90 tokens/sec
Decode latency: 2.83 sec
Prefill latency: 0.09 sec
Bandwidth achieved: 1514.86 GB/s
FLOPS achieved: 7.57 TF/s

Prefill latency: 0.09056087804492563 sec
Decode latency: 2.8111633219523355 sec
Time for inference 6: 2.90 sec total, 705.60 tokens/sec
Decode latency: 2.81 sec
Prefill latency: 0.09 sec
Bandwidth achieved: 1527.20 GB/s
FLOPS achieved: 7.64 TF/s

Prefill latency: 0.09056993399281055 sec
Decode latency: 2.9246485750190914 sec
Time for inference 7: 3.02 sec total, 679.07 tokens/sec
Decode latency: 2.92 sec
Prefill latency: 0.09 sec
Bandwidth achieved: 1469.76 GB/s
FLOPS achieved: 7.35 TF/s

Prefill latency: 0.09062760404776782 sec
Decode latency: 2.92436672502663 sec
Time for inference 8: 3.02 sec total, 679.11 tokens/sec
Decode latency: 2.92 sec
Prefill latency: 0.09 sec
Bandwidth achieved: 1469.85 GB/s
FLOPS achieved: 7.35 TF/s

Prefill latency: 0.09069506905507296 sec
Decode latency: 2.8176518760155886 sec
Time for inference 9: 2.91 sec total, 704.02 tokens/sec
Decode latency: 2.82 sec
Prefill latency: 0.09 sec
Bandwidth achieved: 1523.76 GB/s
FLOPS achieved: 7.62 TF/s

Prefill latency: 0.09052269905805588 sec
Decode latency: 2.924133621971123 sec
Time for inference 10: 3.02 sec total, 679.18 tokens/sec
Decode latency: 2.92 sec
Prefill latency: 0.09 sec
Bandwidth achieved: 1470.01 GB/s
FLOPS achieved: 7.35 TF/s

==========
Batch Size: 8
Prompt Length: 1024
Generated tokens: 256
Average decode latency: 2.8836 sec
Average prefill latency: 0.0906 sec
Average tokens/sec: 688.61
Memory used: 5.96 GB
Done. we are killing the process
