W1001 02:07:32.976000 23436669241152 torch/distributed/run.py:779] 
W1001 02:07:32.976000 23436669241152 torch/distributed/run.py:779] *****************************************
W1001 02:07:32.976000 23436669241152 torch/distributed/run.py:779] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W1001 02:07:32.976000 23436669241152 torch/distributed/run.py:779] *****************************************
flash_kv_decode is set to True
Using device=cuda
Loading model ...
GPTParallel(
  (tok_embeddings): Embedding(49152, 1536)
  (layers): ModuleList(
    (0-39): 40 x ParallelTransformerBlock(
      semi_compiled = False
      (attention): FuseAttentionMLP(
        (wqkv1): Linear(in_features=1536, out_features=1600, bias=False)
        (wo): Linear(in_features=192, out_features=1536, bias=False)
        (w2): Linear(in_features=512, out_features=1536, bias=False)
      )
      (attention_norm): RMSNorm()
    )
  )
  (norm): RMSNorm()
  (output): Linear(in_features=1536, out_features=49152, bias=False)
)
Time to load model: 1.17 seconds
Prefill latency: 0.018822745070792735 sec
Decode latency: 1.7819099120097235 sec
Compilation time: 1.80 seconds
Compilation time: 1.82 seconds
Compilation time: 1.85 seconds
Compilation time: 1.83 seconds
Compilation time: 1.80 seconds
Compilation time: 1.81 seconds
Compilation time: 1.82 seconds
Compilation time: 1.79 seconds
Prefill latency: 0.01152249297592789 sec
Decode latency: 1.7804786649066955 sec
Prefill latency: 0.01135199994314462 sec
Decode latency: 1.7791350889019668 sec
Prefill latency: 0.0114276580279693 sec
Decode latency: 1.7816003309562802 sec
Prefill latency: 0.011621707933954895 sec
Decode latency: 1.7784369320143014 sec
Prefill latency: 0.011422301991842687 sec
Decode latency: 1.7811715140705928 sec
Time for inference 1: 1.79 sec total, 142.74 tokens/sec
Decode latency: 1.78 sec
Prefill latency: 0.01 sec
Bandwidth achieved: 61.98 GB/s
FLOPS achieved: 0.31 TF/s

Prefill latency: 0.011374118970707059 sec
Decode latency: 1.7807470510015264 sec
Time for inference 2: 1.79 sec total, 142.78 tokens/sec
Decode latency: 1.78 sec
Prefill latency: 0.01 sec
Bandwidth achieved: 62.00 GB/s
FLOPS achieved: 0.31 TF/s

Prefill latency: 0.011385970050469041 sec
Decode latency: 1.7804599680239335 sec
Time for inference 3: 1.79 sec total, 142.81 tokens/sec
Decode latency: 1.78 sec
Prefill latency: 0.01 sec
Bandwidth achieved: 62.01 GB/s
FLOPS achieved: 0.31 TF/s

Prefill latency: 0.011352404952049255 sec
Decode latency: 1.7778496569953859 sec
Time for inference 4: 1.79 sec total, 143.01 tokens/sec
Decode latency: 1.78 sec
Prefill latency: 0.01 sec
Bandwidth achieved: 62.10 GB/s
FLOPS achieved: 0.31 TF/s

Prefill latency: 0.01143840595614165 sec
Decode latency: 1.7785521850455552 sec
Time for inference 5: 1.79 sec total, 142.94 tokens/sec
Decode latency: 1.78 sec
Prefill latency: 0.01 sec
Bandwidth achieved: 62.07 GB/s
FLOPS achieved: 0.31 TF/s

Prefill latency: 0.011429184931330383 sec
Decode latency: 1.781505796010606 sec
Time for inference 6: 1.79 sec total, 142.72 tokens/sec
Decode latency: 1.78 sec
Prefill latency: 0.01 sec
Bandwidth achieved: 61.97 GB/s
FLOPS achieved: 0.31 TF/s

Prefill latency: 0.011357996962033212 sec
Decode latency: 1.7811047249706462 sec
Time for inference 7: 1.79 sec total, 142.77 tokens/sec
Decode latency: 1.78 sec
Prefill latency: 0.01 sec
Bandwidth achieved: 61.99 GB/s
FLOPS achieved: 0.31 TF/s

Prefill latency: 0.011370157008059323 sec
Decode latency: 1.7801131489686668 sec
Time for inference 8: 1.79 sec total, 142.84 tokens/sec
Decode latency: 1.78 sec
Prefill latency: 0.01 sec
Bandwidth achieved: 62.03 GB/s
FLOPS achieved: 0.31 TF/s

Prefill latency: 0.011685697943903506 sec
Decode latency: 1.7810014070710167 sec
Time for inference 9: 1.79 sec total, 142.75 tokens/sec
Decode latency: 1.78 sec
Prefill latency: 0.01 sec
Bandwidth achieved: 61.99 GB/s
FLOPS achieved: 0.31 TF/s

Prefill latency: 0.01142959704156965 sec
Decode latency: 1.7815903619630262 sec
Time for inference 10: 1.79 sec total, 142.71 tokens/sec
Decode latency: 1.78 sec
Prefill latency: 0.01 sec
Bandwidth achieved: 61.97 GB/s
FLOPS achieved: 0.31 TF/s

==========
Batch Size: 1
Prompt Length: 1024
Generated tokens: 256
Average decode latency: 1.7804 sec
Average prefill latency: 0.0114 sec
Average tokens/sec: 142.81
Memory used: 1.04 GB
Done. we are killing the process
