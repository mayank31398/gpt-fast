W0930 19:15:34.441000 23178927839040 torch/distributed/run.py:779] 
W0930 19:15:34.441000 23178927839040 torch/distributed/run.py:779] *****************************************
W0930 19:15:34.441000 23178927839040 torch/distributed/run.py:779] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W0930 19:15:34.441000 23178927839040 torch/distributed/run.py:779] *****************************************
flash_kv_decode is set to True
Using device=cuda
Loading model ...
GPTParallel(
  (tok_embeddings): Embedding(49152, 1536)
  (layers): ModuleList(
    (0-39): 40 x ParallelTransformerBlock(
      semi_compiled = False
      (attention): FuseAttentionMLP(
        (wqkv1): Linear(in_features=1536, out_features=1344, bias=False)
        (wo): Linear(in_features=192, out_features=1536, bias=False)
        (w2): Linear(in_features=512, out_features=1536, bias=False)
      )
      (attention_norm): RMSNorm()
    )
  )
  (norm): RMSNorm()
  (output): Linear(in_features=1536, out_features=49152, bias=False)
)
Time to load model: 1.03 seconds
Prefill latency: 0.08660699205938727 sec
Decode latency: 1.7798234389629215 sec
Compilation time: 1.88 seconds
Compilation time: 1.79 secondsCompilation time: 1.84 seconds

Compilation time: 1.83 secondsCompilation time: 1.84 seconds

Compilation time: 1.80 secondsCompilation time: 1.82 seconds

Compilation time: 1.87 seconds
Prefill latency: 0.011514771962538362 sec
Decode latency: 1.7787814289331436 sec
Prefill latency: 0.011429273057729006 sec
Decode latency: 1.7805068050511181 sec
Prefill latency: 0.0114796650595963 sec
Decode latency: 1.7793738399632275 sec
Prefill latency: 0.011485552066005766 sec
Decode latency: 1.7779650449519977 sec
Prefill latency: 0.01151257602032274 sec
Decode latency: 1.7791329859755933 sec
Time for inference 1: 1.79 sec total, 142.91 tokens/sec
Decode latency: 1.78 sec
Prefill latency: 0.01 sec
Bandwidth achieved: 57.56 GB/s
FLOPS achieved: 0.29 TF/s

Prefill latency: 0.011429940001107752 sec
Decode latency: 1.7801702099386603 sec
Time for inference 2: 1.79 sec total, 142.83 tokens/sec
Decode latency: 1.78 sec
Prefill latency: 0.01 sec
Bandwidth achieved: 57.53 GB/s
FLOPS achieved: 0.29 TF/s

Prefill latency: 0.011675120913423598 sec
Decode latency: 1.7764196860371158 sec
Time for inference 3: 1.79 sec total, 143.11 tokens/sec
Decode latency: 1.78 sec
Prefill latency: 0.01 sec
Bandwidth achieved: 57.64 GB/s
FLOPS achieved: 0.29 TF/s

Prefill latency: 0.011476143030449748 sec
Decode latency: 1.7789798219455406 sec
Time for inference 4: 1.79 sec total, 142.92 tokens/sec
Decode latency: 1.78 sec
Prefill latency: 0.01 sec
Bandwidth achieved: 57.57 GB/s
FLOPS achieved: 0.29 TF/s

Prefill latency: 0.01141599495895207 sec
Decode latency: 1.7792581981047988 sec
Time for inference 5: 1.79 sec total, 142.90 tokens/sec
Decode latency: 1.78 sec
Prefill latency: 0.01 sec
Bandwidth achieved: 57.56 GB/s
FLOPS achieved: 0.29 TF/s

Prefill latency: 0.011489102034829557 sec
Decode latency: 1.777885247953236 sec
Time for inference 6: 1.79 sec total, 143.01 tokens/sec
Decode latency: 1.78 sec
Prefill latency: 0.01 sec
Bandwidth achieved: 57.60 GB/s
FLOPS achieved: 0.29 TF/s

Prefill latency: 0.011471505044028163 sec
Decode latency: 1.7795408279635012 sec
Time for inference 7: 1.79 sec total, 142.87 tokens/sec
Decode latency: 1.78 sec
Prefill latency: 0.01 sec
Bandwidth achieved: 57.55 GB/s
FLOPS achieved: 0.29 TF/s

Prefill latency: 0.01157970994245261 sec
Decode latency: 1.7789689700584859 sec
Time for inference 8: 1.79 sec total, 142.92 tokens/sec
Decode latency: 1.78 sec
Prefill latency: 0.01 sec
Bandwidth achieved: 57.56 GB/s
FLOPS achieved: 0.29 TF/s

Prefill latency: 0.011445346986874938 sec
Decode latency: 1.780046063940972 sec
Time for inference 9: 1.79 sec total, 142.84 tokens/sec
Decode latency: 1.78 sec
Prefill latency: 0.01 sec
Bandwidth achieved: 57.53 GB/s
FLOPS achieved: 0.29 TF/s

Prefill latency: 0.011436458094976842 sec
Decode latency: 1.779964744928293 sec
Time for inference 10: 1.79 sec total, 142.83 tokens/sec
Decode latency: 1.78 sec
Prefill latency: 0.01 sec
Bandwidth achieved: 57.53 GB/s
FLOPS achieved: 0.29 TF/s

==========
Batch Size: 1
Prompt Length: 1024
Generated tokens: 256
Average decode latency: 1.7790 sec
Average prefill latency: 0.0115 sec
Average tokens/sec: 142.91
Memory used: 0.97 GB
Done. we are killing the process
