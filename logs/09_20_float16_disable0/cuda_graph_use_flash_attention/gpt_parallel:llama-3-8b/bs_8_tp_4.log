W0928 17:14:08.366000 23079759206208 torch/distributed/run.py:779] 
W0928 17:14:08.366000 23079759206208 torch/distributed/run.py:779] *****************************************
W0928 17:14:08.366000 23079759206208 torch/distributed/run.py:779] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W0928 17:14:08.366000 23079759206208 torch/distributed/run.py:779] *****************************************
flash_kv_decode is set to True
Using device=cuda
Loading model ...
GPTParallel(
  (tok_embeddings): Embedding(128256, 4096)
  (layers): ModuleList(
    (0-31): 32 x ParallelTransformerBlock(
      semi_compiled = False
      (attention): FuseAttentionMLP(
        (wqkv1): Linear(in_features=4096, out_features=8704, bias=False)
        (wo): Linear(in_features=1024, out_features=4096, bias=False)
        (w2): Linear(in_features=3584, out_features=4096, bias=False)
      )
      (attention_norm): RMSNorm()
    )
  )
  (norm): RMSNorm()
  (output): Linear(in_features=4096, out_features=128256, bias=False)
)
Time to load model: 0.94 seconds
Prefill latency: 0.11106514744460583 sec
Decode latency: 2.3602274544537067 sec
Compilation time: 2.46 secondsCompilation time: 2.47 seconds

Compilation time: 2.48 seconds
Compilation time: 2.47 seconds
Prefill latency: 0.10252907685935497 sec
Decode latency: 2.359543001279235 sec
Prefill latency: 0.10297292750328779 sec
Decode latency: 2.3593700723722577 sec
Prefill latency: 0.10219981800764799 sec
Decode latency: 2.360051046125591 sec
Prefill latency: 0.10247462149709463 sec
Decode latency: 2.3612097641453147 sec
Prefill latency: 0.10224474035203457 sec
Decode latency: 2.360581680200994 sec
Time for inference 1: 2.46 sec total, 831.27 tokens/sec
Decode latency: 2.36 sec
Prefill latency: 0.10 sec
Bandwidth achieved: 3774.46 GB/s
FLOPS achieved: 18.87 TF/s

Prefill latency: 0.10265811625868082 sec
Decode latency: 2.360498151741922 sec
Time for inference 2: 2.46 sec total, 831.17 tokens/sec
Decode latency: 2.36 sec
Prefill latency: 0.10 sec
Bandwidth achieved: 3774.03 GB/s
FLOPS achieved: 18.87 TF/s

Prefill latency: 0.10269438661634922 sec
Decode latency: 2.3592480262741446 sec
Time for inference 3: 2.46 sec total, 831.60 tokens/sec
Decode latency: 2.36 sec
Prefill latency: 0.10 sec
Bandwidth achieved: 3775.97 GB/s
FLOPS achieved: 18.88 TF/s

Prefill latency: 0.10258230287581682 sec
Decode latency: 2.360932869836688 sec
Time for inference 4: 2.46 sec total, 831.03 tokens/sec
Decode latency: 2.36 sec
Prefill latency: 0.10 sec
Bandwidth achieved: 3773.40 GB/s
FLOPS achieved: 18.87 TF/s

Prefill latency: 0.10265596956014633 sec
Decode latency: 2.358893061056733 sec
Time for inference 5: 2.46 sec total, 831.73 tokens/sec
Decode latency: 2.36 sec
Prefill latency: 0.10 sec
Bandwidth achieved: 3776.57 GB/s
FLOPS achieved: 18.88 TF/s

Prefill latency: 0.10274042375385761 sec
Decode latency: 2.3597831409424543 sec
Time for inference 6: 2.46 sec total, 831.40 tokens/sec
Decode latency: 2.36 sec
Prefill latency: 0.10 sec
Bandwidth achieved: 3775.08 GB/s
FLOPS achieved: 18.88 TF/s

Prefill latency: 0.10264597740024328 sec
Decode latency: 2.3608140610158443 sec
Time for inference 7: 2.46 sec total, 831.05 tokens/sec
Decode latency: 2.36 sec
Prefill latency: 0.10 sec
Bandwidth achieved: 3773.46 GB/s
FLOPS achieved: 18.87 TF/s

Prefill latency: 0.10238839779049158 sec
Decode latency: 2.35965783521533 sec
Time for inference 8: 2.46 sec total, 831.55 tokens/sec
Decode latency: 2.36 sec
Prefill latency: 0.10 sec
Bandwidth achieved: 3775.76 GB/s
FLOPS achieved: 18.88 TF/s

Prefill latency: 0.10253072530031204 sec
Decode latency: 2.3590602120384574 sec
Time for inference 9: 2.46 sec total, 831.72 tokens/sec
Decode latency: 2.36 sec
Prefill latency: 0.10 sec
Bandwidth achieved: 3776.49 GB/s
FLOPS achieved: 18.88 TF/s

Prefill latency: 0.10256939847022295 sec
Decode latency: 2.3587999576702714 sec
Time for inference 10: 2.46 sec total, 831.81 tokens/sec
Decode latency: 2.36 sec
Prefill latency: 0.10 sec
Bandwidth achieved: 3776.92 GB/s
FLOPS achieved: 18.88 TF/s

==========
Batch Size: 8
Prompt Length: 1024
Generated tokens: 256
Average decode latency: 2.3598 sec
Average prefill latency: 0.1026 sec
Average tokens/sec: 831.43
Memory used: 11.97 GB
Done. we are killing the process
