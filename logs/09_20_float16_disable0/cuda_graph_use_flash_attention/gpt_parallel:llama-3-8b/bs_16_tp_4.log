W0928 17:19:03.133000 23015922636608 torch/distributed/run.py:779] 
W0928 17:19:03.133000 23015922636608 torch/distributed/run.py:779] *****************************************
W0928 17:19:03.133000 23015922636608 torch/distributed/run.py:779] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W0928 17:19:03.133000 23015922636608 torch/distributed/run.py:779] *****************************************
flash_kv_decode is set to True
Using device=cuda
Loading model ...
GPTParallel(
  (tok_embeddings): Embedding(128256, 4096)
  (layers): ModuleList(
    (0-31): 32 x ParallelTransformerBlock(
      semi_compiled = False
      (attention): FuseAttentionMLP(
        (wqkv1): Linear(in_features=4096, out_features=8704, bias=False)
        (wo): Linear(in_features=1024, out_features=4096, bias=False)
        (w2): Linear(in_features=3584, out_features=4096, bias=False)
      )
      (attention_norm): RMSNorm()
    )
  )
  (norm): RMSNorm()
  (output): Linear(in_features=4096, out_features=128256, bias=False)
)
Time to load model: 0.88 seconds
Prefill latency: 0.20897838566452265 sec
Decode latency: 2.760412849485874 sec
Compilation time: 3.01 seconds
Compilation time: 2.99 secondsCompilation time: 2.96 seconds

Compilation time: 2.97 seconds
Prefill latency: 0.1996502624824643 sec
Decode latency: 2.760207653976977 sec
Prefill latency: 0.1986440010368824 sec
Decode latency: 2.7604595329612494 sec
Prefill latency: 0.19835484120994806 sec
Decode latency: 2.7601272566244006 sec
Prefill latency: 0.19924770575016737 sec
Decode latency: 2.759218250401318 sec
Prefill latency: 0.19885805062949657 sec
Decode latency: 2.760655197314918 sec
Time for inference 1: 2.96 sec total, 1383.52 tokens/sec
Decode latency: 2.76 sec
Prefill latency: 0.20 sec
Bandwidth achieved: 6282.02 GB/s
FLOPS achieved: 31.41 TF/s

Prefill latency: 0.19984604138880968 sec
Decode latency: 2.7593484427779913 sec
Time for inference 2: 2.96 sec total, 1383.77 tokens/sec
Decode latency: 2.76 sec
Prefill latency: 0.20 sec
Bandwidth achieved: 6283.15 GB/s
FLOPS achieved: 31.42 TF/s

Prefill latency: 0.19938988238573074 sec
Decode latency: 2.761031142435968 sec
Time for inference 3: 2.96 sec total, 1383.11 tokens/sec
Decode latency: 2.76 sec
Prefill latency: 0.20 sec
Bandwidth achieved: 6280.17 GB/s
FLOPS achieved: 31.40 TF/s

Prefill latency: 0.19855524878948927 sec
Decode latency: 2.7607236495241523 sec
Time for inference 4: 2.96 sec total, 1383.68 tokens/sec
Decode latency: 2.76 sec
Prefill latency: 0.20 sec
Bandwidth achieved: 6282.76 GB/s
FLOPS achieved: 31.41 TF/s

Prefill latency: 0.19966471660882235 sec
Decode latency: 2.760030941106379 sec
Time for inference 5: 2.96 sec total, 1383.52 tokens/sec
Decode latency: 2.76 sec
Prefill latency: 0.20 sec
Bandwidth achieved: 6282.03 GB/s
FLOPS achieved: 31.41 TF/s

Prefill latency: 0.199417844414711 sec
Decode latency: 2.7597574898973107 sec
Time for inference 6: 2.96 sec total, 1383.74 tokens/sec
Decode latency: 2.76 sec
Prefill latency: 0.20 sec
Bandwidth achieved: 6283.02 GB/s
FLOPS achieved: 31.42 TF/s

Prefill latency: 0.20000524539500475 sec
Decode latency: 2.7600078750401735 sec
Time for inference 7: 2.96 sec total, 1383.40 tokens/sec
Decode latency: 2.76 sec
Prefill latency: 0.20 sec
Bandwidth achieved: 6281.49 GB/s
FLOPS achieved: 31.41 TF/s

Prefill latency: 0.19944188371300697 sec
Decode latency: 2.7598834484815598 sec
Time for inference 8: 2.96 sec total, 1383.62 tokens/sec
Decode latency: 2.76 sec
Prefill latency: 0.20 sec
Bandwidth achieved: 6282.48 GB/s
FLOPS achieved: 31.41 TF/s

Prefill latency: 0.19937635120004416 sec
Decode latency: 2.7596226101741195 sec
Time for inference 9: 2.96 sec total, 1383.92 tokens/sec
Decode latency: 2.76 sec
Prefill latency: 0.20 sec
Bandwidth achieved: 6283.84 GB/s
FLOPS achieved: 31.42 TF/s

Prefill latency: 0.19953367207199335 sec
Decode latency: 2.7603108948096633 sec
Time for inference 10: 2.96 sec total, 1383.51 tokens/sec
Decode latency: 2.76 sec
Prefill latency: 0.20 sec
Bandwidth achieved: 6281.95 GB/s
FLOPS achieved: 31.41 TF/s

==========
Batch Size: 16
Prompt Length: 1024
Generated tokens: 256
Average decode latency: 2.7601 sec
Average prefill latency: 0.1994 sec
Average tokens/sec: 1383.58
Memory used: 19.47 GB
Done. we are killing the process
