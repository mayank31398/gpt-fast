W0928 17:07:37.849000 22822215993152 torch/distributed/run.py:779] 
W0928 17:07:37.849000 22822215993152 torch/distributed/run.py:779] *****************************************
W0928 17:07:37.849000 22822215993152 torch/distributed/run.py:779] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W0928 17:07:37.849000 22822215993152 torch/distributed/run.py:779] *****************************************
flash_kv_decode is set to True
Using device=cuda
Loading model ...
GPTParallel(
  (tok_embeddings): Embedding(128256, 4096)
  (layers): ModuleList(
    (0-31): 32 x ParallelTransformerBlock(
      semi_compiled = False
      (attention): FuseAttentionMLP(
        (wqkv1): Linear(in_features=4096, out_features=4352, bias=False)
        (wo): Linear(in_features=512, out_features=4096, bias=False)
        (w2): Linear(in_features=1792, out_features=4096, bias=False)
      )
      (attention_norm): RMSNorm()
    )
  )
  (norm): RMSNorm()
  (output): Linear(in_features=4096, out_features=128256, bias=False)
)
Time to load model: 0.98 seconds
Prefill latency: 0.055780405178666115 sec
Decode latency: 1.724201625213027 sec
Compilation time: 1.77 seconds
Compilation time: 1.78 seconds
Compilation time: 1.79 seconds
Compilation time: 1.76 seconds
Compilation time: 1.74 seconds
Compilation time: 1.77 seconds
Compilation time: 1.76 seconds
Compilation time: 1.78 seconds
Prefill latency: 0.014922959730029106 sec
Decode latency: 1.722650264389813 sec
Prefill latency: 0.015099329873919487 sec
Decode latency: 1.7205080706626177 sec
Prefill latency: 0.015015400014817715 sec
Decode latency: 1.722972061485052 sec
Prefill latency: 0.015010401606559753 sec
Decode latency: 1.7226570220664144 sec
Prefill latency: 0.015011562034487724 sec
Decode latency: 1.7222538199275732 sec
Time for inference 1: 1.74 sec total, 147.30 tokens/sec
Decode latency: 1.72 sec
Prefill latency: 0.02 sec
Bandwidth achieved: 411.82 GB/s
FLOPS achieved: 2.06 TF/s

Prefill latency: 0.015020553022623062 sec
Decode latency: 1.720429296605289 sec
Time for inference 2: 1.74 sec total, 147.46 tokens/sec
Decode latency: 1.72 sec
Prefill latency: 0.02 sec
Bandwidth achieved: 412.26 GB/s
FLOPS achieved: 2.06 TF/s

Prefill latency: 0.015082028694450855 sec
Decode latency: 1.7224154826253653 sec
Time for inference 3: 1.74 sec total, 147.29 tokens/sec
Decode latency: 1.72 sec
Prefill latency: 0.02 sec
Bandwidth achieved: 411.78 GB/s
FLOPS achieved: 2.06 TF/s

Prefill latency: 0.014928717166185379 sec
Decode latency: 1.7198428241536021 sec
Time for inference 4: 1.74 sec total, 147.50 tokens/sec
Decode latency: 1.72 sec
Prefill latency: 0.01 sec
Bandwidth achieved: 412.37 GB/s
FLOPS achieved: 2.06 TF/s

Prefill latency: 0.014996451325714588 sec
Decode latency: 1.7224607383832335 sec
Time for inference 5: 1.74 sec total, 147.26 tokens/sec
Decode latency: 1.72 sec
Prefill latency: 0.01 sec
Bandwidth achieved: 411.71 GB/s
FLOPS achieved: 2.06 TF/s

Prefill latency: 0.015020709484815598 sec
Decode latency: 1.7226087236776948 sec
Time for inference 6: 1.74 sec total, 147.26 tokens/sec
Decode latency: 1.72 sec
Prefill latency: 0.02 sec
Bandwidth achieved: 411.71 GB/s
FLOPS achieved: 2.06 TF/s

Prefill latency: 0.014981926418840885 sec
Decode latency: 1.7202648939564824 sec
Time for inference 7: 1.74 sec total, 147.46 tokens/sec
Decode latency: 1.72 sec
Prefill latency: 0.01 sec
Bandwidth achieved: 412.28 GB/s
FLOPS achieved: 2.06 TF/s

Prefill latency: 0.015037748031318188 sec
Decode latency: 1.720325312577188 sec
Time for inference 8: 1.74 sec total, 147.46 tokens/sec
Decode latency: 1.72 sec
Prefill latency: 0.02 sec
Bandwidth achieved: 412.27 GB/s
FLOPS achieved: 2.06 TF/s

Prefill latency: 0.014985275454819202 sec
Decode latency: 1.7200560104101896 sec
Time for inference 9: 1.74 sec total, 147.49 tokens/sec
Decode latency: 1.72 sec
Prefill latency: 0.01 sec
Bandwidth achieved: 412.34 GB/s
FLOPS achieved: 2.06 TF/s

Prefill latency: 0.015006625093519688 sec
Decode latency: 1.7221148861572146 sec
Time for inference 10: 1.74 sec total, 147.30 tokens/sec
Decode latency: 1.72 sec
Prefill latency: 0.02 sec
Bandwidth achieved: 411.82 GB/s
FLOPS achieved: 2.06 TF/s

==========
Batch Size: 1
Prompt Length: 1024
Generated tokens: 256
Average decode latency: 1.7213 sec
Average prefill latency: 0.0150 sec
Average tokens/sec: 147.38
Memory used: 4.73 GB
Done. we are killing the process
