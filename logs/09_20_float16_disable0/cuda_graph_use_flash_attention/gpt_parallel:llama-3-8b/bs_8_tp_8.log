W0928 17:14:57.008000 22962160740160 torch/distributed/run.py:779] 
W0928 17:14:57.008000 22962160740160 torch/distributed/run.py:779] *****************************************
W0928 17:14:57.008000 22962160740160 torch/distributed/run.py:779] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W0928 17:14:57.008000 22962160740160 torch/distributed/run.py:779] *****************************************
flash_kv_decode is set to True
Using device=cuda
Loading model ...
GPTParallel(
  (tok_embeddings): Embedding(128256, 4096)
  (layers): ModuleList(
    (0-31): 32 x ParallelTransformerBlock(
      semi_compiled = False
      (attention): FuseAttentionMLP(
        (wqkv1): Linear(in_features=4096, out_features=4352, bias=False)
        (wo): Linear(in_features=512, out_features=4096, bias=False)
        (w2): Linear(in_features=1792, out_features=4096, bias=False)
      )
      (attention_norm): RMSNorm()
    )
  )
  (norm): RMSNorm()
  (output): Linear(in_features=4096, out_features=128256, bias=False)
)
Time to load model: 1.05 seconds
Prefill latency: 0.09102700278162956 sec
Decode latency: 2.1627022679895163 sec
Compilation time: 2.26 secondsCompilation time: 2.32 seconds

Compilation time: 2.32 secondsCompilation time: 2.23 seconds

Compilation time: 2.33 seconds
Compilation time: 2.27 secondsCompilation time: 2.26 seconds
Compilation time: 2.25 seconds

Prefill latency: 0.06860033422708511 sec
Decode latency: 2.163295853883028 sec
Prefill latency: 0.0685762008652091 sec
Decode latency: 2.160315237008035 sec
Prefill latency: 0.06844459008425474 sec
Decode latency: 2.1638577301055193 sec
Prefill latency: 0.0686404537409544 sec
Decode latency: 2.1609993698075414 sec
Prefill latency: 0.06849035527557135 sec
Decode latency: 2.1630854476243258 sec
Time for inference 1: 2.23 sec total, 917.45 tokens/sec
Decode latency: 2.16 sec
Prefill latency: 0.07 sec
Bandwidth achieved: 2564.97 GB/s
FLOPS achieved: 12.82 TF/s

Prefill latency: 0.06860819458961487 sec
Decode latency: 2.161329187452793 sec
Time for inference 2: 2.23 sec total, 918.11 tokens/sec
Decode latency: 2.16 sec
Prefill latency: 0.07 sec
Bandwidth achieved: 2566.83 GB/s
FLOPS achieved: 12.83 TF/s

Prefill latency: 0.06860077008605003 sec
Decode latency: 2.161659491248429 sec
Time for inference 3: 2.23 sec total, 917.96 tokens/sec
Decode latency: 2.16 sec
Prefill latency: 0.07 sec
Bandwidth achieved: 2566.40 GB/s
FLOPS achieved: 12.83 TF/s

Prefill latency: 0.06880375184118748 sec
Decode latency: 2.162930393591523 sec
Time for inference 4: 2.23 sec total, 917.38 tokens/sec
Decode latency: 2.16 sec
Prefill latency: 0.07 sec
Bandwidth achieved: 2564.80 GB/s
FLOPS achieved: 12.82 TF/s

Prefill latency: 0.06917065102607012 sec
Decode latency: 2.1602327823638916 sec
Time for inference 5: 2.23 sec total, 918.31 tokens/sec
Decode latency: 2.16 sec
Prefill latency: 0.07 sec
Bandwidth achieved: 2567.40 GB/s
FLOPS achieved: 12.84 TF/s

Prefill latency: 0.06847362406551838 sec
Decode latency: 2.164532421156764 sec
Time for inference 6: 2.23 sec total, 916.82 tokens/sec
Decode latency: 2.16 sec
Prefill latency: 0.07 sec
Bandwidth achieved: 2563.23 GB/s
FLOPS achieved: 12.82 TF/s

Prefill latency: 0.06852131430059671 sec
Decode latency: 2.16086592618376 sec
Time for inference 7: 2.23 sec total, 918.27 tokens/sec
Decode latency: 2.16 sec
Prefill latency: 0.07 sec
Bandwidth achieved: 2567.27 GB/s
FLOPS achieved: 12.84 TF/s

Prefill latency: 0.06853635981678963 sec
Decode latency: 2.164373394101858 sec
Time for inference 8: 2.23 sec total, 916.84 tokens/sec
Decode latency: 2.16 sec
Prefill latency: 0.07 sec
Bandwidth achieved: 2563.28 GB/s
FLOPS achieved: 12.82 TF/s

Prefill latency: 0.06859231181442738 sec
Decode latency: 2.1632642038166523 sec
Time for inference 9: 2.23 sec total, 917.36 tokens/sec
Decode latency: 2.16 sec
Prefill latency: 0.07 sec
Bandwidth achieved: 2564.73 GB/s
FLOPS achieved: 12.82 TF/s

Prefill latency: 0.06873414758592844 sec
Decode latency: 2.160414604470134 sec
Time for inference 10: 2.23 sec total, 918.44 tokens/sec
Decode latency: 2.16 sec
Prefill latency: 0.07 sec
Bandwidth achieved: 2567.74 GB/s
FLOPS achieved: 12.84 TF/s

==========
Batch Size: 8
Prompt Length: 1024
Generated tokens: 256
Average decode latency: 2.1623 sec
Average prefill latency: 0.0687 sec
Average tokens/sec: 917.69
Memory used: 9.56 GB
Done. we are killing the process
