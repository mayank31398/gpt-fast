flash_kv_decode is set to True
Using device=cuda
Loading model ...
GPTParallel(
  (tok_embeddings): Embedding(128256, 4096)
  (layers): ModuleList(
    (0-31): 32 x ParallelTransformerBlock(
      semi_compiled = False
      (attention): FuseAttentionMLP(
        (wqkv1): Linear(in_features=4096, out_features=34816, bias=False)
        (wo): Linear(in_features=4096, out_features=4096, bias=False)
        (w2): Linear(in_features=14336, out_features=4096, bias=False)
      )
      (attention_norm): RMSNorm()
    )
  )
  (norm): RMSNorm()
  (output): Linear(in_features=4096, out_features=128256, bias=False)
)
Time to load model: 0.92 seconds
Prefill latency: 0.03791175875812769 sec
Decode latency: 2.938073947094381 sec
Compilation time: 2.98 seconds
Prefill latency: 0.037525760009884834 sec
Decode latency: 2.938696169294417 sec
Prefill latency: 0.03751569986343384 sec
Decode latency: 2.938857262954116 sec
Prefill latency: 0.037428989075124264 sec
Decode latency: 2.939004042185843 sec
Prefill latency: 0.03748371731489897 sec
Decode latency: 2.939133444800973 sec
Prefill latency: 0.03759313188493252 sec
Decode latency: 2.9382955534383655 sec
Time for inference 1: 2.98 sec total, 86.01 tokens/sec
Decode latency: 2.94 sec
Prefill latency: 0.04 sec
Bandwidth achieved: 1290.92 GB/s
FLOPS achieved: 6.45 TF/s

Prefill latency: 0.03754641581326723 sec
Decode latency: 2.9388802386820316 sec
Time for inference 2: 2.98 sec total, 85.99 tokens/sec
Decode latency: 2.94 sec
Prefill latency: 0.04 sec
Bandwidth achieved: 1290.66 GB/s
FLOPS achieved: 6.45 TF/s

Prefill latency: 0.037525758147239685 sec
Decode latency: 2.9390541333705187 sec
Time for inference 3: 2.98 sec total, 85.99 tokens/sec
Decode latency: 2.94 sec
Prefill latency: 0.04 sec
Bandwidth achieved: 1290.60 GB/s
FLOPS achieved: 6.45 TF/s

Prefill latency: 0.037603503093123436 sec
Decode latency: 2.9391191843897104 sec
Time for inference 4: 2.98 sec total, 85.98 tokens/sec
Decode latency: 2.94 sec
Prefill latency: 0.04 sec
Bandwidth achieved: 1290.56 GB/s
FLOPS achieved: 6.45 TF/s

Prefill latency: 0.03752960544079542 sec
Decode latency: 2.9389677150174975 sec
Time for inference 5: 2.98 sec total, 85.99 tokens/sec
Decode latency: 2.94 sec
Prefill latency: 0.04 sec
Bandwidth achieved: 1290.65 GB/s
FLOPS achieved: 6.45 TF/s

Prefill latency: 0.03764589037746191 sec
Decode latency: 2.938802544027567 sec
Time for inference 6: 2.98 sec total, 85.99 tokens/sec
Decode latency: 2.94 sec
Prefill latency: 0.04 sec
Bandwidth achieved: 1290.67 GB/s
FLOPS achieved: 6.45 TF/s

Prefill latency: 0.037552996538579464 sec
Decode latency: 2.9384940024465322 sec
Time for inference 7: 2.98 sec total, 86.00 tokens/sec
Decode latency: 2.94 sec
Prefill latency: 0.04 sec
Bandwidth achieved: 1290.82 GB/s
FLOPS achieved: 6.45 TF/s

Prefill latency: 0.03754935134202242 sec
Decode latency: 2.938592117279768 sec
Time for inference 8: 2.98 sec total, 86.00 tokens/sec
Decode latency: 2.94 sec
Prefill latency: 0.04 sec
Bandwidth achieved: 1290.79 GB/s
FLOPS achieved: 6.45 TF/s

Prefill latency: 0.037512351758778095 sec
Decode latency: 2.939436494372785 sec
Time for inference 9: 2.98 sec total, 85.97 tokens/sec
Decode latency: 2.94 sec
Prefill latency: 0.04 sec
Bandwidth achieved: 1290.40 GB/s
FLOPS achieved: 6.45 TF/s

Prefill latency: 0.03757094405591488 sec
Decode latency: 2.93930072337389 sec
Time for inference 10: 2.98 sec total, 85.98 tokens/sec
Decode latency: 2.94 sec
Prefill latency: 0.04 sec
Bandwidth achieved: 1290.48 GB/s
FLOPS achieved: 6.45 TF/s

==========
Batch Size: 1
Prompt Length: 1024
Generated tokens: 256
Average decode latency: 2.9389 sec
Average prefill latency: 0.0376 sec
Average tokens/sec: 85.99
Memory used: 17.16 GB
Done. we are killing the process
