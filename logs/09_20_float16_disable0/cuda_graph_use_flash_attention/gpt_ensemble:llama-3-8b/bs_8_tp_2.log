W1001 00:15:47.475000 22643020011328 torch/distributed/run.py:779] 
W1001 00:15:47.475000 22643020011328 torch/distributed/run.py:779] *****************************************
W1001 00:15:47.475000 22643020011328 torch/distributed/run.py:779] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W1001 00:15:47.475000 22643020011328 torch/distributed/run.py:779] *****************************************
flash_kv_decode is set to True
Using device=cuda
Loading model ...
GPTEnsemble(
  (tok_embeddings): Embedding(128256, 4096)
  (layers): ModuleList(
    (0-31): 32 x EnsembleTransformerBlock(
      semi_compiled = False
      (attention): Attention(
        (wqkv): Linear(in_features=4096, out_features=3072, bias=False)
        (wo): Linear(in_features=2048, out_features=4096, bias=False)
      )
      (feed_forward): FeedForward(
        (w1): Linear(in_features=4096, out_features=14336, bias=False)
        (w2): Linear(in_features=7168, out_features=4096, bias=False)
      )
      (ffn_norm): RMSNorm()
      (attention_norm): RMSNorm()
    )
  )
  (norm): RMSNorm()
  (output): Linear(in_features=4096, out_features=128256, bias=False)
)
Time to load model: 0.93 seconds
Prefill latency: 0.17101455200463533 sec
Decode latency: 3.118162606842816 sec
Compilation time: 3.31 seconds
Compilation time: 3.29 seconds
Prefill latency: 0.17162520252168179 sec
Decode latency: 3.1167703047394753 sec
Prefill latency: 0.17121668625622988 sec
Decode latency: 3.118159762583673 sec
Prefill latency: 0.17124488577246666 sec
Decode latency: 3.116813321597874 sec
Prefill latency: 0.1718150842934847 sec
Decode latency: 3.118727962486446 sec
Prefill latency: 0.17176196817308664 sec
Decode latency: 3.1170471608638763 sec
Time for inference 1: 3.29 sec total, 622.57 tokens/sec
Decode latency: 3.12 sec
Prefill latency: 0.17 sec
Bandwidth achieved: 4999.58 GB/s
FLOPS achieved: 25.00 TF/s

Prefill latency: 0.171825529076159 sec
Decode latency: 3.1179581405594945 sec
Time for inference 2: 3.29 sec total, 622.40 tokens/sec
Decode latency: 3.12 sec
Prefill latency: 0.17 sec
Bandwidth achieved: 4998.22 GB/s
FLOPS achieved: 24.99 TF/s

Prefill latency: 0.17179029062390327 sec
Decode latency: 3.1163863986730576 sec
Time for inference 3: 3.29 sec total, 622.69 tokens/sec
Decode latency: 3.12 sec
Prefill latency: 0.17 sec
Bandwidth achieved: 5000.49 GB/s
FLOPS achieved: 25.00 TF/s

Prefill latency: 0.1726489569991827 sec
Decode latency: 3.118697145022452 sec
Time for inference 4: 3.29 sec total, 622.09 tokens/sec
Decode latency: 3.12 sec
Prefill latency: 0.17 sec
Bandwidth achieved: 4995.69 GB/s
FLOPS achieved: 24.98 TF/s

Prefill latency: 0.1716463528573513 sec
Decode latency: 3.1175684724003077 sec
Time for inference 5: 3.29 sec total, 622.50 tokens/sec
Decode latency: 3.12 sec
Prefill latency: 0.17 sec
Bandwidth achieved: 4998.99 GB/s
FLOPS achieved: 24.99 TF/s

Prefill latency: 0.17103540617972612 sec
Decode latency: 3.1178773744031787 sec
Time for inference 6: 3.29 sec total, 622.55 tokens/sec
Decode latency: 3.12 sec
Prefill latency: 0.17 sec
Bandwidth achieved: 4999.40 GB/s
FLOPS achieved: 25.00 TF/s

Prefill latency: 0.17169145587831736 sec
Decode latency: 3.115832111798227 sec
Time for inference 7: 3.29 sec total, 622.84 tokens/sec
Decode latency: 3.12 sec
Prefill latency: 0.17 sec
Bandwidth achieved: 5001.73 GB/s
FLOPS achieved: 25.01 TF/s

Prefill latency: 0.17111109010875225 sec
Decode latency: 3.117385920137167 sec
Time for inference 8: 3.29 sec total, 622.65 tokens/sec
Decode latency: 3.12 sec
Prefill latency: 0.17 sec
Bandwidth achieved: 5000.21 GB/s
FLOPS achieved: 25.00 TF/s

Prefill latency: 0.17142339795827866 sec
Decode latency: 3.116730311885476 sec
Time for inference 9: 3.29 sec total, 622.69 tokens/sec
Decode latency: 3.12 sec
Prefill latency: 0.17 sec
Bandwidth achieved: 5000.50 GB/s
FLOPS achieved: 25.00 TF/s

Prefill latency: 0.1706511126831174 sec
Decode latency: 3.1164207281544805 sec
Time for inference 10: 3.29 sec total, 622.89 tokens/sec
Decode latency: 3.12 sec
Prefill latency: 0.17 sec
Bandwidth achieved: 5002.13 GB/s
FLOPS achieved: 25.01 TF/s

==========
Batch Size: 8
Prompt Length: 1024
Generated tokens: 256
Average decode latency: 3.1172 sec
Average prefill latency: 0.1716 sec
Average tokens/sec: 622.59
Memory used: 16.54 GB
Done. we are killing the process
