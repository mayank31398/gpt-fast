W1001 01:54:43.789000 23284120790848 torch/distributed/run.py:779] 
W1001 01:54:43.789000 23284120790848 torch/distributed/run.py:779] *****************************************
W1001 01:54:43.789000 23284120790848 torch/distributed/run.py:779] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W1001 01:54:43.789000 23284120790848 torch/distributed/run.py:779] *****************************************
flash_kv_decode is set to True
Using device=cuda
Loading model ...
GPTEnsemble(
  (tok_embeddings): Embedding(49152, 2304)
  (layers): ModuleList(
    (0-39): 40 x EnsembleTransformerBlock(
      semi_compiled = False
      (attention): Attention(
        (wqkv): Linear(in_features=2304, out_features=1728, bias=False)
        (wo): Linear(in_features=576, out_features=2304, bias=False)
      )
      (feed_forward): FeedForward(
        (w1): Linear(in_features=2304, out_features=4608, bias=False)
        (w2): Linear(in_features=2304, out_features=2304, bias=False)
      )
      (ffn_norm): RMSNorm()
      (attention_norm): RMSNorm()
    )
  )
  (norm): RMSNorm()
  (output): Linear(in_features=2304, out_features=49152, bias=False)
)
Time to load model: 1.12 seconds
Prefill latency: 0.05984954908490181 sec
Compilation time: 2.20 seconds
Compilation time: 2.32 seconds
Compilation time: 2.35 seconds
Decode latency: 2.274810374015942 sec
Compilation time: 2.34 seconds
Prefill latency: 0.059593316982500255 sec
Decode latency: 2.278064291924238 sec
Prefill latency: 0.05960431008134037 sec
Decode latency: 2.1941950789187104 sec
Prefill latency: 0.059620362939313054 sec
Decode latency: 2.166869994951412 sec
Prefill latency: 0.05968672805465758 sec
Decode latency: 2.28038980695419 sec
Prefill latency: 0.05971832200884819 sec
Decode latency: 2.1418700320646167 sec
Time for inference 1: 2.20 sec total, 929.95 tokens/sec
Decode latency: 2.14 sec
Prefill latency: 0.06 sec
Bandwidth achieved: 1790.68 GB/s
FLOPS achieved: 8.95 TF/s

Prefill latency: 0.05971140298061073 sec
Decode latency: 2.2799787189578637 sec
Time for inference 2: 2.34 sec total, 875.09 tokens/sec
Decode latency: 2.28 sec
Prefill latency: 0.06 sec
Bandwidth achieved: 1685.05 GB/s
FLOPS achieved: 8.43 TF/s

Prefill latency: 0.059755775961093605 sec
Decode latency: 2.279919842025265 sec
Time for inference 3: 2.34 sec total, 875.10 tokens/sec
Decode latency: 2.28 sec
Prefill latency: 0.06 sec
Bandwidth achieved: 1685.05 GB/s
FLOPS achieved: 8.43 TF/s

Prefill latency: 0.05968247400596738 sec
Decode latency: 2.2328621950000525 sec
Time for inference 4: 2.29 sec total, 893.08 tokens/sec
Decode latency: 2.23 sec
Prefill latency: 0.06 sec
Bandwidth achieved: 1719.67 GB/s
FLOPS achieved: 8.60 TF/s

Prefill latency: 0.05978123506065458 sec
Decode latency: 2.279995688004419 sec
Time for inference 5: 2.34 sec total, 875.06 tokens/sec
Decode latency: 2.28 sec
Prefill latency: 0.06 sec
Bandwidth achieved: 1684.98 GB/s
FLOPS achieved: 8.42 TF/s

Prefill latency: 0.059800685034133494 sec
Decode latency: 2.207433755043894 sec
Time for inference 6: 2.27 sec total, 903.05 tokens/sec
Decode latency: 2.21 sec
Prefill latency: 0.06 sec
Bandwidth achieved: 1738.88 GB/s
FLOPS achieved: 8.69 TF/s

Prefill latency: 0.05976044002454728 sec
Decode latency: 2.279498118907213 sec
Time for inference 7: 2.34 sec total, 875.26 tokens/sec
Decode latency: 2.28 sec
Prefill latency: 0.06 sec
Bandwidth achieved: 1685.37 GB/s
FLOPS achieved: 8.43 TF/s

Prefill latency: 0.05978490796405822 sec
Decode latency: 2.2804420669563115 sec
Time for inference 8: 2.34 sec total, 874.86 tokens/sec
Decode latency: 2.28 sec
Prefill latency: 0.06 sec
Bandwidth achieved: 1684.59 GB/s
FLOPS achieved: 8.42 TF/s

Prefill latency: 0.05967310594860464 sec
Decode latency: 2.25364214903675 sec
Time for inference 9: 2.31 sec total, 885.04 tokens/sec
Decode latency: 2.25 sec
Prefill latency: 0.06 sec
Bandwidth achieved: 1704.21 GB/s
FLOPS achieved: 8.52 TF/s

Prefill latency: 0.059752241941168904 sec
Decode latency: 2.2798307680059224 sec
Time for inference 10: 2.34 sec total, 875.12 tokens/sec
Decode latency: 2.28 sec
Prefill latency: 0.06 sec
Bandwidth achieved: 1685.10 GB/s
FLOPS achieved: 8.43 TF/s

==========
Batch Size: 8
Prompt Length: 1024
Generated tokens: 256
Average decode latency: 2.2515 sec
Average prefill latency: 0.0597 sec
Average tokens/sec: 886.16
Memory used: 4.69 GB
Done. we are killing the process
