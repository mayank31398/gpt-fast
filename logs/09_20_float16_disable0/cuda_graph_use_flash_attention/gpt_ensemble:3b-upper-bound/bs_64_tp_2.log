W1001 02:03:03.650000 23151559575360 torch/distributed/run.py:779] 
W1001 02:03:03.650000 23151559575360 torch/distributed/run.py:779] *****************************************
W1001 02:03:03.650000 23151559575360 torch/distributed/run.py:779] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W1001 02:03:03.650000 23151559575360 torch/distributed/run.py:779] *****************************************
flash_kv_decode is set to True
Using device=cuda
Loading model ...
GPTEnsemble(
  (tok_embeddings): Embedding(49152, 2304)
  (layers): ModuleList(
    (0-39): 40 x EnsembleTransformerBlock(
      semi_compiled = False
      (attention): Attention(
        (wqkv): Linear(in_features=2304, out_features=3456, bias=False)
        (wo): Linear(in_features=1152, out_features=2304, bias=False)
      )
      (feed_forward): FeedForward(
        (w1): Linear(in_features=2304, out_features=9216, bias=False)
        (w2): Linear(in_features=4608, out_features=2304, bias=False)
      )
      (ffn_norm): RMSNorm()
      (attention_norm): RMSNorm()
    )
  )
  (norm): RMSNorm()
  (output): Linear(in_features=2304, out_features=49152, bias=False)
)
Time to load model: 1.04 seconds
Prefill latency: 0.8264708460774273 sec
Compilation time: 8.07 seconds
Decode latency: 7.217997012892738 sec
Compilation time: 8.05 seconds
Prefill latency: 0.8213437019148842 sec
Decode latency: 7.215355082997121 sec
Prefill latency: 0.8233726429753006 sec
Decode latency: 7.217655677930452 sec
Prefill latency: 0.8221549849258736 sec
Decode latency: 7.219381989911199 sec
Prefill latency: 0.8204320339718834 sec
Decode latency: 7.220264118979685 sec
Prefill latency: 0.8316705139586702 sec
Decode latency: 7.220790505991317 sec
Time for inference 1: 8.05 sec total, 2034.41 tokens/sec
Decode latency: 7.22 sec
Prefill latency: 0.83 sec
Bandwidth achieved: 7373.23 GB/s
FLOPS achieved: 36.87 TF/s

Prefill latency: 0.824552835081704 sec
Decode latency: 7.222081977990456 sec
Time for inference 2: 8.05 sec total, 2035.90 tokens/sec
Decode latency: 7.22 sec
Prefill latency: 0.82 sec
Bandwidth achieved: 7378.62 GB/s
FLOPS achieved: 36.89 TF/s

Prefill latency: 0.8360813229810447 sec
Decode latency: 7.22110943205189 sec
Time for inference 3: 8.06 sec total, 2033.25 tokens/sec
Decode latency: 7.22 sec
Prefill latency: 0.84 sec
Bandwidth achieved: 7369.02 GB/s
FLOPS achieved: 36.85 TF/s

Prefill latency: 0.8277938880492002 sec
Decode latency: 7.221284130006097 sec
Time for inference 4: 8.05 sec total, 2035.31 tokens/sec
Decode latency: 7.22 sec
Prefill latency: 0.83 sec
Bandwidth achieved: 7376.48 GB/s
FLOPS achieved: 36.88 TF/s

Prefill latency: 0.8289119779365137 sec
Decode latency: 7.222480657976121 sec
Time for inference 5: 8.05 sec total, 2034.70 tokens/sec
Decode latency: 7.22 sec
Prefill latency: 0.83 sec
Bandwidth achieved: 7374.25 GB/s
FLOPS achieved: 36.87 TF/s

Prefill latency: 0.8352087159873918 sec
Decode latency: 7.222578466986306 sec
Time for inference 6: 8.06 sec total, 2033.09 tokens/sec
Decode latency: 7.22 sec
Prefill latency: 0.84 sec
Bandwidth achieved: 7368.45 GB/s
FLOPS achieved: 36.84 TF/s

Prefill latency: 0.8319209469482303 sec
Decode latency: 7.222850269987248 sec
Time for inference 7: 8.06 sec total, 2033.86 tokens/sec
Decode latency: 7.22 sec
Prefill latency: 0.83 sec
Bandwidth achieved: 7371.23 GB/s
FLOPS achieved: 36.86 TF/s

Prefill latency: 0.821878349990584 sec
Decode latency: 7.220629303017631 sec
Time for inference 8: 8.04 sec total, 2036.97 tokens/sec
Decode latency: 7.22 sec
Prefill latency: 0.82 sec
Bandwidth achieved: 7382.50 GB/s
FLOPS achieved: 36.91 TF/s

Prefill latency: 0.8232605010271072 sec
Decode latency: 7.220741432043724 sec
Time for inference 9: 8.04 sec total, 2036.60 tokens/sec
Decode latency: 7.22 sec
Prefill latency: 0.82 sec
Bandwidth achieved: 7381.15 GB/s
FLOPS achieved: 36.91 TF/s

Prefill latency: 0.8329398930072784 sec
Decode latency: 7.219501200946979 sec
Time for inference 10: 8.05 sec total, 2034.44 tokens/sec
Decode latency: 7.22 sec
Prefill latency: 0.83 sec
Bandwidth achieved: 7373.34 GB/s
FLOPS achieved: 36.87 TF/s

==========
Batch Size: 64
Prompt Length: 1024
Generated tokens: 256
Average decode latency: 7.2214 sec
Average prefill latency: 0.8294 sec
Average tokens/sec: 2034.85
Memory used: 31.14 GB
Done. we are killing the process
