W1001 01:51:02.795000 22600053942080 torch/distributed/run.py:779] 
W1001 01:51:02.795000 22600053942080 torch/distributed/run.py:779] *****************************************
W1001 01:51:02.795000 22600053942080 torch/distributed/run.py:779] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W1001 01:51:02.795000 22600053942080 torch/distributed/run.py:779] *****************************************
flash_kv_decode is set to True
Using device=cuda
Loading model ...
GPTEnsemble(
  (tok_embeddings): Embedding(49152, 2304)
  (layers): ModuleList(
    (0-39): 40 x EnsembleTransformerBlock(
      semi_compiled = False
      (attention): Attention(
        (wqkv): Linear(in_features=2304, out_features=3456, bias=False)
        (wo): Linear(in_features=1152, out_features=2304, bias=False)
      )
      (feed_forward): FeedForward(
        (w1): Linear(in_features=2304, out_features=9216, bias=False)
        (w2): Linear(in_features=4608, out_features=2304, bias=False)
      )
      (ffn_norm): RMSNorm()
      (attention_norm): RMSNorm()
    )
  )
  (norm): RMSNorm()
  (output): Linear(in_features=2304, out_features=49152, bias=False)
)
Time to load model: 2.47 seconds
Prefill latency: 0.05652525904588401 sec
Decode latency: 2.417221487965435 sec
Compilation time: 2.47 seconds
Compilation time: 2.51 seconds
Prefill latency: 0.056424268055707216 sec
Decode latency: 2.418318997020833 sec
Prefill latency: 0.05645159899722785 sec
Decode latency: 2.4180370529647917 sec
Prefill latency: 0.05632293096277863 sec
Decode latency: 2.4177371760597453 sec
Prefill latency: 0.05646158894523978 sec
Decode latency: 2.418046641978435 sec
Prefill latency: 0.05650480289477855 sec
Decode latency: 2.418176867067814 sec
Time for inference 1: 2.48 sec total, 413.66 tokens/sec
Decode latency: 2.42 sec
Prefill latency: 0.06 sec
Bandwidth achieved: 1499.20 GB/s
FLOPS achieved: 7.50 TF/s

Prefill latency: 0.05629535799380392 sec
Decode latency: 2.4180186520097777 sec
Time for inference 2: 2.48 sec total, 413.73 tokens/sec
Decode latency: 2.42 sec
Prefill latency: 0.06 sec
Bandwidth achieved: 1499.47 GB/s
FLOPS achieved: 7.50 TF/s

Prefill latency: 0.05631297407671809 sec
Decode latency: 2.418434332939796 sec
Time for inference 3: 2.48 sec total, 413.67 tokens/sec
Decode latency: 2.42 sec
Prefill latency: 0.06 sec
Bandwidth achieved: 1499.23 GB/s
FLOPS achieved: 7.50 TF/s

Prefill latency: 0.05646035901736468 sec
Decode latency: 2.4182045160559937 sec
Time for inference 4: 2.48 sec total, 413.69 tokens/sec
Decode latency: 2.42 sec
Prefill latency: 0.06 sec
Bandwidth achieved: 1499.30 GB/s
FLOPS achieved: 7.50 TF/s

Prefill latency: 0.0565560320392251 sec
Decode latency: 2.4182943070773035 sec
Time for inference 5: 2.48 sec total, 413.65 tokens/sec
Decode latency: 2.42 sec
Prefill latency: 0.06 sec
Bandwidth achieved: 1499.18 GB/s
FLOPS achieved: 7.50 TF/s

Prefill latency: 0.05633248493541032 sec
Decode latency: 2.308745089918375 sec
Time for inference 6: 2.37 sec total, 432.85 tokens/sec
Decode latency: 2.31 sec
Prefill latency: 0.06 sec
Bandwidth achieved: 1568.76 GB/s
FLOPS achieved: 7.84 TF/s

Prefill latency: 0.05645176803227514 sec
Decode latency: 2.4181211199611425 sec
Time for inference 7: 2.48 sec total, 413.70 tokens/sec
Decode latency: 2.42 sec
Prefill latency: 0.06 sec
Bandwidth achieved: 1499.36 GB/s
FLOPS achieved: 7.50 TF/s

Prefill latency: 0.056395621970295906 sec
Decode latency: 2.418143137008883 sec
Time for inference 8: 2.48 sec total, 413.71 tokens/sec
Decode latency: 2.42 sec
Prefill latency: 0.06 sec
Bandwidth achieved: 1499.38 GB/s
FLOPS achieved: 7.50 TF/s

Prefill latency: 0.05647218495141715 sec
Decode latency: 2.418357077986002 sec
Time for inference 9: 2.48 sec total, 413.66 tokens/sec
Decode latency: 2.42 sec
Prefill latency: 0.06 sec
Bandwidth achieved: 1499.21 GB/s
FLOPS achieved: 7.50 TF/s

Prefill latency: 0.0564909199019894 sec
Decode latency: 2.4181215700227767 sec
Time for inference 10: 2.48 sec total, 413.70 tokens/sec
Decode latency: 2.42 sec
Prefill latency: 0.06 sec
Bandwidth achieved: 1499.34 GB/s
FLOPS achieved: 7.50 TF/s

==========
Batch Size: 4
Prompt Length: 1024
Generated tokens: 256
Average decode latency: 2.4073 sec
Average prefill latency: 0.0564 sec
Average tokens/sec: 415.60
Memory used: 5.95 GB
Done. we are killing the process
