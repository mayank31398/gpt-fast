W0930 18:52:06.756000 22945684154176 torch/distributed/run.py:779] 
W0930 18:52:06.756000 22945684154176 torch/distributed/run.py:779] *****************************************
W0930 18:52:06.756000 22945684154176 torch/distributed/run.py:779] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W0930 18:52:06.756000 22945684154176 torch/distributed/run.py:779] *****************************************
flash_kv_decode is set to True
Using device=cuda
Loading model ...
GPTDense(
  (tok_embeddings): Embedding(49152, 1536)
  (layers): ModuleList(
    (0-39): 40 x DenseTransformerBlock(
      semi_compiled = False
      (attention): Attention(
        (wqkv): Linear(in_features=1536, out_features=640, bias=False)
        (wo): Linear(in_features=384, out_features=1536, bias=False)
      )
      (feed_forward): FeedForward(
        (w1): Linear(in_features=1536, out_features=2048, bias=False)
        (w2): Linear(in_features=1024, out_features=1536, bias=False)
      )
      (ffn_norm): RMSNorm()
      (attention_norm): RMSNorm()
    )
  )
  (norm): RMSNorm()
  (output): Linear(in_features=1536, out_features=49152, bias=False)
)
Time to load model: 1.17 seconds
Prefill latency: 0.022801230079494417 sec
Decode latency: 2.007253163959831 sec
Compilation time: 2.02 seconds
Compilation time: 2.03 seconds
Compilation time: 2.09 seconds
Compilation time: 2.03 seconds
Prefill latency: 0.014039814006537199 sec
Decode latency: 2.0065617139916867 sec
Prefill latency: 0.014076860039494932 sec
Decode latency: 2.0072917689103633 sec
Prefill latency: 0.014029974001459777 sec
Decode latency: 2.0087299270089716 sec
Prefill latency: 0.014014958054758608 sec
Decode latency: 2.0082868969766423 sec
Prefill latency: 0.014060339075513184 sec
Decode latency: 2.0070665230741724 sec
Time for inference 1: 2.02 sec total, 126.61 tokens/sec
Decode latency: 2.01 sec
Prefill latency: 0.01 sec
Bandwidth achieved: 82.88 GB/s
FLOPS achieved: 0.41 TF/s

Prefill latency: 0.014002218027599156 sec
Decode latency: 2.00612547097262 sec
Time for inference 2: 2.02 sec total, 126.67 tokens/sec
Decode latency: 2.01 sec
Prefill latency: 0.01 sec
Bandwidth achieved: 82.91 GB/s
FLOPS achieved: 0.41 TF/s

Prefill latency: 0.01403938909061253 sec
Decode latency: 2.005673737032339 sec
Time for inference 3: 2.02 sec total, 126.70 tokens/sec
Decode latency: 2.01 sec
Prefill latency: 0.01 sec
Bandwidth achieved: 82.93 GB/s
FLOPS achieved: 0.41 TF/s

Prefill latency: 0.014279527007602155 sec
Decode latency: 2.0086434310069308 sec
Time for inference 4: 2.02 sec total, 126.50 tokens/sec
Decode latency: 2.01 sec
Prefill latency: 0.01 sec
Bandwidth achieved: 82.80 GB/s
FLOPS achieved: 0.41 TF/s

Prefill latency: 0.014137391932308674 sec
Decode latency: 2.0075709499651566 sec
Time for inference 5: 2.02 sec total, 126.58 tokens/sec
Decode latency: 2.01 sec
Prefill latency: 0.01 sec
Bandwidth achieved: 82.85 GB/s
FLOPS achieved: 0.41 TF/s

Prefill latency: 0.01405346894171089 sec
Decode latency: 2.0051261390326545 sec
Time for inference 6: 2.02 sec total, 126.74 tokens/sec
Decode latency: 2.01 sec
Prefill latency: 0.01 sec
Bandwidth achieved: 82.96 GB/s
FLOPS achieved: 0.41 TF/s

Prefill latency: 0.014087195973843336 sec
Decode latency: 2.008395747980103 sec
Time for inference 7: 2.02 sec total, 126.53 tokens/sec
Decode latency: 2.01 sec
Prefill latency: 0.01 sec
Bandwidth achieved: 82.82 GB/s
FLOPS achieved: 0.41 TF/s

Prefill latency: 0.014248794061131775 sec
Decode latency: 2.0079907930921763 sec
Time for inference 8: 2.02 sec total, 126.54 tokens/sec
Decode latency: 2.01 sec
Prefill latency: 0.01 sec
Bandwidth achieved: 82.83 GB/s
FLOPS achieved: 0.41 TF/s

Prefill latency: 0.01399667700752616 sec
Decode latency: 2.008479033014737 sec
Time for inference 9: 2.02 sec total, 126.53 tokens/sec
Decode latency: 2.01 sec
Prefill latency: 0.01 sec
Bandwidth achieved: 82.82 GB/s
FLOPS achieved: 0.41 TF/s

Prefill latency: 0.014059042907319963 sec
Decode latency: 2.0069807530380785 sec
Time for inference 10: 2.02 sec total, 126.62 tokens/sec
Decode latency: 2.01 sec
Prefill latency: 0.01 sec
Bandwidth achieved: 82.88 GB/s
FLOPS achieved: 0.41 TF/s

==========
Batch Size: 1
Prompt Length: 1024
Generated tokens: 256
Average decode latency: 2.0072 sec
Average prefill latency: 0.0141 sec
Average tokens/sec: 126.60
Memory used: 1.38 GB
Done. we are killing the process
