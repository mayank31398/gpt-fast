W1001 01:42:20.148000 22606995781440 torch/distributed/run.py:779] 
W1001 01:42:20.148000 22606995781440 torch/distributed/run.py:779] *****************************************
W1001 01:42:20.148000 22606995781440 torch/distributed/run.py:779] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W1001 01:42:20.148000 22606995781440 torch/distributed/run.py:779] *****************************************
flash_kv_decode is set to True
Using device=cuda
Loading model ...
GPTDense(
  (tok_embeddings): Embedding(49152, 1536)
  (layers): ModuleList(
    (0-39): 40 x DenseTransformerBlock(
      semi_compiled = False
      (attention): Attention(
        (wqkv): Linear(in_features=1536, out_features=2304, bias=False)
        (wo): Linear(in_features=768, out_features=1536, bias=False)
      )
      (feed_forward): FeedForward(
        (w1): Linear(in_features=1536, out_features=4096, bias=False)
        (w2): Linear(in_features=2048, out_features=1536, bias=False)
      )
      (ffn_norm): RMSNorm()
      (attention_norm): RMSNorm()
    )
  )
  (norm): RMSNorm()
  (output): Linear(in_features=1536, out_features=49152, bias=False)
)
Time to load model: 1.07 seconds
Prefill latency: 0.4923023389419541 sec
Decode latency: 5.457222208962776 sec
Compilation time: 5.95 seconds
Compilation time: 5.95 seconds
Prefill latency: 0.4869258509716019 sec
Decode latency: 5.457570443977602 sec
Prefill latency: 0.48637911095283926 sec
Decode latency: 5.45539253402967 sec
Prefill latency: 0.4862032000673935 sec
Decode latency: 5.4554220490390435 sec
Prefill latency: 0.48611259704921395 sec
Decode latency: 5.455721135018393 sec
Prefill latency: 0.48623422300443053 sec
Decode latency: 5.454219215898775 sec
Time for inference 1: 5.94 sec total, 2757.63 tokens/sec
Decode latency: 5.45 sec
Prefill latency: 0.49 sec
Bandwidth achieved: 3539.99 GB/s
FLOPS achieved: 17.70 TF/s

Prefill latency: 0.4865375270601362 sec
Decode latency: 5.452980406000279 sec
Time for inference 2: 5.94 sec total, 2758.06 tokens/sec
Decode latency: 5.45 sec
Prefill latency: 0.49 sec
Bandwidth achieved: 3540.54 GB/s
FLOPS achieved: 17.70 TF/s

Prefill latency: 0.48636026796884835 sec
Decode latency: 5.454023856087588 sec
Time for inference 3: 5.94 sec total, 2757.67 tokens/sec
Decode latency: 5.45 sec
Prefill latency: 0.49 sec
Bandwidth achieved: 3540.04 GB/s
FLOPS achieved: 17.70 TF/s

Prefill latency: 0.4867631969973445 sec
Decode latency: 5.45288687502034 sec
Time for inference 4: 5.94 sec total, 2757.93 tokens/sec
Decode latency: 5.45 sec
Prefill latency: 0.49 sec
Bandwidth achieved: 3540.37 GB/s
FLOPS achieved: 17.70 TF/s

Prefill latency: 0.48724620195571333 sec
Decode latency: 5.4529099280480295 sec
Time for inference 5: 5.94 sec total, 2757.70 tokens/sec
Decode latency: 5.45 sec
Prefill latency: 0.49 sec
Bandwidth achieved: 3540.07 GB/s
FLOPS achieved: 17.70 TF/s

Prefill latency: 0.4872079649940133 sec
Decode latency: 5.4531695519108325 sec
Time for inference 6: 5.94 sec total, 2757.64 tokens/sec
Decode latency: 5.45 sec
Prefill latency: 0.49 sec
Bandwidth achieved: 3539.99 GB/s
FLOPS achieved: 17.70 TF/s

Prefill latency: 0.4871698439819738 sec
Decode latency: 5.453407841036096 sec
Time for inference 7: 5.94 sec total, 2757.56 tokens/sec
Decode latency: 5.45 sec
Prefill latency: 0.49 sec
Bandwidth achieved: 3539.89 GB/s
FLOPS achieved: 17.70 TF/s

Prefill latency: 0.4872686320450157 sec
Decode latency: 5.454125329037197 sec
Time for inference 8: 5.94 sec total, 2757.22 tokens/sec
Decode latency: 5.45 sec
Prefill latency: 0.49 sec
Bandwidth achieved: 3539.46 GB/s
FLOPS achieved: 17.70 TF/s

Prefill latency: 0.48711581993848085 sec
Decode latency: 5.455098961945623 sec
Time for inference 9: 5.94 sec total, 2756.78 tokens/sec
Decode latency: 5.46 sec
Prefill latency: 0.49 sec
Bandwidth achieved: 3538.89 GB/s
FLOPS achieved: 17.69 TF/s

Prefill latency: 0.4873042500112206 sec
Decode latency: 5.454171346966177 sec
Time for inference 10: 5.94 sec total, 2757.11 tokens/sec
Decode latency: 5.45 sec
Prefill latency: 0.49 sec
Bandwidth achieved: 3539.32 GB/s
FLOPS achieved: 17.70 TF/s

==========
Batch Size: 64
Prompt Length: 1024
Generated tokens: 256
Average decode latency: 5.4537 sec
Average prefill latency: 0.4869 sec
Average tokens/sec: 2757.53
Memory used: 41.58 GB
Done. we are killing the process
