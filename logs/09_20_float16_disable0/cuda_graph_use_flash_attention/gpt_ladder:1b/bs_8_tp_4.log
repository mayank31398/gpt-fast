W1001 01:15:13.962000 22359891842880 torch/distributed/run.py:779] 
W1001 01:15:13.962000 22359891842880 torch/distributed/run.py:779] *****************************************
W1001 01:15:13.962000 22359891842880 torch/distributed/run.py:779] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W1001 01:15:13.962000 22359891842880 torch/distributed/run.py:779] *****************************************
flash_kv_decode is set to True
Using device=cuda
Loading model ...
GPTLadder(
  (tok_embeddings): Embedding(49152, 1536)
  (layers): ModuleList(
    (0-39): 40 x LadderTransformerBlock(
      semi_compiled = False
      (attention): Attention(
        (wqkv): Linear(in_features=1536, out_features=1152, bias=False)
        (wo): Linear(in_features=384, out_features=1536, bias=False)
      )
      (feed_forward): FeedForward(
        (w1): Linear(in_features=1536, out_features=2048, bias=False)
        (w2): Linear(in_features=1024, out_features=1536, bias=False)
      )
      (ffn_norm): RMSNorm()
      (attention_norm): RMSNorm()
    )
  )
  (norm): RMSNorm()
  (output): Linear(in_features=1536, out_features=49152, bias=False)
)
Time to load model: 0.14 seconds
[rank2]:[W1001 01:15:21.860786011 CUDAGraph.cpp:150] Warning: Waiting for pending NCCL work to finish before starting graph capture. (function operator())
[rank3]:[W1001 01:15:21.861737663 CUDAGraph.cpp:150] Warning: Waiting for pending NCCL work to finish before starting graph capture. (function operator())
[rank0]:[W1001 01:15:21.862313820 CUDAGraph.cpp:150] Warning: Waiting for pending NCCL work to finish before starting graph capture. (function operator())
[rank1]:[W1001 01:15:21.886037916 CUDAGraph.cpp:150] Warning: Waiting for pending NCCL work to finish before starting graph capture. (function operator())
Prefill latency: 0.056701886001974344 sec
Decode latency: 2.133791172062047 sec
Compilation time: 2.19 seconds
Compilation time: 2.23 seconds
Compilation time: 2.17 seconds
Compilation time: 2.19 seconds
Prefill latency: 0.03915878897532821 sec
Decode latency: 2.134096608031541 sec
Prefill latency: 0.03914522798731923 sec
Decode latency: 2.133817452006042 sec
Prefill latency: 0.039439548971131444 sec
Decode latency: 2.1343923290260136 sec
Prefill latency: 0.039521459955722094 sec
Decode latency: 2.133958515012637 sec
Prefill latency: 0.039211122086271644 sec
Decode latency: 2.134075894020498 sec
Time for inference 1: 2.17 sec total, 942.03 tokens/sec
Decode latency: 2.13 sec
Prefill latency: 0.04 sec
Bandwidth achieved: 675.88 GB/s
FLOPS achieved: 3.38 TF/s

Prefill latency: 0.03926035400945693 sec
Decode latency: 2.133805016055703 sec
Time for inference 2: 2.17 sec total, 942.09 tokens/sec
Decode latency: 2.13 sec
Prefill latency: 0.04 sec
Bandwidth achieved: 675.93 GB/s
FLOPS achieved: 3.38 TF/s

Prefill latency: 0.039411770994775 sec
Decode latency: 2.133472823887132 sec
Time for inference 3: 2.17 sec total, 942.22 tokens/sec
Decode latency: 2.13 sec
Prefill latency: 0.04 sec
Bandwidth achieved: 676.02 GB/s
FLOPS achieved: 3.38 TF/s

Prefill latency: 0.03950052603613585 sec
Decode latency: 2.1335837410297245 sec
Time for inference 4: 2.17 sec total, 942.10 tokens/sec
Decode latency: 2.13 sec
Prefill latency: 0.04 sec
Bandwidth achieved: 675.94 GB/s
FLOPS achieved: 3.38 TF/s

Prefill latency: 0.039411567035131156 sec
Decode latency: 2.133687869994901 sec
Time for inference 5: 2.17 sec total, 942.11 tokens/sec
Decode latency: 2.13 sec
Prefill latency: 0.04 sec
Bandwidth achieved: 675.94 GB/s
FLOPS achieved: 3.38 TF/s

Prefill latency: 0.03914403496310115 sec
Decode latency: 2.134120799950324 sec
Time for inference 6: 2.17 sec total, 942.05 tokens/sec
Decode latency: 2.13 sec
Prefill latency: 0.04 sec
Bandwidth achieved: 675.90 GB/s
FLOPS achieved: 3.38 TF/s

Prefill latency: 0.03922492091078311 sec
Decode latency: 2.1341024179710075 sec
Time for inference 7: 2.17 sec total, 941.92 tokens/sec
Decode latency: 2.13 sec
Prefill latency: 0.04 sec
Bandwidth achieved: 675.80 GB/s
FLOPS achieved: 3.38 TF/s

Prefill latency: 0.03919531696010381 sec
Decode latency: 2.134451724938117 sec
Time for inference 8: 2.17 sec total, 941.79 tokens/sec
Decode latency: 2.13 sec
Prefill latency: 0.04 sec
Bandwidth achieved: 675.71 GB/s
FLOPS achieved: 3.38 TF/s

Prefill latency: 0.039255760028027 sec
Decode latency: 2.1296229979489 sec
Time for inference 9: 2.17 sec total, 943.84 tokens/sec
Decode latency: 2.13 sec
Prefill latency: 0.04 sec
Bandwidth achieved: 677.18 GB/s
FLOPS achieved: 3.39 TF/s

Prefill latency: 0.0392057920107618 sec
Decode latency: 2.1290677309734747 sec
Time for inference 10: 2.17 sec total, 944.18 tokens/sec
Decode latency: 2.13 sec
Prefill latency: 0.04 sec
Bandwidth achieved: 677.42 GB/s
FLOPS achieved: 3.39 TF/s

==========
Batch Size: 8
Prompt Length: 1024
Generated tokens: 256
Average decode latency: 2.1330 sec
Average prefill latency: 0.0393 sec
Average tokens/sec: 942.43
Memory used: 5.19 GB
Done. we are killing the process
