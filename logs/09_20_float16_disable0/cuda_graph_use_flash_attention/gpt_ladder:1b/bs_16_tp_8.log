W1001 01:19:23.055000 23350077351744 torch/distributed/run.py:779] 
W1001 01:19:23.055000 23350077351744 torch/distributed/run.py:779] *****************************************
W1001 01:19:23.055000 23350077351744 torch/distributed/run.py:779] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W1001 01:19:23.055000 23350077351744 torch/distributed/run.py:779] *****************************************
flash_kv_decode is set to True
Using device=cuda
Loading model ...
GPTLadder(
  (tok_embeddings): Embedding(49152, 1536)
  (layers): ModuleList(
    (0-39): 40 x LadderTransformerBlock(
      semi_compiled = False
      (attention): Attention(
        (wqkv): Linear(in_features=1536, out_features=576, bias=False)
        (wo): Linear(in_features=192, out_features=1536, bias=False)
      )
      (feed_forward): FeedForward(
        (w1): Linear(in_features=1536, out_features=1024, bias=False)
        (w2): Linear(in_features=512, out_features=1536, bias=False)
      )
      (ffn_norm): RMSNorm()
      (attention_norm): RMSNorm()
    )
  )
  (norm): RMSNorm()
  (output): Linear(in_features=1536, out_features=49152, bias=False)
)
Time to load model: 0.17 seconds
[rank2]:[W1001 01:19:36.108706920 CUDAGraph.cpp:150] Warning: Waiting for pending NCCL work to finish before starting graph capture. (function operator())
[rank5]:[W1001 01:19:36.763432822 CUDAGraph.cpp:150] Warning: Waiting for pending NCCL work to finish before starting graph capture. (function operator())
[rank0]:[W1001 01:19:36.783890117 CUDAGraph.cpp:150] Warning: Waiting for pending NCCL work to finish before starting graph capture. (function operator())
[rank4]:[W1001 01:19:36.787957825 CUDAGraph.cpp:150] Warning: Waiting for pending NCCL work to finish before starting graph capture. (function operator())
Prefill latency: 0.06967045099008828 sec
Decode latency: 2.1232646900461987 sec
Compilation time: 2.19 seconds
Compilation time: 2.22 seconds
Compilation time: 2.22 seconds
Compilation time: 2.18 seconds
Compilation time: 2.18 seconds
Compilation time: 2.18 seconds
Compilation time: 2.19 seconds
Compilation time: 2.22 seconds
Prefill latency: 0.05212741799186915 sec
Decode latency: 2.1243324540555477 sec
Prefill latency: 0.052371679921634495 sec
Decode latency: 2.123687605955638 sec
Prefill latency: 0.052097267005592585 sec
Decode latency: 2.1240594119299203 sec
Prefill latency: 0.052278399001806974 sec
Decode latency: 2.1235634699696675 sec
Prefill latency: 0.05216750595718622 sec
Decode latency: 2.1232332199579105 sec
Time for inference 1: 2.18 sec total, 1882.08 tokens/sec
Decode latency: 2.12 sec
Prefill latency: 0.05 sec
Bandwidth achieved: 817.50 GB/s
FLOPS achieved: 4.09 TF/s

Prefill latency: 0.05224310408812016 sec
Decode latency: 2.123577798018232 sec
Time for inference 2: 2.18 sec total, 1881.74 tokens/sec
Decode latency: 2.12 sec
Prefill latency: 0.05 sec
Bandwidth achieved: 817.35 GB/s
FLOPS achieved: 4.09 TF/s

Prefill latency: 0.052336483960971236 sec
Decode latency: 2.1231038640253246 sec
Time for inference 3: 2.18 sec total, 1882.09 tokens/sec
Decode latency: 2.12 sec
Prefill latency: 0.05 sec
Bandwidth achieved: 817.50 GB/s
FLOPS achieved: 4.09 TF/s

Prefill latency: 0.05215202900581062 sec
Decode latency: 2.1234162339242175 sec
Time for inference 4: 2.18 sec total, 1882.10 tokens/sec
Decode latency: 2.12 sec
Prefill latency: 0.05 sec
Bandwidth achieved: 817.51 GB/s
FLOPS achieved: 4.09 TF/s

Prefill latency: 0.05213660793378949 sec
Decode latency: 2.122717412072234 sec
Time for inference 5: 2.18 sec total, 1882.67 tokens/sec
Decode latency: 2.12 sec
Prefill latency: 0.05 sec
Bandwidth achieved: 817.76 GB/s
FLOPS achieved: 4.09 TF/s

Prefill latency: 0.052175235003232956 sec
Decode latency: 2.123690700973384 sec
Time for inference 6: 2.18 sec total, 1881.74 tokens/sec
Decode latency: 2.12 sec
Prefill latency: 0.05 sec
Bandwidth achieved: 817.35 GB/s
FLOPS achieved: 4.09 TF/s

Prefill latency: 0.05230236693751067 sec
Decode latency: 2.1236052269814536 sec
Time for inference 7: 2.18 sec total, 1881.76 tokens/sec
Decode latency: 2.12 sec
Prefill latency: 0.05 sec
Bandwidth achieved: 817.36 GB/s
FLOPS achieved: 4.09 TF/s

Prefill latency: 0.052254158072173595 sec
Decode latency: 2.123356800992042 sec
Time for inference 8: 2.18 sec total, 1881.89 tokens/sec
Decode latency: 2.12 sec
Prefill latency: 0.05 sec
Bandwidth achieved: 817.42 GB/s
FLOPS achieved: 4.09 TF/s

Prefill latency: 0.052238831063732505 sec
Decode latency: 2.12356411293149 sec
Time for inference 9: 2.18 sec total, 1881.81 tokens/sec
Decode latency: 2.12 sec
Prefill latency: 0.05 sec
Bandwidth achieved: 817.38 GB/s
FLOPS achieved: 4.09 TF/s

Prefill latency: 0.05265582806896418 sec
Decode latency: 2.12338473694399 sec
Time for inference 10: 2.18 sec total, 1881.73 tokens/sec
Decode latency: 2.12 sec
Prefill latency: 0.05 sec
Bandwidth achieved: 817.35 GB/s
FLOPS achieved: 4.09 TF/s

==========
Batch Size: 16
Prompt Length: 1024
Generated tokens: 256
Average decode latency: 2.1234 sec
Average prefill latency: 0.0523 sec
Average tokens/sec: 1881.96
Memory used: 7.49 GB
Done. we are killing the process
