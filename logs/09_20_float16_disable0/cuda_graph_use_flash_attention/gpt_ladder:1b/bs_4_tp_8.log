W0930 18:36:00.607000 22996944303936 torch/distributed/run.py:779] 
W0930 18:36:00.607000 22996944303936 torch/distributed/run.py:779] *****************************************
W0930 18:36:00.607000 22996944303936 torch/distributed/run.py:779] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W0930 18:36:00.607000 22996944303936 torch/distributed/run.py:779] *****************************************
flash_kv_decode is set to True
Using device=cuda
Loading model ...
GPTLadder(
  (tok_embeddings): Embedding(49152, 1536)
  (layers): ModuleList(
    (0-39): 40 x LadderTransformerBlock(
      semi_compiled = False
      (attention): Attention(
        (wqkv): Linear(in_features=1536, out_features=320, bias=False)
        (wo): Linear(in_features=192, out_features=1536, bias=False)
      )
      (feed_forward): FeedForward(
        (w1): Linear(in_features=1536, out_features=1024, bias=False)
        (w2): Linear(in_features=512, out_features=1536, bias=False)
      )
      (ffn_norm): RMSNorm()
      (attention_norm): RMSNorm()
    )
  )
  (norm): RMSNorm()
  (output): Linear(in_features=1536, out_features=49152, bias=False)
)
Time to load model: 0.18 seconds
[rank3]:[W930 18:36:15.308244395 CUDAGraph.cpp:150] Warning: Waiting for pending NCCL work to finish before starting graph capture. (function operator())
[rank0]:[W930 18:36:15.310203371 CUDAGraph.cpp:150] Warning: Waiting for pending NCCL work to finish before starting graph capture. (function operator())
[rank6]:[W930 18:36:15.319690078 CUDAGraph.cpp:150] Warning: Waiting for pending NCCL work to finish before starting graph capture. (function operator())
[rank1]:[W930 18:36:15.320624665 CUDAGraph.cpp:150] Warning: Waiting for pending NCCL work to finish before starting graph capture. (function operator())
[rank4]:[W930 18:36:15.922800286 CUDAGraph.cpp:150] Warning: Waiting for pending NCCL work to finish before starting graph capture. (function operator())
Prefill latency: 0.018613797961734235 sec
Decode latency: 1.8353710119845346 sec
Compilation time: 1.89 seconds
Compilation time: 1.87 seconds
Compilation time: 1.88 seconds
Compilation time: 1.87 secondsCompilation time: 1.86 seconds

Compilation time: 1.88 seconds
Compilation time: 1.93 seconds
Compilation time: 1.86 seconds
Prefill latency: 0.018397577106952667 sec
Decode latency: 1.8349746270105243 sec
Prefill latency: 0.0183295359602198 sec
Decode latency: 1.834722385974601 sec
Prefill latency: 0.018342119990848005 sec
Decode latency: 1.8348424509167671 sec
Prefill latency: 0.018284240970388055 sec
Decode latency: 1.834888605051674 sec
Prefill latency: 0.018307512975297868 sec
Decode latency: 1.8352499139728025 sec
Time for inference 1: 1.85 sec total, 552.23 tokens/sec
Decode latency: 1.84 sec
Prefill latency: 0.02 sec
Bandwidth achieved: 222.50 GB/s
FLOPS achieved: 1.11 TF/s

Prefill latency: 0.01829616993200034 sec
Decode latency: 1.8372356030158699 sec
Time for inference 2: 1.86 sec total, 551.64 tokens/sec
Decode latency: 1.84 sec
Prefill latency: 0.02 sec
Bandwidth achieved: 222.26 GB/s
FLOPS achieved: 1.11 TF/s

Prefill latency: 0.018298030947335064 sec
Decode latency: 1.8375472460174933 sec
Time for inference 3: 1.86 sec total, 551.53 tokens/sec
Decode latency: 1.84 sec
Prefill latency: 0.02 sec
Bandwidth achieved: 222.21 GB/s
FLOPS achieved: 1.11 TF/s

Prefill latency: 0.018293488072231412 sec
Decode latency: 1.8375955789815634 sec
Time for inference 4: 1.86 sec total, 551.53 tokens/sec
Decode latency: 1.84 sec
Prefill latency: 0.02 sec
Bandwidth achieved: 222.21 GB/s
FLOPS achieved: 1.11 TF/s

Prefill latency: 0.018309199018403888 sec
Decode latency: 1.8376235999166965 sec
Time for inference 5: 1.86 sec total, 551.52 tokens/sec
Decode latency: 1.84 sec
Prefill latency: 0.02 sec
Bandwidth achieved: 222.21 GB/s
FLOPS achieved: 1.11 TF/s

Prefill latency: 0.018382910988293588 sec
Decode latency: 1.8373983709607273 sec
Time for inference 6: 1.86 sec total, 551.59 tokens/sec
Decode latency: 1.84 sec
Prefill latency: 0.02 sec
Bandwidth achieved: 222.24 GB/s
FLOPS achieved: 1.11 TF/s

Prefill latency: 0.018386514042504132 sec
Decode latency: 1.8371968640713021 sec
Time for inference 7: 1.86 sec total, 551.62 tokens/sec
Decode latency: 1.84 sec
Prefill latency: 0.02 sec
Bandwidth achieved: 222.25 GB/s
FLOPS achieved: 1.11 TF/s

Prefill latency: 0.018471780000254512 sec
Decode latency: 1.8370620519854128 sec
Time for inference 8: 1.86 sec total, 551.62 tokens/sec
Decode latency: 1.84 sec
Prefill latency: 0.02 sec
Bandwidth achieved: 222.25 GB/s
FLOPS achieved: 1.11 TF/s

Prefill latency: 0.01831477100495249 sec
Decode latency: 1.8376905469922349 sec
Time for inference 9: 1.86 sec total, 551.49 tokens/sec
Decode latency: 1.84 sec
Prefill latency: 0.02 sec
Bandwidth achieved: 222.20 GB/s
FLOPS achieved: 1.11 TF/s

Prefill latency: 0.01831541594583541 sec
Decode latency: 1.8374977599596605 sec
Time for inference 10: 1.86 sec total, 551.55 tokens/sec
Decode latency: 1.84 sec
Prefill latency: 0.02 sec
Bandwidth achieved: 222.22 GB/s
FLOPS achieved: 1.11 TF/s

==========
Batch Size: 4
Prompt Length: 1024
Generated tokens: 256
Average decode latency: 1.8372 sec
Average prefill latency: 0.0183 sec
Average tokens/sec: 551.63
Memory used: 2.26 GB
Done. we are killing the process
