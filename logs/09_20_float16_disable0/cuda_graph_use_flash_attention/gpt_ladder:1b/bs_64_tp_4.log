W0930 18:48:30.509000 22562347722560 torch/distributed/run.py:779] 
W0930 18:48:30.509000 22562347722560 torch/distributed/run.py:779] *****************************************
W0930 18:48:30.509000 22562347722560 torch/distributed/run.py:779] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W0930 18:48:30.509000 22562347722560 torch/distributed/run.py:779] *****************************************
flash_kv_decode is set to True
Using device=cuda
Loading model ...
GPTLadder(
  (tok_embeddings): Embedding(49152, 1536)
  (layers): ModuleList(
    (0-39): 40 x LadderTransformerBlock(
      semi_compiled = False
      (attention): Attention(
        (wqkv): Linear(in_features=1536, out_features=640, bias=False)
        (wo): Linear(in_features=384, out_features=1536, bias=False)
      )
      (feed_forward): FeedForward(
        (w1): Linear(in_features=1536, out_features=2048, bias=False)
        (w2): Linear(in_features=1024, out_features=1536, bias=False)
      )
      (ffn_norm): RMSNorm()
      (attention_norm): RMSNorm()
    )
  )
  (norm): RMSNorm()
  (output): Linear(in_features=1536, out_features=49152, bias=False)
)
Time to load model: 0.15 seconds
Prefill latency: 0.24655993294436485 sec
Decode latency: 3.813837783993222 sec
Compilation time: 4.05 seconds
Compilation time: 4.06 seconds
Compilation time: 4.06 seconds
Compilation time: 4.05 seconds
Prefill latency: 0.2349948149640113 sec
Decode latency: 3.8046731839422137 sec
Prefill latency: 0.23422362504061311 sec
Decode latency: 3.80622039292939 sec
Prefill latency: 0.23455162800382823 sec
Decode latency: 3.8058598049683496 sec
Prefill latency: 0.23461110598873347 sec
Decode latency: 3.8071943420218304 sec
Prefill latency: 0.23455729894340038 sec
Decode latency: 3.805878333048895 sec
Time for inference 1: 4.04 sec total, 4054.21 tokens/sec
Decode latency: 3.81 sec
Prefill latency: 0.23 sec
Bandwidth achieved: 2653.73 GB/s
FLOPS achieved: 13.27 TF/s

Prefill latency: 0.234578100964427 sec
Decode latency: 3.8083920010831207 sec
Time for inference 2: 4.04 sec total, 4051.74 tokens/sec
Decode latency: 3.81 sec
Prefill latency: 0.23 sec
Bandwidth achieved: 2652.11 GB/s
FLOPS achieved: 13.26 TF/s

Prefill latency: 0.2350564410444349 sec
Decode latency: 3.8078804599354044 sec
Time for inference 3: 4.04 sec total, 4051.79 tokens/sec
Decode latency: 3.81 sec
Prefill latency: 0.24 sec
Bandwidth achieved: 2652.14 GB/s
FLOPS achieved: 13.26 TF/s

Prefill latency: 0.2343887590104714 sec
Decode latency: 3.808167868060991 sec
Time for inference 4: 4.04 sec total, 4052.12 tokens/sec
Decode latency: 3.81 sec
Prefill latency: 0.23 sec
Bandwidth achieved: 2652.35 GB/s
FLOPS achieved: 13.26 TF/s

Prefill latency: 0.23467208701185882 sec
Decode latency: 3.806078452966176 sec
Time for inference 5: 4.04 sec total, 4053.83 tokens/sec
Decode latency: 3.81 sec
Prefill latency: 0.23 sec
Bandwidth achieved: 2653.48 GB/s
FLOPS achieved: 13.27 TF/s

Prefill latency: 0.23449742409866303 sec
Decode latency: 3.8067729379981756 sec
Time for inference 6: 4.04 sec total, 4053.24 tokens/sec
Decode latency: 3.81 sec
Prefill latency: 0.23 sec
Bandwidth achieved: 2653.09 GB/s
FLOPS achieved: 13.27 TF/s

Prefill latency: 0.2345279110595584 sec
Decode latency: 3.8080399869941175 sec
Time for inference 7: 4.04 sec total, 4052.09 tokens/sec
Decode latency: 3.81 sec
Prefill latency: 0.23 sec
Bandwidth achieved: 2652.34 GB/s
FLOPS achieved: 13.26 TF/s

Prefill latency: 0.23405690398067236 sec
Decode latency: 3.8073783610016108 sec
Time for inference 8: 4.04 sec total, 4053.23 tokens/sec
Decode latency: 3.81 sec
Prefill latency: 0.23 sec
Bandwidth achieved: 2653.08 GB/s
FLOPS achieved: 13.27 TF/s

Prefill latency: 0.23445395892485976 sec
Decode latency: 3.8093906060094014 sec
Time for inference 9: 4.04 sec total, 4050.83 tokens/sec
Decode latency: 3.81 sec
Prefill latency: 0.23 sec
Bandwidth achieved: 2651.51 GB/s
FLOPS achieved: 13.26 TF/s

Prefill latency: 0.23466965497937053 sec
Decode latency: 3.8062965100398287 sec
Time for inference 10: 4.04 sec total, 4053.73 tokens/sec
Decode latency: 3.81 sec
Prefill latency: 0.23 sec
Bandwidth achieved: 2653.41 GB/s
FLOPS achieved: 13.27 TF/s

==========
Batch Size: 64
Prompt Length: 1024
Generated tokens: 256
Average decode latency: 3.8074 sec
Average prefill latency: 0.2345 sec
Average tokens/sec: 4052.68
Memory used: 29.51 GB
Done. we are killing the process
