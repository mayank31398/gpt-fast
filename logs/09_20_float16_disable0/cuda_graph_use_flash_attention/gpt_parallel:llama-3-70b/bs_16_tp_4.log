W0928 17:49:51.629000 23089420625728 torch/distributed/run.py:779] 
W0928 17:49:51.629000 23089420625728 torch/distributed/run.py:779] *****************************************
W0928 17:49:51.629000 23089420625728 torch/distributed/run.py:779] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W0928 17:49:51.629000 23089420625728 torch/distributed/run.py:779] *****************************************
flash_kv_decode is set to True
Using device=cuda
Loading model ...
GPTParallel(
  (tok_embeddings): Embedding(128256, 8192)
  (layers): ModuleList(
    (0-79): 80 x ParallelTransformerBlock(
      semi_compiled = False
      (attention): FuseAttentionMLP(
        (wqkv1): Linear(in_features=8192, out_features=16896, bias=False)
        (wo): Linear(in_features=2048, out_features=8192, bias=False)
        (w2): Linear(in_features=7168, out_features=8192, bias=False)
      )
      (attention_norm): RMSNorm()
    )
  )
  (norm): RMSNorm()
  (output): Linear(in_features=8192, out_features=128256, bias=False)
)
Time to load model: 1.03 seconds
Prefill latency: 1.464226040057838 sec
Decode latency: 11.417986690998077 sec
Compilation time: 12.85 seconds
Compilation time: 12.88 seconds
Compilation time: 12.84 seconds
Compilation time: 12.88 seconds
Prefill latency: 1.416247951798141 sec
Decode latency: 11.41844149492681 sec
Prefill latency: 1.4147300319746137 sec
Decode latency: 11.418258531950414 sec
Prefill latency: 1.416557151824236 sec
Decode latency: 11.415636476129293 sec
Prefill latency: 1.4163542799651623 sec
Decode latency: 11.41738242842257 sec
Prefill latency: 1.4158636629581451 sec
Decode latency: 11.41634904872626 sec
Time for inference 1: 12.83 sec total, 319.17 tokens/sec
Decode latency: 11.42 sec
Prefill latency: 1.42 sec
Bandwidth achieved: 11595.01 GB/s
FLOPS achieved: 57.98 TF/s

Prefill latency: 1.4149935999885201 sec
Decode latency: 11.418886962346733 sec
Time for inference 2: 12.83 sec total, 319.13 tokens/sec
Decode latency: 11.42 sec
Prefill latency: 1.41 sec
Bandwidth achieved: 11593.59 GB/s
FLOPS achieved: 57.97 TF/s

Prefill latency: 1.4186060903593898 sec
Decode latency: 11.41869452688843 sec
Time for inference 3: 12.84 sec total, 319.05 tokens/sec
Decode latency: 11.42 sec
Prefill latency: 1.42 sec
Bandwidth achieved: 11590.50 GB/s
FLOPS achieved: 57.95 TF/s

Prefill latency: 1.4177462896332145 sec
Decode latency: 11.41921578347683 sec
Time for inference 4: 12.84 sec total, 319.06 tokens/sec
Decode latency: 11.42 sec
Prefill latency: 1.42 sec
Bandwidth achieved: 11590.77 GB/s
FLOPS achieved: 57.95 TF/s

Prefill latency: 1.4199963733553886 sec
Decode latency: 11.41972666978836 sec
Time for inference 5: 12.84 sec total, 318.99 tokens/sec
Decode latency: 11.42 sec
Prefill latency: 1.42 sec
Bandwidth achieved: 11588.29 GB/s
FLOPS achieved: 57.94 TF/s

Prefill latency: 1.4160071881487966 sec
Decode latency: 11.421086351387203 sec
Time for inference 6: 12.84 sec total, 319.06 tokens/sec
Decode latency: 11.42 sec
Prefill latency: 1.42 sec
Bandwidth achieved: 11590.75 GB/s
FLOPS achieved: 57.95 TF/s

Prefill latency: 1.4165490865707397 sec
Decode latency: 11.418421396054327 sec
Time for inference 7: 12.84 sec total, 319.11 tokens/sec
Decode latency: 11.42 sec
Prefill latency: 1.42 sec
Bandwidth achieved: 11592.60 GB/s
FLOPS achieved: 57.96 TF/s

Prefill latency: 1.416120819747448 sec
Decode latency: 11.420570629648864 sec
Time for inference 8: 12.84 sec total, 319.06 tokens/sec
Decode latency: 11.42 sec
Prefill latency: 1.42 sec
Bandwidth achieved: 11591.02 GB/s
FLOPS achieved: 57.96 TF/s

Prefill latency: 1.4132812339812517 sec
Decode latency: 11.419651983305812 sec
Time for inference 9: 12.83 sec total, 319.16 tokens/sec
Decode latency: 11.42 sec
Prefill latency: 1.41 sec
Bandwidth achieved: 11594.45 GB/s
FLOPS achieved: 57.97 TF/s

Prefill latency: 1.4192046793177724 sec
Decode latency: 11.418989921920002 sec
Time for inference 10: 12.84 sec total, 319.03 tokens/sec
Decode latency: 11.42 sec
Prefill latency: 1.42 sec
Bandwidth achieved: 11589.71 GB/s
FLOPS achieved: 57.95 TF/s

==========
Batch Size: 16
Prompt Length: 1024
Generated tokens: 256
Average decode latency: 11.4192 sec
Average prefill latency: 1.4168 sec
Average tokens/sec: 319.08
Memory used: 68.76 GB
Done. we are killing the process
