W0928 17:33:23.802000 23049355577152 torch/distributed/run.py:779] 
W0928 17:33:23.802000 23049355577152 torch/distributed/run.py:779] *****************************************
W0928 17:33:23.802000 23049355577152 torch/distributed/run.py:779] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W0928 17:33:23.802000 23049355577152 torch/distributed/run.py:779] *****************************************
flash_kv_decode is set to True
Using device=cuda
Loading model ...
GPTParallel(
  (tok_embeddings): Embedding(128256, 8192)
  (layers): ModuleList(
    (0-79): 80 x ParallelTransformerBlock(
      semi_compiled = False
      (attention): FuseAttentionMLP(
        (wqkv1): Linear(in_features=8192, out_features=33792, bias=False)
        (wo): Linear(in_features=4096, out_features=8192, bias=False)
        (w2): Linear(in_features=14336, out_features=8192, bias=False)
      )
      (attention_norm): RMSNorm()
    )
  )
  (norm): RMSNorm()
  (output): Linear(in_features=8192, out_features=128256, bias=False)
)
Time to load model: 0.91 seconds
Prefill latency: 0.1668481109663844 sec
Decode latency: 10.10002495162189 sec
Compilation time: 10.27 seconds
Compilation time: 10.27 seconds
Prefill latency: 0.16590758971869946 sec
Decode latency: 10.099776415154338 sec
Prefill latency: 0.16691135615110397 sec
Decode latency: 10.100034756585956 sec
Prefill latency: 0.16670989338308573 sec
Decode latency: 10.100372660905123 sec
Prefill latency: 0.16567282937467098 sec
Decode latency: 10.101393875665963 sec
Prefill latency: 0.16574947722256184 sec
Decode latency: 10.10261011030525 sec
Time for inference 1: 10.27 sec total, 24.93 tokens/sec
Decode latency: 10.10 sec
Prefill latency: 0.17 sec
Bandwidth achieved: 1758.83 GB/s
FLOPS achieved: 8.79 TF/s

Prefill latency: 0.16649194341152906 sec
Decode latency: 10.102954032830894 sec
Time for inference 2: 10.27 sec total, 24.93 tokens/sec
Decode latency: 10.10 sec
Prefill latency: 0.17 sec
Bandwidth achieved: 1758.64 GB/s
FLOPS achieved: 8.79 TF/s

Prefill latency: 0.16645912546664476 sec
Decode latency: 10.102473897859454 sec
Time for inference 3: 10.27 sec total, 24.93 tokens/sec
Decode latency: 10.10 sec
Prefill latency: 0.17 sec
Bandwidth achieved: 1758.73 GB/s
FLOPS achieved: 8.79 TF/s

Prefill latency: 0.16534478683024645 sec
Decode latency: 10.102535454556346 sec
Time for inference 4: 10.27 sec total, 24.93 tokens/sec
Decode latency: 10.10 sec
Prefill latency: 0.17 sec
Bandwidth achieved: 1758.92 GB/s
FLOPS achieved: 8.79 TF/s

Prefill latency: 0.16734652873128653 sec
Decode latency: 10.103349428623915 sec
Time for inference 5: 10.27 sec total, 24.92 tokens/sec
Decode latency: 10.10 sec
Prefill latency: 0.17 sec
Bandwidth achieved: 1758.43 GB/s
FLOPS achieved: 8.79 TF/s

Prefill latency: 0.16572456900030375 sec
Decode latency: 10.103192522190511 sec
Time for inference 6: 10.27 sec total, 24.93 tokens/sec
Decode latency: 10.10 sec
Prefill latency: 0.17 sec
Bandwidth achieved: 1758.74 GB/s
FLOPS achieved: 8.79 TF/s

Prefill latency: 0.1661544069647789 sec
Decode latency: 10.103350426070392 sec
Time for inference 7: 10.27 sec total, 24.93 tokens/sec
Decode latency: 10.10 sec
Prefill latency: 0.17 sec
Bandwidth achieved: 1758.64 GB/s
FLOPS achieved: 8.79 TF/s

Prefill latency: 0.16652941424399614 sec
Decode latency: 10.104623509570956 sec
Time for inference 8: 10.27 sec total, 24.92 tokens/sec
Decode latency: 10.10 sec
Prefill latency: 0.17 sec
Bandwidth achieved: 1758.35 GB/s
FLOPS achieved: 8.79 TF/s

Prefill latency: 0.16633238177746534 sec
Decode latency: 10.10414018202573 sec
Time for inference 9: 10.27 sec total, 24.92 tokens/sec
Decode latency: 10.10 sec
Prefill latency: 0.17 sec
Bandwidth achieved: 1758.47 GB/s
FLOPS achieved: 8.79 TF/s

Prefill latency: 0.1656923172995448 sec
Decode latency: 10.103201355785131 sec
Time for inference 10: 10.27 sec total, 24.93 tokens/sec
Decode latency: 10.10 sec
Prefill latency: 0.17 sec
Bandwidth achieved: 1758.74 GB/s
FLOPS achieved: 8.79 TF/s

==========
Batch Size: 1
Prompt Length: 1024
Generated tokens: 256
Average decode latency: 10.1032 sec
Average prefill latency: 0.1662 sec
Average tokens/sec: 24.93
Memory used: 75.79 GB
Done. we are killing the process
