W0928 17:44:39.060000 22962534336320 torch/distributed/run.py:779] 
W0928 17:44:39.060000 22962534336320 torch/distributed/run.py:779] *****************************************
W0928 17:44:39.060000 22962534336320 torch/distributed/run.py:779] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W0928 17:44:39.060000 22962534336320 torch/distributed/run.py:779] *****************************************
flash_kv_decode is set to True
Using device=cuda
Loading model ...
GPTParallel(
  (tok_embeddings): Embedding(128256, 8192)
  (layers): ModuleList(
    (0-79): 80 x ParallelTransformerBlock(
      semi_compiled = False
      (attention): FuseAttentionMLP(
        (wqkv1): Linear(in_features=8192, out_features=16896, bias=False)
        (wo): Linear(in_features=2048, out_features=8192, bias=False)
        (w2): Linear(in_features=7168, out_features=8192, bias=False)
      )
      (attention_norm): RMSNorm()
    )
  )
  (norm): RMSNorm()
  (output): Linear(in_features=8192, out_features=128256, bias=False)
)
Time to load model: 0.93 seconds
Prefill latency: 0.739860069938004 sec
Decode latency: 9.129906026646495 sec
Compilation time: 9.85 secondsCompilation time: 9.83 seconds

Compilation time: 9.83 seconds
Compilation time: 9.87 seconds
Prefill latency: 0.6958401435986161 sec
Decode latency: 9.131725722923875 sec
Prefill latency: 0.6964804595336318 sec
Decode latency: 9.129901808686554 sec
Prefill latency: 0.697284416295588 sec
Decode latency: 9.132029053755105 sec
Prefill latency: 0.6981516992673278 sec
Decode latency: 9.132414593361318 sec
Prefill latency: 0.6989675778895617 sec
Decode latency: 9.13328267633915 sec
Time for inference 1: 9.83 sec total, 208.28 tokens/sec
Decode latency: 9.13 sec
Prefill latency: 0.70 sec
Bandwidth achieved: 7566.26 GB/s
FLOPS achieved: 37.83 TF/s

Prefill latency: 0.6990799736231565 sec
Decode latency: 9.132841559126973 sec
Time for inference 2: 9.83 sec total, 208.28 tokens/sec
Decode latency: 9.13 sec
Prefill latency: 0.70 sec
Bandwidth achieved: 7566.57 GB/s
FLOPS achieved: 37.83 TF/s

Prefill latency: 0.698588834144175 sec
Decode latency: 9.130813851952553 sec
Time for inference 3: 9.83 sec total, 208.34 tokens/sec
Decode latency: 9.13 sec
Prefill latency: 0.70 sec
Bandwidth achieved: 7568.49 GB/s
FLOPS achieved: 37.84 TF/s

Prefill latency: 0.6985534727573395 sec
Decode latency: 9.129968495108187 sec
Time for inference 4: 9.83 sec total, 208.36 tokens/sec
Decode latency: 9.13 sec
Prefill latency: 0.70 sec
Bandwidth achieved: 7569.18 GB/s
FLOPS achieved: 37.85 TF/s

Prefill latency: 0.7000793432816863 sec
Decode latency: 9.133144742809236 sec
Time for inference 5: 9.83 sec total, 208.26 tokens/sec
Decode latency: 9.13 sec
Prefill latency: 0.70 sec
Bandwidth achieved: 7565.57 GB/s
FLOPS achieved: 37.83 TF/s

Prefill latency: 0.7005270989611745 sec
Decode latency: 9.131866311654449 sec
Time for inference 6: 9.83 sec total, 208.27 tokens/sec
Decode latency: 9.13 sec
Prefill latency: 0.70 sec
Bandwidth achieved: 7566.21 GB/s
FLOPS achieved: 37.83 TF/s

Prefill latency: 0.6992358602583408 sec
Decode latency: 9.126319479197264 sec
Time for inference 7: 9.83 sec total, 208.42 tokens/sec
Decode latency: 9.13 sec
Prefill latency: 0.70 sec
Bandwidth achieved: 7571.47 GB/s
FLOPS achieved: 37.86 TF/s

Prefill latency: 0.7008296651765704 sec
Decode latency: 9.131369408220053 sec
Time for inference 8: 9.83 sec total, 208.28 tokens/sec
Decode latency: 9.13 sec
Prefill latency: 0.70 sec
Bandwidth achieved: 7566.36 GB/s
FLOPS achieved: 37.83 TF/s

Prefill latency: 0.6993537470698357 sec
Decode latency: 9.130036945454776 sec
Time for inference 9: 9.83 sec total, 208.34 tokens/sec
Decode latency: 9.13 sec
Prefill latency: 0.70 sec
Bandwidth achieved: 7568.55 GB/s
FLOPS achieved: 37.84 TF/s

Prefill latency: 0.7001249846071005 sec
Decode latency: 9.133333657868207 sec
Time for inference 10: 9.83 sec total, 208.25 tokens/sec
Decode latency: 9.13 sec
Prefill latency: 0.70 sec
Bandwidth achieved: 7565.37 GB/s
FLOPS achieved: 37.83 TF/s

==========
Batch Size: 8
Prompt Length: 1024
Generated tokens: 256
Average decode latency: 9.1313 sec
Average prefill latency: 0.6995 sec
Average tokens/sec: 208.31
Memory used: 53.67 GB
Done. we are killing the process
