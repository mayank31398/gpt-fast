W1001 02:10:13.573000 23077766137664 torch/distributed/run.py:779] 
W1001 02:10:13.573000 23077766137664 torch/distributed/run.py:779] *****************************************
W1001 02:10:13.573000 23077766137664 torch/distributed/run.py:779] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W1001 02:10:13.573000 23077766137664 torch/distributed/run.py:779] *****************************************
flash_kv_decode is set to True
Using device=cuda
Loading model ...
GPTParallel(
  (tok_embeddings): Embedding(49152, 2304)
  (layers): ModuleList(
    (0-39): 40 x ParallelTransformerBlock(
      semi_compiled = False
      (attention): FuseAttentionMLP(
        (wqkv1): Linear(in_features=2304, out_features=12672, bias=False)
        (wo): Linear(in_features=1152, out_features=2304, bias=False)
        (w2): Linear(in_features=4608, out_features=2304, bias=False)
      )
      (attention_norm): RMSNorm()
    )
  )
  (norm): RMSNorm()
  (output): Linear(in_features=2304, out_features=49152, bias=False)
)
Time to load model: 0.99 seconds
Prefill latency: 0.06084508600179106 sec
Decode latency: 2.5136349480599165 sec
Compilation time: 2.58 seconds
Compilation time: 2.58 seconds
Prefill latency: 0.060389740974642336 sec
Decode latency: 2.513343625003472 sec
Prefill latency: 0.06039357197005302 sec
Decode latency: 2.5137087430339307 sec
Prefill latency: 0.06034770398400724 sec
Decode latency: 2.5131869280012324 sec
Prefill latency: 0.060367868980392814 sec
Decode latency: 2.5096678799018264 sec
Prefill latency: 0.06035421905107796 sec
Decode latency: 2.5088568419450894 sec
Time for inference 1: 2.57 sec total, 398.46 tokens/sec
Decode latency: 2.51 sec
Prefill latency: 0.06 sec
Bandwidth achieved: 1444.04 GB/s
FLOPS achieved: 7.22 TF/s

Prefill latency: 0.060297549003735185 sec
Decode latency: 2.509155760984868 sec
Time for inference 2: 2.57 sec total, 398.42 tokens/sec
Decode latency: 2.51 sec
Prefill latency: 0.06 sec
Bandwidth achieved: 1443.90 GB/s
FLOPS achieved: 7.22 TF/s

Prefill latency: 0.060287004918791354 sec
Decode latency: 2.509559455094859 sec
Time for inference 3: 2.57 sec total, 398.36 tokens/sec
Decode latency: 2.51 sec
Prefill latency: 0.06 sec
Bandwidth achieved: 1443.68 GB/s
FLOPS achieved: 7.22 TF/s

Prefill latency: 0.060430026962421834 sec
Decode latency: 2.5096865330124274 sec
Time for inference 4: 2.57 sec total, 398.32 tokens/sec
Decode latency: 2.51 sec
Prefill latency: 0.06 sec
Bandwidth achieved: 1443.53 GB/s
FLOPS achieved: 7.22 TF/s

Prefill latency: 0.060453479061834514 sec
Decode latency: 2.509307601954788 sec
Time for inference 5: 2.57 sec total, 398.37 tokens/sec
Decode latency: 2.51 sec
Prefill latency: 0.06 sec
Bandwidth achieved: 1443.72 GB/s
FLOPS achieved: 7.22 TF/s

Prefill latency: 0.060459358035586774 sec
Decode latency: 2.5093899129424244 sec
Time for inference 6: 2.57 sec total, 398.36 tokens/sec
Decode latency: 2.51 sec
Prefill latency: 0.06 sec
Bandwidth achieved: 1443.68 GB/s
FLOPS achieved: 7.22 TF/s

Prefill latency: 0.060301046003587544 sec
Decode latency: 2.509814301971346 sec
Time for inference 7: 2.57 sec total, 398.31 tokens/sec
Decode latency: 2.51 sec
Prefill latency: 0.06 sec
Bandwidth achieved: 1443.49 GB/s
FLOPS achieved: 7.22 TF/s

Prefill latency: 0.06036259699612856 sec
Decode latency: 2.5087015869794413 sec
Time for inference 8: 2.57 sec total, 398.47 tokens/sec
Decode latency: 2.51 sec
Prefill latency: 0.06 sec
Bandwidth achieved: 1444.10 GB/s
FLOPS achieved: 7.22 TF/s

Prefill latency: 0.060374598018825054 sec
Decode latency: 2.5092561779310927 sec
Time for inference 9: 2.57 sec total, 398.38 tokens/sec
Decode latency: 2.51 sec
Prefill latency: 0.06 sec
Bandwidth achieved: 1443.74 GB/s
FLOPS achieved: 7.22 TF/s

Prefill latency: 0.060375010012649 sec
Decode latency: 2.5093911440344527 sec
Time for inference 10: 2.57 sec total, 398.36 tokens/sec
Decode latency: 2.51 sec
Prefill latency: 0.06 sec
Bandwidth achieved: 1443.69 GB/s
FLOPS achieved: 7.22 TF/s

==========
Batch Size: 4
Prompt Length: 1024
Generated tokens: 256
Average decode latency: 2.5093 sec
Average prefill latency: 0.0604 sec
Average tokens/sec: 398.38
Memory used: 6.62 GB
Done. we are killing the process
