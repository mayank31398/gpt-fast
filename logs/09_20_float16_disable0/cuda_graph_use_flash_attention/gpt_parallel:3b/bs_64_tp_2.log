W1001 02:22:16.956000 22461322344256 torch/distributed/run.py:779] 
W1001 02:22:16.956000 22461322344256 torch/distributed/run.py:779] *****************************************
W1001 02:22:16.956000 22461322344256 torch/distributed/run.py:779] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W1001 02:22:16.956000 22461322344256 torch/distributed/run.py:779] *****************************************
flash_kv_decode is set to True
Using device=cuda
Loading model ...
GPTParallel(
  (tok_embeddings): Embedding(49152, 2304)
  (layers): ModuleList(
    (0-39): 40 x ParallelTransformerBlock(
      semi_compiled = False
      (attention): FuseAttentionMLP(
        (wqkv1): Linear(in_features=2304, out_features=12672, bias=False)
        (wo): Linear(in_features=1152, out_features=2304, bias=False)
        (w2): Linear(in_features=4608, out_features=2304, bias=False)
      )
      (attention_norm): RMSNorm()
    )
  )
  (norm): RMSNorm()
  (output): Linear(in_features=2304, out_features=49152, bias=False)
)
Time to load model: 1.07 seconds
Prefill latency: 0.8873353180242702 sec
Decode latency: 7.3604315359843895 sec
Compilation time: 8.23 seconds
Compilation time: 8.25 seconds
Prefill latency: 0.869730741949752 sec
Decode latency: 7.360080781043507 sec
Prefill latency: 0.8689756360836327 sec
Decode latency: 7.358984026941471 sec
Prefill latency: 0.8710360820405185 sec
Decode latency: 7.3578804129501805 sec
Prefill latency: 0.8699886639369652 sec
Decode latency: 7.357438690960407 sec
Prefill latency: 0.8712818080093712 sec
Decode latency: 7.358739805989899 sec
Time for inference 1: 8.23 sec total, 1990.57 tokens/sec
Decode latency: 7.36 sec
Prefill latency: 0.87 sec
Bandwidth achieved: 7213.95 GB/s
FLOPS achieved: 36.07 TF/s

Prefill latency: 0.8704600350465626 sec
Decode latency: 7.357368058990687 sec
Time for inference 2: 8.23 sec total, 1991.03 tokens/sec
Decode latency: 7.36 sec
Prefill latency: 0.87 sec
Bandwidth achieved: 7215.63 GB/s
FLOPS achieved: 36.08 TF/s

Prefill latency: 0.8705850740661845 sec
Decode latency: 7.3587103378959 sec
Time for inference 3: 8.23 sec total, 1990.65 tokens/sec
Decode latency: 7.36 sec
Prefill latency: 0.87 sec
Bandwidth achieved: 7214.26 GB/s
FLOPS achieved: 36.07 TF/s

Prefill latency: 0.8703462479170412 sec
Decode latency: 7.343901934102178 sec
Time for inference 4: 8.22 sec total, 1994.34 tokens/sec
Decode latency: 7.34 sec
Prefill latency: 0.87 sec
Bandwidth achieved: 7227.62 GB/s
FLOPS achieved: 36.14 TF/s

Prefill latency: 0.8723113089799881 sec
Decode latency: 7.34257224900648 sec
Time for inference 5: 8.22 sec total, 1994.20 tokens/sec
Decode latency: 7.34 sec
Prefill latency: 0.87 sec
Bandwidth achieved: 7227.13 GB/s
FLOPS achieved: 36.14 TF/s

Prefill latency: 0.8719504529144615 sec
Decode latency: 7.346480254898779 sec
Time for inference 6: 8.22 sec total, 1993.30 tokens/sec
Decode latency: 7.35 sec
Prefill latency: 0.87 sec
Bandwidth achieved: 7223.87 GB/s
FLOPS achieved: 36.12 TF/s

Prefill latency: 0.8739004289964214 sec
Decode latency: 7.345662470092066 sec
Time for inference 7: 8.22 sec total, 1993.06 tokens/sec
Decode latency: 7.35 sec
Prefill latency: 0.87 sec
Bandwidth achieved: 7222.98 GB/s
FLOPS achieved: 36.11 TF/s

Prefill latency: 0.8731671570567414 sec
Decode latency: 7.349811248015612 sec
Time for inference 8: 8.22 sec total, 1992.26 tokens/sec
Decode latency: 7.35 sec
Prefill latency: 0.87 sec
Bandwidth achieved: 7220.09 GB/s
FLOPS achieved: 36.10 TF/s

Prefill latency: 0.8727177149849012 sec
Decode latency: 7.344520085025579 sec
Time for inference 9: 8.22 sec total, 1993.64 tokens/sec
Decode latency: 7.34 sec
Prefill latency: 0.87 sec
Bandwidth achieved: 7225.07 GB/s
FLOPS achieved: 36.13 TF/s

Prefill latency: 0.872675008024089 sec
Decode latency: 7.346573529066518 sec
Time for inference 10: 8.22 sec total, 1993.11 tokens/sec
Decode latency: 7.35 sec
Prefill latency: 0.87 sec
Bandwidth achieved: 7223.18 GB/s
FLOPS achieved: 36.12 TF/s

==========
Batch Size: 64
Prompt Length: 1024
Generated tokens: 256
Average decode latency: 7.3494 sec
Average prefill latency: 0.8719 sec
Average tokens/sec: 1992.62
Memory used: 43.17 GB
Done. we are killing the process
