W1001 02:07:42.921000 23388763981632 torch/distributed/run.py:779] 
W1001 02:07:42.921000 23388763981632 torch/distributed/run.py:779] *****************************************
W1001 02:07:42.921000 23388763981632 torch/distributed/run.py:779] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W1001 02:07:42.921000 23388763981632 torch/distributed/run.py:779] *****************************************
flash_kv_decode is set to True
Using device=cuda
Loading model ...
GPTParallel(
  (tok_embeddings): Embedding(49152, 2304)
  (layers): ModuleList(
    (0-39): 40 x ParallelTransformerBlock(
      semi_compiled = False
      (attention): FuseAttentionMLP(
        (wqkv1): Linear(in_features=2304, out_features=12672, bias=False)
        (wo): Linear(in_features=1152, out_features=2304, bias=False)
        (w2): Linear(in_features=4608, out_features=2304, bias=False)
      )
      (attention_norm): RMSNorm()
    )
  )
  (norm): RMSNorm()
  (output): Linear(in_features=2304, out_features=49152, bias=False)
)
Time to load model: 0.90 seconds
Prefill latency: 0.03896398504730314 sec
Decode latency: 2.231085514067672 sec
Compilation time: 2.25 seconds
Compilation time: 2.27 seconds
Prefill latency: 0.020400102017447352 sec
Decode latency: 2.2299120780080557 sec
Prefill latency: 0.020436687977053225 sec
Decode latency: 2.2303178180009127 sec
Prefill latency: 0.02042278100270778 sec
Decode latency: 2.229992203065194 sec
Prefill latency: 0.020416076062247157 sec
Decode latency: 2.2300635549472645 sec
Prefill latency: 0.02045819000340998 sec
Decode latency: 2.2299549530725926 sec
Time for inference 1: 2.25 sec total, 113.72 tokens/sec
Decode latency: 2.23 sec
Prefill latency: 0.02 sec
Bandwidth achieved: 412.13 GB/s
FLOPS achieved: 2.06 TF/s

Prefill latency: 0.020437360974028707 sec
Decode latency: 2.2297565980115905 sec
Time for inference 2: 2.25 sec total, 113.73 tokens/sec
Decode latency: 2.23 sec
Prefill latency: 0.02 sec
Bandwidth achieved: 412.18 GB/s
FLOPS achieved: 2.06 TF/s

Prefill latency: 0.020441735978238285 sec
Decode latency: 2.2300511670764536 sec
Time for inference 3: 2.25 sec total, 113.72 tokens/sec
Decode latency: 2.23 sec
Prefill latency: 0.02 sec
Bandwidth achieved: 412.12 GB/s
FLOPS achieved: 2.06 TF/s

Prefill latency: 0.020467721042223275 sec
Decode latency: 2.2306651569670066 sec
Time for inference 4: 2.25 sec total, 113.68 tokens/sec
Decode latency: 2.23 sec
Prefill latency: 0.02 sec
Bandwidth achieved: 412.00 GB/s
FLOPS achieved: 2.06 TF/s

Prefill latency: 0.020499018020927906 sec
Decode latency: 2.2302570450119674 sec
Time for inference 5: 2.25 sec total, 113.70 tokens/sec
Decode latency: 2.23 sec
Prefill latency: 0.02 sec
Bandwidth achieved: 412.07 GB/s
FLOPS achieved: 2.06 TF/s

Prefill latency: 0.020432516001164913 sec
Decode latency: 2.22994807199575 sec
Time for inference 6: 2.25 sec total, 113.72 tokens/sec
Decode latency: 2.23 sec
Prefill latency: 0.02 sec
Bandwidth achieved: 412.14 GB/s
FLOPS achieved: 2.06 TF/s

Prefill latency: 0.02038446196820587 sec
Decode latency: 2.230150813004002 sec
Time for inference 7: 2.25 sec total, 113.71 tokens/sec
Decode latency: 2.23 sec
Prefill latency: 0.02 sec
Bandwidth achieved: 412.11 GB/s
FLOPS achieved: 2.06 TF/s

Prefill latency: 0.020427986048161983 sec
Decode latency: 2.230401883018203 sec
Time for inference 8: 2.25 sec total, 113.70 tokens/sec
Decode latency: 2.23 sec
Prefill latency: 0.02 sec
Bandwidth achieved: 412.06 GB/s
FLOPS achieved: 2.06 TF/s

Prefill latency: 0.020470696035772562 sec
Decode latency: 2.230619024951011 sec
Time for inference 9: 2.25 sec total, 113.68 tokens/sec
Decode latency: 2.23 sec
Prefill latency: 0.02 sec
Bandwidth achieved: 411.97 GB/s
FLOPS achieved: 2.06 TF/s

Prefill latency: 0.020481155021116138 sec
Decode latency: 2.2303634129930288 sec
Time for inference 10: 2.25 sec total, 113.68 tokens/sec
Decode latency: 2.23 sec
Prefill latency: 0.02 sec
Bandwidth achieved: 411.99 GB/s
FLOPS achieved: 2.06 TF/s

==========
Batch Size: 1
Prompt Length: 1024
Generated tokens: 256
Average decode latency: 2.2302 sec
Average prefill latency: 0.0205 sec
Average tokens/sec: 113.71
Memory used: 4.74 GB
Done. we are killing the process
