W1001 02:16:22.652000 23301194364736 torch/distributed/run.py:779] 
W1001 02:16:22.652000 23301194364736 torch/distributed/run.py:779] *****************************************
W1001 02:16:22.652000 23301194364736 torch/distributed/run.py:779] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W1001 02:16:22.652000 23301194364736 torch/distributed/run.py:779] *****************************************
flash_kv_decode is set to True
Using device=cuda
Loading model ...
GPTParallel(
  (tok_embeddings): Embedding(49152, 2304)
  (layers): ModuleList(
    (0-39): 40 x ParallelTransformerBlock(
      semi_compiled = False
      (attention): FuseAttentionMLP(
        (wqkv1): Linear(in_features=2304, out_features=12672, bias=False)
        (wo): Linear(in_features=1152, out_features=2304, bias=False)
        (w2): Linear(in_features=4608, out_features=2304, bias=False)
      )
      (attention_norm): RMSNorm()
    )
  )
  (norm): RMSNorm()
  (output): Linear(in_features=2304, out_features=49152, bias=False)
)
Time to load model: 1.04 seconds
Prefill latency: 0.2250484749674797 sec
Decode latency: 3.299926272011362 sec
Compilation time: 3.52 seconds
Compilation time: 3.53 seconds
Prefill latency: 0.22078929608687758 sec
Decode latency: 3.2977846519788727 sec
Prefill latency: 0.2214030009927228 sec
Decode latency: 3.2991203169804066 sec
Prefill latency: 0.22084515599999577 sec
Decode latency: 3.2989126089960337 sec
Prefill latency: 0.22032563108950853 sec
Decode latency: 3.2995862190146 sec
Prefill latency: 0.22086698201019317 sec
Decode latency: 3.299186818068847 sec
Time for inference 1: 3.52 sec total, 1163.34 tokens/sec
Decode latency: 3.30 sec
Prefill latency: 0.22 sec
Bandwidth achieved: 4216.02 GB/s
FLOPS achieved: 21.08 TF/s

Prefill latency: 0.2211313518928364 sec
Decode latency: 3.2988515809411183 sec
Time for inference 2: 3.52 sec total, 1163.28 tokens/sec
Decode latency: 3.30 sec
Prefill latency: 0.22 sec
Bandwidth achieved: 4215.79 GB/s
FLOPS achieved: 21.08 TF/s

Prefill latency: 0.22070768696721643 sec
Decode latency: 3.2997756840195507 sec
Time for inference 3: 3.52 sec total, 1163.13 tokens/sec
Decode latency: 3.30 sec
Prefill latency: 0.22 sec
Bandwidth achieved: 4215.25 GB/s
FLOPS achieved: 21.08 TF/s

Prefill latency: 0.22027593909297138 sec
Decode latency: 3.2995939860120416 sec
Time for inference 4: 3.52 sec total, 1163.39 tokens/sec
Decode latency: 3.30 sec
Prefill latency: 0.22 sec
Bandwidth achieved: 4216.21 GB/s
FLOPS achieved: 21.08 TF/s

Prefill latency: 0.22071286907885224 sec
Decode latency: 3.2987761710537598 sec
Time for inference 5: 3.52 sec total, 1163.54 tokens/sec
Decode latency: 3.30 sec
Prefill latency: 0.22 sec
Bandwidth achieved: 4216.76 GB/s
FLOPS achieved: 21.08 TF/s

Prefill latency: 0.22084563493262976 sec
Decode latency: 3.30032155290246 sec
Time for inference 6: 3.52 sec total, 1163.02 tokens/sec
Decode latency: 3.30 sec
Prefill latency: 0.22 sec
Bandwidth achieved: 4214.86 GB/s
FLOPS achieved: 21.07 TF/s

Prefill latency: 0.22077512100804597 sec
Decode latency: 3.2991056699538603 sec
Time for inference 7: 3.52 sec total, 1163.42 tokens/sec
Decode latency: 3.30 sec
Prefill latency: 0.22 sec
Bandwidth achieved: 4216.32 GB/s
FLOPS achieved: 21.08 TF/s

Prefill latency: 0.2210689289495349 sec
Decode latency: 3.2978540851036087 sec
Time for inference 8: 3.52 sec total, 1163.75 tokens/sec
Decode latency: 3.30 sec
Prefill latency: 0.22 sec
Bandwidth achieved: 4217.50 GB/s
FLOPS achieved: 21.09 TF/s

Prefill latency: 0.22136715310625732 sec
Decode latency: 3.298744975007139 sec
Time for inference 9: 3.52 sec total, 1163.33 tokens/sec
Decode latency: 3.30 sec
Prefill latency: 0.22 sec
Bandwidth achieved: 4215.99 GB/s
FLOPS achieved: 21.08 TF/s

Prefill latency: 0.2211804889375344 sec
Decode latency: 3.299252419034019 sec
Time for inference 10: 3.52 sec total, 1163.19 tokens/sec
Decode latency: 3.30 sec
Prefill latency: 0.22 sec
Bandwidth achieved: 4215.46 GB/s
FLOPS achieved: 21.08 TF/s

==========
Batch Size: 16
Prompt Length: 1024
Generated tokens: 256
Average decode latency: 3.2991 sec
Average prefill latency: 0.2209 sec
Average tokens/sec: 1163.34
Memory used: 13.98 GB
Done. we are killing the process
