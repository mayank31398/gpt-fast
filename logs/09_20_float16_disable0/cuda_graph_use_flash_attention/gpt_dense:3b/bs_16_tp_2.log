W1001 01:37:23.868000 23175146280768 torch/distributed/run.py:779] 
W1001 01:37:23.868000 23175146280768 torch/distributed/run.py:779] *****************************************
W1001 01:37:23.868000 23175146280768 torch/distributed/run.py:779] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W1001 01:37:23.868000 23175146280768 torch/distributed/run.py:779] *****************************************
flash_kv_decode is set to True
Using device=cuda
Loading model ...
GPTDense(
  (tok_embeddings): Embedding(49152, 2304)
  (layers): ModuleList(
    (0-39): 40 x DenseTransformerBlock(
      semi_compiled = False
      (attention): Attention(
        (wqkv): Linear(in_features=2304, out_features=3456, bias=False)
        (wo): Linear(in_features=1152, out_features=2304, bias=False)
      )
      (feed_forward): FeedForward(
        (w1): Linear(in_features=2304, out_features=9216, bias=False)
        (w2): Linear(in_features=4608, out_features=2304, bias=False)
      )
      (ffn_norm): RMSNorm()
      (attention_norm): RMSNorm()
    )
  )
  (norm): RMSNorm()
  (output): Linear(in_features=2304, out_features=49152, bias=False)
)
Time to load model: 0.96 seconds
Prefill latency: 0.23617863410618156 sec
Decode latency: 3.5260753320762888 sec
Compilation time: 3.76 seconds
Compilation time: 3.76 seconds
Prefill latency: 0.23408520000521094 sec
Decode latency: 3.519681090954691 sec
Prefill latency: 0.2354631869820878 sec
Decode latency: 3.5218873569974676 sec
Prefill latency: 0.23545524198561907 sec
Decode latency: 3.5196290500462055 sec
Prefill latency: 0.2359950749669224 sec
Decode latency: 3.5218289570184425 sec
Prefill latency: 0.23537213692907244 sec
Decode latency: 3.5189371899468824 sec
Time for inference 1: 3.76 sec total, 1090.74 tokens/sec
Decode latency: 3.52 sec
Prefill latency: 0.24 sec
Bandwidth achieved: 3953.12 GB/s
FLOPS achieved: 19.77 TF/s

Prefill latency: 0.23617216700222343 sec
Decode latency: 3.5190422979649156 sec
Time for inference 2: 3.76 sec total, 1090.44 tokens/sec
Decode latency: 3.52 sec
Prefill latency: 0.24 sec
Bandwidth achieved: 3952.03 GB/s
FLOPS achieved: 19.76 TF/s

Prefill latency: 0.2361130730714649 sec
Decode latency: 3.520639849943109 sec
Time for inference 3: 3.76 sec total, 1090.02 tokens/sec
Decode latency: 3.52 sec
Prefill latency: 0.24 sec
Bandwidth achieved: 3950.49 GB/s
FLOPS achieved: 19.75 TF/s

Prefill latency: 0.23619557498022914 sec
Decode latency: 3.5189508290495723 sec
Time for inference 4: 3.76 sec total, 1090.52 tokens/sec
Decode latency: 3.52 sec
Prefill latency: 0.24 sec
Bandwidth achieved: 3952.31 GB/s
FLOPS achieved: 19.76 TF/s

Prefill latency: 0.23459702194668353 sec
Decode latency: 3.5193408529739827 sec
Time for inference 5: 3.75 sec total, 1090.89 tokens/sec
Decode latency: 3.52 sec
Prefill latency: 0.23 sec
Bandwidth achieved: 3953.67 GB/s
FLOPS achieved: 19.77 TF/s

Prefill latency: 0.23575650295242667 sec
Decode latency: 3.5201859900262207 sec
Time for inference 6: 3.76 sec total, 1090.30 tokens/sec
Decode latency: 3.52 sec
Prefill latency: 0.24 sec
Bandwidth achieved: 3951.52 GB/s
FLOPS achieved: 19.76 TF/s

Prefill latency: 0.2349002059781924 sec
Decode latency: 3.5205802699783817 sec
Time for inference 7: 3.76 sec total, 1090.44 tokens/sec
Decode latency: 3.52 sec
Prefill latency: 0.23 sec
Bandwidth achieved: 3952.03 GB/s
FLOPS achieved: 19.76 TF/s

Prefill latency: 0.2359025019686669 sec
Decode latency: 3.522124740993604 sec
Time for inference 8: 3.76 sec total, 1089.64 tokens/sec
Decode latency: 3.52 sec
Prefill latency: 0.24 sec
Bandwidth achieved: 3949.14 GB/s
FLOPS achieved: 19.75 TF/s

Prefill latency: 0.23630622902419418 sec
Decode latency: 3.520936566987075 sec
Time for inference 9: 3.76 sec total, 1089.90 tokens/sec
Decode latency: 3.52 sec
Prefill latency: 0.24 sec
Bandwidth achieved: 3950.07 GB/s
FLOPS achieved: 19.75 TF/s

Prefill latency: 0.23542802699375898 sec
Decode latency: 3.5189510519849136 sec
Time for inference 10: 3.76 sec total, 1090.74 tokens/sec
Decode latency: 3.52 sec
Prefill latency: 0.24 sec
Bandwidth achieved: 3953.10 GB/s
FLOPS achieved: 19.77 TF/s

==========
Batch Size: 16
Prompt Length: 1024
Generated tokens: 256
Average decode latency: 3.5200 sec
Average prefill latency: 0.2357 sec
Average tokens/sec: 1090.36
Memory used: 16.94 GB
Done. we are killing the process
