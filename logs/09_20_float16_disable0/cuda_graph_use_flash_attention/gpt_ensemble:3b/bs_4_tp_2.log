W1001 02:29:40.400000 22753743984448 torch/distributed/run.py:779] 
W1001 02:29:40.400000 22753743984448 torch/distributed/run.py:779] *****************************************
W1001 02:29:40.400000 22753743984448 torch/distributed/run.py:779] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W1001 02:29:40.400000 22753743984448 torch/distributed/run.py:779] *****************************************
flash_kv_decode is set to True
Using device=cuda
Loading model ...
GPTEnsemble(
  (tok_embeddings): Embedding(49152, 2304)
  (layers): ModuleList(
    (0-39): 40 x EnsembleTransformerBlock(
      semi_compiled = False
      (attention): Attention(
        (wqkv): Linear(in_features=2304, out_features=3456, bias=False)
        (wo): Linear(in_features=1152, out_features=2304, bias=False)
      )
      (feed_forward): FeedForward(
        (w1): Linear(in_features=2304, out_features=9216, bias=False)
        (w2): Linear(in_features=4608, out_features=2304, bias=False)
      )
      (ffn_norm): RMSNorm()
      (attention_norm): RMSNorm()
    )
  )
  (norm): RMSNorm()
  (output): Linear(in_features=2304, out_features=49152, bias=False)
)
Time to load model: 1.07 seconds
Prefill latency: 0.06254065595567226 sec
Decode latency: 2.60547123698052 sec
Compilation time: 2.67 seconds
Compilation time: 2.67 seconds
Prefill latency: 0.062242005951702595 sec
Decode latency: 2.603721011080779 sec
Prefill latency: 0.062228483031503856 sec
Decode latency: 2.6033843479817733 sec
Prefill latency: 0.062013919930905104 sec
Decode latency: 2.6039758670376614 sec
Prefill latency: 0.061929643037728965 sec
Decode latency: 2.604705859092064 sec
Prefill latency: 0.062130756909027696 sec
Decode latency: 2.6036365129984915 sec
Time for inference 1: 2.67 sec total, 384.01 tokens/sec
Decode latency: 2.60 sec
Prefill latency: 0.06 sec
Bandwidth achieved: 1391.76 GB/s
FLOPS achieved: 6.96 TF/s

Prefill latency: 0.0620512900641188 sec
Decode latency: 2.6038524030009285 sec
Time for inference 2: 2.67 sec total, 384.01 tokens/sec
Decode latency: 2.60 sec
Prefill latency: 0.06 sec
Bandwidth achieved: 1391.74 GB/s
FLOPS achieved: 6.96 TF/s

Prefill latency: 0.06204403599258512 sec
Decode latency: 2.603806521045044 sec
Time for inference 3: 2.67 sec total, 384.01 tokens/sec
Decode latency: 2.60 sec
Prefill latency: 0.06 sec
Bandwidth achieved: 1391.75 GB/s
FLOPS achieved: 6.96 TF/s

Prefill latency: 0.062006541993469 sec
Decode latency: 2.6041241260245442 sec
Time for inference 4: 2.67 sec total, 383.96 tokens/sec
Decode latency: 2.60 sec
Prefill latency: 0.06 sec
Bandwidth achieved: 1391.57 GB/s
FLOPS achieved: 6.96 TF/s

Prefill latency: 0.062122205970808864 sec
Decode latency: 2.603500778088346 sec
Time for inference 5: 2.67 sec total, 384.05 tokens/sec
Decode latency: 2.60 sec
Prefill latency: 0.06 sec
Bandwidth achieved: 1391.89 GB/s
FLOPS achieved: 6.96 TF/s

Prefill latency: 0.06209806597325951 sec
Decode latency: 2.603720086044632 sec
Time for inference 6: 2.67 sec total, 384.02 tokens/sec
Decode latency: 2.60 sec
Prefill latency: 0.06 sec
Bandwidth achieved: 1391.78 GB/s
FLOPS achieved: 6.96 TF/s

Prefill latency: 0.061994979972951114 sec
Decode latency: 2.603654784965329 sec
Time for inference 7: 2.67 sec total, 384.03 tokens/sec
Decode latency: 2.60 sec
Prefill latency: 0.06 sec
Bandwidth achieved: 1391.81 GB/s
FLOPS achieved: 6.96 TF/s

Prefill latency: 0.06202512595336884 sec
Decode latency: 2.6037125440780073 sec
Time for inference 8: 2.67 sec total, 384.02 tokens/sec
Decode latency: 2.60 sec
Prefill latency: 0.06 sec
Bandwidth achieved: 1391.78 GB/s
FLOPS achieved: 6.96 TF/s

Prefill latency: 0.0620486669940874 sec
Decode latency: 2.6032780969981104 sec
Time for inference 9: 2.67 sec total, 384.08 tokens/sec
Decode latency: 2.60 sec
Prefill latency: 0.06 sec
Bandwidth achieved: 1392.02 GB/s
FLOPS achieved: 6.96 TF/s

Prefill latency: 0.06208312092348933 sec
Decode latency: 2.6041386779397726 sec
Time for inference 10: 2.67 sec total, 383.93 tokens/sec
Decode latency: 2.60 sec
Prefill latency: 0.06 sec
Bandwidth achieved: 1391.46 GB/s
FLOPS achieved: 6.96 TF/s

==========
Batch Size: 4
Prompt Length: 1024
Generated tokens: 256
Average decode latency: 2.6037 sec
Average prefill latency: 0.0621 sec
Average tokens/sec: 384.01
Memory used: 6.60 GB
Done. we are killing the process
