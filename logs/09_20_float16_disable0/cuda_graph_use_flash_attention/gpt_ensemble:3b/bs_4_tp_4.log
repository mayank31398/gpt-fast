W1001 02:30:29.879000 22664906385216 torch/distributed/run.py:779] 
W1001 02:30:29.879000 22664906385216 torch/distributed/run.py:779] *****************************************
W1001 02:30:29.879000 22664906385216 torch/distributed/run.py:779] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W1001 02:30:29.879000 22664906385216 torch/distributed/run.py:779] *****************************************
flash_kv_decode is set to True
Using device=cuda
Loading model ...
GPTEnsemble(
  (tok_embeddings): Embedding(49152, 2304)
  (layers): ModuleList(
    (0-39): 40 x EnsembleTransformerBlock(
      semi_compiled = False
      (attention): Attention(
        (wqkv): Linear(in_features=2304, out_features=1728, bias=False)
        (wo): Linear(in_features=576, out_features=2304, bias=False)
      )
      (feed_forward): FeedForward(
        (w1): Linear(in_features=2304, out_features=4608, bias=False)
        (w2): Linear(in_features=2304, out_features=2304, bias=False)
      )
      (ffn_norm): RMSNorm()
      (attention_norm): RMSNorm()
    )
  )
  (norm): RMSNorm()
  (output): Linear(in_features=2304, out_features=49152, bias=False)
)
Time to load model: 1.09 seconds
Prefill latency: 0.0537481380160898 sec
Decode latency: 2.335660121985711 sec
Compilation time: 2.40 secondsCompilation time: 2.39 seconds

Compilation time: 2.41 seconds
Compilation time: 2.38 seconds
Prefill latency: 0.03902017802465707 sec
Decode latency: 2.3353643520968035 sec
Prefill latency: 0.03913663292769343 sec
Decode latency: 2.3330085850320756 sec
Prefill latency: 0.039075358072295785 sec
Decode latency: 2.332139989011921 sec
Prefill latency: 0.0389745170250535 sec
Decode latency: 2.3317228090018034 sec
Prefill latency: 0.039013226982206106 sec
Decode latency: 2.331824401044287 sec
Time for inference 1: 2.37 sec total, 431.77 tokens/sec
Decode latency: 2.33 sec
Prefill latency: 0.04 sec
Bandwidth achieved: 831.40 GB/s
FLOPS achieved: 4.16 TF/s

Prefill latency: 0.03905925701837987 sec
Decode latency: 2.3311408299487084 sec
Time for inference 2: 2.37 sec total, 431.85 tokens/sec
Decode latency: 2.33 sec
Prefill latency: 0.04 sec
Bandwidth achieved: 831.56 GB/s
FLOPS achieved: 4.16 TF/s

Prefill latency: 0.039088679011911154 sec
Decode latency: 2.3321762069826946 sec
Time for inference 3: 2.37 sec total, 431.68 tokens/sec
Decode latency: 2.33 sec
Prefill latency: 0.04 sec
Bandwidth achieved: 831.23 GB/s
FLOPS achieved: 4.16 TF/s

Prefill latency: 0.03909519489388913 sec
Decode latency: 2.330932085053064 sec
Time for inference 4: 2.37 sec total, 431.93 tokens/sec
Decode latency: 2.33 sec
Prefill latency: 0.04 sec
Bandwidth achieved: 831.70 GB/s
FLOPS achieved: 4.16 TF/s

Prefill latency: 0.03903610596898943 sec
Decode latency: 2.3314250219846144 sec
Time for inference 5: 2.37 sec total, 431.85 tokens/sec
Decode latency: 2.33 sec
Prefill latency: 0.04 sec
Bandwidth achieved: 831.56 GB/s
FLOPS achieved: 4.16 TF/s

Prefill latency: 0.039050030056387186 sec
Decode latency: 2.3314031469635665 sec
Time for inference 6: 2.37 sec total, 431.86 tokens/sec
Decode latency: 2.33 sec
Prefill latency: 0.04 sec
Bandwidth achieved: 831.57 GB/s
FLOPS achieved: 4.16 TF/s

Prefill latency: 0.03902816399931908 sec
Decode latency: 2.3316213110229 sec
Time for inference 7: 2.37 sec total, 431.82 tokens/sec
Decode latency: 2.33 sec
Prefill latency: 0.04 sec
Bandwidth achieved: 831.49 GB/s
FLOPS achieved: 4.16 TF/s

Prefill latency: 0.03893258108291775 sec
Decode latency: 2.33058276202064 sec
Time for inference 8: 2.37 sec total, 432.04 tokens/sec
Decode latency: 2.33 sec
Prefill latency: 0.04 sec
Bandwidth achieved: 831.91 GB/s
FLOPS achieved: 4.16 TF/s

Prefill latency: 0.03908918704837561 sec
Decode latency: 2.3315614809980616 sec
Time for inference 9: 2.37 sec total, 431.82 tokens/sec
Decode latency: 2.33 sec
Prefill latency: 0.04 sec
Bandwidth achieved: 831.50 GB/s
FLOPS achieved: 4.16 TF/s

Prefill latency: 0.0392431829823181 sec
Decode latency: 2.331387879909016 sec
Time for inference 10: 2.37 sec total, 431.83 tokens/sec
Decode latency: 2.33 sec
Prefill latency: 0.04 sec
Bandwidth achieved: 831.52 GB/s
FLOPS achieved: 4.16 TF/s

==========
Batch Size: 4
Prompt Length: 1024
Generated tokens: 256
Average decode latency: 2.3314 sec
Average prefill latency: 0.0391 sec
Average tokens/sec: 431.84
Memory used: 4.31 GB
Done. we are killing the process
