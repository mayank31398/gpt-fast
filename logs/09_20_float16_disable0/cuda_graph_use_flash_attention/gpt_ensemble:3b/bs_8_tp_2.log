W1001 02:32:33.588000 23061615257408 torch/distributed/run.py:779] 
W1001 02:32:33.588000 23061615257408 torch/distributed/run.py:779] *****************************************
W1001 02:32:33.588000 23061615257408 torch/distributed/run.py:779] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W1001 02:32:33.588000 23061615257408 torch/distributed/run.py:779] *****************************************
flash_kv_decode is set to True
Using device=cuda
Loading model ...
GPTEnsemble(
  (tok_embeddings): Embedding(49152, 2304)
  (layers): ModuleList(
    (0-39): 40 x EnsembleTransformerBlock(
      semi_compiled = False
      (attention): Attention(
        (wqkv): Linear(in_features=2304, out_features=3456, bias=False)
        (wo): Linear(in_features=1152, out_features=2304, bias=False)
      )
      (feed_forward): FeedForward(
        (w1): Linear(in_features=2304, out_features=9216, bias=False)
        (w2): Linear(in_features=4608, out_features=2304, bias=False)
      )
      (ffn_norm): RMSNorm()
      (attention_norm): RMSNorm()
    )
  )
  (norm): RMSNorm()
  (output): Linear(in_features=2304, out_features=49152, bias=False)
)
Time to load model: 0.97 seconds
Prefill latency: 0.1157063590362668 sec
Decode latency: 2.8932133360067382 sec
Compilation time: 3.01 seconds
Compilation time: 3.02 seconds
Prefill latency: 0.11575142003130168 sec
Decode latency: 2.8925767730688676 sec
Prefill latency: 0.11576650000642985 sec
Decode latency: 2.887381189968437 sec
Prefill latency: 0.11555191304069012 sec
Decode latency: 2.887426709989086 sec
Prefill latency: 0.11549136391840875 sec
Decode latency: 2.886768523021601 sec
Prefill latency: 0.11578898492734879 sec
Decode latency: 2.8873781070578843 sec
Time for inference 1: 3.00 sec total, 681.76 tokens/sec
Decode latency: 2.89 sec
Prefill latency: 0.12 sec
Bandwidth achieved: 2470.85 GB/s
FLOPS achieved: 12.35 TF/s

Prefill latency: 0.11541948490776122 sec
Decode latency: 2.8883182039717212 sec
Time for inference 2: 3.00 sec total, 681.65 tokens/sec
Decode latency: 2.89 sec
Prefill latency: 0.12 sec
Bandwidth achieved: 2470.48 GB/s
FLOPS achieved: 12.35 TF/s

Prefill latency: 0.11555916594807059 sec
Decode latency: 2.8876844329060987 sec
Time for inference 3: 3.00 sec total, 681.77 tokens/sec
Decode latency: 2.89 sec
Prefill latency: 0.12 sec
Bandwidth achieved: 2470.90 GB/s
FLOPS achieved: 12.35 TF/s

Prefill latency: 0.11565871105995029 sec
Decode latency: 2.886770141078159 sec
Time for inference 4: 3.00 sec total, 681.94 tokens/sec
Decode latency: 2.89 sec
Prefill latency: 0.12 sec
Bandwidth achieved: 2471.54 GB/s
FLOPS achieved: 12.36 TF/s

Prefill latency: 0.11540927097667009 sec
Decode latency: 2.8866133959963918 sec
Time for inference 5: 3.00 sec total, 682.01 tokens/sec
Decode latency: 2.89 sec
Prefill latency: 0.12 sec
Bandwidth achieved: 2471.77 GB/s
FLOPS achieved: 12.36 TF/s

Prefill latency: 0.11568150401581079 sec
Decode latency: 2.887180465972051 sec
Time for inference 6: 3.00 sec total, 681.83 tokens/sec
Decode latency: 2.89 sec
Prefill latency: 0.12 sec
Bandwidth achieved: 2471.12 GB/s
FLOPS achieved: 12.36 TF/s

Prefill latency: 0.11533411906566471 sec
Decode latency: 2.886942692915909 sec
Time for inference 7: 3.00 sec total, 681.98 tokens/sec
Decode latency: 2.89 sec
Prefill latency: 0.12 sec
Bandwidth achieved: 2471.67 GB/s
FLOPS achieved: 12.36 TF/s

Prefill latency: 0.11575590493157506 sec
Decode latency: 2.88684251497034 sec
Time for inference 8: 3.00 sec total, 681.91 tokens/sec
Decode latency: 2.89 sec
Prefill latency: 0.12 sec
Bandwidth achieved: 2471.40 GB/s
FLOPS achieved: 12.36 TF/s

Prefill latency: 0.11540157103445381 sec
Decode latency: 2.8866826969897375 sec
Time for inference 9: 3.00 sec total, 682.01 tokens/sec
Decode latency: 2.89 sec
Prefill latency: 0.12 sec
Bandwidth achieved: 2471.79 GB/s
FLOPS achieved: 12.36 TF/s

Prefill latency: 0.11555496603250504 sec
Decode latency: 2.8875679329503328 sec
Time for inference 10: 3.00 sec total, 681.75 tokens/sec
Decode latency: 2.89 sec
Prefill latency: 0.12 sec
Bandwidth achieved: 2470.83 GB/s
FLOPS achieved: 12.35 TF/s

==========
Batch Size: 8
Prompt Length: 1024
Generated tokens: 256
Average decode latency: 2.8872 sec
Average prefill latency: 0.1156 sec
Average tokens/sec: 681.86
Memory used: 9.07 GB
Done. we are killing the process
