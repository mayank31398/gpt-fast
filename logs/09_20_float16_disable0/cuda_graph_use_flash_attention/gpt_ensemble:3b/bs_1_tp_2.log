W1001 02:27:04.670000 22891883534144 torch/distributed/run.py:779] 
W1001 02:27:04.670000 22891883534144 torch/distributed/run.py:779] *****************************************
W1001 02:27:04.670000 22891883534144 torch/distributed/run.py:779] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W1001 02:27:04.670000 22891883534144 torch/distributed/run.py:779] *****************************************
flash_kv_decode is set to True
Using device=cuda
Loading model ...
GPTEnsemble(
  (tok_embeddings): Embedding(49152, 2304)
  (layers): ModuleList(
    (0-39): 40 x EnsembleTransformerBlock(
      semi_compiled = False
      (attention): Attention(
        (wqkv): Linear(in_features=2304, out_features=3456, bias=False)
        (wo): Linear(in_features=1152, out_features=2304, bias=False)
      )
      (feed_forward): FeedForward(
        (w1): Linear(in_features=2304, out_features=9216, bias=False)
        (w2): Linear(in_features=4608, out_features=2304, bias=False)
      )
      (ffn_norm): RMSNorm()
      (attention_norm): RMSNorm()
    )
  )
  (norm): RMSNorm()
  (output): Linear(in_features=2304, out_features=49152, bias=False)
)
Time to load model: 0.93 seconds
Prefill latency: 0.021433862973935902 sec
Decode latency: 2.328898907988332 sec
Compilation time: 2.35 seconds
Compilation time: 2.35 seconds
Prefill latency: 0.020851065986789763 sec
Decode latency: 2.328236123896204 sec
Prefill latency: 0.02082938200328499 sec
Decode latency: 2.3281232219887897 sec
Prefill latency: 0.020757352001965046 sec
Decode latency: 2.3284019889542833 sec
Prefill latency: 0.020883171004243195 sec
Decode latency: 2.328923130990006 sec
Prefill latency: 0.020825646934099495 sec
Decode latency: 2.328961582039483 sec
Time for inference 1: 2.35 sec total, 108.90 tokens/sec
Decode latency: 2.33 sec
Prefill latency: 0.02 sec
Bandwidth achieved: 394.69 GB/s
FLOPS achieved: 1.97 TF/s

Prefill latency: 0.020876711001619697 sec
Decode latency: 2.3291817859280854 sec
Time for inference 2: 2.35 sec total, 108.88 tokens/sec
Decode latency: 2.33 sec
Prefill latency: 0.02 sec
Bandwidth achieved: 394.61 GB/s
FLOPS achieved: 1.97 TF/s

Prefill latency: 0.020839645992964506 sec
Decode latency: 2.3293845190200955 sec
Time for inference 3: 2.35 sec total, 108.90 tokens/sec
Decode latency: 2.33 sec
Prefill latency: 0.02 sec
Bandwidth achieved: 394.67 GB/s
FLOPS achieved: 1.97 TF/s

Prefill latency: 0.020861633005551994 sec
Decode latency: 2.3293529100483283 sec
Time for inference 4: 2.35 sec total, 108.89 tokens/sec
Decode latency: 2.33 sec
Prefill latency: 0.02 sec
Bandwidth achieved: 394.65 GB/s
FLOPS achieved: 1.97 TF/s

Prefill latency: 0.02084612299222499 sec
Decode latency: 2.329044419922866 sec
Time for inference 5: 2.35 sec total, 108.90 tokens/sec
Decode latency: 2.33 sec
Prefill latency: 0.02 sec
Bandwidth achieved: 394.69 GB/s
FLOPS achieved: 1.97 TF/s

Prefill latency: 0.020764685003086925 sec
Decode latency: 2.3290626630187035 sec
Time for inference 6: 2.35 sec total, 108.91 tokens/sec
Decode latency: 2.33 sec
Prefill latency: 0.02 sec
Bandwidth achieved: 394.71 GB/s
FLOPS achieved: 1.97 TF/s

Prefill latency: 0.020850839093327522 sec
Decode latency: 2.328936734003946 sec
Time for inference 7: 2.35 sec total, 108.91 tokens/sec
Decode latency: 2.33 sec
Prefill latency: 0.02 sec
Bandwidth achieved: 394.72 GB/s
FLOPS achieved: 1.97 TF/s

Prefill latency: 0.020796625991351902 sec
Decode latency: 2.329266182030551 sec
Time for inference 8: 2.35 sec total, 108.90 tokens/sec
Decode latency: 2.33 sec
Prefill latency: 0.02 sec
Bandwidth achieved: 394.68 GB/s
FLOPS achieved: 1.97 TF/s

Prefill latency: 0.020910201012156904 sec
Decode latency: 2.3288055129814893 sec
Time for inference 9: 2.35 sec total, 108.91 tokens/sec
Decode latency: 2.33 sec
Prefill latency: 0.02 sec
Bandwidth achieved: 394.73 GB/s
FLOPS achieved: 1.97 TF/s

Prefill latency: 0.020833524991758168 sec
Decode latency: 2.329356920090504 sec
Time for inference 10: 2.35 sec total, 108.89 tokens/sec
Decode latency: 2.33 sec
Prefill latency: 0.02 sec
Bandwidth achieved: 394.66 GB/s
FLOPS achieved: 1.97 TF/s

==========
Batch Size: 1
Prompt Length: 1024
Generated tokens: 256
Average decode latency: 2.3291 sec
Average prefill latency: 0.0208 sec
Average tokens/sec: 108.90
Memory used: 4.79 GB
Done. we are killing the process
