W1001 02:42:50.147000 22487536809792 torch/distributed/run.py:779] 
W1001 02:42:50.147000 22487536809792 torch/distributed/run.py:779] *****************************************
W1001 02:42:50.147000 22487536809792 torch/distributed/run.py:779] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W1001 02:42:50.147000 22487536809792 torch/distributed/run.py:779] *****************************************
flash_kv_decode is set to True
Using device=cuda
Loading model ...
GPTEnsemble(
  (tok_embeddings): Embedding(49152, 2304)
  (layers): ModuleList(
    (0-39): 40 x EnsembleTransformerBlock(
      semi_compiled = False
      (attention): Attention(
        (wqkv): Linear(in_features=2304, out_features=3456, bias=False)
        (wo): Linear(in_features=1152, out_features=2304, bias=False)
      )
      (feed_forward): FeedForward(
        (w1): Linear(in_features=2304, out_features=9216, bias=False)
        (w2): Linear(in_features=4608, out_features=2304, bias=False)
      )
      (ffn_norm): RMSNorm()
      (attention_norm): RMSNorm()
    )
  )
  (norm): RMSNorm()
  (output): Linear(in_features=2304, out_features=49152, bias=False)
)
Time to load model: 1.03 seconds
Prefill latency: 0.8924488890916109 sec
Decode latency: 7.445214912062511 sec
Compilation time: 8.35 seconds
Compilation time: 8.34 seconds
Prefill latency: 0.8952679169597104 sec
Decode latency: 7.44502254400868 sec
Prefill latency: 0.8941207230091095 sec
Decode latency: 7.44385041797068 sec
Prefill latency: 0.8953120239311829 sec
Decode latency: 7.441772206919268 sec
Prefill latency: 0.8961772229522467 sec
Decode latency: 7.44233334006276 sec
Prefill latency: 0.8959585638949648 sec
Decode latency: 7.442664440954104 sec
Time for inference 1: 8.34 sec total, 1964.62 tokens/sec
Decode latency: 7.44 sec
Prefill latency: 0.90 sec
Bandwidth achieved: 7120.27 GB/s
FLOPS achieved: 35.60 TF/s

Prefill latency: 0.8953685080632567 sec
Decode latency: 7.444600951042958 sec
Time for inference 2: 8.34 sec total, 1964.27 tokens/sec
Decode latency: 7.44 sec
Prefill latency: 0.90 sec
Bandwidth achieved: 7119.01 GB/s
FLOPS achieved: 35.60 TF/s

Prefill latency: 0.8951637899735942 sec
Decode latency: 7.443351511028595 sec
Time for inference 3: 8.34 sec total, 1964.64 tokens/sec
Decode latency: 7.44 sec
Prefill latency: 0.90 sec
Bandwidth achieved: 7120.37 GB/s
FLOPS achieved: 35.60 TF/s

Prefill latency: 0.8953679269179702 sec
Decode latency: 7.429452733020298 sec
Time for inference 4: 8.33 sec total, 1967.89 tokens/sec
Decode latency: 7.43 sec
Prefill latency: 0.90 sec
Bandwidth achieved: 7132.14 GB/s
FLOPS achieved: 35.66 TF/s

Prefill latency: 0.8948021999094635 sec
Decode latency: 7.428217238979414 sec
Time for inference 5: 8.32 sec total, 1968.28 tokens/sec
Decode latency: 7.43 sec
Prefill latency: 0.89 sec
Bandwidth achieved: 7133.53 GB/s
FLOPS achieved: 35.67 TF/s

Prefill latency: 0.8941507959971204 sec
Decode latency: 7.431859006988816 sec
Time for inference 6: 8.33 sec total, 1967.55 tokens/sec
Decode latency: 7.43 sec
Prefill latency: 0.89 sec
Bandwidth achieved: 7130.91 GB/s
FLOPS achieved: 35.65 TF/s

Prefill latency: 0.8955174449365586 sec
Decode latency: 7.429344782023691 sec
Time for inference 7: 8.33 sec total, 1967.85 tokens/sec
Decode latency: 7.43 sec
Prefill latency: 0.90 sec
Bandwidth achieved: 7132.00 GB/s
FLOPS achieved: 35.66 TF/s

Prefill latency: 0.897240037098527 sec
Decode latency: 7.430208973004483 sec
Time for inference 8: 8.33 sec total, 1967.26 tokens/sec
Decode latency: 7.43 sec
Prefill latency: 0.90 sec
Bandwidth achieved: 7129.85 GB/s
FLOPS achieved: 35.65 TF/s

Prefill latency: 0.8943312420742586 sec
Decode latency: 7.430455524008721 sec
Time for inference 9: 8.33 sec total, 1967.87 tokens/sec
Decode latency: 7.43 sec
Prefill latency: 0.89 sec
Bandwidth achieved: 7132.05 GB/s
FLOPS achieved: 35.66 TF/s

Prefill latency: 0.8955452869413421 sec
Decode latency: 7.431711985962465 sec
Time for inference 10: 8.33 sec total, 1967.30 tokens/sec
Decode latency: 7.43 sec
Prefill latency: 0.90 sec
Bandwidth achieved: 7129.98 GB/s
FLOPS achieved: 35.65 TF/s

==========
Batch Size: 64
Prompt Length: 1024
Generated tokens: 256
Average decode latency: 7.4342 sec
Average prefill latency: 0.8953 sec
Average tokens/sec: 1966.75
Memory used: 42.02 GB
Done. we are killing the process
