W1001 01:05:36.353000 23162712405824 torch/distributed/run.py:779] 
W1001 01:05:36.353000 23162712405824 torch/distributed/run.py:779] *****************************************
W1001 01:05:36.353000 23162712405824 torch/distributed/run.py:779] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W1001 01:05:36.353000 23162712405824 torch/distributed/run.py:779] *****************************************
flash_kv_decode is set to True
Using device=cuda
Loading model ...
GPTEnsemble(
  (tok_embeddings): Embedding(49152, 1536)
  (layers): ModuleList(
    (0-39): 40 x EnsembleTransformerBlock(
      semi_compiled = False
      (attention): Attention(
        (wqkv): Linear(in_features=1536, out_features=1280, bias=False)
        (wo): Linear(in_features=768, out_features=1536, bias=False)
      )
      (feed_forward): FeedForward(
        (w1): Linear(in_features=1536, out_features=4096, bias=False)
        (w2): Linear(in_features=2048, out_features=1536, bias=False)
      )
      (ffn_norm): RMSNorm()
      (attention_norm): RMSNorm()
    )
  )
  (norm): RMSNorm()
  (output): Linear(in_features=1536, out_features=49152, bias=False)
)
Time to load model: 0.92 seconds
Prefill latency: 0.013864887994714081 sec
Decode latency: 1.8860853969817981 sec
Compilation time: 1.91 seconds
Compilation time: 1.90 seconds
Prefill latency: 0.013367458013817668 sec
Decode latency: 1.8852623190032318 sec
Prefill latency: 0.013622957048937678 sec
Decode latency: 1.885176473064348 sec
Prefill latency: 0.013437374960631132 sec
Decode latency: 1.886665188940242 sec
Prefill latency: 0.013577251927927136 sec
Decode latency: 1.882592794019729 sec
Prefill latency: 0.01339875697158277 sec
Decode latency: 1.882652409025468 sec
Time for inference 1: 1.90 sec total, 134.97 tokens/sec
Decode latency: 1.88 sec
Prefill latency: 0.01 sec
Bandwidth achieved: 156.28 GB/s
FLOPS achieved: 0.78 TF/s

Prefill latency: 0.013419828028418124 sec
Decode latency: 1.881785538047552 sec
Time for inference 2: 1.90 sec total, 135.03 tokens/sec
Decode latency: 1.88 sec
Prefill latency: 0.01 sec
Bandwidth achieved: 156.35 GB/s
FLOPS achieved: 0.78 TF/s

Prefill latency: 0.013360324082896113 sec
Decode latency: 1.8840774520067498 sec
Time for inference 3: 1.90 sec total, 134.87 tokens/sec
Decode latency: 1.88 sec
Prefill latency: 0.01 sec
Bandwidth achieved: 156.16 GB/s
FLOPS achieved: 0.78 TF/s

Prefill latency: 0.01341615803539753 sec
Decode latency: 1.8824493270367384 sec
Time for inference 4: 1.90 sec total, 134.98 tokens/sec
Decode latency: 1.88 sec
Prefill latency: 0.01 sec
Bandwidth achieved: 156.29 GB/s
FLOPS achieved: 0.78 TF/s

Prefill latency: 0.01335493999067694 sec
Decode latency: 1.8820012779906392 sec
Time for inference 5: 1.90 sec total, 135.02 tokens/sec
Decode latency: 1.88 sec
Prefill latency: 0.01 sec
Bandwidth achieved: 156.34 GB/s
FLOPS achieved: 0.78 TF/s

Prefill latency: 0.01334860292263329 sec
Decode latency: 1.8823262229561806 sec
Time for inference 6: 1.90 sec total, 134.99 tokens/sec
Decode latency: 1.88 sec
Prefill latency: 0.01 sec
Bandwidth achieved: 156.30 GB/s
FLOPS achieved: 0.78 TF/s

Prefill latency: 0.013438040972687304 sec
Decode latency: 1.8824612989556044 sec
Time for inference 7: 1.90 sec total, 134.98 tokens/sec
Decode latency: 1.88 sec
Prefill latency: 0.01 sec
Bandwidth achieved: 156.28 GB/s
FLOPS achieved: 0.78 TF/s

Prefill latency: 0.013363695004954934 sec
Decode latency: 1.8823519729776308 sec
Time for inference 8: 1.90 sec total, 135.00 tokens/sec
Decode latency: 1.88 sec
Prefill latency: 0.01 sec
Bandwidth achieved: 156.31 GB/s
FLOPS achieved: 0.78 TF/s

Prefill latency: 0.013409637962467968 sec
Decode latency: 1.8832699740305543 sec
Time for inference 9: 1.90 sec total, 134.92 tokens/sec
Decode latency: 1.88 sec
Prefill latency: 0.01 sec
Bandwidth achieved: 156.23 GB/s
FLOPS achieved: 0.78 TF/s

Prefill latency: 0.013359705917537212 sec
Decode latency: 1.8825341979973018 sec
Time for inference 10: 1.90 sec total, 134.98 tokens/sec
Decode latency: 1.88 sec
Prefill latency: 0.01 sec
Bandwidth achieved: 156.30 GB/s
FLOPS achieved: 0.78 TF/s

==========
Batch Size: 1
Prompt Length: 1024
Generated tokens: 256
Average decode latency: 1.8826 sec
Average prefill latency: 0.0134 sec
Average tokens/sec: 134.97
Memory used: 1.85 GB
Done. we are killing the process
