W1001 01:49:54.228000 22987280267072 torch/distributed/run.py:779] 
W1001 01:49:54.228000 22987280267072 torch/distributed/run.py:779] *****************************************
W1001 01:49:54.228000 22987280267072 torch/distributed/run.py:779] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W1001 01:49:54.228000 22987280267072 torch/distributed/run.py:779] *****************************************
flash_kv_decode is set to True
Using device=cuda
Loading model ...
GPTEnsemble(
  (tok_embeddings): Embedding(49152, 1536)
  (layers): ModuleList(
    (0-39): 40 x EnsembleTransformerBlock(
      semi_compiled = False
      (attention): Attention(
        (wqkv): Linear(in_features=1536, out_features=2304, bias=False)
        (wo): Linear(in_features=768, out_features=1536, bias=False)
      )
      (feed_forward): FeedForward(
        (w1): Linear(in_features=1536, out_features=4096, bias=False)
        (w2): Linear(in_features=2048, out_features=1536, bias=False)
      )
      (ffn_norm): RMSNorm()
      (attention_norm): RMSNorm()
    )
  )
  (norm): RMSNorm()
  (output): Linear(in_features=1536, out_features=49152, bias=False)
)
Time to load model: 1.39 seconds
Prefill latency: 0.039189547998830676 sec
Decode latency: 2.252507727011107 sec
Compilation time: 2.29 seconds
Compilation time: 2.29 seconds
Prefill latency: 0.03462203696835786 sec
Decode latency: 2.252633642987348 sec
Prefill latency: 0.03460703801829368 sec
Decode latency: 2.253326967009343 sec
Prefill latency: 0.03483491996303201 sec
Decode latency: 2.253268379950896 sec
Prefill latency: 0.03458058193791658 sec
Decode latency: 2.252797771943733 sec
Prefill latency: 0.03461153502576053 sec
Decode latency: 2.2530477850232273 sec
Time for inference 1: 2.29 sec total, 447.49 tokens/sec
Decode latency: 2.25 sec
Prefill latency: 0.03 sec
Bandwidth achieved: 574.45 GB/s
FLOPS achieved: 2.87 TF/s

Prefill latency: 0.03469771903473884 sec
Decode latency: 2.253467117086984 sec
Time for inference 2: 2.29 sec total, 447.36 tokens/sec
Decode latency: 2.25 sec
Prefill latency: 0.03 sec
Bandwidth achieved: 574.28 GB/s
FLOPS achieved: 2.87 TF/s

Prefill latency: 0.034659573109820485 sec
Decode latency: 2.2530522460583597 sec
Time for inference 3: 2.29 sec total, 447.44 tokens/sec
Decode latency: 2.25 sec
Prefill latency: 0.03 sec
Bandwidth achieved: 574.38 GB/s
FLOPS achieved: 2.87 TF/s

Prefill latency: 0.034714619047008455 sec
Decode latency: 2.2518121680477634 sec
Time for inference 4: 2.29 sec total, 447.68 tokens/sec
Decode latency: 2.25 sec
Prefill latency: 0.03 sec
Bandwidth achieved: 574.69 GB/s
FLOPS achieved: 2.87 TF/s

Prefill latency: 0.034598688944242895 sec
Decode latency: 2.2525495309382677 sec
Time for inference 5: 2.29 sec total, 447.57 tokens/sec
Decode latency: 2.25 sec
Prefill latency: 0.03 sec
Bandwidth achieved: 574.55 GB/s
FLOPS achieved: 2.87 TF/s

Prefill latency: 0.034547128016129136 sec
Decode latency: 2.2525013650301844 sec
Time for inference 6: 2.29 sec total, 447.60 tokens/sec
Decode latency: 2.25 sec
Prefill latency: 0.03 sec
Bandwidth achieved: 574.59 GB/s
FLOPS achieved: 2.87 TF/s

Prefill latency: 0.034601241000927985 sec
Decode latency: 2.252464742050506 sec
Time for inference 7: 2.29 sec total, 447.60 tokens/sec
Decode latency: 2.25 sec
Prefill latency: 0.03 sec
Bandwidth achieved: 574.58 GB/s
FLOPS achieved: 2.87 TF/s

Prefill latency: 0.034714333014562726 sec
Decode latency: 2.2524699399946257 sec
Time for inference 8: 2.29 sec total, 447.58 tokens/sec
Decode latency: 2.25 sec
Prefill latency: 0.03 sec
Bandwidth achieved: 574.56 GB/s
FLOPS achieved: 2.87 TF/s

Prefill latency: 0.034642048995010555 sec
Decode latency: 2.251717385952361 sec
Time for inference 9: 2.29 sec total, 447.74 tokens/sec
Decode latency: 2.25 sec
Prefill latency: 0.03 sec
Bandwidth achieved: 574.76 GB/s
FLOPS achieved: 2.87 TF/s

Prefill latency: 0.034675905015319586 sec
Decode latency: 2.252549191005528 sec
Time for inference 10: 2.29 sec total, 447.59 tokens/sec
Decode latency: 2.25 sec
Prefill latency: 0.03 sec
Bandwidth achieved: 574.57 GB/s
FLOPS achieved: 2.87 TF/s

==========
Batch Size: 4
Prompt Length: 1024
Generated tokens: 256
Average decode latency: 2.2526 sec
Average prefill latency: 0.0346 sec
Average tokens/sec: 447.56
Memory used: 3.62 GB
Done. we are killing the process
