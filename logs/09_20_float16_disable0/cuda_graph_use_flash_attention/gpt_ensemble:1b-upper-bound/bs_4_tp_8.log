W1001 01:51:27.263000 22588396345152 torch/distributed/run.py:779] 
W1001 01:51:27.263000 22588396345152 torch/distributed/run.py:779] *****************************************
W1001 01:51:27.263000 22588396345152 torch/distributed/run.py:779] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W1001 01:51:27.263000 22588396345152 torch/distributed/run.py:779] *****************************************
flash_kv_decode is set to True
Using device=cuda
Loading model ...
GPTEnsemble(
  (tok_embeddings): Embedding(49152, 1536)
  (layers): ModuleList(
    (0-39): 40 x EnsembleTransformerBlock(
      semi_compiled = False
      (attention): Attention(
        (wqkv): Linear(in_features=1536, out_features=576, bias=False)
        (wo): Linear(in_features=192, out_features=1536, bias=False)
      )
      (feed_forward): FeedForward(
        (w1): Linear(in_features=1536, out_features=1024, bias=False)
        (w2): Linear(in_features=512, out_features=1536, bias=False)
      )
      (ffn_norm): RMSNorm()
      (attention_norm): RMSNorm()
    )
  )
  (norm): RMSNorm()
  (output): Linear(in_features=1536, out_features=49152, bias=False)
)
Time to load model: 1.13 seconds
Prefill latency: 0.03992588189430535 sec
Decode latency: 2.061841723974794 sec
Compilation time: 2.08 secondsCompilation time: 2.09 seconds
Compilation time: 2.14 seconds

Compilation time: 2.13 seconds
Compilation time: 2.11 seconds
Compilation time: 2.09 seconds
Compilation time: 2.10 seconds
Compilation time: 2.14 seconds
Prefill latency: 0.01946502097416669 sec
Decode latency: 2.0617875060997903 sec
Prefill latency: 0.01930539298336953 sec
Decode latency: 2.062314415932633 sec
Prefill latency: 0.019320628023706377 sec
Decode latency: 2.062116542016156 sec
Prefill latency: 0.019464786048047245 sec
Decode latency: 2.061380795086734 sec
Prefill latency: 0.019244551076553762 sec
Decode latency: 2.0618186179781333 sec
Time for inference 1: 2.08 sec total, 491.84 tokens/sec
Decode latency: 2.06 sec
Prefill latency: 0.02 sec
Bandwidth achieved: 213.63 GB/s
FLOPS achieved: 1.07 TF/s

Prefill latency: 0.019310868927277625 sec
Decode latency: 2.061976497992873 sec
Time for inference 2: 2.08 sec total, 491.77 tokens/sec
Decode latency: 2.06 sec
Prefill latency: 0.02 sec
Bandwidth achieved: 213.61 GB/s
FLOPS achieved: 1.07 TF/s

Prefill latency: 0.0193162530194968 sec
Decode latency: 2.0617806300288066 sec
Time for inference 3: 2.08 sec total, 491.88 tokens/sec
Decode latency: 2.06 sec
Prefill latency: 0.02 sec
Bandwidth achieved: 213.65 GB/s
FLOPS achieved: 1.07 TF/s

Prefill latency: 0.019230503006838262 sec
Decode latency: 2.0617960329400375 sec
Time for inference 4: 2.08 sec total, 491.87 tokens/sec
Decode latency: 2.06 sec
Prefill latency: 0.02 sec
Bandwidth achieved: 213.65 GB/s
FLOPS achieved: 1.07 TF/s

Prefill latency: 0.019307835958898067 sec
Decode latency: 2.061276532942429 sec
Time for inference 5: 2.08 sec total, 491.93 tokens/sec
Decode latency: 2.06 sec
Prefill latency: 0.02 sec
Bandwidth achieved: 213.67 GB/s
FLOPS achieved: 1.07 TF/s

Prefill latency: 0.019323760992847383 sec
Decode latency: 2.061433703987859 sec
Time for inference 6: 2.08 sec total, 491.94 tokens/sec
Decode latency: 2.06 sec
Prefill latency: 0.02 sec
Bandwidth achieved: 213.68 GB/s
FLOPS achieved: 1.07 TF/s

Prefill latency: 0.0193092729896307 sec
Decode latency: 2.0612749049905688 sec
Time for inference 7: 2.08 sec total, 492.00 tokens/sec
Decode latency: 2.06 sec
Prefill latency: 0.02 sec
Bandwidth achieved: 213.70 GB/s
FLOPS achieved: 1.07 TF/s

Prefill latency: 0.019255965016782284 sec
Decode latency: 2.060577320982702 sec
Time for inference 8: 2.08 sec total, 492.18 tokens/sec
Decode latency: 2.06 sec
Prefill latency: 0.02 sec
Bandwidth achieved: 213.78 GB/s
FLOPS achieved: 1.07 TF/s

Prefill latency: 0.019263579975813627 sec
Decode latency: 2.0611580460099503 sec
Time for inference 9: 2.08 sec total, 492.02 tokens/sec
Decode latency: 2.06 sec
Prefill latency: 0.02 sec
Bandwidth achieved: 213.71 GB/s
FLOPS achieved: 1.07 TF/s

Prefill latency: 0.019300560001283884 sec
Decode latency: 2.0612850710749626 sec
Time for inference 10: 2.08 sec total, 491.99 tokens/sec
Decode latency: 2.06 sec
Prefill latency: 0.02 sec
Bandwidth achieved: 213.70 GB/s
FLOPS achieved: 1.07 TF/s

==========
Batch Size: 4
Prompt Length: 1024
Generated tokens: 256
Average decode latency: 2.0614 sec
Average prefill latency: 0.0193 sec
Average tokens/sec: 491.94
Memory used: 1.89 GB
Done. we are killing the process
