W1001 01:56:35.830000 22668697909056 torch/distributed/run.py:779] 
W1001 01:56:35.830000 22668697909056 torch/distributed/run.py:779] *****************************************
W1001 01:56:35.830000 22668697909056 torch/distributed/run.py:779] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W1001 01:56:35.830000 22668697909056 torch/distributed/run.py:779] *****************************************
flash_kv_decode is set to True
Using device=cuda
Loading model ...
GPTEnsemble(
  (tok_embeddings): Embedding(49152, 1536)
  (layers): ModuleList(
    (0-39): 40 x EnsembleTransformerBlock(
      semi_compiled = False
      (attention): Attention(
        (wqkv): Linear(in_features=1536, out_features=2304, bias=False)
        (wo): Linear(in_features=768, out_features=1536, bias=False)
      )
      (feed_forward): FeedForward(
        (w1): Linear(in_features=1536, out_features=4096, bias=False)
        (w2): Linear(in_features=2048, out_features=1536, bias=False)
      )
      (ffn_norm): RMSNorm()
      (attention_norm): RMSNorm()
    )
  )
  (norm): RMSNorm()
  (output): Linear(in_features=1536, out_features=49152, bias=False)
)
Time to load model: 1.20 seconds
Prefill latency: 0.12994093808811158 sec
Decode latency: 2.7819637339562178 sec
Compilation time: 2.91 seconds
Compilation time: 2.91 seconds
Prefill latency: 0.12158356700092554 sec
Decode latency: 2.7805315690347925 sec
Prefill latency: 0.12166141893249005 sec
Decode latency: 2.781473301933147 sec
Prefill latency: 0.12156959599815309 sec
Decode latency: 2.781293763895519 sec
Prefill latency: 0.12171973602380604 sec
Decode latency: 2.7815150229725987 sec
Prefill latency: 0.12170848599635065 sec
Decode latency: 2.7806289760628715 sec
Time for inference 1: 2.90 sec total, 1410.87 tokens/sec
Decode latency: 2.78 sec
Prefill latency: 0.12 sec
Bandwidth achieved: 1811.14 GB/s
FLOPS achieved: 9.06 TF/s

Prefill latency: 0.12173817900475115 sec
Decode latency: 2.7801062520593405 sec
Time for inference 2: 2.90 sec total, 1411.13 tokens/sec
Decode latency: 2.78 sec
Prefill latency: 0.12 sec
Bandwidth achieved: 1811.47 GB/s
FLOPS achieved: 9.06 TF/s

Prefill latency: 0.12178314104676247 sec
Decode latency: 2.7814412460429594 sec
Time for inference 3: 2.90 sec total, 1410.46 tokens/sec
Decode latency: 2.78 sec
Prefill latency: 0.12 sec
Bandwidth achieved: 1810.61 GB/s
FLOPS achieved: 9.05 TF/s

Prefill latency: 0.12165385892149061 sec
Decode latency: 2.780303432024084 sec
Time for inference 4: 2.90 sec total, 1411.10 tokens/sec
Decode latency: 2.78 sec
Prefill latency: 0.12 sec
Bandwidth achieved: 1811.44 GB/s
FLOPS achieved: 9.06 TF/s

Prefill latency: 0.12177392293233424 sec
Decode latency: 2.7803105959901586 sec
Time for inference 5: 2.90 sec total, 1411.04 tokens/sec
Decode latency: 2.78 sec
Prefill latency: 0.12 sec
Bandwidth achieved: 1811.35 GB/s
FLOPS achieved: 9.06 TF/s

Prefill latency: 0.12177116004750133 sec
Decode latency: 2.7809102809987962 sec
Time for inference 6: 2.90 sec total, 1410.76 tokens/sec
Decode latency: 2.78 sec
Prefill latency: 0.12 sec
Bandwidth achieved: 1811.00 GB/s
FLOPS achieved: 9.05 TF/s

Prefill latency: 0.12160089402459562 sec
Decode latency: 2.7809189149411395 sec
Time for inference 7: 2.90 sec total, 1410.68 tokens/sec
Decode latency: 2.78 sec
Prefill latency: 0.12 sec
Bandwidth achieved: 1810.89 GB/s
FLOPS achieved: 9.05 TF/s

Prefill latency: 0.12169010401703417 sec
Decode latency: 2.780378969036974 sec
Time for inference 8: 2.90 sec total, 1410.91 tokens/sec
Decode latency: 2.78 sec
Prefill latency: 0.12 sec
Bandwidth achieved: 1811.20 GB/s
FLOPS achieved: 9.06 TF/s

Prefill latency: 0.12166368192993104 sec
Decode latency: 2.780579657992348 sec
Time for inference 9: 2.90 sec total, 1410.84 tokens/sec
Decode latency: 2.78 sec
Prefill latency: 0.12 sec
Bandwidth achieved: 1811.11 GB/s
FLOPS achieved: 9.06 TF/s

Prefill latency: 0.12167958996724337 sec
Decode latency: 2.7815064509632066 sec
Time for inference 10: 2.90 sec total, 1410.42 tokens/sec
Decode latency: 2.78 sec
Prefill latency: 0.12 sec
Bandwidth achieved: 1810.57 GB/s
FLOPS achieved: 9.05 TF/s

==========
Batch Size: 16
Prompt Length: 1024
Generated tokens: 256
Average decode latency: 2.7807 sec
Average prefill latency: 0.1217 sec
Average tokens/sec: 1410.82
Memory used: 8.91 GB
Done. we are killing the process
