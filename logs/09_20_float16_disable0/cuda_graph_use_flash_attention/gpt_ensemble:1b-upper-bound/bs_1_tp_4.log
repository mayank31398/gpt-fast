W1001 01:47:41.388000 22454374893376 torch/distributed/run.py:779] 
W1001 01:47:41.388000 22454374893376 torch/distributed/run.py:779] *****************************************
W1001 01:47:41.388000 22454374893376 torch/distributed/run.py:779] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W1001 01:47:41.388000 22454374893376 torch/distributed/run.py:779] *****************************************
flash_kv_decode is set to True
Using device=cuda
Loading model ...
GPTEnsemble(
  (tok_embeddings): Embedding(49152, 1536)
  (layers): ModuleList(
    (0-39): 40 x EnsembleTransformerBlock(
      semi_compiled = False
      (attention): Attention(
        (wqkv): Linear(in_features=1536, out_features=1152, bias=False)
        (wo): Linear(in_features=384, out_features=1536, bias=False)
      )
      (feed_forward): FeedForward(
        (w1): Linear(in_features=1536, out_features=2048, bias=False)
        (w2): Linear(in_features=1024, out_features=1536, bias=False)
      )
      (ffn_norm): RMSNorm()
      (attention_norm): RMSNorm()
    )
  )
  (norm): RMSNorm()
  (output): Linear(in_features=1536, out_features=49152, bias=False)
)
Time to load model: 1.03 seconds
Prefill latency: 0.097438327036798 sec
Decode latency: 1.8577613539528102 sec
Compilation time: 1.87 secondsCompilation time: 1.88 seconds

Compilation time: 1.91 seconds
Compilation time: 1.96 seconds
Prefill latency: 0.012114721001125872 sec
Decode latency: 1.8574170399224386 sec
Prefill latency: 0.01219061401207 sec
Decode latency: 1.8571374809835106 sec
Prefill latency: 0.012139489990659058 sec
Decode latency: 1.8566143190255389 sec
Prefill latency: 0.012156118056736887 sec
Decode latency: 1.8571968380128965 sec
Prefill latency: 0.012372649041935802 sec
Decode latency: 1.8586075530620292 sec
Time for inference 1: 1.87 sec total, 136.77 tokens/sec
Decode latency: 1.86 sec
Prefill latency: 0.01 sec
Bandwidth achieved: 98.13 GB/s
FLOPS achieved: 0.49 TF/s

Prefill latency: 0.012294937972910702 sec
Decode latency: 1.8571442869724706 sec
Time for inference 2: 1.87 sec total, 136.88 tokens/sec
Decode latency: 1.86 sec
Prefill latency: 0.01 sec
Bandwidth achieved: 98.21 GB/s
FLOPS achieved: 0.49 TF/s

Prefill latency: 0.012129002017900348 sec
Decode latency: 1.8575150349643081 sec
Time for inference 3: 1.87 sec total, 136.87 tokens/sec
Decode latency: 1.86 sec
Prefill latency: 0.01 sec
Bandwidth achieved: 98.20 GB/s
FLOPS achieved: 0.49 TF/s

Prefill latency: 0.012195082963444293 sec
Decode latency: 1.8567825349746272 sec
Time for inference 4: 1.87 sec total, 136.93 tokens/sec
Decode latency: 1.86 sec
Prefill latency: 0.01 sec
Bandwidth achieved: 98.24 GB/s
FLOPS achieved: 0.49 TF/s

Prefill latency: 0.01230910001322627 sec
Decode latency: 1.8574027379509062 sec
Time for inference 5: 1.87 sec total, 136.87 tokens/sec
Decode latency: 1.86 sec
Prefill latency: 0.01 sec
Bandwidth achieved: 98.20 GB/s
FLOPS achieved: 0.49 TF/s

Prefill latency: 0.01210185803938657 sec
Decode latency: 1.8578200979391113 sec
Time for inference 6: 1.87 sec total, 136.85 tokens/sec
Decode latency: 1.86 sec
Prefill latency: 0.01 sec
Bandwidth achieved: 98.18 GB/s
FLOPS achieved: 0.49 TF/s

Prefill latency: 0.012152365990914404 sec
Decode latency: 1.8577064300188795 sec
Time for inference 7: 1.87 sec total, 136.85 tokens/sec
Decode latency: 1.86 sec
Prefill latency: 0.01 sec
Bandwidth achieved: 98.19 GB/s
FLOPS achieved: 0.49 TF/s

Prefill latency: 0.01232497999444604 sec
Decode latency: 1.8569398010149598 sec
Time for inference 8: 1.87 sec total, 136.90 tokens/sec
Decode latency: 1.86 sec
Prefill latency: 0.01 sec
Bandwidth achieved: 98.22 GB/s
FLOPS achieved: 0.49 TF/s

Prefill latency: 0.01219261297956109 sec
Decode latency: 1.8567085919203237 sec
Time for inference 9: 1.87 sec total, 136.93 tokens/sec
Decode latency: 1.86 sec
Prefill latency: 0.01 sec
Bandwidth achieved: 98.24 GB/s
FLOPS achieved: 0.49 TF/s

Prefill latency: 0.01213350601028651 sec
Decode latency: 1.859197888057679 sec
Time for inference 10: 1.87 sec total, 136.74 tokens/sec
Decode latency: 1.86 sec
Prefill latency: 0.01 sec
Bandwidth achieved: 98.11 GB/s
FLOPS achieved: 0.49 TF/s

==========
Batch Size: 1
Prompt Length: 1024
Generated tokens: 256
Average decode latency: 1.8576 sec
Average prefill latency: 0.0122 sec
Average tokens/sec: 136.86
Memory used: 1.38 GB
Done. we are killing the process
