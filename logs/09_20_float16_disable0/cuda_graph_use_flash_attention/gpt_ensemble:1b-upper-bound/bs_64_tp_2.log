W1001 02:01:45.821000 23070905915200 torch/distributed/run.py:779] 
W1001 02:01:45.821000 23070905915200 torch/distributed/run.py:779] *****************************************
W1001 02:01:45.821000 23070905915200 torch/distributed/run.py:779] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W1001 02:01:45.821000 23070905915200 torch/distributed/run.py:779] *****************************************
flash_kv_decode is set to True
Using device=cuda
Loading model ...
GPTEnsemble(
  (tok_embeddings): Embedding(49152, 1536)
  (layers): ModuleList(
    (0-39): 40 x EnsembleTransformerBlock(
      semi_compiled = False
      (attention): Attention(
        (wqkv): Linear(in_features=1536, out_features=2304, bias=False)
        (wo): Linear(in_features=768, out_features=1536, bias=False)
      )
      (feed_forward): FeedForward(
        (w1): Linear(in_features=1536, out_features=4096, bias=False)
        (w2): Linear(in_features=2048, out_features=1536, bias=False)
      )
      (ffn_norm): RMSNorm()
      (attention_norm): RMSNorm()
    )
  )
  (norm): RMSNorm()
  (output): Linear(in_features=1536, out_features=49152, bias=False)
)
Time to load model: 0.99 seconds
Prefill latency: 0.48533524002414197 sec
Decode latency: 5.31533903896343 sec
Compilation time: 5.78 seconds
Compilation time: 5.80 seconds
Prefill latency: 0.46439900097902864 sec
Decode latency: 5.312742148060352 sec
Prefill latency: 0.46423449309077114 sec
Decode latency: 5.308239995967597 sec
Prefill latency: 0.4642457669833675 sec
Decode latency: 5.311514656059444 sec
Prefill latency: 0.4643591969506815 sec
Decode latency: 5.31003409891855 sec
Prefill latency: 0.46435170096810907 sec
Decode latency: 5.313431100919843 sec
Time for inference 1: 5.78 sec total, 2835.24 tokens/sec
Decode latency: 5.31 sec
Prefill latency: 0.46 sec
Bandwidth achieved: 3639.61 GB/s
FLOPS achieved: 18.20 TF/s

Prefill latency: 0.46445406798738986 sec
Decode latency: 5.315077646984719 sec
Time for inference 2: 5.78 sec total, 2834.39 tokens/sec
Decode latency: 5.32 sec
Prefill latency: 0.46 sec
Bandwidth achieved: 3638.52 GB/s
FLOPS achieved: 18.19 TF/s

Prefill latency: 0.4644583559129387 sec
Decode latency: 5.3140867670299485 sec
Time for inference 3: 5.78 sec total, 2834.89 tokens/sec
Decode latency: 5.31 sec
Prefill latency: 0.46 sec
Bandwidth achieved: 3639.16 GB/s
FLOPS achieved: 18.20 TF/s

Prefill latency: 0.4645623550750315 sec
Decode latency: 5.31316193100065 sec
Time for inference 4: 5.78 sec total, 2835.30 tokens/sec
Decode latency: 5.31 sec
Prefill latency: 0.46 sec
Bandwidth achieved: 3639.69 GB/s
FLOPS achieved: 18.20 TF/s

Prefill latency: 0.46459584799595177 sec
Decode latency: 5.313651175936684 sec
Time for inference 5: 5.78 sec total, 2835.00 tokens/sec
Decode latency: 5.31 sec
Prefill latency: 0.46 sec
Bandwidth achieved: 3639.30 GB/s
FLOPS achieved: 18.20 TF/s

Prefill latency: 0.4645363800227642 sec
Decode latency: 5.313564377021976 sec
Time for inference 6: 5.78 sec total, 2835.08 tokens/sec
Decode latency: 5.31 sec
Prefill latency: 0.46 sec
Bandwidth achieved: 3639.41 GB/s
FLOPS achieved: 18.20 TF/s

Prefill latency: 0.46457771700806916 sec
Decode latency: 5.312564768013544 sec
Time for inference 7: 5.78 sec total, 2835.56 tokens/sec
Decode latency: 5.31 sec
Prefill latency: 0.46 sec
Bandwidth achieved: 3640.02 GB/s
FLOPS achieved: 18.20 TF/s

Prefill latency: 0.4646419290220365 sec
Decode latency: 5.310512501979247 sec
Time for inference 8: 5.78 sec total, 2836.62 tokens/sec
Decode latency: 5.31 sec
Prefill latency: 0.46 sec
Bandwidth achieved: 3641.38 GB/s
FLOPS achieved: 18.21 TF/s

Prefill latency: 0.46495649905409664 sec
Decode latency: 5.30922356096562 sec
Time for inference 9: 5.77 sec total, 2837.06 tokens/sec
Decode latency: 5.31 sec
Prefill latency: 0.46 sec
Bandwidth achieved: 3641.95 GB/s
FLOPS achieved: 18.21 TF/s

Prefill latency: 0.4648653999902308 sec
Decode latency: 5.31222963903565 sec
Time for inference 10: 5.78 sec total, 2835.50 tokens/sec
Decode latency: 5.31 sec
Prefill latency: 0.46 sec
Bandwidth achieved: 3639.95 GB/s
FLOPS achieved: 18.20 TF/s

==========
Batch Size: 64
Prompt Length: 1024
Generated tokens: 256
Average decode latency: 5.3128 sec
Average prefill latency: 0.4646 sec
Average tokens/sec: 2835.46
Memory used: 30.83 GB
Done. we are killing the process
