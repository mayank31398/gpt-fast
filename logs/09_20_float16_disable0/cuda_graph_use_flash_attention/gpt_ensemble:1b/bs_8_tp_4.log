W0930 19:41:02.685000 22419395721024 torch/distributed/run.py:779] 
W0930 19:41:02.685000 22419395721024 torch/distributed/run.py:779] *****************************************
W0930 19:41:02.685000 22419395721024 torch/distributed/run.py:779] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W0930 19:41:02.685000 22419395721024 torch/distributed/run.py:779] *****************************************
flash_kv_decode is set to True
Using device=cuda
Loading model ...
GPTEnsemble(
  (tok_embeddings): Embedding(49152, 1536)
  (layers): ModuleList(
    (0-39): 40 x EnsembleTransformerBlock(
      semi_compiled = False
      (attention): Attention(
        (wqkv): Linear(in_features=1536, out_features=640, bias=False)
        (wo): Linear(in_features=384, out_features=1536, bias=False)
      )
      (feed_forward): FeedForward(
        (w1): Linear(in_features=1536, out_features=2048, bias=False)
        (w2): Linear(in_features=1024, out_features=1536, bias=False)
      )
      (ffn_norm): RMSNorm()
      (attention_norm): RMSNorm()
    )
  )
  (norm): RMSNorm()
  (output): Linear(in_features=1536, out_features=49152, bias=False)
)
Time to load model: 1.06 seconds
Prefill latency: 0.09083889599423856 sec
Decode latency: 2.292281305999495 sec
Compilation time: 2.36 seconds
Compilation time: 2.35 seconds
Compilation time: 2.33 seconds
Compilation time: 2.38 seconds
Prefill latency: 0.03808892099186778 sec
Decode latency: 2.2920059770112857 sec
Prefill latency: 0.03802085493225604 sec
Decode latency: 2.289877248927951 sec
Prefill latency: 0.038270139019005 sec
Decode latency: 2.2892982359044254 sec
Prefill latency: 0.03813264099881053 sec
Decode latency: 2.2887216210365295 sec
Prefill latency: 0.038087442982941866 sec
Decode latency: 2.2888773609884083 sec
Time for inference 1: 2.33 sec total, 879.79 tokens/sec
Decode latency: 2.29 sec
Prefill latency: 0.04 sec
Bandwidth achieved: 575.87 GB/s
FLOPS achieved: 2.88 TF/s

Prefill latency: 0.03809147793799639 sec
Decode latency: 2.2893941910006106 sec
Time for inference 2: 2.33 sec total, 879.55 tokens/sec
Decode latency: 2.29 sec
Prefill latency: 0.04 sec
Bandwidth achieved: 575.72 GB/s
FLOPS achieved: 2.88 TF/s

Prefill latency: 0.03801966202445328 sec
Decode latency: 2.2892110019456595 sec
Time for inference 3: 2.33 sec total, 879.68 tokens/sec
Decode latency: 2.29 sec
Prefill latency: 0.04 sec
Bandwidth achieved: 575.80 GB/s
FLOPS achieved: 2.88 TF/s

Prefill latency: 0.03806271497160196 sec
Decode latency: 2.28850636491552 sec
Time for inference 4: 2.33 sec total, 879.96 tokens/sec
Decode latency: 2.29 sec
Prefill latency: 0.04 sec
Bandwidth achieved: 575.99 GB/s
FLOPS achieved: 2.88 TF/s

Prefill latency: 0.03810484509449452 sec
Decode latency: 2.2890114260371774 sec
Time for inference 5: 2.33 sec total, 879.78 tokens/sec
Decode latency: 2.29 sec
Prefill latency: 0.04 sec
Bandwidth achieved: 575.87 GB/s
FLOPS achieved: 2.88 TF/s

Prefill latency: 0.038143491954542696 sec
Decode latency: 2.2900108289904892 sec
Time for inference 6: 2.33 sec total, 879.39 tokens/sec
Decode latency: 2.29 sec
Prefill latency: 0.04 sec
Bandwidth achieved: 575.62 GB/s
FLOPS achieved: 2.88 TF/s

Prefill latency: 0.038200654089450836 sec
Decode latency: 2.289283699938096 sec
Time for inference 7: 2.33 sec total, 879.66 tokens/sec
Decode latency: 2.29 sec
Prefill latency: 0.04 sec
Bandwidth achieved: 575.79 GB/s
FLOPS achieved: 2.88 TF/s

Prefill latency: 0.03843472292646766 sec
Decode latency: 2.2891053030034527 sec
Time for inference 8: 2.33 sec total, 879.56 tokens/sec
Decode latency: 2.29 sec
Prefill latency: 0.04 sec
Bandwidth achieved: 575.73 GB/s
FLOPS achieved: 2.88 TF/s

Prefill latency: 0.038116167997941375 sec
Decode latency: 2.2891608650097623 sec
Time for inference 9: 2.33 sec total, 879.67 tokens/sec
Decode latency: 2.29 sec
Prefill latency: 0.04 sec
Bandwidth achieved: 575.80 GB/s
FLOPS achieved: 2.88 TF/s

Prefill latency: 0.03822338406462222 sec
Decode latency: 2.289593115914613 sec
Time for inference 10: 2.33 sec total, 879.47 tokens/sec
Decode latency: 2.29 sec
Prefill latency: 0.04 sec
Bandwidth achieved: 575.67 GB/s
FLOPS achieved: 2.88 TF/s

==========
Batch Size: 8
Prompt Length: 1024
Generated tokens: 256
Average decode latency: 2.2892 sec
Average prefill latency: 0.0381 sec
Average tokens/sec: 879.65
Memory used: 3.45 GB
Done. we are killing the process
