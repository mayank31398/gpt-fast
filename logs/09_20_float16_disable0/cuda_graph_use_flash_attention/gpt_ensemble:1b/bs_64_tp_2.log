W1001 02:39:17.822000 23245861205824 torch/distributed/run.py:779] 
W1001 02:39:17.822000 23245861205824 torch/distributed/run.py:779] *****************************************
W1001 02:39:17.822000 23245861205824 torch/distributed/run.py:779] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W1001 02:39:17.822000 23245861205824 torch/distributed/run.py:779] *****************************************
flash_kv_decode is set to True
Using device=cuda
Loading model ...
GPTEnsemble(
  (tok_embeddings): Embedding(49152, 1536)
  (layers): ModuleList(
    (0-39): 40 x EnsembleTransformerBlock(
      semi_compiled = False
      (attention): Attention(
        (wqkv): Linear(in_features=1536, out_features=2304, bias=False)
        (wo): Linear(in_features=768, out_features=1536, bias=False)
      )
      (feed_forward): FeedForward(
        (w1): Linear(in_features=1536, out_features=4096, bias=False)
        (w2): Linear(in_features=2048, out_features=1536, bias=False)
      )
      (ffn_norm): RMSNorm()
      (attention_norm): RMSNorm()
    )
  )
  (norm): RMSNorm()
  (output): Linear(in_features=1536, out_features=49152, bias=False)
)
Time to load model: 1.82 seconds
Prefill latency: 0.428531899000518 sec
Compilation time: 5.56 seconds
Decode latency: 5.111352913081646 sec
Compilation time: 5.54 seconds
Prefill latency: 0.4282024500425905 sec
Decode latency: 5.1117846419801936 sec
Prefill latency: 0.4282523059519008 sec
Decode latency: 5.110920249950141 sec
Prefill latency: 0.4282031380571425 sec
Decode latency: 5.110432007000782 sec
Prefill latency: 0.4286541120382026 sec
Decode latency: 5.111923033953644 sec
Prefill latency: 0.42838045093230903 sec
Decode latency: 5.111713916994631 sec
Time for inference 1: 5.54 sec total, 2956.94 tokens/sec
Decode latency: 5.11 sec
Prefill latency: 0.43 sec
Bandwidth achieved: 3795.84 GB/s
FLOPS achieved: 18.98 TF/s

Prefill latency: 0.4283552310662344 sec
Decode latency: 5.110564599977806 sec
Time for inference 2: 5.54 sec total, 2957.57 tokens/sec
Decode latency: 5.11 sec
Prefill latency: 0.43 sec
Bandwidth achieved: 3796.65 GB/s
FLOPS achieved: 18.98 TF/s

Prefill latency: 0.42836155102122575 sec
Decode latency: 5.110981383011676 sec
Time for inference 3: 5.54 sec total, 2957.36 tokens/sec
Decode latency: 5.11 sec
Prefill latency: 0.43 sec
Bandwidth achieved: 3796.38 GB/s
FLOPS achieved: 18.98 TF/s

Prefill latency: 0.4284180619288236 sec
Decode latency: 5.111517344950698 sec
Time for inference 4: 5.54 sec total, 2956.93 tokens/sec
Decode latency: 5.11 sec
Prefill latency: 0.43 sec
Bandwidth achieved: 3795.83 GB/s
FLOPS achieved: 18.98 TF/s

Prefill latency: 0.4283425098983571 sec
Decode latency: 5.110237922053784 sec
Time for inference 5: 5.54 sec total, 2957.68 tokens/sec
Decode latency: 5.11 sec
Prefill latency: 0.43 sec
Bandwidth achieved: 3796.78 GB/s
FLOPS achieved: 18.98 TF/s

Prefill latency: 0.42843686300329864 sec
Decode latency: 5.110711568966508 sec
Time for inference 6: 5.54 sec total, 2957.47 tokens/sec
Decode latency: 5.11 sec
Prefill latency: 0.43 sec
Bandwidth achieved: 3796.53 GB/s
FLOPS achieved: 18.98 TF/s

Prefill latency: 0.4283280689269304 sec
Decode latency: 5.110981057048775 sec
Time for inference 7: 5.54 sec total, 2957.43 tokens/sec
Decode latency: 5.11 sec
Prefill latency: 0.43 sec
Bandwidth achieved: 3796.47 GB/s
FLOPS achieved: 18.98 TF/s

Prefill latency: 0.42840842402074486 sec
Decode latency: 5.111177859944291 sec
Time for inference 8: 5.54 sec total, 2957.27 tokens/sec
Decode latency: 5.11 sec
Prefill latency: 0.43 sec
Bandwidth achieved: 3796.27 GB/s
FLOPS achieved: 18.98 TF/s

Prefill latency: 0.4283404489979148 sec
Decode latency: 5.1112296499777585 sec
Time for inference 9: 5.54 sec total, 2957.18 tokens/sec
Decode latency: 5.11 sec
Prefill latency: 0.43 sec
Bandwidth achieved: 3796.15 GB/s
FLOPS achieved: 18.98 TF/s

Prefill latency: 0.4283063010079786 sec
Decode latency: 5.110876056947745 sec
Time for inference 10: 5.54 sec total, 2957.38 tokens/sec
Decode latency: 5.11 sec
Prefill latency: 0.43 sec
Bandwidth achieved: 3796.41 GB/s
FLOPS achieved: 18.98 TF/s

==========
Batch Size: 64
Prompt Length: 1024
Generated tokens: 256
Average decode latency: 5.1110 sec
Average prefill latency: 0.4284 sec
Average tokens/sec: 2957.32
Memory used: 20.89 GB
Done. we are killing the process
