W0930 19:43:50.358000 22992193763136 torch/distributed/run.py:779] 
W0930 19:43:50.358000 22992193763136 torch/distributed/run.py:779] *****************************************
W0930 19:43:50.358000 22992193763136 torch/distributed/run.py:779] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W0930 19:43:50.358000 22992193763136 torch/distributed/run.py:779] *****************************************
flash_kv_decode is set to True
Using device=cuda
Loading model ...
GPTEnsemble(
  (tok_embeddings): Embedding(49152, 1536)
  (layers): ModuleList(
    (0-39): 40 x EnsembleTransformerBlock(
      semi_compiled = False
      (attention): Attention(
        (wqkv): Linear(in_features=1536, out_features=1280, bias=False)
        (wo): Linear(in_features=768, out_features=1536, bias=False)
      )
      (feed_forward): FeedForward(
        (w1): Linear(in_features=1536, out_features=4096, bias=False)
        (w2): Linear(in_features=2048, out_features=1536, bias=False)
      )
      (ffn_norm): RMSNorm()
      (attention_norm): RMSNorm()
    )
  )
  (norm): RMSNorm()
  (output): Linear(in_features=1536, out_features=49152, bias=False)
)
Time to load model: 0.92 seconds
Prefill latency: 0.11249858397059143 sec
Decode latency: 3.0357619349379092 sec
Compilation time: 3.14 seconds
Compilation time: 3.15 seconds
Prefill latency: 0.10680486902128905 sec
Decode latency: 3.0368767849868163 sec
Prefill latency: 0.10694806801620871 sec
Decode latency: 3.0355994200799614 sec
Prefill latency: 0.10686585598159581 sec
Decode latency: 3.0356928210239857 sec
Prefill latency: 0.10691913997288793 sec
Decode latency: 3.0339482970302925 sec
Prefill latency: 0.10700532200280577 sec
Decode latency: 3.03445923991967 sec
Time for inference 1: 3.14 sec total, 1303.54 tokens/sec
Decode latency: 3.03 sec
Prefill latency: 0.11 sec
Bandwidth achieved: 1509.34 GB/s
FLOPS achieved: 7.55 TF/s

Prefill latency: 0.10687372495885938 sec
Decode latency: 3.0337134329602122 sec
Time for inference 2: 3.14 sec total, 1303.82 tokens/sec
Decode latency: 3.03 sec
Prefill latency: 0.11 sec
Bandwidth achieved: 1509.66 GB/s
FLOPS achieved: 7.55 TF/s

Prefill latency: 0.10679836105555296 sec
Decode latency: 3.033576784073375 sec
Time for inference 3: 3.14 sec total, 1303.93 tokens/sec
Decode latency: 3.03 sec
Prefill latency: 0.11 sec
Bandwidth achieved: 1509.79 GB/s
FLOPS achieved: 7.55 TF/s

Prefill latency: 0.10684171505272388 sec
Decode latency: 3.033174626994878 sec
Time for inference 4: 3.14 sec total, 1304.15 tokens/sec
Decode latency: 3.03 sec
Prefill latency: 0.11 sec
Bandwidth achieved: 1510.04 GB/s
FLOPS achieved: 7.55 TF/s

Prefill latency: 0.10676130803767592 sec
Decode latency: 3.033544622012414 sec
Time for inference 5: 3.14 sec total, 1304.03 tokens/sec
Decode latency: 3.03 sec
Prefill latency: 0.11 sec
Bandwidth achieved: 1509.91 GB/s
FLOPS achieved: 7.55 TF/s

Prefill latency: 0.10671660501975566 sec
Decode latency: 3.0341928279958665 sec
Time for inference 6: 3.14 sec total, 1303.78 tokens/sec
Decode latency: 3.03 sec
Prefill latency: 0.11 sec
Bandwidth achieved: 1509.62 GB/s
FLOPS achieved: 7.55 TF/s

Prefill latency: 0.10693193296901882 sec
Decode latency: 3.031107146991417 sec
Time for inference 7: 3.14 sec total, 1304.96 tokens/sec
Decode latency: 3.03 sec
Prefill latency: 0.11 sec
Bandwidth achieved: 1510.99 GB/s
FLOPS achieved: 7.55 TF/s

Prefill latency: 0.10652455908712 sec
Decode latency: 3.029822070035152 sec
Time for inference 8: 3.14 sec total, 1305.68 tokens/sec
Decode latency: 3.03 sec
Prefill latency: 0.11 sec
Bandwidth achieved: 1511.82 GB/s
FLOPS achieved: 7.56 TF/s

Prefill latency: 0.10658122098539025 sec
Decode latency: 3.0304029639810324 sec
Time for inference 9: 3.14 sec total, 1305.42 tokens/sec
Decode latency: 3.03 sec
Prefill latency: 0.11 sec
Bandwidth achieved: 1511.52 GB/s
FLOPS achieved: 7.56 TF/s

Prefill latency: 0.10657927196007222 sec
Decode latency: 3.030132446088828 sec
Time for inference 10: 3.14 sec total, 1305.52 tokens/sec
Decode latency: 3.03 sec
Prefill latency: 0.11 sec
Bandwidth achieved: 1511.63 GB/s
FLOPS achieved: 7.56 TF/s

==========
Batch Size: 16
Prompt Length: 1024
Generated tokens: 256
Average decode latency: 3.0324 sec
Average prefill latency: 0.1068 sec
Average tokens/sec: 1304.48
Memory used: 7.20 GB
Done. we are killing the process
