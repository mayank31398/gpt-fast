W0930 19:34:09.622000 22993477871424 torch/distributed/run.py:779] 
W0930 19:34:09.622000 22993477871424 torch/distributed/run.py:779] *****************************************
W0930 19:34:09.622000 22993477871424 torch/distributed/run.py:779] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W0930 19:34:09.622000 22993477871424 torch/distributed/run.py:779] *****************************************
flash_kv_decode is set to True
Using device=cuda
Loading model ...
GPTEnsemble(
  (tok_embeddings): Embedding(49152, 1536)
  (layers): ModuleList(
    (0-39): 40 x EnsembleTransformerBlock(
      semi_compiled = False
      (attention): Attention(
        (wqkv): Linear(in_features=1536, out_features=1280, bias=False)
        (wo): Linear(in_features=768, out_features=1536, bias=False)
      )
      (feed_forward): FeedForward(
        (w1): Linear(in_features=1536, out_features=4096, bias=False)
        (w2): Linear(in_features=2048, out_features=1536, bias=False)
      )
      (ffn_norm): RMSNorm()
      (attention_norm): RMSNorm()
    )
  )
  (norm): RMSNorm()
  (output): Linear(in_features=1536, out_features=49152, bias=False)
)
Time to load model: 1.04 seconds
Prefill latency: 0.014154232922010124 sec
Decode latency: 1.8837643139995635 sec
Compilation time: 1.90 seconds
Compilation time: 1.90 seconds
Prefill latency: 0.013608481967821717 sec
Decode latency: 1.8825029979925603 sec
Prefill latency: 0.013378349016420543 sec
Decode latency: 1.8829453469952568 sec
Prefill latency: 0.013607185916043818 sec
Decode latency: 1.883663214975968 sec
Prefill latency: 0.013506741030141711 sec
Decode latency: 1.8827136490726843 sec
Prefill latency: 0.01340374001301825 sec
Decode latency: 1.8820289249997586 sec
Time for inference 1: 1.90 sec total, 135.02 tokens/sec
Decode latency: 1.88 sec
Prefill latency: 0.01 sec
Bandwidth achieved: 156.33 GB/s
FLOPS achieved: 0.78 TF/s

Prefill latency: 0.013408528990112245 sec
Decode latency: 1.8823161369655281 sec
Time for inference 2: 1.90 sec total, 134.99 tokens/sec
Decode latency: 1.88 sec
Prefill latency: 0.01 sec
Bandwidth achieved: 156.30 GB/s
FLOPS achieved: 0.78 TF/s

Prefill latency: 0.013390672043897212 sec
Decode latency: 1.8832460190169513 sec
Time for inference 3: 1.90 sec total, 134.93 tokens/sec
Decode latency: 1.88 sec
Prefill latency: 0.01 sec
Bandwidth achieved: 156.24 GB/s
FLOPS achieved: 0.78 TF/s

Prefill latency: 0.013394289999268949 sec
Decode latency: 1.8834319160087034 sec
Time for inference 4: 1.90 sec total, 134.91 tokens/sec
Decode latency: 1.88 sec
Prefill latency: 0.01 sec
Bandwidth achieved: 156.21 GB/s
FLOPS achieved: 0.78 TF/s

Prefill latency: 0.013452172977849841 sec
Decode latency: 1.8819494639756158 sec
Time for inference 5: 1.90 sec total, 135.02 tokens/sec
Decode latency: 1.88 sec
Prefill latency: 0.01 sec
Bandwidth achieved: 156.33 GB/s
FLOPS achieved: 0.78 TF/s

Prefill latency: 0.01335429004393518 sec
Decode latency: 1.8826730709988624 sec
Time for inference 6: 1.90 sec total, 134.97 tokens/sec
Decode latency: 1.88 sec
Prefill latency: 0.01 sec
Bandwidth achieved: 156.28 GB/s
FLOPS achieved: 0.78 TF/s

Prefill latency: 0.013330580084584653 sec
Decode latency: 1.8835869330214337 sec
Time for inference 7: 1.90 sec total, 134.91 tokens/sec
Decode latency: 1.88 sec
Prefill latency: 0.01 sec
Bandwidth achieved: 156.21 GB/s
FLOPS achieved: 0.78 TF/s

Prefill latency: 0.013380673015490174 sec
Decode latency: 1.885552000021562 sec
Time for inference 8: 1.90 sec total, 134.75 tokens/sec
Decode latency: 1.89 sec
Prefill latency: 0.01 sec
Bandwidth achieved: 156.03 GB/s
FLOPS achieved: 0.78 TF/s

Prefill latency: 0.013424862991087139 sec
Decode latency: 1.8832761499797925 sec
Time for inference 9: 1.90 sec total, 134.92 tokens/sec
Decode latency: 1.88 sec
Prefill latency: 0.01 sec
Bandwidth achieved: 156.22 GB/s
FLOPS achieved: 0.78 TF/s

Prefill latency: 0.01334192301146686 sec
Decode latency: 1.8838321689981967 sec
Time for inference 10: 1.90 sec total, 134.89 tokens/sec
Decode latency: 1.88 sec
Prefill latency: 0.01 sec
Bandwidth achieved: 156.19 GB/s
FLOPS achieved: 0.78 TF/s

==========
Batch Size: 1
Prompt Length: 1024
Generated tokens: 256
Average decode latency: 1.8832 sec
Average prefill latency: 0.0134 sec
Average tokens/sec: 134.93
Memory used: 1.85 GB
Done. we are killing the process
