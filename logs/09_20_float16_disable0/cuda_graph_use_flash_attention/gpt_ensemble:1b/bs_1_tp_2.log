W1001 02:24:57.427000 22783651116864 torch/distributed/run.py:779] 
W1001 02:24:57.427000 22783651116864 torch/distributed/run.py:779] *****************************************
W1001 02:24:57.427000 22783651116864 torch/distributed/run.py:779] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W1001 02:24:57.427000 22783651116864 torch/distributed/run.py:779] *****************************************
flash_kv_decode is set to True
Using device=cuda
Loading model ...
GPTEnsemble(
  (tok_embeddings): Embedding(49152, 1536)
  (layers): ModuleList(
    (0-39): 40 x EnsembleTransformerBlock(
      semi_compiled = False
      (attention): Attention(
        (wqkv): Linear(in_features=1536, out_features=2304, bias=False)
        (wo): Linear(in_features=768, out_features=1536, bias=False)
      )
      (feed_forward): FeedForward(
        (w1): Linear(in_features=1536, out_features=4096, bias=False)
        (w2): Linear(in_features=2048, out_features=1536, bias=False)
      )
      (ffn_norm): RMSNorm()
      (attention_norm): RMSNorm()
    )
  )
  (norm): RMSNorm()
  (output): Linear(in_features=1536, out_features=49152, bias=False)
)
Time to load model: 0.98 seconds
Prefill latency: 0.01202276290860027 sec
Compilation time: 1.85 seconds
Decode latency: 1.8294116470497102 sec
Compilation time: 1.84 seconds
Prefill latency: 0.012019422953017056 sec
Decode latency: 1.7472661139909178 sec
Prefill latency: 0.01203055097721517 sec
Decode latency: 1.7344322660937905 sec
Prefill latency: 0.012030203943140805 sec
Decode latency: 1.6958297709934413 sec
Prefill latency: 0.012000757968053222 sec
Decode latency: 1.732833924004808 sec
Prefill latency: 0.01202172797638923 sec
Decode latency: 1.8295595380477607 sec
Time for inference 1: 1.84 sec total, 138.97 tokens/sec
Decode latency: 1.83 sec
Prefill latency: 0.01 sec
Bandwidth achieved: 178.39 GB/s
FLOPS achieved: 0.89 TF/s

Prefill latency: 0.011998477973975241 sec
Decode latency: 1.7275007109856233 sec
Time for inference 2: 1.74 sec total, 147.12 tokens/sec
Decode latency: 1.73 sec
Prefill latency: 0.01 sec
Bandwidth achieved: 188.86 GB/s
FLOPS achieved: 0.94 TF/s

Prefill latency: 0.012025415082462132 sec
Decode latency: 1.6923018689267337 sec
Time for inference 3: 1.70 sec total, 150.15 tokens/sec
Decode latency: 1.69 sec
Prefill latency: 0.01 sec
Bandwidth achieved: 192.75 GB/s
FLOPS achieved: 0.96 TF/s

Prefill latency: 0.012003502924926579 sec
Decode latency: 1.8294507489772514 sec
Time for inference 4: 1.84 sec total, 138.97 tokens/sec
Decode latency: 1.83 sec
Prefill latency: 0.01 sec
Bandwidth achieved: 178.40 GB/s
FLOPS achieved: 0.89 TF/s

Prefill latency: 0.012025270028971136 sec
Decode latency: 1.710265601053834 sec
Time for inference 5: 1.72 sec total, 148.58 tokens/sec
Decode latency: 1.71 sec
Prefill latency: 0.01 sec
Bandwidth achieved: 190.74 GB/s
FLOPS achieved: 0.95 TF/s

Prefill latency: 0.011998800910077989 sec
Decode latency: 1.8295987229794264 sec
Time for inference 6: 1.84 sec total, 138.96 tokens/sec
Decode latency: 1.83 sec
Prefill latency: 0.01 sec
Bandwidth achieved: 178.39 GB/s
FLOPS achieved: 0.89 TF/s

Prefill latency: 0.011999021051451564 sec
Decode latency: 1.7298785920720547 sec
Time for inference 7: 1.74 sec total, 146.92 tokens/sec
Decode latency: 1.73 sec
Prefill latency: 0.01 sec
Bandwidth achieved: 188.60 GB/s
FLOPS achieved: 0.94 TF/s

Prefill latency: 0.01200413005426526 sec
Decode latency: 1.828921346925199 sec
Time for inference 8: 1.84 sec total, 139.02 tokens/sec
Decode latency: 1.83 sec
Prefill latency: 0.01 sec
Bandwidth achieved: 178.46 GB/s
FLOPS achieved: 0.89 TF/s

Prefill latency: 0.01200730400159955 sec
Decode latency: 1.7652697960147634 sec
Time for inference 9: 1.78 sec total, 143.99 tokens/sec
Decode latency: 1.77 sec
Prefill latency: 0.01 sec
Bandwidth achieved: 184.84 GB/s
FLOPS achieved: 0.92 TF/s

Prefill latency: 0.012008866993710399 sec
Decode latency: 1.7198644679738209 sec
Time for inference 10: 1.73 sec total, 147.77 tokens/sec
Decode latency: 1.72 sec
Prefill latency: 0.01 sec
Bandwidth achieved: 189.69 GB/s
FLOPS achieved: 0.95 TF/s

==========
Batch Size: 1
Prompt Length: 1024
Generated tokens: 256
Average decode latency: 1.7663 sec
Average prefill latency: 0.0120 sec
Average tokens/sec: 144.05
Memory used: 1.92 GB
Done. we are killing the process
