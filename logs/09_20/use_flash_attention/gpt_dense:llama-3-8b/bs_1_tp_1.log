flash_kv_decode is set to True
Using device=cuda
Loading model ...
GPTDense(
  (tok_embeddings): Embedding(128256, 4096)
  (layers): ModuleList(
    (0-31): 32 x DenseTransformerBlock(
      semi_compiled = False
      (attention): Attention(
        (wqkv): Linear(in_features=4096, out_features=6144, bias=False)
        (wo): Linear(in_features=4096, out_features=4096, bias=False)
      )
      (feed_forward): FeedForward(
        (w1): Linear(in_features=4096, out_features=28672, bias=False)
        (w2): Linear(in_features=14336, out_features=4096, bias=False)
      )
      (ffn_norm): RMSNorm()
      (attention_norm): RMSNorm()
    )
  )
  (norm): RMSNorm()
  (output): Linear(in_features=4096, out_features=128256, bias=False)
)
Time to load model: 1.16 seconds
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
Prefill latency: 2.1241121124476194 sec
Decode latency: 7.42527886480093 sec
Compilation time: 9.55 seconds
Prefill latency: 0.0438003521412611 sec
Decode latency: 7.334213929250836 sec
Prefill latency: 0.0439849179238081 sec
Decode latency: 7.30094931088388 sec
Prefill latency: 0.04404946230351925 sec
Decode latency: 7.453994896262884 sec
Prefill latency: 0.04408452473580837 sec
Decode latency: 7.287975775077939 sec
Prefill latency: 0.04391459934413433 sec
Decode latency: 7.304522346705198 sec
Time for inference 1: 7.35 sec total, 34.83 tokens/sec
Decode latency: 7.30 sec
Prefill latency: 0.04 sec
Bandwidth achieved: 522.83 GB/s
FLOPS achieved: 2.61 TF/s

Prefill latency: 0.04456108435988426 sec
Decode latency: 7.284000061452389 sec
Time for inference 2: 7.33 sec total, 34.93 tokens/sec
Decode latency: 7.28 sec
Prefill latency: 0.04 sec
Bandwidth achieved: 524.25 GB/s
FLOPS achieved: 2.62 TF/s

Prefill latency: 0.04381503164768219 sec
Decode latency: 7.406980682164431 sec
Time for inference 3: 7.45 sec total, 34.35 tokens/sec
Decode latency: 7.41 sec
Prefill latency: 0.04 sec
Bandwidth achieved: 515.64 GB/s
FLOPS achieved: 2.58 TF/s

Prefill latency: 0.043822458013892174 sec
Decode latency: 7.262451432645321 sec
Time for inference 4: 7.31 sec total, 35.03 tokens/sec
Decode latency: 7.26 sec
Prefill latency: 0.04 sec
Bandwidth achieved: 525.85 GB/s
FLOPS achieved: 2.63 TF/s

Prefill latency: 0.04409727640450001 sec
Decode latency: 7.268706776201725 sec
Time for inference 5: 7.31 sec total, 35.00 tokens/sec
Decode latency: 7.27 sec
Prefill latency: 0.04 sec
Bandwidth achieved: 525.38 GB/s
FLOPS achieved: 2.63 TF/s

Prefill latency: 0.04361329227685928 sec
Decode latency: 7.269971011206508 sec
Time for inference 6: 7.31 sec total, 35.00 tokens/sec
Decode latency: 7.27 sec
Prefill latency: 0.04 sec
Bandwidth achieved: 525.32 GB/s
FLOPS achieved: 2.63 TF/s

Prefill latency: 0.04415508918464184 sec
Decode latency: 7.382925178855658 sec
Time for inference 7: 7.43 sec total, 34.46 tokens/sec
Decode latency: 7.38 sec
Prefill latency: 0.04 sec
Bandwidth achieved: 517.30 GB/s
FLOPS achieved: 2.59 TF/s

Prefill latency: 0.043630365282297134 sec
Decode latency: 7.335529159754515 sec
Time for inference 8: 7.38 sec total, 34.69 tokens/sec
Decode latency: 7.34 sec
Prefill latency: 0.04 sec
Bandwidth achieved: 520.65 GB/s
FLOPS achieved: 2.60 TF/s

Prefill latency: 0.0444177370518446 sec
Decode latency: 7.338151838630438 sec
Time for inference 9: 7.38 sec total, 34.67 tokens/sec
Decode latency: 7.34 sec
Prefill latency: 0.04 sec
Bandwidth achieved: 520.42 GB/s
FLOPS achieved: 2.60 TF/s

Prefill latency: 0.04451684094965458 sec
Decode latency: 7.375725708901882 sec
Time for inference 10: 7.42 sec total, 34.50 tokens/sec
Decode latency: 7.38 sec
Prefill latency: 0.04 sec
Bandwidth achieved: 517.78 GB/s
FLOPS achieved: 2.59 TF/s

==========
Batch Size: 1
Prompt Length: 1024
Generated tokens: 256
Average decode latency: 7.3229 sec
Average prefill latency: 0.0441 sec
Average tokens/sec: 34.75
Memory used: 16.83 GB
