W0920 01:57:07.774000 22933254068032 torch/distributed/run.py:779] 
W0920 01:57:07.774000 22933254068032 torch/distributed/run.py:779] *****************************************
W0920 01:57:07.774000 22933254068032 torch/distributed/run.py:779] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W0920 01:57:07.774000 22933254068032 torch/distributed/run.py:779] *****************************************
flash_kv_decode is set to True
Using device=cuda
Loading model ...
GPTDense(
  (tok_embeddings): Embedding(128256, 8192)
  (layers): ModuleList(
    (0-79): 80 x DenseTransformerBlock(
      semi_compiled = False
      (attention): Attention(
        (wqkv): Linear(in_features=8192, out_features=5120, bias=False)
        (wo): Linear(in_features=4096, out_features=8192, bias=False)
      )
      (feed_forward): FeedForward(
        (w1): Linear(in_features=8192, out_features=28672, bias=False)
        (w2): Linear(in_features=14336, out_features=8192, bias=False)
      )
      (ffn_norm): RMSNorm()
      (attention_norm): RMSNorm()
    )
  )
  (norm): RMSNorm()
  (output): Linear(in_features=8192, out_features=128256, bias=False)
)
Time to load model: 0.83 seconds
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
Prefill latency: 3.1184107661247253 sec
Decode latency: 12.619391253218055 sec
Compilation time: 15.63 seconds
Compilation time: 15.74 seconds
Prefill latency: 0.15517997927963734 sec
Decode latency: 12.32822611182928 sec
Prefill latency: 0.15541258081793785 sec
Decode latency: 12.339965036138892 sec
Prefill latency: 0.1552715189754963 sec
Decode latency: 12.310015294700861 sec
Prefill latency: 0.1552329994738102 sec
Decode latency: 12.312081523239613 sec
Prefill latency: 0.1552145816385746 sec
Decode latency: 12.308897905051708 sec
Time for inference 1: 12.46 sec total, 20.54 tokens/sec
Decode latency: 12.31 sec
Prefill latency: 0.16 sec
Bandwidth achieved: 1449.03 GB/s
FLOPS achieved: 7.25 TF/s

Prefill latency: 0.15504790097475052 sec
Decode latency: 12.306367363780737 sec
Time for inference 2: 12.46 sec total, 20.54 tokens/sec
Decode latency: 12.31 sec
Prefill latency: 0.16 sec
Bandwidth achieved: 1449.35 GB/s
FLOPS achieved: 7.25 TF/s

Prefill latency: 0.1555085852742195 sec
Decode latency: 12.325659727677703 sec
Time for inference 3: 12.48 sec total, 20.51 tokens/sec
Decode latency: 12.33 sec
Prefill latency: 0.16 sec
Bandwidth achieved: 1447.06 GB/s
FLOPS achieved: 7.24 TF/s

Prefill latency: 0.15503410436213017 sec
Decode latency: 12.321195462718606 sec
Time for inference 4: 12.48 sec total, 20.52 tokens/sec
Decode latency: 12.32 sec
Prefill latency: 0.16 sec
Bandwidth achieved: 1447.62 GB/s
FLOPS achieved: 7.24 TF/s

Prefill latency: 0.15519803948700428 sec
Decode latency: 12.310941012576222 sec
Time for inference 5: 12.47 sec total, 20.53 tokens/sec
Decode latency: 12.31 sec
Prefill latency: 0.16 sec
Bandwidth achieved: 1448.80 GB/s
FLOPS achieved: 7.24 TF/s

Prefill latency: 0.15541987493634224 sec
Decode latency: 12.32475571334362 sec
Time for inference 6: 12.48 sec total, 20.51 tokens/sec
Decode latency: 12.32 sec
Prefill latency: 0.16 sec
Bandwidth achieved: 1447.17 GB/s
FLOPS achieved: 7.24 TF/s

Prefill latency: 0.15457299910485744 sec
Decode latency: 12.310822019353509 sec
Time for inference 7: 12.47 sec total, 20.54 tokens/sec
Decode latency: 12.31 sec
Prefill latency: 0.15 sec
Bandwidth achieved: 1448.89 GB/s
FLOPS achieved: 7.24 TF/s

Prefill latency: 0.1553444992750883 sec
Decode latency: 12.307455955073237 sec
Time for inference 8: 12.46 sec total, 20.54 tokens/sec
Decode latency: 12.31 sec
Prefill latency: 0.16 sec
Bandwidth achieved: 1449.18 GB/s
FLOPS achieved: 7.25 TF/s

Prefill latency: 0.1553015261888504 sec
Decode latency: 12.365644998848438 sec
Time for inference 9: 12.52 sec total, 20.44 tokens/sec
Decode latency: 12.37 sec
Prefill latency: 0.16 sec
Bandwidth achieved: 1442.46 GB/s
FLOPS achieved: 7.21 TF/s

Prefill latency: 0.15501181595027447 sec
Decode latency: 12.338604778051376 sec
Time for inference 10: 12.49 sec total, 20.49 tokens/sec
Decode latency: 12.34 sec
Prefill latency: 0.16 sec
Bandwidth achieved: 1445.62 GB/s
FLOPS achieved: 7.23 TF/s

==========
Batch Size: 1
Prompt Length: 1024
Generated tokens: 256
Average decode latency: 12.3220 sec
Average prefill latency: 0.1552 sec
Average tokens/sec: 20.52
Memory used: 73.48 GB
