W0920 01:32:06.335000 22565455263552 torch/distributed/run.py:779] 
W0920 01:32:06.335000 22565455263552 torch/distributed/run.py:779] *****************************************
W0920 01:32:06.335000 22565455263552 torch/distributed/run.py:779] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W0920 01:32:06.335000 22565455263552 torch/distributed/run.py:779] *****************************************
flash_kv_decode is set to True
Using device=cuda
Loading model ...
GPTLadder(
  (tok_embeddings): Embedding(128256, 8192)
  (layers): ModuleList(
    (0-79): 80 x LadderTransformerBlock(
      semi_compiled = False
      (attention): Attention(
        (wqkv): Linear(in_features=8192, out_features=5120, bias=False)
        (wo): Linear(in_features=4096, out_features=8192, bias=False)
      )
      (feed_forward): FeedForward(
        (w1): Linear(in_features=8192, out_features=28672, bias=False)
        (w2): Linear(in_features=14336, out_features=8192, bias=False)
      )
      (ffn_norm): RMSNorm()
      (attention_norm): RMSNorm()
    )
  )
  (norm): RMSNorm()
  (output): Linear(in_features=8192, out_features=128256, bias=False)
)
Time to load model: 0.18 seconds
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
Prefill latency: 3.4770449195057154 sec
Decode latency: 12.425756882876158 sec
Compilation time: 15.90 seconds
Compilation time: 15.90 seconds
Prefill latency: 1.1461834944784641 sec
Decode latency: 12.333817172795534 sec
Prefill latency: 1.1449938490986824 sec
Decode latency: 12.215670032426715 sec
Prefill latency: 1.1442435141652822 sec
Decode latency: 12.237978918477893 sec
Prefill latency: 1.1425133291631937 sec
Decode latency: 12.239645570516586 sec
Prefill latency: 1.146280912682414 sec
Decode latency: 12.24262098968029 sec
Time for inference 1: 13.39 sec total, 152.95 tokens/sec
Decode latency: 12.24 sec
Prefill latency: 1.15 sec
Bandwidth achieved: 10791.65 GB/s
FLOPS achieved: 53.96 TF/s

Prefill latency: 1.144912177696824 sec
Decode latency: 12.208581222221255 sec
Time for inference 2: 13.35 sec total, 153.36 tokens/sec
Decode latency: 12.21 sec
Prefill latency: 1.14 sec
Bandwidth achieved: 10820.21 GB/s
FLOPS achieved: 54.10 TF/s

Prefill latency: 1.1455424912273884 sec
Decode latency: 12.299245897680521 sec
Time for inference 3: 13.45 sec total, 152.32 tokens/sec
Decode latency: 12.30 sec
Prefill latency: 1.15 sec
Bandwidth achieved: 10746.73 GB/s
FLOPS achieved: 53.73 TF/s

Prefill latency: 1.1427879612892866 sec
Decode latency: 12.35977772437036 sec
Time for inference 4: 13.50 sec total, 151.67 tokens/sec
Decode latency: 12.36 sec
Prefill latency: 1.14 sec
Bandwidth achieved: 10700.83 GB/s
FLOPS achieved: 53.50 TF/s

Prefill latency: 1.1433331370353699 sec
Decode latency: 12.361336048692465 sec
Time for inference 5: 13.51 sec total, 151.64 tokens/sec
Decode latency: 12.36 sec
Prefill latency: 1.14 sec
Bandwidth achieved: 10699.14 GB/s
FLOPS achieved: 53.50 TF/s

Prefill latency: 1.1426060926169157 sec
Decode latency: 12.357255786657333 sec
Time for inference 6: 13.50 sec total, 151.70 tokens/sec
Decode latency: 12.36 sec
Prefill latency: 1.14 sec
Bandwidth achieved: 10702.93 GB/s
FLOPS achieved: 53.51 TF/s

Prefill latency: 1.1457873787730932 sec
Decode latency: 12.353799110278487 sec
Time for inference 7: 13.50 sec total, 151.70 tokens/sec
Decode latency: 12.35 sec
Prefill latency: 1.15 sec
Bandwidth achieved: 10703.19 GB/s
FLOPS achieved: 53.52 TF/s

Prefill latency: 1.1431584302335978 sec
Decode latency: 12.300811041146517 sec
Time for inference 8: 13.44 sec total, 152.33 tokens/sec
Decode latency: 12.30 sec
Prefill latency: 1.14 sec
Bandwidth achieved: 10747.42 GB/s
FLOPS achieved: 53.74 TF/s

Prefill latency: 1.1433989778161049 sec
Decode latency: 12.312897646799684 sec
Time for inference 9: 13.46 sec total, 152.19 tokens/sec
Decode latency: 12.31 sec
Prefill latency: 1.14 sec
Bandwidth achieved: 10737.60 GB/s
FLOPS achieved: 53.69 TF/s

Prefill latency: 1.1439326740801334 sec
Decode latency: 12.28229127638042 sec
Time for inference 10: 13.43 sec total, 152.53 tokens/sec
Decode latency: 12.28 sec
Prefill latency: 1.14 sec
Bandwidth achieved: 10761.63 GB/s
FLOPS achieved: 53.81 TF/s

==========
Batch Size: 8
Prompt Length: 1024
Generated tokens: 256
Average decode latency: 12.3079 sec
Average prefill latency: 1.1442 sec
Average tokens/sec: 152.24
Memory used: 78.72 GB
