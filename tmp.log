Using device=cuda
Loading model ...
we finish operating the TP!
we finish operating the TP!
we finish operating the TP!
we finish operating the TP!
we finish operating the TP!
we finish operating the TP!
we finish operating the TP!
Applying tensor parallel to model ...
we finish operating the TP!
GPTResidual(
  (tok_embeddings): Embedding(32000, 8192)
  (layers): ModuleList(
    (0-47): 48 x TurboTransformerBlock(
      (attention): Attention(
        (wqkv): Linear(in_features=8192, out_features=1280, bias=False)
        (wo): Linear(in_features=1024, out_features=8192, bias=False)
      )
      (feed_forward): FeedForward(
        (w1): Linear(in_features=8192, out_features=5504, bias=False)
        (w2): Linear(in_features=2752, out_features=8192, bias=False)
      )
      (ffn_norm): RMSNorm()
      (attention_norm): RMSNorm()
    )
  )
  (norm): RMSNorm()
  (output): Linear(in_features=8192, out_features=32000, bias=False)
)
model s all reduce stream is None
Time to load model: 0.46 seconds
Prefill latency: 116.17 sec
Time for inference -4: 225.24 sec total, 4.55 tokens/sec
Bandwidth achieved: 40.15 GB/s
FLOPS achieved: 0.08 TF/s

Prefill latency: 0.26 sec
Time for inference -3: 5.50 sec total, 186.17 tokens/sec
Bandwidth achieved: 1644.02 GB/s
FLOPS achieved: 3.29 TF/s

Prefill latency: 0.02 sec
Time for inference -2: 5.25 sec total, 195.08 tokens/sec
Bandwidth achieved: 1722.64 GB/s
FLOPS achieved: 3.45 TF/s

Prefill latency: 0.02 sec
Time for inference -1: 5.24 sec total, 195.56 tokens/sec
Bandwidth achieved: 1726.93 GB/s
FLOPS achieved: 3.45 TF/s

Prefill latency: 0.02 sec
Compilation time: 5.22 seconds
Prefill latency: 0.02 sec
Time for inference 1: 5.22 sec total, 196.32 tokens/sec
Bandwidth achieved: 1733.58 GB/s
FLOPS achieved: 3.47 TF/s

Prefill latency: 0.02 sec
Time for inference 2: 5.24 sec total, 195.47 tokens/sec
Bandwidth achieved: 1726.13 GB/s
FLOPS achieved: 3.45 TF/s

Prefill latency: 0.02 sec
Time for inference 3: 5.26 sec total, 194.80 tokens/sec
Bandwidth achieved: 1720.21 GB/s
FLOPS achieved: 3.44 TF/s

Prefill latency: 0.02 sec
Time for inference 4: 5.22 sec total, 195.98 tokens/sec
Bandwidth achieved: 1730.65 GB/s
FLOPS achieved: 3.46 TF/s

Prefill latency: 0.02 sec
Time for inference 5: 5.23 sec total, 195.85 tokens/sec
Bandwidth achieved: 1729.50 GB/s
FLOPS achieved: 3.46 TF/s

Prefill latency: 0.02 sec
Time for inference 6: 5.23 sec total, 195.98 tokens/sec
Bandwidth achieved: 1730.62 GB/s
FLOPS achieved: 3.46 TF/s

Prefill latency: 0.02 sec
Time for inference 7: 5.22 sec total, 196.05 tokens/sec
Bandwidth achieved: 1731.25 GB/s
FLOPS achieved: 3.46 TF/s

Prefill latency: 0.02 sec
Time for inference 8: 5.26 sec total, 194.69 tokens/sec
Bandwidth achieved: 1719.19 GB/s
FLOPS achieved: 3.44 TF/s

Prefill latency: 0.03 sec
Time for inference 9: 5.25 sec total, 195.05 tokens/sec
Bandwidth achieved: 1722.39 GB/s
FLOPS achieved: 3.44 TF/s

Prefill latency: 0.02 sec
Time for inference 10: 5.22 sec total, 196.10 tokens/sec
Bandwidth achieved: 1731.72 GB/s
FLOPS achieved: 3.46 TF/s

Prefill latency: 0.02 sec
Time for inference 11: 5.22 sec total, 196.10 tokens/sec
Bandwidth achieved: 1731.67 GB/s
FLOPS achieved: 3.46 TF/s

Prefill latency: 0.02 sec
Time for inference 12: 5.22 sec total, 196.13 tokens/sec
Bandwidth achieved: 1731.97 GB/s
FLOPS achieved: 3.46 TF/s

Prefill latency: 0.02 sec
Time for inference 13: 5.25 sec total, 195.18 tokens/sec
Bandwidth achieved: 1723.52 GB/s
FLOPS achieved: 3.45 TF/s

Prefill latency: 0.02 sec
Time for inference 14: 5.22 sec total, 196.00 tokens/sec
Bandwidth achieved: 1730.84 GB/s
FLOPS achieved: 3.46 TF/s

Prefill latency: 0.02 sec
Time for inference 15: 5.22 sec total, 196.04 tokens/sec
Bandwidth achieved: 1731.17 GB/s
FLOPS achieved: 3.46 TF/s

Prefill latency: 0.02 sec
Time for inference 16: 5.42 sec total, 188.81 tokens/sec
Bandwidth achieved: 1667.28 GB/s
FLOPS achieved: 3.33 TF/s

==========
Batch Size: 1
Prompt Length: 1024
Generated tokens: 1024
Average tokens/sec: 185.30
Memory used: 22.16 GB
