W0920 07:24:45.845000 22514074494784 torch/distributed/run.py:779] 
W0920 07:24:45.845000 22514074494784 torch/distributed/run.py:779] *****************************************
W0920 07:24:45.845000 22514074494784 torch/distributed/run.py:779] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W0920 07:24:45.845000 22514074494784 torch/distributed/run.py:779] *****************************************
[W920 07:24:49.657455916 Utils.hpp:164] Warning: Environment variable NCCL_BLOCKING_WAIT is deprecated; use TORCH_NCCL_BLOCKING_WAIT instead (function operator())
[W920 07:24:49.659509537 Utils.hpp:164] Warning: Environment variable NCCL_BLOCKING_WAIT is deprecated; use TORCH_NCCL_BLOCKING_WAIT instead (function operator())
[W920 07:24:49.663156419 Utils.hpp:164] Warning: Environment variable NCCL_BLOCKING_WAIT is deprecated; use TORCH_NCCL_BLOCKING_WAIT instead (function operator())
[W920 07:24:49.665604584 Utils.hpp:164] Warning: Environment variable NCCL_BLOCKING_WAIT is deprecated; use TORCH_NCCL_BLOCKING_WAIT instead (function operator())
flash_kv_decode is set to True
Using device=cuda
Loading model ...
GPTLadder(
  (tok_embeddings): Embedding(128256, 8192)
  (layers): ModuleList(
    (0-79): 80 x LadderTransformerBlock(
      semi_compiled = False
      (attention): Attention(
        (wqkv): Linear(in_features=8192, out_features=2560, bias=False)
        (wo): Linear(in_features=2048, out_features=8192, bias=False)
      )
      (feed_forward): FeedForward(
        (w1): Linear(in_features=8192, out_features=14336, bias=False)
        (w2): Linear(in_features=7168, out_features=8192, bias=False)
      )
      (ffn_norm): RMSNorm()
      (attention_norm): RMSNorm()
    )
  )
  (norm): RMSNorm()
  (output): Linear(in_features=8192, out_features=128256, bias=False)
)
Time to load model: 0.25 seconds
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/home/charlie/anaconda3/envs/gpt-fast/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
Prefill latency: 3.6376133029989433 sec
Decode latency: 2.118643241992686 sec
Compilation time: 5.76 seconds
Compilation time: 5.76 seconds
Compilation time: 5.76 seconds
Compilation time: 5.76 seconds
Prefill latency: 0.11000501000671647 sec
Decode latency: 2.077835578995291 sec
Prefill latency: 0.10992377100046724 sec
Decode latency: 2.034831661992939 sec
Prefill latency: 0.10959794098744169 sec
Decode latency: 2.0303111640096176 sec
Prefill latency: 0.10819433099823073 sec
Decode latency: 2.0303064259933308 sec
Prefill latency: 0.108762054995168 sec
Decode latency: 2.0461082860128954 sec
Time for inference 1: 2.16 sec total, 59.38 tokens/sec
Decode latency: 2.05 sec
Prefill latency: 0.11 sec
Bandwidth achieved: 2157.35 GB/s
FLOPS achieved: 19.42 TF/s

Prefill latency: 0.10873830199125223 sec
Decode latency: 2.037600121984724 sec
Time for inference 2: 2.15 sec total, 59.62 tokens/sec
Decode latency: 2.04 sec
Prefill latency: 0.11 sec
Bandwidth achieved: 2165.95 GB/s
FLOPS achieved: 19.49 TF/s

Prefill latency: 0.10868577999644913 sec
Decode latency: 2.024517451005522 sec
Time for inference 3: 2.13 sec total, 59.99 tokens/sec
Decode latency: 2.02 sec
Prefill latency: 0.11 sec
Bandwidth achieved: 2179.26 GB/s
FLOPS achieved: 19.61 TF/s

Prefill latency: 0.10838419399806298 sec
Decode latency: 2.0258486710081343 sec
Time for inference 4: 2.13 sec total, 59.96 tokens/sec
Decode latency: 2.03 sec
Prefill latency: 0.11 sec
Bandwidth achieved: 2178.24 GB/s
FLOPS achieved: 19.60 TF/s

Prefill latency: 0.10794929999974556 sec
Decode latency: 2.024151477002306 sec
Time for inference 5: 2.13 sec total, 60.02 tokens/sec
Decode latency: 2.02 sec
Prefill latency: 0.11 sec
Bandwidth achieved: 2180.39 GB/s
FLOPS achieved: 19.62 TF/s

Prefill latency: 0.10865953299799003 sec
Decode latency: 2.02288890699856 sec
Time for inference 6: 2.13 sec total, 60.03 tokens/sec
Decode latency: 2.02 sec
Prefill latency: 0.11 sec
Bandwidth achieved: 2180.97 GB/s
FLOPS achieved: 19.63 TF/s

Prefill latency: 0.10825154298800044 sec
Decode latency: 2.0235064439766575 sec
Time for inference 7: 2.13 sec total, 60.03 tokens/sec
Decode latency: 2.02 sec
Prefill latency: 0.11 sec
Bandwidth achieved: 2180.73 GB/s
FLOPS achieved: 19.63 TF/s

Prefill latency: 0.1081903769809287 sec
Decode latency: 2.0239359679981135 sec
Time for inference 8: 2.13 sec total, 60.02 tokens/sec
Decode latency: 2.02 sec
Prefill latency: 0.11 sec
Bandwidth achieved: 2180.36 GB/s
FLOPS achieved: 19.62 TF/s

Prefill latency: 0.10875101701822132 sec
Decode latency: 2.025601795001421 sec
Time for inference 9: 2.14 sec total, 59.95 tokens/sec
Decode latency: 2.03 sec
Prefill latency: 0.11 sec
Bandwidth achieved: 2178.04 GB/s
FLOPS achieved: 19.60 TF/s

Prefill latency: 0.18157931801397353 sec
Decode latency: 3.737182245007716 sec
Time for inference 10: 90.89 sec total, 1.41 tokens/sec
Decode latency: 3.74 sec
Prefill latency: 0.18 sec
Bandwidth achieved: 51.17 GB/s
FLOPS achieved: 0.46 TF/s

==========
Batch Size: 4
Prompt Length: 256
Generated tokens: 32
Average decode latency: 2.1991 sec
Average prefill latency: 0.1158 sec
Average tokens/sec: 54.04
Memory used: 39.07 GB
