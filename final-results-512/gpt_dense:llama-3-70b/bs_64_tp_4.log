W1114 18:21:44.565000 2714518 site-packages/torch/distributed/run.py:793] 
W1114 18:21:44.565000 2714518 site-packages/torch/distributed/run.py:793] *****************************************
W1114 18:21:44.565000 2714518 site-packages/torch/distributed/run.py:793] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W1114 18:21:44.565000 2714518 site-packages/torch/distributed/run.py:793] *****************************************
flash_kv_decode is set to False
Using device=cuda
Loading model ...
GPTDense(
  (tok_embeddings): Embedding(128256, 8192)
  (layers): ModuleList(
    (0-79): 80 x DenseTransformerBlock(
      semi_compiled = False
      (attention): Attention(
        (wqkv): Linear(in_features=8192, out_features=2560, bias=False)
        (wo): Linear(in_features=2048, out_features=8192, bias=False)
      )
      (feed_forward): FeedForward(
        (w1): Linear(in_features=8192, out_features=14336, bias=False)
        (w2): Linear(in_features=7168, out_features=8192, bias=False)
      )
      (ffn_norm): RMSNorm()
      (attention_norm): RMSNorm()
    )
  )
  (norm): RMSNorm()
  (output): Linear(in_features=8192, out_features=128256, bias=False)
)
Time to load model: 1.16 seconds
/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
Compiling prefill with dynamic=False
/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/site-packages/torch/_inductor/compile_fx.py:222: UserWarning: TensorFloat32 tensor cores for float32 matrix multiplication available but not enabled. Consider setting `torch.set_float32_matmul_precision('high')` for better performance.
  warnings.warn(
/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/site-packages/torch/_inductor/compile_fx.py:222: UserWarning: TensorFloat32 tensor cores for float32 matrix multiplication available but not enabled. Consider setting `torch.set_float32_matmul_precision('high')` for better performance.
  warnings.warn(
/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/site-packages/torch/_inductor/compile_fx.py:222: UserWarning: TensorFloat32 tensor cores for float32 matrix multiplication available but not enabled. Consider setting `torch.set_float32_matmul_precision('high')` for better performance.
  warnings.warn(
/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/site-packages/torch/_inductor/compile_fx.py:222: UserWarning: TensorFloat32 tensor cores for float32 matrix multiplication available but not enabled. Consider setting `torch.set_float32_matmul_precision('high')` for better performance.
  warnings.warn(
Prefill latency: 128.06146330898628 sec
/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
[rank2]: Traceback (most recent call last):
[rank2]:   File "/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/site-packages/torch/_inductor/cudagraph_trees.py", line 1204, in _record
[rank2]:     static_outputs = model(inputs)
[rank2]:   File "/tmp/torchinductor_mayank/lw/clwx5ixp6cxc3xz5pvzxraw7gmd3qidsqehfyfgcvw2crx2fcneh.py", line 5473, in call
[rank2]:     torch.ops._c10d_functional.all_reduce_.default(reinterpret_tensor(buf1580, (64, 1, 8192), (8192, 8192, 1), 0), 'sum', '0')
[rank2]:   File "/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/site-packages/torch/_ops.py", line 723, in __call__
[rank2]:     return self._op(*args, **kwargs)
[rank2]: torch.distributed.DistBackendError: NCCL error in: ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:2977, unhandled cuda error (run with NCCL_DEBUG=INFO for details), NCCL version 2.21.5
[rank2]: ncclUnhandledCudaError: Call to CUDA function failed.
[rank2]: Last error:
[rank2]: Failed to CUDA malloc 12288 bytes

[rank2]: During handling of the above exception, another exception occurred:

[rank2]: Traceback (most recent call last):
[rank2]:   File "/dccstor/mayankmish2/scratch/gpt-fast/benchmark.py", line 491, in <module>
[rank2]:     main(
[rank2]:   File "/dccstor/mayankmish2/scratch/gpt-fast/benchmark.py", line 418, in main
[rank2]:     y, decode_latency, prefill_latency = generate(
[rank2]:   File "/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
[rank2]:     return func(*args, **kwargs)
[rank2]:   File "/dccstor/mayankmish2/scratch/gpt-fast/benchmark.py", line 152, in generate
[rank2]:     generated_tokens, _ = decode_n_tokens(model, next_token.view(batch_size, -1), input_pos, max_new_tokens - 1, callback=callback, **sampling_kwargs)
[rank2]:   File "/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
[rank2]:     return func(*args, **kwargs)
[rank2]:   File "/dccstor/mayankmish2/scratch/gpt-fast/benchmark.py", line 104, in decode_n_tokens
[rank2]:     next_token, next_prob = decode_one_token(
[rank2]:   File "/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py", line 556, in _fn
[rank2]:     return fn(*args, **kwargs)
[rank2]:   File "/dccstor/mayankmish2/scratch/gpt-fast/benchmark.py", line 85, in decode_one_token
[rank2]:     def decode_one_token(model: torch.nn.Module, x: torch.Tensor, input_pos: torch.Tensor, **sampling_kwargs) -> Tuple[torch.Tensor, torch.Tensor]:
[rank2]:   File "/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py", line 721, in _fn
[rank2]:     return fn(*args, **kwargs)
[rank2]:   File "/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 1132, in forward
[rank2]:     return compiled_fn(full_args)
[rank2]:   File "/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 324, in runtime_wrapper
[rank2]:     all_outs = call_func_at_runtime_with_args(
[rank2]:   File "/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/utils.py", line 126, in call_func_at_runtime_with_args
[rank2]:     out = normalize_as_list(f(args))
[rank2]:   File "/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 673, in inner_fn
[rank2]:     outs = compiled_fn(args)
[rank2]:   File "/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 491, in wrapper
[rank2]:     return compiled_fn(runtime_args)
[rank2]:   File "/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 1686, in __call__
[rank2]:     return self.current_callable(inputs)
[rank2]:   File "/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 1104, in run
[rank2]:     return compiled_fn(new_inputs)
[rank2]:   File "/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/site-packages/torch/_inductor/cudagraph_trees.py", line 382, in deferred_cudagraphify
[rank2]:     return fn(inputs)
[rank2]:   File "/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/site-packages/torch/_inductor/utils.py", line 2065, in run
[rank2]:     return model(new_inputs)
[rank2]:   File "/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/site-packages/torch/_inductor/cudagraph_trees.py", line 1929, in run
[rank2]:     out = self._run(new_inputs, function_id)
[rank2]:   File "/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/site-packages/torch/_inductor/cudagraph_trees.py", line 2109, in _run
[rank2]:     out = self.record_function(new_inputs, function_id)
[rank2]:   File "/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/site-packages/torch/_inductor/cudagraph_trees.py", line 2145, in record_function
[rank2]:     node = CUDAGraphNode(
[rank2]:   File "/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/site-packages/torch/_inductor/cudagraph_trees.py", line 970, in __init__
[rank2]:     self.recording_outputs: Optional[OutputType] = self._record(
[rank2]:   File "/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/site-packages/torch/_inductor/cudagraph_trees.py", line 1196, in _record
[rank2]:     with preserve_rng_state(), torch.cuda.device(
[rank2]:   File "/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/site-packages/torch/cuda/graphs.py", line 186, in __exit__
[rank2]:     self.cuda_graph.capture_end()
[rank2]:   File "/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/site-packages/torch/cuda/graphs.py", line 84, in capture_end
[rank2]:     super().capture_end()
[rank2]: RuntimeError: CUDA error: out of memory
[rank2]: CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
[rank2]: For debugging consider passing CUDA_LAUNCH_BLOCKING=1
[rank2]: Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

[rank0]: Traceback (most recent call last):
[rank0]:   File "/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/site-packages/torch/_inductor/cudagraph_trees.py", line 1204, in _record
[rank0]:     static_outputs = model(inputs)
[rank0]:   File "/tmp/torchinductor_mayank/vj/cvjz2agp4bbcvq5du73pmwjzok5o24hprxbysf2yqcxs4xd7l2lv.py", line 6115, in call
[rank0]:     torch.ops._c10d_functional.all_reduce_.default(reinterpret_tensor(buf1910, (64, 1, 8192), (8192, 8192, 1), 0), 'sum', '0')
[rank0]:   File "/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/site-packages/torch/_ops.py", line 723, in __call__
[rank0]:     return self._op(*args, **kwargs)
[rank0]: torch.distributed.DistBackendError: NCCL error in: ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:2977, unhandled cuda error (run with NCCL_DEBUG=INFO for details), NCCL version 2.21.5
[rank0]: ncclUnhandledCudaError: Call to CUDA function failed.
[rank0]: Last error:
[rank0]: Failed to CUDA malloc 12288 bytes

[rank0]: During handling of the above exception, another exception occurred:

[rank0]: Traceback (most recent call last):
[rank0]:   File "/dccstor/mayankmish2/scratch/gpt-fast/benchmark.py", line 491, in <module>
[rank0]:     main(
[rank0]:   File "/dccstor/mayankmish2/scratch/gpt-fast/benchmark.py", line 418, in main
[rank0]:     y, decode_latency, prefill_latency = generate(
[rank0]:   File "/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
[rank0]:     return func(*args, **kwargs)
[rank0]:   File "/dccstor/mayankmish2/scratch/gpt-fast/benchmark.py", line 152, in generate
[rank0]:     generated_tokens, _ = decode_n_tokens(model, next_token.view(batch_size, -1), input_pos, max_new_tokens - 1, callback=callback, **sampling_kwargs)
[rank0]:   File "/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
[rank0]:     return func(*args, **kwargs)
[rank0]:   File "/dccstor/mayankmish2/scratch/gpt-fast/benchmark.py", line 104, in decode_n_tokens
[rank0]:     next_token, next_prob = decode_one_token(
[rank0]:   File "/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py", line 556, in _fn
[rank0]:     return fn(*args, **kwargs)
[rank0]:   File "/dccstor/mayankmish2/scratch/gpt-fast/benchmark.py", line 85, in decode_one_token
[rank0]:     def decode_one_token(model: torch.nn.Module, x: torch.Tensor, input_pos: torch.Tensor, **sampling_kwargs) -> Tuple[torch.Tensor, torch.Tensor]:
[rank0]:   File "/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py", line 721, in _fn
[rank0]:     return fn(*args, **kwargs)
[rank0]:   File "/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 1132, in forward
[rank0]:     return compiled_fn(full_args)
[rank0]:   File "/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 324, in runtime_wrapper
[rank0]:     all_outs = call_func_at_runtime_with_args(
[rank0]:   File "/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/utils.py", line 126, in call_func_at_runtime_with_args
[rank0]:     out = normalize_as_list(f(args))
[rank0]:   File "/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 673, in inner_fn
[rank0]:     outs = compiled_fn(args)
[rank0]:   File "/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 491, in wrapper
[rank0]:     return compiled_fn(runtime_args)
[rank0]:   File "/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 1686, in __call__
[rank0]:     return self.current_callable(inputs)
[rank0]:   File "/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 1104, in run
[rank0]:     return compiled_fn(new_inputs)
[rank0]:   File "/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/site-packages/torch/_inductor/cudagraph_trees.py", line 382, in deferred_cudagraphify
[rank0]:     return fn(inputs)
[rank0]:   File "/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/site-packages/torch/_inductor/utils.py", line 2065, in run
[rank0]:     return model(new_inputs)
[rank0]:   File "/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/site-packages/torch/_inductor/cudagraph_trees.py", line 1929, in run
[rank0]:     out = self._run(new_inputs, function_id)
[rank0]:   File "/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/site-packages/torch/_inductor/cudagraph_trees.py", line 2109, in _run
[rank0]:     out = self.record_function(new_inputs, function_id)
[rank0]:   File "/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/site-packages/torch/_inductor/cudagraph_trees.py", line 2145, in record_function
[rank0]:     node = CUDAGraphNode(
[rank0]:   File "/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/site-packages/torch/_inductor/cudagraph_trees.py", line 970, in __init__
[rank0]:     self.recording_outputs: Optional[OutputType] = self._record(
[rank0]:   File "/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/site-packages/torch/_inductor/cudagraph_trees.py", line 1196, in _record
[rank0]:     with preserve_rng_state(), torch.cuda.device(
[rank0]:   File "/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/site-packages/torch/cuda/graphs.py", line 186, in __exit__
[rank0]:     self.cuda_graph.capture_end()
[rank0]:   File "/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/site-packages/torch/cuda/graphs.py", line 84, in capture_end
[rank0]:     super().capture_end()
[rank0]: RuntimeError: CUDA error: out of memory
[rank0]: CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
[rank0]: For debugging consider passing CUDA_LAUNCH_BLOCKING=1
[rank0]: Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

[rank1]: Traceback (most recent call last):
[rank1]:   File "/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/site-packages/torch/_inductor/cudagraph_trees.py", line 1204, in _record
[rank1]:     static_outputs = model(inputs)
[rank1]:   File "/tmp/torchinductor_mayank/kt/ckt2oxv7cvw5f7llwk7635nfmepd5ryui3hue2ifkwrw7kruomim.py", line 5473, in call
[rank1]:     torch.ops._c10d_functional.all_reduce_.default(reinterpret_tensor(buf1580, (64, 1, 8192), (8192, 8192, 1), 0), 'sum', '0')
[rank1]:   File "/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/site-packages/torch/_ops.py", line 723, in __call__
[rank1]:     return self._op(*args, **kwargs)
[rank1]: torch.distributed.DistBackendError: NCCL error in: ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:2977, unhandled cuda error (run with NCCL_DEBUG=INFO for details), NCCL version 2.21.5
[rank1]: ncclUnhandledCudaError: Call to CUDA function failed.
[rank1]: Last error:
[rank1]: Failed to CUDA malloc 12288 bytes

[rank1]: During handling of the above exception, another exception occurred:

[rank1]: Traceback (most recent call last):
[rank1]:   File "/dccstor/mayankmish2/scratch/gpt-fast/benchmark.py", line 491, in <module>
[rank1]:     main(
[rank1]:   File "/dccstor/mayankmish2/scratch/gpt-fast/benchmark.py", line 418, in main
[rank1]:     y, decode_latency, prefill_latency = generate(
[rank1]:   File "/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
[rank1]:     return func(*args, **kwargs)
[rank1]:   File "/dccstor/mayankmish2/scratch/gpt-fast/benchmark.py", line 152, in generate
[rank1]:     generated_tokens, _ = decode_n_tokens(model, next_token.view(batch_size, -1), input_pos, max_new_tokens - 1, callback=callback, **sampling_kwargs)
[rank1]:   File "/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
[rank1]:     return func(*args, **kwargs)
[rank1]:   File "/dccstor/mayankmish2/scratch/gpt-fast/benchmark.py", line 104, in decode_n_tokens
[rank1]:     next_token, next_prob = decode_one_token(
[rank1]:   File "/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py", line 556, in _fn
[rank1]:     return fn(*args, **kwargs)
[rank1]:   File "/dccstor/mayankmish2/scratch/gpt-fast/benchmark.py", line 85, in decode_one_token
[rank1]:     def decode_one_token(model: torch.nn.Module, x: torch.Tensor, input_pos: torch.Tensor, **sampling_kwargs) -> Tuple[torch.Tensor, torch.Tensor]:
[rank1]:   File "/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py", line 721, in _fn
[rank1]:     return fn(*args, **kwargs)
[rank1]:   File "/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 1132, in forward
[rank1]:     return compiled_fn(full_args)
[rank1]:   File "/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 324, in runtime_wrapper
[rank1]:     all_outs = call_func_at_runtime_with_args(
[rank1]:   File "/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/utils.py", line 126, in call_func_at_runtime_with_args
[rank1]:     out = normalize_as_list(f(args))
[rank1]:   File "/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 673, in inner_fn
[rank1]:     outs = compiled_fn(args)
[rank1]:   File "/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 491, in wrapper
[rank1]:     return compiled_fn(runtime_args)
[rank1]:   File "/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 1686, in __call__
[rank1]:     return self.current_callable(inputs)
[rank1]:   File "/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 1104, in run
[rank1]:     return compiled_fn(new_inputs)
[rank1]:   File "/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/site-packages/torch/_inductor/cudagraph_trees.py", line 382, in deferred_cudagraphify
[rank1]:     return fn(inputs)
[rank1]:   File "/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/site-packages/torch/_inductor/utils.py", line 2065, in run
[rank1]:     return model(new_inputs)
[rank1]:   File "/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/site-packages/torch/_inductor/cudagraph_trees.py", line 1929, in run
[rank1]:     out = self._run(new_inputs, function_id)
[rank1]:   File "/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/site-packages/torch/_inductor/cudagraph_trees.py", line 2109, in _run
[rank1]:     out = self.record_function(new_inputs, function_id)
[rank1]:   File "/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/site-packages/torch/_inductor/cudagraph_trees.py", line 2145, in record_function
[rank1]:     node = CUDAGraphNode(
[rank1]:   File "/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/site-packages/torch/_inductor/cudagraph_trees.py", line 970, in __init__
[rank1]:     self.recording_outputs: Optional[OutputType] = self._record(
[rank1]:   File "/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/site-packages/torch/_inductor/cudagraph_trees.py", line 1196, in _record
[rank1]:     with preserve_rng_state(), torch.cuda.device(
[rank1]:   File "/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/site-packages/torch/cuda/graphs.py", line 186, in __exit__
[rank1]:     self.cuda_graph.capture_end()
[rank1]:   File "/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/site-packages/torch/cuda/graphs.py", line 84, in capture_end
[rank1]:     super().capture_end()
[rank1]: RuntimeError: CUDA error: out of memory
[rank1]: CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
[rank1]: For debugging consider passing CUDA_LAUNCH_BLOCKING=1
[rank1]: Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

[rank0]:[W1114 18:25:42.295084226 ProcessGroupNCCL.cpp:1374] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
W1114 18:25:48.970000 2714518 site-packages/torch/distributed/elastic/multiprocessing/api.py:897] Sending process 2714532 closing signal SIGTERM
W1114 18:25:48.970000 2714518 site-packages/torch/distributed/elastic/multiprocessing/api.py:897] Sending process 2714534 closing signal SIGTERM
W1114 18:25:48.970000 2714518 site-packages/torch/distributed/elastic/multiprocessing/api.py:897] Sending process 2714535 closing signal SIGTERM
E1114 18:25:54.476000 2714518 site-packages/torch/distributed/elastic/multiprocessing/api.py:869] failed (exitcode: 1) local_rank: 1 (pid: 2714533) of binary: /dccstor/mayankmish2/miniconda3/envs/ai/bin/python
Traceback (most recent call last):
  File "/dccstor/mayankmish2/miniconda3/envs/ai/bin/torchrun", line 8, in <module>
    sys.exit(main())
  File "/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 355, in wrapper
    return f(*args, **kwargs)
  File "/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/site-packages/torch/distributed/run.py", line 919, in main
    run(args)
  File "/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/site-packages/torch/distributed/run.py", line 910, in run
    elastic_launch(
  File "/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 138, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 269, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
benchmark.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2024-11-14_18:25:48
  host      : cccxc706.pok.ibm.com
  rank      : 1 (local_rank: 1)
  exitcode  : 1 (pid: 2714533)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
