W1114 16:13:22.486000 2491351 site-packages/torch/distributed/run.py:793] 
W1114 16:13:22.486000 2491351 site-packages/torch/distributed/run.py:793] *****************************************
W1114 16:13:22.486000 2491351 site-packages/torch/distributed/run.py:793] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W1114 16:13:22.486000 2491351 site-packages/torch/distributed/run.py:793] *****************************************
flash_kv_decode is set to False
Using device=cuda
Loading model ...
GPTLadder(
  (tok_embeddings): Embedding(128256, 8192)
  (layers): ModuleList(
    (0-79): 80 x LadderTransformerBlock(
      semi_compiled = False
      (attention): Attention(
        (wqkv): Linear(in_features=8192, out_features=2560, bias=False)
        (wo): Linear(in_features=2048, out_features=8192, bias=False)
      )
      (feed_forward): FeedForward(
        (w1): Linear(in_features=8192, out_features=14336, bias=False)
        (w2): Linear(in_features=7168, out_features=8192, bias=False)
      )
      (ffn_norm): RMSNorm()
      (attention_norm): RMSNorm()
    )
  )
  (norm): RMSNorm()
  (output): Linear(in_features=8192, out_features=128256, bias=False)
)
Time to load model: 0.26 seconds
/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
Compiling prefill with dynamic=False
/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/site-packages/torch/_inductor/compile_fx.py:222: UserWarning: TensorFloat32 tensor cores for float32 matrix multiplication available but not enabled. Consider setting `torch.set_float32_matmul_precision('high')` for better performance.
  warnings.warn(
/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/site-packages/torch/_inductor/compile_fx.py:222: UserWarning: TensorFloat32 tensor cores for float32 matrix multiplication available but not enabled. Consider setting `torch.set_float32_matmul_precision('high')` for better performance.
  warnings.warn(
/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/site-packages/torch/_inductor/compile_fx.py:222: UserWarning: TensorFloat32 tensor cores for float32 matrix multiplication available but not enabled. Consider setting `torch.set_float32_matmul_precision('high')` for better performance.
  warnings.warn(
/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/site-packages/torch/_inductor/compile_fx.py:222: UserWarning: TensorFloat32 tensor cores for float32 matrix multiplication available but not enabled. Consider setting `torch.set_float32_matmul_precision('high')` for better performance.
  warnings.warn(
Prefill latency: 90.06576211797073 sec
/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
Decode latency: 93.86536992015317 sec
Compilation time: 183.93 seconds
Compilation time: 183.94 seconds
Compilation time: 183.94 seconds
Compilation time: 183.94 seconds
Prefill latency: 2.407942669931799 sec
/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
Decode latency: 9.596924852812663 sec
Prefill latency: 0.4240129110403359 sec
Decode latency: 9.60161006404087 sec
Prefill latency: 0.4234251989983022 sec
Decode latency: 9.601335714804009 sec
Prefill latency: 0.42385384696535766 sec
Decode latency: 9.601888193981722 sec
Prefill latency: 0.4224422888364643 sec
Decode latency: 9.599956196034327 sec
Time for inference 1: 10.02 sec total, 204.29 tokens/sec
Decode latency: 9.60 sec
Prefill latency: 0.42 sec
Bandwidth achieved: 7421.84 GB/s
FLOPS achieved: 22.27 TF/s

Prefill latency: 0.4230220918543637 sec
Decode latency: 9.599051221972331 sec
Time for inference 2: 10.02 sec total, 204.30 tokens/sec
Decode latency: 9.60 sec
Prefill latency: 0.42 sec
Bandwidth achieved: 7422.01 GB/s
FLOPS achieved: 22.27 TF/s

Prefill latency: 0.42306509311310947 sec
Decode latency: 9.597593222977594 sec
Time for inference 3: 10.02 sec total, 204.33 tokens/sec
Decode latency: 9.60 sec
Prefill latency: 0.42 sec
Bandwidth achieved: 7423.08 GB/s
FLOPS achieved: 22.27 TF/s

Prefill latency: 0.42403734009712934 sec
Decode latency: 9.59629491600208 sec
Time for inference 4: 10.02 sec total, 204.33 tokens/sec
Decode latency: 9.60 sec
Prefill latency: 0.42 sec
Bandwidth achieved: 7423.34 GB/s
FLOPS achieved: 22.27 TF/s

Prefill latency: 0.42641417495906353 sec
Decode latency: 9.598852587165311 sec
Time for inference 5: 10.03 sec total, 204.23 tokens/sec
Decode latency: 9.60 sec
Prefill latency: 0.43 sec
Bandwidth achieved: 7419.43 GB/s
FLOPS achieved: 22.26 TF/s

Prefill latency: 0.4261940410360694 sec
Decode latency: 9.599564904114231 sec
Time for inference 6: 10.03 sec total, 204.22 tokens/sec
Decode latency: 9.60 sec
Prefill latency: 0.43 sec
Bandwidth achieved: 7419.29 GB/s
FLOPS achieved: 22.26 TF/s

Prefill latency: 0.4242410850711167 sec
Decode latency: 9.59920918312855 sec
Time for inference 7: 10.03 sec total, 204.27 tokens/sec
Decode latency: 9.60 sec
Prefill latency: 0.42 sec
Bandwidth achieved: 7421.03 GB/s
FLOPS achieved: 22.26 TF/s

Prefill latency: 0.42711183708161116 sec
Decode latency: 9.5989514591638 sec
Time for inference 8: 10.03 sec total, 204.22 tokens/sec
Decode latency: 9.60 sec
Prefill latency: 0.43 sec
Bandwidth achieved: 7419.08 GB/s
FLOPS achieved: 22.26 TF/s

Prefill latency: 0.42166526592336595 sec
Decode latency: 9.592755106044933 sec
Time for inference 9: 10.02 sec total, 204.45 tokens/sec
Decode latency: 9.59 sec
Prefill latency: 0.42 sec
Bandwidth achieved: 7427.73 GB/s
FLOPS achieved: 22.28 TF/s

Prefill latency: 0.4244005021173507 sec
Decode latency: 9.595260930946097 sec
Time for inference 10: 10.02 sec total, 204.35 tokens/sec
Decode latency: 9.60 sec
Prefill latency: 0.42 sec
Bandwidth achieved: 7423.88 GB/s
FLOPS achieved: 22.27 TF/s

==========
Batch Size: 4
Prompt Length: 1024
Generated tokens: 512
Average decode latency: 9.5977 sec
Average prefill latency: 0.4243 sec
Average tokens/sec: 204.30
Memory used: 43.76 GB
Done. we are killing the process
[rank0]:[W1114 16:19:00.863126920 ProcessGroupNCCL.cpp:1374] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
