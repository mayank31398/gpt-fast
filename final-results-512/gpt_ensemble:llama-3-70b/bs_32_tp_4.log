W1114 21:31:03.534000 2997539 site-packages/torch/distributed/run.py:793] 
W1114 21:31:03.534000 2997539 site-packages/torch/distributed/run.py:793] *****************************************
W1114 21:31:03.534000 2997539 site-packages/torch/distributed/run.py:793] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W1114 21:31:03.534000 2997539 site-packages/torch/distributed/run.py:793] *****************************************
flash_kv_decode is set to False
Using device=cuda
Loading model ...
/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
GPTEnsemble(
  (tok_embeddings): Embedding(128256, 8192)
  (layers): ModuleList(
    (0-79): 80 x EnsembleTransformerBlock(
      semi_compiled = False
      (attention): Attention(
        (wqkv): Linear(in_features=8192, out_features=2560, bias=False)
        (wo): Linear(in_features=2048, out_features=8192, bias=False)
      )
      (feed_forward): FeedForward(
        (w1): Linear(in_features=8192, out_features=14336, bias=False)
        (w2): Linear(in_features=7168, out_features=8192, bias=False)
      )
      (ffn_norm): RMSNorm()
      (attention_norm): RMSNorm()
    )
  )
  (norm): RMSNorm()
  (output): Linear(in_features=8192, out_features=128256, bias=False)
)
Time to load model: 1.45 seconds
Compiling prefill with dynamic=False
/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/site-packages/torch/_inductor/compile_fx.py:222: UserWarning: TensorFloat32 tensor cores for float32 matrix multiplication available but not enabled. Consider setting `torch.set_float32_matmul_precision('high')` for better performance.
  warnings.warn(
/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/site-packages/torch/_inductor/compile_fx.py:222: UserWarning: TensorFloat32 tensor cores for float32 matrix multiplication available but not enabled. Consider setting `torch.set_float32_matmul_precision('high')` for better performance.
  warnings.warn(
/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/site-packages/torch/_inductor/compile_fx.py:222: UserWarning: TensorFloat32 tensor cores for float32 matrix multiplication available but not enabled. Consider setting `torch.set_float32_matmul_precision('high')` for better performance.
  warnings.warn(
/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/site-packages/torch/_inductor/compile_fx.py:222: UserWarning: TensorFloat32 tensor cores for float32 matrix multiplication available but not enabled. Consider setting `torch.set_float32_matmul_precision('high')` for better performance.
  warnings.warn(
Prefill latency: 80.31202281801961 sec
/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
Decode latency: 83.05376724991947 sec
Compilation time: 163.81 seconds
Compilation time: 163.37 seconds
Compilation time: 163.34 seconds
Compilation time: 163.70 seconds
/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
Prefill latency: 5.084837561007589 sec
/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
Decode latency: 14.245195798110217 sec
Prefill latency: 3.334004001924768 sec
Decode latency: 14.23685949598439 sec
Prefill latency: 3.3371377210132778 sec
Decode latency: 14.238062015036121 sec
Prefill latency: 3.34054131899029 sec
Decode latency: 14.237813376821578 sec
Prefill latency: 3.3414954631589353 sec
Decode latency: 14.236899703042582 sec
Time for inference 1: 17.58 sec total, 931.92 tokens/sec
Decode latency: 14.24 sec
Prefill latency: 3.34 sec
Bandwidth achieved: 33856.15 GB/s
FLOPS achieved: 101.57 TF/s

Prefill latency: 3.3405176589731127 sec
Decode latency: 14.239644686924294 sec
Time for inference 2: 17.58 sec total, 931.83 tokens/sec
Decode latency: 14.24 sec
Prefill latency: 3.34 sec
Bandwidth achieved: 33852.89 GB/s
FLOPS achieved: 101.56 TF/s

Prefill latency: 3.33913261606358 sec
Decode latency: 14.234979707980528 sec
Time for inference 3: 17.58 sec total, 932.15 tokens/sec
Decode latency: 14.23 sec
Prefill latency: 3.34 sec
Bandwidth achieved: 33864.59 GB/s
FLOPS achieved: 101.59 TF/s

Prefill latency: 3.3216221700422466 sec
Decode latency: 14.240751676028594 sec
Time for inference 4: 17.56 sec total, 932.77 tokens/sec
Decode latency: 14.24 sec
Prefill latency: 3.32 sec
Bandwidth achieved: 33887.25 GB/s
FLOPS achieved: 101.66 TF/s

Prefill latency: 3.3334523448720574 sec
Decode latency: 14.23880474595353 sec
Time for inference 5: 17.57 sec total, 932.25 tokens/sec
Decode latency: 14.24 sec
Prefill latency: 3.33 sec
Bandwidth achieved: 33868.19 GB/s
FLOPS achieved: 101.60 TF/s

Prefill latency: 3.337716493057087 sec
Decode latency: 14.241112953051925 sec
Time for inference 6: 17.58 sec total, 931.90 tokens/sec
Decode latency: 14.24 sec
Prefill latency: 3.34 sec
Bandwidth achieved: 33855.53 GB/s
FLOPS achieved: 101.57 TF/s

Prefill latency: 3.339108827058226 sec
Decode latency: 14.236467918846756 sec
Time for inference 7: 17.58 sec total, 932.06 tokens/sec
Decode latency: 14.24 sec
Prefill latency: 3.34 sec
Bandwidth achieved: 33861.44 GB/s
FLOPS achieved: 101.58 TF/s

Prefill latency: 3.3574042320251465 sec
Decode latency: 14.243840225040913 sec
Time for inference 8: 17.60 sec total, 930.71 tokens/sec
Decode latency: 14.24 sec
Prefill latency: 3.36 sec
Bandwidth achieved: 33812.33 GB/s
FLOPS achieved: 101.44 TF/s

Prefill latency: 3.317609529942274 sec
Decode latency: 14.236514420015737 sec
Time for inference 9: 17.56 sec total, 933.21 tokens/sec
Decode latency: 14.24 sec
Prefill latency: 3.32 sec
Bandwidth achieved: 33903.17 GB/s
FLOPS achieved: 101.71 TF/s

Prefill latency: 3.3418957800604403 sec
Decode latency: 14.239692903123796 sec
Time for inference 10: 17.58 sec total, 931.75 tokens/sec
Decode latency: 14.24 sec
Prefill latency: 3.34 sec
Bandwidth achieved: 33850.09 GB/s
FLOPS achieved: 101.55 TF/s

==========
Batch Size: 32
Prompt Length: 1024
Generated tokens: 512
Average decode latency: 14.2389 sec
Average prefill latency: 3.3370 sec
Average tokens/sec: 932.06
Memory used: 63.75 GB
Done. we are killing the process
[rank0]:[W1114 21:38:07.433200900 ProcessGroupNCCL.cpp:1374] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
