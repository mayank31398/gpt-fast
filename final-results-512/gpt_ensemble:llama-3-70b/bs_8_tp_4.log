W1114 21:09:20.450000 2981758 site-packages/torch/distributed/run.py:793] 
W1114 21:09:20.450000 2981758 site-packages/torch/distributed/run.py:793] *****************************************
W1114 21:09:20.450000 2981758 site-packages/torch/distributed/run.py:793] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W1114 21:09:20.450000 2981758 site-packages/torch/distributed/run.py:793] *****************************************
flash_kv_decode is set to False
Using device=cuda
Loading model ...
GPTEnsemble(
  (tok_embeddings): Embedding(128256, 8192)
  (layers): ModuleList(
    (0-79): 80 x EnsembleTransformerBlock(
      semi_compiled = False
      (attention): Attention(
        (wqkv): Linear(in_features=8192, out_features=2560, bias=False)
        (wo): Linear(in_features=2048, out_features=8192, bias=False)
      )
      (feed_forward): FeedForward(
        (w1): Linear(in_features=8192, out_features=14336, bias=False)
        (w2): Linear(in_features=7168, out_features=8192, bias=False)
      )
      (ffn_norm): RMSNorm()
      (attention_norm): RMSNorm()
    )
  )
  (norm): RMSNorm()
  (output): Linear(in_features=8192, out_features=128256, bias=False)
)
/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
Time to load model: 1.24 seconds
/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
Compiling prefill with dynamic=False
/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/site-packages/torch/_inductor/compile_fx.py:222: UserWarning: TensorFloat32 tensor cores for float32 matrix multiplication available but not enabled. Consider setting `torch.set_float32_matmul_precision('high')` for better performance.
  warnings.warn(
/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/site-packages/torch/_inductor/compile_fx.py:222: UserWarning: TensorFloat32 tensor cores for float32 matrix multiplication available but not enabled. Consider setting `torch.set_float32_matmul_precision('high')` for better performance.
  warnings.warn(
/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/site-packages/torch/_inductor/compile_fx.py:222: UserWarning: TensorFloat32 tensor cores for float32 matrix multiplication available but not enabled. Consider setting `torch.set_float32_matmul_precision('high')` for better performance.
  warnings.warn(
/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/site-packages/torch/_inductor/compile_fx.py:222: UserWarning: TensorFloat32 tensor cores for float32 matrix multiplication available but not enabled. Consider setting `torch.set_float32_matmul_precision('high')` for better performance.
  warnings.warn(
Prefill latency: 74.64774746005423 sec
/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
Decode latency: 79.48722854396328 sec
Compilation time: 154.14 seconds
Compilation time: 154.16 seconds
Compilation time: 154.25 seconds
Compilation time: 154.25 seconds
Prefill latency: 2.447297052014619 sec
/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
Decode latency: 10.560116160893813 sec
Prefill latency: 0.8174483969341964 sec
Decode latency: 10.561706078005955 sec
Prefill latency: 0.8183169898111373 sec
Decode latency: 10.558620264055207 sec
Prefill latency: 0.8191996831446886 sec
Decode latency: 10.561015703016892 sec
Prefill latency: 0.8251856591086835 sec
Decode latency: 10.559312195982784 sec
Time for inference 1: 11.39 sec total, 359.70 tokens/sec
Decode latency: 10.56 sec
Prefill latency: 0.83 sec
Bandwidth achieved: 13067.88 GB/s
FLOPS achieved: 39.20 TF/s

Prefill latency: 0.8237121549900621 sec
Decode latency: 10.56184855895117 sec
Time for inference 2: 11.39 sec total, 359.69 tokens/sec
Decode latency: 10.56 sec
Prefill latency: 0.82 sec
Bandwidth achieved: 13067.46 GB/s
FLOPS achieved: 39.20 TF/s

Prefill latency: 0.8216112840455025 sec
Decode latency: 10.564887881977484 sec
Time for inference 3: 11.39 sec total, 359.66 tokens/sec
Decode latency: 10.56 sec
Prefill latency: 0.82 sec
Bandwidth achieved: 13066.15 GB/s
FLOPS achieved: 39.20 TF/s

Prefill latency: 0.8226042611058801 sec
Decode latency: 10.562177638988942 sec
Time for inference 4: 11.39 sec total, 359.71 tokens/sec
Decode latency: 10.56 sec
Prefill latency: 0.82 sec
Bandwidth achieved: 13068.12 GB/s
FLOPS achieved: 39.20 TF/s

Prefill latency: 0.8201890119817108 sec
Decode latency: 10.558932671090588 sec
Time for inference 5: 11.38 sec total, 359.89 tokens/sec
Decode latency: 10.56 sec
Prefill latency: 0.82 sec
Bandwidth achieved: 13074.69 GB/s
FLOPS achieved: 39.22 TF/s

Prefill latency: 0.8236636170186102 sec
Decode latency: 10.563418619800359 sec
Time for inference 6: 11.39 sec total, 359.64 tokens/sec
Decode latency: 10.56 sec
Prefill latency: 0.82 sec
Bandwidth achieved: 13065.44 GB/s
FLOPS achieved: 39.20 TF/s

Prefill latency: 0.8179230859968811 sec
Decode latency: 10.559656688943505 sec
Time for inference 7: 11.38 sec total, 359.94 tokens/sec
Decode latency: 10.56 sec
Prefill latency: 0.82 sec
Bandwidth achieved: 13076.54 GB/s
FLOPS achieved: 39.23 TF/s

Prefill latency: 0.8263040790334344 sec
Decode latency: 10.558360856026411 sec
Time for inference 8: 11.39 sec total, 359.71 tokens/sec
Decode latency: 10.56 sec
Prefill latency: 0.83 sec
Bandwidth achieved: 13068.15 GB/s
FLOPS achieved: 39.20 TF/s

Prefill latency: 0.8221957359928638 sec
Decode latency: 10.56540413107723 sec
Time for inference 9: 11.39 sec total, 359.63 tokens/sec
Decode latency: 10.57 sec
Prefill latency: 0.82 sec
Bandwidth achieved: 13065.07 GB/s
FLOPS achieved: 39.20 TF/s

Prefill latency: 0.8223552689887583 sec
Decode latency: 10.561085717985407 sec
Time for inference 10: 11.39 sec total, 359.75 tokens/sec
Decode latency: 10.56 sec
Prefill latency: 0.82 sec
Bandwidth achieved: 13069.59 GB/s
FLOPS achieved: 39.21 TF/s

==========
Batch Size: 8
Prompt Length: 1024
Generated tokens: 512
Average decode latency: 10.5615 sec
Average prefill latency: 0.8226 sec
Average tokens/sec: 359.73
Memory used: 44.89 GB
Done. we are killing the process
[rank0]:[W1114 21:14:48.066233829 ProcessGroupNCCL.cpp:1374] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
