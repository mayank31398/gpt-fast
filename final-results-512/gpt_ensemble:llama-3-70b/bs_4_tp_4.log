W1114 20:58:59.761000 2973144 site-packages/torch/distributed/run.py:793] 
W1114 20:58:59.761000 2973144 site-packages/torch/distributed/run.py:793] *****************************************
W1114 20:58:59.761000 2973144 site-packages/torch/distributed/run.py:793] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W1114 20:58:59.761000 2973144 site-packages/torch/distributed/run.py:793] *****************************************
flash_kv_decode is set to False
Using device=cuda
Loading model ...
GPTEnsemble(
  (tok_embeddings): Embedding(128256, 8192)
  (layers): ModuleList(
    (0-79): 80 x EnsembleTransformerBlock(
      semi_compiled = False
      (attention): Attention(
        (wqkv): Linear(in_features=8192, out_features=2560, bias=False)
        (wo): Linear(in_features=2048, out_features=8192, bias=False)
      )
      (feed_forward): FeedForward(
        (w1): Linear(in_features=8192, out_features=14336, bias=False)
        (w2): Linear(in_features=7168, out_features=8192, bias=False)
      )
      (ffn_norm): RMSNorm()
      (attention_norm): RMSNorm()
    )
  )
  (norm): RMSNorm()
  (output): Linear(in_features=8192, out_features=128256, bias=False)
)
/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
Time to load model: 1.17 seconds
Compiling prefill with dynamic=False
/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/site-packages/torch/_inductor/compile_fx.py:222: UserWarning: TensorFloat32 tensor cores for float32 matrix multiplication available but not enabled. Consider setting `torch.set_float32_matmul_precision('high')` for better performance.
  warnings.warn(
/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/site-packages/torch/_inductor/compile_fx.py:222: UserWarning: TensorFloat32 tensor cores for float32 matrix multiplication available but not enabled. Consider setting `torch.set_float32_matmul_precision('high')` for better performance.
  warnings.warn(
/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/site-packages/torch/_inductor/compile_fx.py:222: UserWarning: TensorFloat32 tensor cores for float32 matrix multiplication available but not enabled. Consider setting `torch.set_float32_matmul_precision('high')` for better performance.
  warnings.warn(
/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/site-packages/torch/_inductor/compile_fx.py:222: UserWarning: TensorFloat32 tensor cores for float32 matrix multiplication available but not enabled. Consider setting `torch.set_float32_matmul_precision('high')` for better performance.
  warnings.warn(
Prefill latency: 76.61550292302854 sec
/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
Decode latency: 82.11335523216985 sec
Compilation time: 158.64 seconds
Compilation time: 158.82 secondsCompilation time: 158.73 seconds

Compilation time: 158.71 seconds
Prefill latency: 2.161729535087943 sec
/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
Decode latency: 9.88886543083936 sec
Prefill latency: 0.42455137404613197 sec
Decode latency: 9.88632126012817 sec
Prefill latency: 0.42143634613603354 sec
Decode latency: 9.883831292157993 sec
Prefill latency: 0.4251289430540055 sec
Decode latency: 9.882018788950518 sec
Prefill latency: 0.42164376797154546 sec
Decode latency: 9.88714521494694 sec
Time for inference 1: 10.31 sec total, 198.62 tokens/sec
Decode latency: 9.89 sec
Prefill latency: 0.42 sec
Bandwidth achieved: 7215.87 GB/s
FLOPS achieved: 21.65 TF/s

Prefill latency: 0.4231082699261606 sec
Decode latency: 9.884043827885762 sec
Time for inference 2: 10.31 sec total, 198.65 tokens/sec
Decode latency: 9.88 sec
Prefill latency: 0.42 sec
Bandwidth achieved: 7216.92 GB/s
FLOPS achieved: 21.65 TF/s

Prefill latency: 0.4235874379519373 sec
Decode latency: 9.878976322012022 sec
Time for inference 3: 10.30 sec total, 198.74 tokens/sec
Decode latency: 9.88 sec
Prefill latency: 0.42 sec
Bandwidth achieved: 7220.21 GB/s
FLOPS achieved: 21.66 TF/s

Prefill latency: 0.42096001701429486 sec
Decode latency: 9.88083171308972 sec
Time for inference 4: 10.30 sec total, 198.74 tokens/sec
Decode latency: 9.88 sec
Prefill latency: 0.42 sec
Bandwidth achieved: 7220.29 GB/s
FLOPS achieved: 21.66 TF/s

Prefill latency: 0.4248123778961599 sec
Decode latency: 9.8810892670881 sec
Time for inference 5: 10.31 sec total, 198.68 tokens/sec
Decode latency: 9.88 sec
Prefill latency: 0.42 sec
Bandwidth achieved: 7217.88 GB/s
FLOPS achieved: 21.65 TF/s

Prefill latency: 0.4224686499219388 sec
Decode latency: 9.882904270198196 sec
Time for inference 6: 10.31 sec total, 198.69 tokens/sec
Decode latency: 9.88 sec
Prefill latency: 0.42 sec
Bandwidth achieved: 7218.28 GB/s
FLOPS achieved: 21.65 TF/s

Prefill latency: 0.4212950880173594 sec
Decode latency: 9.883062520995736 sec
Time for inference 7: 10.31 sec total, 198.69 tokens/sec
Decode latency: 9.88 sec
Prefill latency: 0.42 sec
Bandwidth achieved: 7218.44 GB/s
FLOPS achieved: 21.66 TF/s

Prefill latency: 0.42130997800268233 sec
Decode latency: 9.88544023502618 sec
Time for inference 8: 10.31 sec total, 198.66 tokens/sec
Decode latency: 9.89 sec
Prefill latency: 0.42 sec
Bandwidth achieved: 7217.30 GB/s
FLOPS achieved: 21.65 TF/s

Prefill latency: 0.42059090710245073 sec
Decode latency: 9.880614537978545 sec
Time for inference 9: 10.30 sec total, 198.77 tokens/sec
Decode latency: 9.88 sec
Prefill latency: 0.42 sec
Bandwidth achieved: 7221.21 GB/s
FLOPS achieved: 21.66 TF/s

Prefill latency: 0.42026066593825817 sec
Decode latency: 9.880444963928312 sec
Time for inference 10: 10.30 sec total, 198.78 tokens/sec
Decode latency: 9.88 sec
Prefill latency: 0.42 sec
Bandwidth achieved: 7221.53 GB/s
FLOPS achieved: 21.66 TF/s

==========
Batch Size: 4
Prompt Length: 1024
Generated tokens: 512
Average decode latency: 9.8825 sec
Average prefill latency: 0.4220 sec
Average tokens/sec: 198.70
Memory used: 41.90 GB
Done. we are killing the process
[rank0]:[W1114 21:04:17.143576884 ProcessGroupNCCL.cpp:1374] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
