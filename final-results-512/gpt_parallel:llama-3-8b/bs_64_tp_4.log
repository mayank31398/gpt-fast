W1114 13:58:14.933000 4122291 site-packages/torch/distributed/run.py:793] 
W1114 13:58:14.933000 4122291 site-packages/torch/distributed/run.py:793] *****************************************
W1114 13:58:14.933000 4122291 site-packages/torch/distributed/run.py:793] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W1114 13:58:14.933000 4122291 site-packages/torch/distributed/run.py:793] *****************************************
flash_kv_decode is set to False
Using device=cuda
Loading model ...
GPTParallel(
  (tok_embeddings): Embedding(128256, 4096)
  (layers): ModuleList(
    (0-31): 32 x ParallelTransformerBlock(
      semi_compiled = False
      (attention): FuseAttentionMLP(
        (wqkv1): Linear(in_features=4096, out_features=8704, bias=False)
        (wo): Linear(in_features=1024, out_features=4096, bias=False)
        (w2): Linear(in_features=3584, out_features=4096, bias=False)
      )
      (attention_norm): RMSNorm()
    )
  )
  (norm): RMSNorm()
  (output): Linear(in_features=4096, out_features=128256, bias=False)
)
Time to load model: 0.87 seconds
/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
Compiling prefill with dynamic=False
/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/site-packages/torch/_inductor/compile_fx.py:222: UserWarning: TensorFloat32 tensor cores for float32 matrix multiplication available but not enabled. Consider setting `torch.set_float32_matmul_precision('high')` for better performance.
  warnings.warn(
/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/site-packages/torch/_inductor/compile_fx.py:222: UserWarning: TensorFloat32 tensor cores for float32 matrix multiplication available but not enabled. Consider setting `torch.set_float32_matmul_precision('high')` for better performance.
  warnings.warn(
/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/site-packages/torch/_inductor/compile_fx.py:222: UserWarning: TensorFloat32 tensor cores for float32 matrix multiplication available but not enabled. Consider setting `torch.set_float32_matmul_precision('high')` for better performance.
  warnings.warn(
/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/site-packages/torch/_inductor/compile_fx.py:222: UserWarning: TensorFloat32 tensor cores for float32 matrix multiplication available but not enabled. Consider setting `torch.set_float32_matmul_precision('high')` for better performance.
  warnings.warn(
/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
Prefill latency: 53.73983566276729 sec
/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
Decode latency: 54.27080407785252 sec
Compilation time: 108.01 seconds
Compilation time: 108.05 seconds
Compilation time: 107.90 seconds
Compilation time: 108.01 seconds
/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
Prefill latency: 1.7929011727683246 sec
/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
Decode latency: 3.678119400050491 sec
Prefill latency: 0.9787857253104448 sec
Decode latency: 3.6755169411189854 sec
Prefill latency: 0.9794190381653607 sec
Decode latency: 3.678979311604053 sec
Prefill latency: 0.9793808981776237 sec
Decode latency: 3.675424428191036 sec
Prefill latency: 0.9780569700524211 sec
Decode latency: 3.6792365782894194 sec
Time for inference 1: 4.66 sec total, 7032.43 tokens/sec
Decode latency: 3.68 sec
Prefill latency: 0.98 sec
Bandwidth achieved: 31931.50 GB/s
FLOPS achieved: 95.79 TF/s

Prefill latency: 0.9795650811865926 sec
Decode latency: 3.6791622559539974 sec
Time for inference 2: 4.66 sec total, 7030.36 tokens/sec
Decode latency: 3.68 sec
Prefill latency: 0.98 sec
Bandwidth achieved: 31922.09 GB/s
FLOPS achieved: 95.77 TF/s

Prefill latency: 0.9791218116879463 sec
Decode latency: 3.676626643165946 sec
Time for inference 3: 4.66 sec total, 7034.15 tokens/sec
Decode latency: 3.68 sec
Prefill latency: 0.98 sec
Bandwidth achieved: 31939.31 GB/s
FLOPS achieved: 95.82 TF/s

Prefill latency: 0.9782995753921568 sec
Decode latency: 3.6784357903525233 sec
Time for inference 4: 4.66 sec total, 7033.62 tokens/sec
Decode latency: 3.68 sec
Prefill latency: 0.98 sec
Bandwidth achieved: 31936.91 GB/s
FLOPS achieved: 95.81 TF/s

Prefill latency: 0.978424868080765 sec
Decode latency: 3.6778966789133847 sec
Time for inference 5: 4.66 sec total, 7034.05 tokens/sec
Decode latency: 3.68 sec
Prefill latency: 0.98 sec
Bandwidth achieved: 31938.82 GB/s
FLOPS achieved: 95.82 TF/s

Prefill latency: 0.9790226402692497 sec
Decode latency: 3.6779866688884795 sec
Time for inference 6: 4.66 sec total, 7032.57 tokens/sec
Decode latency: 3.68 sec
Prefill latency: 0.98 sec
Bandwidth achieved: 31932.11 GB/s
FLOPS achieved: 95.80 TF/s

Prefill latency: 0.9785105986520648 sec
Decode latency: 3.676166049670428 sec
Time for inference 7: 4.66 sec total, 7036.45 tokens/sec
Decode latency: 3.68 sec
Prefill latency: 0.98 sec
Bandwidth achieved: 31949.75 GB/s
FLOPS achieved: 95.85 TF/s

Prefill latency: 0.9777755839750171 sec
Decode latency: 3.6798665770329535 sec
Time for inference 8: 4.66 sec total, 7031.77 tokens/sec
Decode latency: 3.68 sec
Prefill latency: 0.98 sec
Bandwidth achieved: 31928.48 GB/s
FLOPS achieved: 95.79 TF/s

Prefill latency: 0.9816187443211675 sec
Decode latency: 3.675650173332542 sec
Time for inference 9: 4.66 sec total, 7032.61 tokens/sec
Decode latency: 3.68 sec
Prefill latency: 0.98 sec
Bandwidth achieved: 31932.29 GB/s
FLOPS achieved: 95.80 TF/s

Prefill latency: 0.9810036406852305 sec
Decode latency: 3.6761864433065057 sec
Time for inference 10: 4.66 sec total, 7032.66 tokens/sec
Decode latency: 3.68 sec
Prefill latency: 0.98 sec
Bandwidth achieved: 31932.52 GB/s
FLOPS achieved: 95.80 TF/s

==========
Batch Size: 64
Prompt Length: 1024
Generated tokens: 512
Average decode latency: 3.6777 sec
Average prefill latency: 0.9791 sec
Average tokens/sec: 7033.07
Memory used: 43.65 GB
Done. we are killing the process
[rank0]:[W1114 14:01:19.434874637 ProcessGroupNCCL.cpp:1374] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
