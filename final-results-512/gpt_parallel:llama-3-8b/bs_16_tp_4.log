W1114 13:31:09.087000 4073873 site-packages/torch/distributed/run.py:793] 
W1114 13:31:09.087000 4073873 site-packages/torch/distributed/run.py:793] *****************************************
W1114 13:31:09.087000 4073873 site-packages/torch/distributed/run.py:793] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W1114 13:31:09.087000 4073873 site-packages/torch/distributed/run.py:793] *****************************************
flash_kv_decode is set to False
Using device=cuda
Loading model ...
GPTParallel(
  (tok_embeddings): Embedding(128256, 4096)
  (layers): ModuleList(
    (0-31): 32 x ParallelTransformerBlock(
      semi_compiled = False
      (attention): FuseAttentionMLP(
        (wqkv1): Linear(in_features=4096, out_features=8704, bias=False)
        (wo): Linear(in_features=1024, out_features=4096, bias=False)
        (w2): Linear(in_features=3584, out_features=4096, bias=False)
      )
      (attention_norm): RMSNorm()
    )
  )
  (norm): RMSNorm()
  (output): Linear(in_features=4096, out_features=128256, bias=False)
)
Time to load model: 0.83 seconds
Compiling prefill with dynamic=False
/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/site-packages/torch/_inductor/compile_fx.py:222: UserWarning: TensorFloat32 tensor cores for float32 matrix multiplication available but not enabled. Consider setting `torch.set_float32_matmul_precision('high')` for better performance.
  warnings.warn(
/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/site-packages/torch/_inductor/compile_fx.py:222: UserWarning: TensorFloat32 tensor cores for float32 matrix multiplication available but not enabled. Consider setting `torch.set_float32_matmul_precision('high')` for better performance.
  warnings.warn(
/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/site-packages/torch/_inductor/compile_fx.py:222: UserWarning: TensorFloat32 tensor cores for float32 matrix multiplication available but not enabled. Consider setting `torch.set_float32_matmul_precision('high')` for better performance.
  warnings.warn(
/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/site-packages/torch/_inductor/compile_fx.py:222: UserWarning: TensorFloat32 tensor cores for float32 matrix multiplication available but not enabled. Consider setting `torch.set_float32_matmul_precision('high')` for better performance.
  warnings.warn(
Prefill latency: 46.95697182510048 sec
/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
Decode latency: 36.77328348066658 sec
Compilation time: 83.73 seconds
Compilation time: 83.72 seconds
Compilation time: 83.53 seconds
Compilation time: 83.73 seconds
Prefill latency: 1.3384557710960507 sec
/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
Decode latency: 2.306380193680525 sec
Prefill latency: 0.24584771692752838 sec
Decode latency: 2.3044782648794353 sec
Prefill latency: 0.24503865977749228 sec
Decode latency: 2.304662938695401 sec
Prefill latency: 0.2456456432119012 sec
Decode latency: 2.302597267087549 sec
Prefill latency: 0.24682810716331005 sec
Decode latency: 2.3055811380036175 sec
Time for inference 1: 2.55 sec total, 3207.23 tokens/sec
Decode latency: 2.31 sec
Prefill latency: 0.25 sec
Bandwidth achieved: 14562.75 GB/s
FLOPS achieved: 43.69 TF/s

Prefill latency: 0.24542892910540104 sec
Decode latency: 2.303460653871298 sec
Time for inference 2: 2.55 sec total, 3211.73 tokens/sec
Decode latency: 2.30 sec
Prefill latency: 0.25 sec
Bandwidth achieved: 14583.19 GB/s
FLOPS achieved: 43.75 TF/s

Prefill latency: 0.24746609991416335 sec
Decode latency: 2.303996605798602 sec
Time for inference 3: 2.55 sec total, 3207.89 tokens/sec
Decode latency: 2.30 sec
Prefill latency: 0.25 sec
Bandwidth achieved: 14565.75 GB/s
FLOPS achieved: 43.70 TF/s

Prefill latency: 0.24439466698095202 sec
Decode latency: 2.3032022579573095 sec
Time for inference 4: 2.55 sec total, 3213.30 tokens/sec
Decode latency: 2.30 sec
Prefill latency: 0.24 sec
Bandwidth achieved: 14590.33 GB/s
FLOPS achieved: 43.77 TF/s

Prefill latency: 0.24600238958373666 sec
Decode latency: 2.304798762779683 sec
Time for inference 5: 2.55 sec total, 3209.31 tokens/sec
Decode latency: 2.30 sec
Prefill latency: 0.25 sec
Bandwidth achieved: 14572.23 GB/s
FLOPS achieved: 43.72 TF/s

Prefill latency: 0.24547222908586264 sec
Decode latency: 2.303059107158333 sec
Time for inference 6: 2.55 sec total, 3212.19 tokens/sec
Decode latency: 2.30 sec
Prefill latency: 0.25 sec
Bandwidth achieved: 14585.30 GB/s
FLOPS achieved: 43.76 TF/s

Prefill latency: 0.24597211042419076 sec
Decode latency: 2.3045570771209896 sec
Time for inference 7: 2.55 sec total, 3209.46 tokens/sec
Decode latency: 2.30 sec
Prefill latency: 0.25 sec
Bandwidth achieved: 14572.88 GB/s
FLOPS achieved: 43.72 TF/s

Prefill latency: 0.24754583230242133 sec
Decode latency: 2.3035600362345576 sec
Time for inference 8: 2.55 sec total, 3208.96 tokens/sec
Decode latency: 2.30 sec
Prefill latency: 0.25 sec
Bandwidth achieved: 14570.61 GB/s
FLOPS achieved: 43.71 TF/s

Prefill latency: 0.24542799778282642 sec
Decode latency: 2.3018043101765215 sec
Time for inference 9: 2.55 sec total, 3213.83 tokens/sec
Decode latency: 2.30 sec
Prefill latency: 0.25 sec
Bandwidth achieved: 14592.72 GB/s
FLOPS achieved: 43.78 TF/s

Prefill latency: 0.24537349678575993 sec
Decode latency: 2.303060696925968 sec
Time for inference 10: 2.55 sec total, 3212.30 tokens/sec
Decode latency: 2.30 sec
Prefill latency: 0.25 sec
Bandwidth achieved: 14585.80 GB/s
FLOPS achieved: 43.76 TF/s

==========
Batch Size: 16
Prompt Length: 1024
Generated tokens: 512
Average decode latency: 2.3037 sec
Average prefill latency: 0.2460 sec
Average tokens/sec: 3210.62
Memory used: 15.74 GB
Done. we are killing the process
[rank0]:[W1114 13:33:19.119208241 ProcessGroupNCCL.cpp:1374] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
