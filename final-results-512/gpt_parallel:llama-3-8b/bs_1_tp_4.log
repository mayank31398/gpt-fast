W1114 13:00:24.557000 4000831 site-packages/torch/distributed/run.py:793] 
W1114 13:00:24.557000 4000831 site-packages/torch/distributed/run.py:793] *****************************************
W1114 13:00:24.557000 4000831 site-packages/torch/distributed/run.py:793] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W1114 13:00:24.557000 4000831 site-packages/torch/distributed/run.py:793] *****************************************
flash_kv_decode is set to False
Using device=cuda
Loading model ...
GPTParallel(
  (tok_embeddings): Embedding(128256, 4096)
  (layers): ModuleList(
    (0-31): 32 x ParallelTransformerBlock(
      semi_compiled = False
      (attention): FuseAttentionMLP(
        (wqkv1): Linear(in_features=4096, out_features=8704, bias=False)
        (wo): Linear(in_features=1024, out_features=4096, bias=False)
        (w2): Linear(in_features=3584, out_features=4096, bias=False)
      )
      (attention_norm): RMSNorm()
    )
  )
  (norm): RMSNorm()
  (output): Linear(in_features=4096, out_features=128256, bias=False)
)
Time to load model: 0.82 seconds
Compiling prefill with dynamic=False
/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/site-packages/torch/_inductor/compile_fx.py:222: UserWarning: TensorFloat32 tensor cores for float32 matrix multiplication available but not enabled. Consider setting `torch.set_float32_matmul_precision('high')` for better performance.
  warnings.warn(
/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/site-packages/torch/_inductor/compile_fx.py:222: UserWarning: TensorFloat32 tensor cores for float32 matrix multiplication available but not enabled. Consider setting `torch.set_float32_matmul_precision('high')` for better performance.
  warnings.warn(
/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/site-packages/torch/_inductor/compile_fx.py:222: UserWarning: TensorFloat32 tensor cores for float32 matrix multiplication available but not enabled. Consider setting `torch.set_float32_matmul_precision('high')` for better performance.
  warnings.warn(
/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/site-packages/torch/_inductor/compile_fx.py:222: UserWarning: TensorFloat32 tensor cores for float32 matrix multiplication available but not enabled. Consider setting `torch.set_float32_matmul_precision('high')` for better performance.
  warnings.warn(
Prefill latency: 46.952985684387386 sec
/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
Decode latency: 47.00973586598411 sec
Compilation time: 93.96 seconds
Compilation time: 93.74 secondsCompilation time: 93.91 seconds

Compilation time: 93.81 seconds
Prefill latency: 0.6670317891985178 sec
/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
Decode latency: 1.5493857776746154 sec
Prefill latency: 0.019802992697805166 sec
Decode latency: 1.5497168847359717 sec
Prefill latency: 0.020456406753510237 sec
Decode latency: 1.549210974946618 sec
Prefill latency: 0.020864305086433887 sec
Decode latency: 1.549287705682218 sec
Prefill latency: 0.01976907206699252 sec
Decode latency: 1.5501887248829007 sec
Time for inference 1: 1.57 sec total, 325.74 tokens/sec
Decode latency: 1.55 sec
Prefill latency: 0.02 sec
Bandwidth achieved: 1479.08 GB/s
FLOPS achieved: 4.44 TF/s

Prefill latency: 0.02051121788099408 sec
Decode latency: 1.549231975339353 sec
Time for inference 2: 1.57 sec total, 325.80 tokens/sec
Decode latency: 1.55 sec
Prefill latency: 0.02 sec
Bandwidth achieved: 1479.31 GB/s
FLOPS achieved: 4.44 TF/s

Prefill latency: 0.019636238925158978 sec
Decode latency: 1.5491750435903668 sec
Time for inference 3: 1.57 sec total, 325.98 tokens/sec
Decode latency: 1.55 sec
Prefill latency: 0.02 sec
Bandwidth achieved: 1480.13 GB/s
FLOPS achieved: 4.44 TF/s

Prefill latency: 0.019643120002001524 sec
Decode latency: 1.5494474191218615 sec
Time for inference 4: 1.57 sec total, 325.93 tokens/sec
Decode latency: 1.55 sec
Prefill latency: 0.02 sec
Bandwidth achieved: 1479.92 GB/s
FLOPS achieved: 4.44 TF/s

Prefill latency: 0.019617878831923008 sec
Decode latency: 1.5492141251452267 sec
Time for inference 5: 1.57 sec total, 325.97 tokens/sec
Decode latency: 1.55 sec
Prefill latency: 0.02 sec
Bandwidth achieved: 1480.11 GB/s
FLOPS achieved: 4.44 TF/s

Prefill latency: 0.02080462407320738 sec
Decode latency: 1.5495227710343897 sec
Time for inference 6: 1.57 sec total, 325.67 tokens/sec
Decode latency: 1.55 sec
Prefill latency: 0.02 sec
Bandwidth achieved: 1478.74 GB/s
FLOPS achieved: 4.44 TF/s

Prefill latency: 0.019654229748994112 sec
Decode latency: 1.549701124895364 sec
Time for inference 7: 1.57 sec total, 325.87 tokens/sec
Decode latency: 1.55 sec
Prefill latency: 0.02 sec
Bandwidth achieved: 1479.65 GB/s
FLOPS achieved: 4.44 TF/s

Prefill latency: 0.019634900148957968 sec
Decode latency: 1.549134323373437 sec
Time for inference 8: 1.57 sec total, 325.99 tokens/sec
Decode latency: 1.55 sec
Prefill latency: 0.02 sec
Bandwidth achieved: 1480.18 GB/s
FLOPS achieved: 4.44 TF/s

Prefill latency: 0.02041176613420248 sec
Decode latency: 1.5489740101620555 sec
Time for inference 9: 1.57 sec total, 325.87 tokens/sec
Decode latency: 1.55 sec
Prefill latency: 0.02 sec
Bandwidth achieved: 1479.63 GB/s
FLOPS achieved: 4.44 TF/s

Prefill latency: 0.01969351014122367 sec
Decode latency: 1.5491175330244005 sec
Time for inference 10: 1.57 sec total, 325.98 tokens/sec
Decode latency: 1.55 sec
Prefill latency: 0.02 sec
Bandwidth achieved: 1480.15 GB/s
FLOPS achieved: 4.44 TF/s

==========
Batch Size: 1
Prompt Length: 1024
Generated tokens: 512
Average decode latency: 1.5494 sec
Average prefill latency: 0.0199 sec
Average tokens/sec: 325.88
Memory used: 6.70 GB
Done. we are killing the process
[rank0]:[W1114 13:02:31.766581070 ProcessGroupNCCL.cpp:1374] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
