W1114 13:43:18.468000 4098919 site-packages/torch/distributed/run.py:793] 
W1114 13:43:18.468000 4098919 site-packages/torch/distributed/run.py:793] *****************************************
W1114 13:43:18.468000 4098919 site-packages/torch/distributed/run.py:793] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W1114 13:43:18.468000 4098919 site-packages/torch/distributed/run.py:793] *****************************************
flash_kv_decode is set to False
Using device=cuda
Loading model ...
GPTParallel(
  (tok_embeddings): Embedding(128256, 4096)
  (layers): ModuleList(
    (0-31): 32 x ParallelTransformerBlock(
      semi_compiled = False
      (attention): FuseAttentionMLP(
        (wqkv1): Linear(in_features=4096, out_features=8704, bias=False)
        (wo): Linear(in_features=1024, out_features=4096, bias=False)
        (w2): Linear(in_features=3584, out_features=4096, bias=False)
      )
      (attention_norm): RMSNorm()
    )
  )
  (norm): RMSNorm()
  (output): Linear(in_features=4096, out_features=128256, bias=False)
)
Time to load model: 0.83 seconds
/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
Compiling prefill with dynamic=False
/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/site-packages/torch/_inductor/compile_fx.py:222: UserWarning: TensorFloat32 tensor cores for float32 matrix multiplication available but not enabled. Consider setting `torch.set_float32_matmul_precision('high')` for better performance.
  warnings.warn(
/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/site-packages/torch/_inductor/compile_fx.py:222: UserWarning: TensorFloat32 tensor cores for float32 matrix multiplication available but not enabled. Consider setting `torch.set_float32_matmul_precision('high')` for better performance.
  warnings.warn(
/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/site-packages/torch/_inductor/compile_fx.py:222: UserWarning: TensorFloat32 tensor cores for float32 matrix multiplication available but not enabled. Consider setting `torch.set_float32_matmul_precision('high')` for better performance.
  warnings.warn(
/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/site-packages/torch/_inductor/compile_fx.py:222: UserWarning: TensorFloat32 tensor cores for float32 matrix multiplication available but not enabled. Consider setting `torch.set_float32_matmul_precision('high')` for better performance.
  warnings.warn(
Prefill latency: 49.463389256969094 sec
/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
Decode latency: 51.15871664695442 sec
Compilation time: 100.41 seconds
Compilation time: 100.63 seconds
Compilation time: 100.63 seconds
Compilation time: 100.63 seconds
Prefill latency: 1.1824521920643747 sec
/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
/dccstor/mayankmish2/miniconda3/envs/ai/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
Decode latency: 2.8675791299901903 sec
Prefill latency: 0.48451876686885953 sec
Decode latency: 2.864255690947175 sec
Prefill latency: 0.4828470521606505 sec
Decode latency: 2.864325272385031 sec
Prefill latency: 0.48262814804911613 sec
Decode latency: 2.8647700822912157 sec
Prefill latency: 0.4836626900359988 sec
Decode latency: 2.8638356924057007 sec
Time for inference 1: 3.35 sec total, 4891.44 tokens/sec
Decode latency: 2.86 sec
Prefill latency: 0.48 sec
Bandwidth achieved: 22210.08 GB/s
FLOPS achieved: 66.63 TF/s

Prefill latency: 0.48413799004629254 sec
Decode latency: 2.867624420672655 sec
Time for inference 2: 3.35 sec total, 4885.31 tokens/sec
Decode latency: 2.87 sec
Prefill latency: 0.48 sec
Bandwidth achieved: 22182.24 GB/s
FLOPS achieved: 66.55 TF/s

Prefill latency: 0.4846442798152566 sec
Decode latency: 2.8654255652800202 sec
Time for inference 3: 3.35 sec total, 4887.77 tokens/sec
Decode latency: 2.87 sec
Prefill latency: 0.48 sec
Bandwidth achieved: 22193.41 GB/s
FLOPS achieved: 66.58 TF/s

Prefill latency: 0.4828355424106121 sec
Decode latency: 2.8668957352638245 sec
Time for inference 4: 3.35 sec total, 4888.05 tokens/sec
Decode latency: 2.87 sec
Prefill latency: 0.48 sec
Bandwidth achieved: 22194.68 GB/s
FLOPS achieved: 66.58 TF/s

Prefill latency: 0.4820325351320207 sec
Decode latency: 2.8662393908016384 sec
Time for inference 5: 3.35 sec total, 4890.12 tokens/sec
Decode latency: 2.87 sec
Prefill latency: 0.48 sec
Bandwidth achieved: 22204.10 GB/s
FLOPS achieved: 66.61 TF/s

Prefill latency: 0.4850846389308572 sec
Decode latency: 2.8665579492226243 sec
Time for inference 6: 3.35 sec total, 4885.18 tokens/sec
Decode latency: 2.87 sec
Prefill latency: 0.49 sec
Bandwidth achieved: 22181.65 GB/s
FLOPS achieved: 66.54 TF/s

Prefill latency: 0.48582153487950563 sec
Decode latency: 2.8654564949683845 sec
Time for inference 7: 3.35 sec total, 4885.57 tokens/sec
Decode latency: 2.87 sec
Prefill latency: 0.49 sec
Bandwidth achieved: 22183.44 GB/s
FLOPS achieved: 66.55 TF/s

Prefill latency: 0.48459350876510143 sec
Decode latency: 2.8676922428421676 sec
Time for inference 8: 3.35 sec total, 4884.53 tokens/sec
Decode latency: 2.87 sec
Prefill latency: 0.48 sec
Bandwidth achieved: 22178.74 GB/s
FLOPS achieved: 66.54 TF/s

Prefill latency: 0.48452949803322554 sec
Decode latency: 2.8648900240659714 sec
Time for inference 9: 3.35 sec total, 4888.40 tokens/sec
Decode latency: 2.86 sec
Prefill latency: 0.48 sec
Bandwidth achieved: 22196.29 GB/s
FLOPS achieved: 66.59 TF/s

Prefill latency: 0.48593213595449924 sec
Decode latency: 2.866395204793662 sec
Time for inference 10: 3.35 sec total, 4884.45 tokens/sec
Decode latency: 2.87 sec
Prefill latency: 0.49 sec
Bandwidth achieved: 22178.35 GB/s
FLOPS achieved: 66.54 TF/s

==========
Batch Size: 32
Prompt Length: 1024
Generated tokens: 512
Average decode latency: 2.8661 sec
Average prefill latency: 0.4843 sec
Average tokens/sec: 4887.08
Memory used: 25.94 GB
Done. we are killing the process
[rank0]:[W1114 13:45:56.926493433 ProcessGroupNCCL.cpp:1374] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
